# 1. `B.md`
~~~~~~markdown
# 1. `᛭MDi`
## 1.1.
Каждый отдельный (произвольный, неопределённый) документ в формате Markdown, прикреплённый мной к этому запросу, буду обозначать `᛭Di`.
## 1.2.
Имя файла `᛭Di` всегда имеет расширение `.md`.
## 1.3.
Множество всех `᛭Di` буду обозначать `᛭Ds`.

# 2. `L.md`
### 2.1.
`L.md` ∈ `᛭Ds`.
## 2.2.
`L.md` описывает полуформальный язык: `᛭L`.
## 2.3.
Большинство `᛭Di` написаны на `᛭L`.
## 2.4.
Множество всех `᛭Di`, написанных на `᛭L`, буду обозначать `᛭DLs`.
Таким образом, `᛭DLs` ⊆ `᛭Ds`. 

# 3. `O.md`
## 3.1.
`O.md` ∈ `᛭DLs`
## 3.2.
`O.md` описывает некую **онтологию** (`᛭O`)  — модель предметной области, в которой тебе предстоит решать задачу.
«An **ontology** encompasses a representation, formal naming, and definitions of the categories, properties, and relations between the concepts, data, or entities»: https://en.wikipedia.org/wiki/Ontology_(information_science)

# 4. `T.md`
## 4.1.
`T.md` ∈ `᛭DLs`
## 4.2.
`T.md` описывает задачу (`᛭T`), которую ты должен решить.

# 5. Порядок твоих действий
Действуй пошагово:
## 5.1.
Сначала внимательно и полностью прочитай `L.md`.
В точности запомни его содержание.

## 5.2.
Затем внимательно и полностью прочитай `O.md`. 
В точности запомни его содержание.

## 5.3.
Затем внимательно и полностью прочитай `T.md`. 
Выполни `᛭T`.

# 6. Требования к заголовкам в твоём ответе
## 6.1.
У твоего ответа не должно быть одного общего заголовка, потому что твой ответ будет вставлен внутрь секции 1-го уровня (`#`) другого документа Markdown.
## 6.2.
Исходя из §6.1, в качестве заголовков верхего уровня ты должен использовать заголовки 2-го уровня (`##`).
Таких заголовков должно быть несколько: тем самым ты разбиваешь свой ответ на разделы.
Если твой ответ краток, то не разбивай его на разделы вообще.
## 6.3.
Разумеется, ты также можешь использовать заголовки более нижних уровней внутри заголовков 2-го уровня: для дополнительной структуризации текста.
## 6.4.
Никогда не используй выделение жирным (`**`) в заголовках.
## 6.5.
Всегда форматируй заголовки только символами решётки (`#`), не другими способами. 

~~~~~~

# 2. `L.md`
~~~~~~markdown
# 1. `≔`
## 1.1.
- `≔` — это бинарный оператор.

## 1.2.
`A ≔ B` means that `A` **denotes** `B`.

## 1.3.
Я использую `≔` для сокращения записи.
В выражении `A ≔ B` `B` обычно — это длинный текст, а `A` — это более короткое обозначение.  

## 1.4.
~~~code
A ≔
```
B
```
~~~
равнозначно `A ≔ B` и используется, когда `B` — многострочный текст.

## 1.5.
~~~code
A ≔ ⟨ B ⟩
~~~
равнозначно `A ≔ B` и используется, когда `B` — длинный однострочный текст.

## 1.6.
### Syntax
#### Variant 1
~~~code
A ≔ ⟪ D ⟫ B
~~~
#### Variant 2
~~~code
A ≔ ⟪ D ⟫
```
B
```
~~~

### Meaning
~~~code
(`A ≔ B`) AND (`D` — это комментарий, поясняющий роль `B`)
~~~

### Example
`A` ≔ ⟪ мой ответ клиенту на его письмо `X` ⟫
```
содержание моего ответа
```

## 1.7.
### Syntax
~~~code
A ≔Ⱳ B
~~~
### Meaning
`A` обозначает понятие, которому посвящена статья Wikipedia по адресу `B`.
### Note
`A` обозначает не статью Wikipedia, а именно понятие, которое описывает эта статья.
### Example
~~~code
`A` ≔Ⱳ https://en.wikipedia.org/wiki/Upwork
~~~
Этот пример эквивалентен следующей записи:
~~~code
`A` ≔ ⟨ Upwork Inc. (an American freelancing platform) ⟩
~~~

# 2. `→`
~~~code
A → B
~~~
denotes a material conditional ⟨ https://en.wikipedia.org/wiki/Material_conditional ⟩

# 3. `⊢`
~~~code
A ⊢ B
~~~
denotes a logical consequence ⟨ https://en.wikipedia.org/wiki/Logical_consequence ⟩

# 4. `⊤`
## 4.1.
~~~code
⊤ B
~~~
means that `B` is true (is a fact).

## 4.2.
~~~code
⊤⟦Rs⟧ B
~~~
means:
```
(⊤ `B`) AND (`Rs` are the reasons why `B` is true)
```

## 4.3.
~~~code
A ≔⊤
```
B
```
~~~
means:
```code
(`A` ≔ `B`) AND (⊤ `B`).
```

## 4.4.
~~~code
A ≔⊤⟦Rs⟧
```
B
```
~~~
means:
```code
(`A` ≔ `B`) AND (⊤⟦Rs⟧ B).
```

# 5. `≔!`
## 5.1.
~~~code
A ≔! B
~~~
means:
```code
(`A` ≔⊤ `B`) AND (`B` is surprising).
```

## 5.2.
~~~code
A ≔!⟦Rs⟧ B
~~~
means:
```code
(`A` ≔⊤⟦Rs⟧ `B`) AND (`B` is surprising).
```

# 6. `?`
## 6.1.
~~~code
? B
~~~
means that `B` is a hypothesis.

## 6.2.
~~~code
?⟦Rs⟧ B
~~~
means:
```code
(? `B`) AND (`Rs` are the reasons for the hypothesis)
```

## 6.3.
~~~code
A ≔? B
~~~
means:
```code
(? `B`) AND (`A` ≔ `B`)
```

## 6.4.
~~~code
A ≔?⟦Rs⟧ B
~~~
means:
```code
(?⟦Rs⟧ `B`) AND (`A` ≔ `B`)
```

# 7.
## 7.1.
~~~code
A : S ≔ B
~~~
means:
```code
(`A` ≔ `B`) AND (`A` ∈ `S`).
```

## 7.2.
~~~code
A : S
~~~
means:
```code
`A` : `S` ≔ ⟨ an arbitrary element of `S` ⟩
```

# 8. `⠿{…}`
## 8.1. `⠿{I₁, I₂, …, Iₙ}`
`⠿{I₁, I₂, …, Iₙ}` обозначает множество, заданное точным перечислением всех его элементов: {`I₁`, `I₂`, …, `Iₙ`}.

## 8.2. `⠿{I₁-Iₙ}` 
`⠿{I₁-Iₙ}` обозначает множество, заданное интервалом (диапазоном) его значений.
Это множество, в числе прочего, включает границы указанного интервала: `I₁` и `Iₙ`.

# 9. `⠿~`
## 9.1. `⠿~ ⟨ D ⟩`
`⠿~ ⟨ D ⟩` обозначает множество, заданное неформальным (словесным) описанием его элементов (`D`).

## 9.2.
~~~code
⠿~
```
D
```	
~~~
равнозначно `⠿~ ⟨ D ⟩` и используется, когда `D` — многострочный текст.

## 9.3.
~~~code
S ≔ ⠿~ ⟨ D ⟩
```yaml
- I₁
- I₂
- …
- Iₙ
```	
~~~
означает: (`S ≔ ⠿~ ⟨ D ⟩`) AND (⠿{`I₁`, `I₂`, …, `Iₙ`} ⊆ `S`) .

# 10.
## 10.1.
`᛭DLi` : `᛭DLs`
## 10.2.
### 10.2.1.
`᛭Dc` — это обозначение `᛭DLi` самого себя.
Другими словами, если текст `᛭DLi` содержит упоминание `᛭Dс` — это значит, что `᛭Di` упоминает сам себя. 
### 10.2.2.
Например: если имя файла `᛭Di` — `sample.md`, и текст `sample.md` использует обозначение `᛭Dc`, это значит, что `᛭Dc` в данном случае обозначает документ `sample.md`.  

# 11. `§`
## 11.1.
~~~code
§P
~~~
означает ссылку на пункт `P` `᛭Dc`.
Например, §8.2.2 означает ссылку на пункт 8.2.2 `᛭Dc`.
## 11.2.
~~~code
`᛭DLi`::§P
~~~
означает ссылку на пункт `P` `᛭DLi`.
  
# 12. Local Definitions
## 12.1.
~~~code
A[§P] ≔ B
~~~
Означает:
- Для понятия `B` я **временно**, **только в рамках** §`P`, использую обозначение `A`.
- Вне §`P` это правило не применяется: в частности, если до §`P` обозначение `A` имело другой смысл, то после §`P` обозначение `A` снова будет иметь этот смысл.
- По сути, `A[§P] ≔ B` объявляет **локальную переменную** `A` с **областью действия** §`P`.
- В отличие от `A[§P] ≔ B`, `A ≔ B` объявляет **глобальную переменную** `A`.

## 12.2.
~~~code
A[§P₁, §P₂, …, §Pₙ] ≔ B
~~~
Означает, что обозначение `A` имеет значение `B` в контексте ⠿{§`P₁`, §`P₂`, …, §`Pₙ`}.
По сути, это правило аналогично §12.1, но область действия локальной переменной `A` ограничивается не одним пунктом, а множеством пунктов.

## 12.3.
~~~code
A[§P₁-§Pₙ] ≔ B
~~~
Означает, что обозначение `A` имеет значение `B` в контексте ⠿{§P₁-§Pₙ}.
По сути, это правило аналогично §12.1 и §12.2.

# 13. `≔†`
~~~code
A ≔† B
~~~
means:
```code
(`A` ≔ `B`) AND (`B` is a **problem** to me).
```

# 14. `▶`
```code
▶ A
```
означает, что в описываемой мной ситуации я использую `A`.

# 15. `ⰳ`
```code
Aⰳ(a, b, …) ≔ B
```
means:
- `A` — это функция с параметрами ⠿{`a`, `b`, …}.
- `B` — семантика `A`

# 16. `߷`
## 16.1.
```
߷⠿ ≔ ⠿~ ⟨ приложенные к этому запросу файлы ⟩
```

## 16.2.
```code
߷ⰳ(ID, Name) ≔ Desc
```
means:
```code
- `ID` : `߷⠿` ≔ `Desc`
- `Name` — имя файла
```

# 17. `≔⊥`
~~~code
A ≔⊥ (B, C)
~~~
обозначает, что я вижу противоречие между `B` и `C` и обозначаю это противоречие как `A`.
Альтернативная запись:
```code
A ≔ (B, C ⊢ ⊥)
```

# 18. `⌖`
### Syntax
#### Variant 1
```
⌖ ⟦A⟧ ❮ T ❯
```
#### Variant 2
~~~code
⌖ ⟦A⟧ 
```
T
```
~~~
### Meaning
`T` is a citation from `A`.


# 19. `ꘖ` (attributes / properties)
## 19.1. Definitions using a global symbol
### 19.1.1. 
#### Syntax
~~~code
ꘖ A ∋ B
~~~
#### Meaning
`B` is an attribute / property of `A`.

### 19.1.2.
#### Syntax
~~~code
ꘖ A ∋ B ≔ ⟪ D ⟫ 
```
V
```
~~~
#### Meaning
~~~code
(ꘖ A ∋ B) AND (B ≔ ⟪ D ⟫ V)
~~~

## 19.2. Definitions using local keys
### 19.2.1. Common rules
####
В §19.1 мы описывали an attribute / property of `A` using глобально доступный затем символ `B`.
####
В §19.2 мы описываем attributes / properties of `A` иначе: using local keys.
####
Эти local keys имеют уникальное значение только в контексте `A`.
####
Вне контекста `A` эти local keys могут иметь другие значения.
Поэтому при сссылке на эти local keys надо обязательно указывать их : `A`.
Конкретный синтаксис для указания контекста описан в §19.2.4. 

### 19.2.2.
#### Syntax
##### Variant 1
~~~code
ꘖ A ∋ ⟨ B ⟩ ≔ V
~~~
##### Variant 2
~~~code
ꘖ A ∋ ⟨ B ⟩ ≔
```
V
```
~~~

#### Meaning
~~~code
	(`B` is an attribute / property of `A`) 
AND 
	(`V` is the value of `B`) 
AND 
	(`B` is a local key, not a standalone entity)
~~~

### 19.2.3.
#### Syntax
~~~code
ꘖ A ∋
```toml
'B1' = 'V1'
'B2' = 'V2'
`B3` = 'V3'
<…>
``` 
~~~
#### Meaning
~~~code
ꘖ A ∋ ⟨ B1 ⟩ ≔ V1
ꘖ A ∋ ⟨ B2 ⟩ ≔ V2
ꘖ A ∋ ⟨ B3 ⟩ ≔ V3
<…>
~~~

### 19.2.4.
#### Syntax
~~~code
A「B」
~~~
#### Meaning
Таким способом мы ссылаемся на local key `B`, определённый ранее в качестве attribute / property of `A` посредством синтаксиса §19.2.2 или §19.2.3.  

~~~~~~

# 3. `O.md`
~~~~~~markdown
# 0.
Сегодня 2025-12-12.

# 1.
## 1.1.
`UW` ≔Ⱳ https://en.wikipedia.org/wiki/Upwork

## 1.2.
`ꆜ` ≔ ⟨ a potential client on `UW` ⟩

# 2. `P⁎`
## 2.1.
`P⁎` ≔ ⟨ a potential project of `ꆜ`, published on `UW` ⟩

## 2.2.
ꘖ `P⁎` ∋
```toml
URL = 'https://www.upwork.com/jobs/~021999029723057542100'
Title = 'Varnish Cache Expert (consultancy) - Memory Management'
Publication_Date = 2025-12-11
``` 

## 2.3. 
ꘖ `P⁎` ∋ `PD` ≔ ⟪ Description ⟫ 
~~~markdown
#
Me an my developer are looking for a Varnish Cache specialist to help us diagnose and resolve persistent memory issues in our caching layer on our website RunRepeat.com

#
Our frontend is on a Gravitron CPU 8 Cores, 32Gb RAM. 

#
Basically, Varnish repeatedly grows the memory, which leads to performance degradation - regardless of what config we've tried. 

#
We need help with VCL configuration, cache policies, proper memory allocation, TTLs, eviction strategies and guidance on monitoring and alerting best practices.

#
Our site receives about 4M monthly sessions and the complexity is that our pages are not fully static, as users can filter by gender, size, color, which is then used throughout the site. We also have ads on the site. 

#
This is a one-time-consultantion for now, but we might need more help on server-setup things in the future, and it would be amazing to have you as a point of contact.
~~~

# 4. ꘖ `ꆜ`
ꘖ `ꆜ` ∋
```toml
Location = 'Frederiksberg, Denmark'

['Характеристики компании `ꆜ`']
'Сектор экономики' = 'Sports & Recreation'
'Количество сотрудников' = '10-99'

['Характеристики учётной записи `ꆜ` на `UW`']
'Member since' = 'Jun 8, 2013'
'Hire rate (%)' = 93
'Количество опубликованных проектов (jobs posted)' = 113
'Total spent (USD)' = '540K'
'Количество оплаченных часов в почасовых проектах' = 42423
'Средняя почасовая ставка (USD)' = 12.46
```

# 5. `P⠿`
## 
`PO⠿` ~ ⟨ другие проекты `ꆜ` на `UW` ⟩

##
`P⠿` ≔ ⠿{`P⁎`} ⋃ `PO⠿`

##
`Pᵢ` : `P⠿`

## `P1⁎`
###
`P1⁎` : `PO⠿`

###
ꘖ `P1⁎` ∋
```toml
URL = 'https://www.upwork.com/jobs/~013caa0ae3e610c8bb'
Title = 'Large-scale NLP and AI copy for book reviews'
Publication_Date = '4 years ago'
``` 

### 
ꘖ `P1⁎` ∋ ⟨ Description ⟩ ≔
~~~markdown
I’m Jens, founder of RunRepeat.com. We’re a 25 people team and I have worked on this for 7 years. 

I’m now starting a new project aggregating and summarizing reviews of books. It’s a huge project that depends on two main skills: (1) heavy scraping and (2) NLP and AI copy. This post is about NLP and AI copy. I have created a separate one for the scraping part as I figured we might need a separate person for that part.

Why this job is cool:
(1) it's a huge project = stable income, and you can combine with other freelance jobs as you like
(2) I have a profitable business (RunRepeat), which means that we would not run out of money. 
(3) A lot of decision-making on your end, and zero bureaucracy. 

It’s a big project, and you will be part of defining the direction of where we’ll go. Below are the bare fundamentals on where we want to get at. I understand that some of these require different skill sets, and you might not have them all. But, if you have fundamental skills in these areas and hands-on experience with something similar, I’d love to chat with you about this and see how we could work together. The tasks below are for both scrapings, NLP and AI copy - just to give you the overview of the entire project. 

(a) Scrape Amazon and Goodreads for all book titles and store basic information about the book, author, categories etc. (Millions of books). Millions of books. Example page: https://www.amazon.com/Zero-to-One-audiobook/dp/B00M284NY2/ref=sr_1_1

(b) Find all critic reviews of that book title and consider how to match variations, e.g. some only mentioning the first part of the title, or another word for it.

(c) Do text analysis of each critic review to rate them 1-100 in how positive the critic is about the review itself. I understand that it will be hard/impossible to reach such a granular score, but maybe we’ll end up with a 1 to 4 rating scale like what this site has or similar: https://bookmarks.reviews/reviews/something-new-under-the-sun/

(d) Find the best way to make AI writeups summarizing critic opinions as well as book summary/introduction to have unique copy on our pages. 

(e) Look for all “lists” where books are mentioned. For example “best business books” or “most recommended books to read in 2021” and suggest an algorithm how we incorporate these “buying guides” into our overall scoring system. How to weigh the first book listed, the 10th etc?  

(f) Get an overview of all cases of where the book has been recommended by some person or entity. The end goal is that product pages would have sections like “Recommneded by: Elon Musk, Bill Gates” and then users can click on these tags to land on a page with all books recommended by Elon Musk. Store quotes. 

(g) Scrape all user reviews and make text analysis to extract characteristics of the books.

(h) Get all awards for each book. 

(i) Overview of all forum discussions, e.g. scraping of reddit and other sites that users can click on to read more. Provide short snippets. 

(j) Based on user and critic reviews, get to an overall score, and create our own lists for all possible categories, like “best python programming books” or “most recommended” that can then be narrowed down with filters. 

I know, it’s not something that you’ll have done by tomorrow. As a first step, let’s see if there’s a match between you, I and the project. 
~~~

# 6. `С⁎`
## 6.1.
`С⁎` ≔ ⟨ компания `ꆜ` ⟩

## 6.2. 
ꘖ `С⁎` ∋ ⟨ Description ⟩ ≔
~~~markdown
- ⌖ ⟦`P⠿`⟧ ❮ RunRepeat.com ❯
~~~

## 6.3. 
ꘖ `С⁎` ∋ ⟨ Website ⟩ ≔ https://runrepeat.com

## 6.4.
⊤ (Все `Pᵢ` касаются `С⁎`)

# 7. `P†`
## `P†`
`P†` ≔† ⟪ проблема `ꆜ` в рамках `P⁎` ⟫ ⌖ ⟦`PD`⟧
~~~markdown
Varnish repeatedly grows the memory, which leads to performance degradation - regardless of what config we've tried
~~~

# 10. Что беспокоит `ꆜ` (анализ выполнен Gemini Deep Think)
https://gemini.google.com/share/91e87ec1062c

## 1. Выявление проблем в проекте `P⁎`

На основе анализа описания задачи `PD` и онтологии `O.md`, можно выделить следующие ключевые проблемы, которые беспокоят клиента `ꆜ`:

1.  **Неконтролируемый рост потребления оперативной памяти (Memory Leak / Unbounded Growth).** Varnish постоянно увеличивает потребление RAM вплоть до исчерпания ресурсов сервера (32 ГБ), несмотря на установленные лимиты.
2.  **Деградация производительности (Performance Degradation).** Исчерпание памяти приводит к замедлению работы сайта. Вероятно, это связано с уходом системы в swap, повышением нагрузки на CPU из-за агрессивной работы сборщика мусора (LRU nuking) или фрагментацией памяти.
3.  **Неэффективность конфигурации («Config changes haven't helped»).** Клиент утверждает, что стандартные методы тюнинга не решают проблему. Это указывает на то, что корень проблемы лежит вне стандартных настроек размера кэша (`-s malloc,SIZE`).
4.  **Сложность кэширования динамического контента (High Cardinality).** Наличие фасетного поиска (фильтры по полу, размеру, цвету) и рекламных меток создает высокую вариативность запросов.
5.  **Влияние аппаратной архитектуры (Graviton CPU).** Использование процессоров ARM64 (AWS Graviton) может вносить специфику в управление памятью, если используемое ПО не оптимизировано под эту архитектуру.

## 2. Анализ обоснованности выявленных проблем

Выявленные проблемы технически обоснованы. Ситуация `RunRepeat.com` представляет собой классический анти-паттерн конфигурации Varnish для E-commerce проектов с высокой вариативностью.

### 2.1. Проблема «Взрыва кэша» (Cache Bloat / High Cardinality)
Эта проблема является **наиболее вероятной первопричиной** и полностью обоснована техническим устройством Varnish.
*   **Механизм:** Varnish по умолчанию использует полный URL (включая строку запроса `query string`) для формирования ключа объекта.
*   **Анализ:**
    *   Фильтры (`gender`, `size`, `color`) создают множество перестановок. Запросы `/shoe?size=42&color=red` и `/shoe?color=red&size=42` считаются разными объектами.
    *   Реклама на сайте («We also have ads») подразумевает наличие меток (gclid, fbclid, utm), уникальных для каждого пользователя. Это заставляет Varnish кэшировать копию страницы для каждого клика.
*   **Влияние на память:** Даже если размер *данных* ограничен параметром `-s malloc`, каждый объект потребляет около **1 КБ** оперативной памяти на **метаданные** (структуры `struct obj`, `struct objcore`), которые хранятся вне основного хранилища. При миллионах мелких объектов (из-за фильтров и рекламы) одни только метаданные могут занять десятки гигабайт RAM, вызывая переполнение памяти.

### 2.2. Проблема Transient Storage (Временное хранилище)
Эта проблема обосновывает жалобу клиента на то, что «изменения конфигов не помогают».
*   **Обоснование:** В Varnish существует отдельное хранилище `Transient` для объектов с коротким TTL и технических записей `hit-for-pass` / `hit-for-miss` (меток о том, что объект нельзя кэшировать).
*   **Анализ:**
    *   По умолчанию размер `Transient` хранилища **не ограничен** (unbounded).
    *   Если бэкенд сайта выставляет заголовок `Set-Cookie` или `Cache-Control: private` в ответ на запросы с рекламными метками, Varnish создает запись `hit-for-miss` для каждого такого запроса.
    *   Эти записи накапливаются в Transient-хранилище, потребляя память бесконтрольно, игнорируя основной лимит кэша. Это выглядит как утечка памяти, которую невозможно устранить стандартными настройками `-s`.

### 2.3. Фрагментация памяти (Memory Fragmentation)
Обоснована, учитывая архитектуру `P⁎`.
*   **Обоснование:** Varnish часто использует системный аллокатор памяти (`glibc malloc`). В сценариях с активным созданием и удалением миллионов мелких объектов (фильтры, сессии) возникает сильная фрагментация кучи.
*   **Анализ:** Операционная система может сообщать, что процесс занимает всю память (RSS), хотя полезных данных в кэше гораздо меньше. Стандартным решением является использование аллокатора **jemalloc**, который лучше справляется с фрагментацией, но он может требовать явной настройки.

### 2.4. Специфика Graviton (ARM64)
Является важным фактором обоснованности проблем с производительностью.
*   **Анализ:** Для архитектуры ARM64 критически важен размер страниц памяти. Стандартные настройки Linux (4K pages) могут создавать высокую нагрузку на TLB (Translation Lookaside Buffer) при работе с большими объемами памяти (32 ГБ) и огромным количеством объектов. Переход на 64K pages часто дает прирост производительности и стабильности, но требует поддержки со стороны ОС и сборки Varnish.

# 11. Что беспокоит `ꆜ` (анализ выполнен Gemini Deep Research) 
https://gemini.google.com/share/abbaebeb2f0d

## **1. Стратегический обзор архитектурных вызовов в условиях высокой кардинальности**

Проект RunRepeat.com (в дальнейшем именуемый "Проект P⁎"), представляющий собой масштабную платформу агрегации обзоров и электронной коммерции, столкнулся с рядом критических проблем производительности и стабильности инфраструктуры кэширования. Анализ симптоматики, предоставленной технической командой клиента, указывает на классическую, но сложную в диагностике дихотомию между "утечкой памяти" (memory leak) и "раздуванием кэша" (cache bloat). В контексте высоконагруженных систем, использующих Varnish Cache в качестве HTTP-акселератора, эти понятия часто смешиваются, приводя к ошибочным стратегиям оптимизации.

Современные архитектуры e-commerce, подобные RunRepeat, характеризуются использованием фасетной навигации — системы глубокой фильтрации контента по множеству атрибутов (размер, цвет, бренд, технические характеристики обуви).1 Это создает среду с экстремально высокой кардинальностью URL-адресов. В отсутствие строгих механизмов нормализации запросов, Varnish Cache вынужден обрабатывать комбинаторный взрыв уникальных объектов, что неизбежно приводит к исчерпанию ресурсов оперативной памяти. Однако, как показывает детальное изучение технических данных, проблема RunRepeat выходит за рамки простого управления объектами и затрагивает фундаментальные механизмы взаимодействия демона varnishd с подсистемой управления памятью операционной системы Linux.

Центральной гипотезой данного исследования является утверждение, что наблюдаемая нестабильность вызвана тремя взаимосвязанными факторами:

1. **Фрагментация кучи (Heap Fragmentation):** Неэффективность стандартного аллокатора glibc при работе с паттернами аллокации Varnish, приводящая к росту RSS (Resident Set Size) процесса без реального увеличения полезной нагрузки.3  
2. **Аномалии временного хранилища (Transient Storage):** Неконтролируемый рост "Transient" хранилища, которое по умолчанию не имеет верхнего лимита памяти и используется для короткоживущих объектов и буферизации потоковой передачи данных.5  
3. **Кэш-блоттинг (Cache Bloat):** Заполнение хранилища дубликатами контента из-за отсутствия нормализации Query String и заголовков User-Agent, что превращает полезный кэш в хранилище мусорных данных.7

В данном отчете представлен исчерпывающий анализ каждого из этих слоев, подкрепленный техническими данными и рекомендациями по переходу к устойчивой архитектуре.

## ---

**2. Глубинный анализ подсистемы управления памятью: Аллокаторы и Фрагментация**

Для понимания природы "утечек памяти", о которых сообщает клиент, необходимо рассмотреть механизм взаимодействия Varnish с системной памятью. Varnish не управляет физической памятью напрямую; вместо этого, при использовании бэкенда хранения malloc, он делегирует эту задачу стандартному системному аллокатору через вызовы malloc() и free().8

### **2.1. Механика взаимодействия Varnish и системного аллокатора**

Когда Varnish настроен с параметром -s malloc,256G, это создает иллюзию, что потребление памяти жестко ограничено 256 гигабайтами. В реальности этот лимит применяется только к *полезной нагрузке* кэшированных объектов. Он не учитывает накладные расходы на структуры данных ядра Varnish (overhead), такие как struct object, struct objcore и struct objhead, которые необходимы для отслеживания заголовков, сроков действия (TTL) и состояния объектов. Оценки показывают, что накладные расходы составляют примерно 1 КБ на каждый объект.8

Для сайта масштаба RunRepeat, где количество объектов может исчисляться десятками миллионов (из-за вариативности фильтров), накладные расходы могут составлять десятки гигабайт сверх установленного лимита -s.

| Тип памяти | Описание | Управляемость лимитом -s |
| :---- | :---- | :---- |
| **Object Storage** | Тело кэшированного объекта (HTML, JSON, изображения) | **Да** (Жесткий лимит) |
| **Object Overhead** | Метаданные (заголовки, баны, указатели) ~1KB/объект | **Нет** (Линейный рост от кол-ва объектов) |
| **Transient Storage** | Временные объекты, streaming buffers, hit-for-miss | **Нет** (По умолчанию unbounded) |
| **Workspace Memory** | Память потоков (workspace_client, thread_pool_stack) | **Нет** (Зависит от кол-ва потоков) |
| **Fragmentation** | Потерянная память внутри аллокатора ("дыры") | **Нет** (Зависит от эффективности аллокатора) |

### **2.2. Проблема фрагментации в glibc malloc**

Стандартным аллокатором в большинстве дистрибутивов Linux (RHEL, Debian, Ubuntu) является реализация malloc из библиотеки glibc (основанная на ptmalloc). Анализ источников указывает на то, что glibc крайне неэффективен для паттернов нагрузки, характерных для Varnish: высокая конкурентность, частые аллокации и деаллокации объектов различного размера.3

Проблема заключается в механизме работы с "аренами" (arenas). Для уменьшения блокировок (lock contention) в многопоточной среде, glibc создает несколько арен памяти. Когда память освобождается (free()), она возвращается в арену, но не всегда возвращается операционной системе. Если Varnish запрашивает блок памяти, который не помещается в существующие "дыры" фрагментированной кучи, аллокатор запрашивает новые страницы у ОС. Это приводит к росту виртуальной памяти (VSZ) и резидентной памяти (RSS), даже если внутренние счетчики Varnish показывают наличие свободного места в хранилище.4

Клиент интерпретирует это как утечку памяти, так как процесс varnishd потребляет все больше RAM, в то время как объем полезных данных в кэше может оставаться стабильным. Это классический пример внешней фрагментации. В особо тяжелых случаях, описанных в технических отчетах, переключение с glibc на альтернативные аллокаторы позволяло сократить потребление памяти с 192 ГБ до 18 ГБ.10

### **2.3. Превосходство jemalloc в высоконагруженных средах**

Техническим стандартом де-факто для высокопроизводительных приложений управления памятью (таких как Redis, Varnish, Firefox) является использование аллокатора jemalloc, разработанного Джейсоном Эвансом.

jemalloc использует принципиально иную стратегию управления памятью, разделяя объекты на классы по размеру (size classes) и используя структуру "chunks" и "runs". Это позволяет минимизировать фрагментацию, так как объекты одного размера группируются вместе. Освобождение блока памяти в jemalloc с гораздо большей вероятностью приводит к освобождению целого чанка, который может быть немедленно возвращен операционной системе.3

Кроме того, jemalloc предоставляет расширенные возможности интроспекции и настройки, такие как параметры "decay", управляющие скоростью возврата "грязных" страниц (dirty pages) ядру ОС. Установка агрессивных параметров decay может существенно снизить RSS процесса ценой незначительного увеличения нагрузки на CPU.12

Для RunRepeat.com критически важно верифицировать, с какой библиотекой слинкован исполняемый файл varnishd. В системах на базе RHEL/CentOS jemalloc часто не является дефолтным и требует явной установки пакета jemalloc и настройки systemd unit-файла для предзагрузки библиотеки или использования специально скомпилированной версии Varnish.14 Игнорирование этого фактора делает любые настройки VCL косметическими мерами на фоне фундаментальной утечки ресурсов.

## ---

**3. Парадокс временного хранилища (Transient Storage)**

Одной из наиболее коварных и наименее очевидных причин нестабильности Varnish является механизм Transient Storage. Анализ конфигурации и симптомов указывает на высокую вероятность того, что именно этот компонент ответственен за неконтролируемые всплески потребления памяти, приводящие к срабатыванию OOM Killer.15

### **3.1. Архитектура Transient Storage**

В архитектуре Varnish предусмотрено специальное хранилище для объектов, которые считаются "короткоживущими". По умолчанию, любой объект, чей TTL (Time To Live) меньше значения параметра shortlived (по умолчанию 10.0 секунд), автоматически помещается в Transient Storage, а не в основное хранилище (например, malloc или file).17

Критическая уязвимость конфигурации по умолчанию заключается в том, что Transient Storage использует **неограниченный** (unbounded) бэкенд malloc. Это означает, что если сайт подвергается атаке, или бэкенд начинает отдавать массовые ошибки с коротким TTL, или происходит всплеск посещаемости на страницах с отключенным кэшированием (hit-for-miss), Varnish будет аллоцировать память под эти объекты до полного исчерпания физической RAM сервера, игнорируя любые лимиты, установленные для основного хранилища.5

### **3.2. Векторы атаки через короткоживущие объекты**

Для RunRepeat.com существует несколько сценариев, при которых Transient Storage становится вектором отказа в обслуживании:

1. **Массовое создание объектов Hit-For-Miss:** Если Varnish настроен на создание hit-for-miss объектов (запоминание того, что страница не кэшируется) для запросов с уникальными параметрами, и TTL этих записей мал (например, 2 минуты, что является дефолтом для uncacheable_ttl 20), они могут попадать в Transient Storage, если параметр shortlived настроен некорректно или если логика VCL явно не переопределяет хранилище.  
2. **Буферизация потоков (Streaming Buffering):** Когда Varnish получает ответ от бэкенда, который нельзя кэшировать (например, из-за заголовка Set-Cookie), но который нужно передать медленному клиенту, данные буферизируются. Эти байты учитываются в счетчиках Transient Storage (SMA.Transient.c_bytes). При большом количестве одновременных подключений (high concurrency) объем этих буферов может достигать гигабайт.6  
3. **Синтетические ответы:** Ошибки, генерируемые внутри Varnish (vcl_backend_error), также часто попадают в Transient Storage. При сбое бэкенда лавина ошибок 503 может заполнить память.22

### **3.3. Стратегия ограничения (Bounding)**

Решение проблемы Transient Storage является императивным требованием для стабильности. Необходимо явно определить лимит для этого хранилища в параметрах запуска демона varnishd.

Синтаксис для ограничения Transient Storage:

Bash

-s malloc,20G   
-s Transient=malloc,2G

В данной конфигурации основное хранилище получает 20 ГБ, а временное жестко ограничено 2 ГБ. При достижении лимита в 2 ГБ Varnish начнет применять политику вытеснения (LRU) к временным объектам, вместо того чтобы аварийно завершать работу всего процесса.23

Также рекомендуется пересмотреть значение параметра shortlived. Установка его в 0s заставит Varnish помещать все объекты, независимо от их TTL, в основное хранилище, которое имеет строгие лимиты. Это предотвратит "скрытое" потребление памяти, хотя может усилить фрагментацию основного хранилища из-за частого удаления короткоживущих объектов.

## ---

**4. Феномен Cache Bloat в условиях фасетной навигации**

Проект RunRepeat.com обладает архитектурной особенностью, которая делает его экстремально уязвимым к раздуванию кэша (Cache Bloat) — это сложная система фильтрации товаров. Исследование структуры URL показывает наличие множественных параметров фильтрации: size, width, brand, color, drop, terrain и других.2

### **4.1. Комбинаторный взрыв URL-адресов**

Varnish кэширует объекты, используя хэш, вычисляемый (по умолчанию) на основе URL и заголовка Host. Это означает, что порядок параметров в строке запроса имеет значение.

Рассмотрим два запроса:

1. /running-shoes?brand=Nike&size=10&color=Black  
2. /running-shoes?size=10&brand=Nike&color=Black

С точки зрения логики приложения (бэкенда), эти запросы идентичны и возвращают одинаковый HTML. С точки зрения Varnish, это **два разных объекта**.

Количество возможных перестановок параметров растет факториально. Если пользователь может выбрать 5 фильтров из доступных 20, количество уникальных URL-адресов превышает количество атомов во вселенной. Поисковые боты и сканеры, перебирающие фильтры в произвольном порядке, могут генерировать миллионы уникальных запросов в сутки. Это явление называется "Cache Bloat" — заполнение кэша низкополезными дубликатами, что приводит к вытеснению (eviction) действительно востребованного контента (например, главной страницы или популярных категорий).7

Счетчик n_lru_nuked в varnishstat является главным индикатором этой проблемы. Высокие значения этого счетчика свидетельствуют о том, что Varnish вынужден агрессивно удалять объекты, чтобы освободить место для новых, зачастую бесполезных вариаций.27

### **4.2. Маркетинговые метки и "мусорные" параметры**

Помимо функциональных фильтров, e-commerce трафик насыщен маркетинговыми параметрами: utm_source, utm_medium, gclid, fbclid и уникальными идентификаторами сессий. Если эти параметры попадают в хэш кэша, каждый переход пользователя из рекламной рассылки создает уникальную копию страницы в памяти.

Для сайта с посещаемостью RunRepeat один популярный newsletter может мгновенно инвалидировать эффективность кэширования для целевых страниц, заполнив память тысячами копий одной и той же страницы, отличающихся лишь меткой utm_id.

## ---

**5. Стратегии нормализации VCL: От хаоса к порядку**

Решение проблемы Cache Bloat лежит исключительно в плоскости конфигурации VCL (Varnish Configuration Language). Необходима жесткая нормализация входящих запросов в процедуре vcl_recv **до** того, как будет вычислен хэш объекта.

### **5.1. Алгоритмическая сортировка параметров (Query String Sorting)**

Единственным надежным способом борьбы с комбинаторным взрывом перестановок является алфавитная сортировка параметров запроса. Это гарантирует, что запросы ?a=1&b=2 и ?b=2&a=1 будут преобразованы в единую каноническую форму перед поиском в кэше.

Использование модуля vmod_querystring (или функционала std в современных версиях Varnish) позволяет реализовать это одной строкой кода.

**Пример реализации (VCL):**

Code snippet

import std;  
import querystring;

sub vcl_recv {  
    # Сортировка параметров для канонизации URL  
    set req.url = std.querysort(req.url);  
      
    # Альтернативно с использованием vmod_querystring для очистки  
    set req.url = querystring.sort(req.url);  
}

Внедрение сортировки немедленно устраняет дублирование, вызванное произвольным порядком кликов пользователя или поведением ботов.29

### **5.2. Санитизация маркетинговых параметров**

Необходимо внедрить белый (whitelist) или черный (blacklist) список параметров. Для RunRepeat, учитывая сложность фильтров, черный список (удаление известного мусора) может быть более безопасным стартом, но белый список (разрешение только известных фильтров) является идеалом архитектурной чистоты.

**Рекомендуемый VCL для очистки:**

Code snippet

sub vcl_recv {  
    # Удаление стандартных меток Google Analytics и Facebook  
    if (req.url ~ "(?|&)(utm_source|utm_medium|utm_campaign|gclid|fbclid|cx|ie|cof|siteurl)=") {  
        set req.url = regsuball(req.url, "&(utm_source|utm_medium|utm_campaign|gclid|fbclid|cx|ie|cof|siteurl)=([A-z0-9_-.%25]+)", "");  
        set req.url = regsub(req.url, "(?&)", "?");  
        set req.url = regsub(req.url, "?$", "");  
    }  
}

Этот код удаляет параметры, которые нужны только клиентскому JavaScript (Google Analytics), но не влияют на генерацию HTML на бэкенде. Это позволяет отдавать один и тот же кэшированный объект пользователям, пришедшим из разных рекламных каналов.7

### **5.3. Нормализация заголовка User-Agent**

Еще одним вектором раздувания кэша является заголовок Vary: User-Agent. Если бэкенд RunRepeat выдает этот заголовок (что часто случается в PHP-фреймворках для разделения мобильной и десктопной версий), Varnish будет хранить копию страницы для *каждой* версии браузера Chrome, Safari, Firefox и т.д.

Учитывая тысячи вариаций User-Agent, это катастрофически снижает Hit Rate. Решением является нормализация User-Agent в vcl_recv до ограниченного набора бакетов: "mobile", "tablet", "desktop".

Code snippet

sub vcl_recv {  
    if (req.http.User-Agent ~ "(?i)(mobile|android|iphone)") {  
        set req.http.X-UA-Device = "mobile";  
    } else {  
        set req.http.X-UA-Device = "desktop";  
    }  
    # Опционально: перезаписать User-Agent для бэкенда или использовать X-UA-Device в vcl_hash  
}

Если сайт использует адаптивный дизайн (Responsive Design) и HTML не меняется в зависимости от устройства, заголовок Vary: User-Agent следует принудительно удалять в vcl_backend_response.30

## ---

**6. Тонкая настройка инфраструктуры и многопоточности**

Помимо управления памятью и нормализации запросов, стабильность Varnish под нагрузкой зависит от конфигурации пулов потоков (thread pools) и рабочих областей памяти (workspaces).

### **6.1. Динамика Thread Pools**

Клиент может наблюдать большое количество потоков или "дубликатов процессов". Varnish использует модель пула потоков для обработки соединений. Параметры thread_pool_min и thread_pool_max определяют границы масштабирования.

Распространенной ошибкой является установка слишком низкого значения thread_pool_min (по умолчанию 100). В условиях трафика RunRepeat резкие всплески нагрузки (micro-bursts) могут приводить к задержкам, пока Varnish спавнит новые потоки. Это явление, известное как "Thundering Herd" на уровне планировщика потоков.

**Рекомендация:** Увеличить thread_pool_min до 500-1000, чтобы держать "горячий" резерв потоков. При этом thread_pool_max не должен превышать лимиты файловых дескрипторов системы. Важно мониторить счетчик sess_dropped, который показывает количество соединений, сброшенных из-за переполнения очереди ожидания потоков.6

### **6.2. Расчет Workspace Memory**

Каждый поток Varnish имеет выделенную область памяти (workspace_client и workspace_backend) для обработки заголовков и выполнения логики VCL. Для e-commerce сайтов с большим количеством Cookie и длинными URL (из-за фильтров), дефолтный размер (обычно 64k) может быть недостаточен.

Переполнение workspace приводит к ошибкам 500/503. Увеличение workspace_client до 128k или 256k является безопасной мерой оптимизации, незначительно влияющей на общее потребление памяти, но критически важной для стабильности обработки сложных запросов.32

## ---

**7. Мониторинг, Наблюдаемость и Форензика**

Переход от реактивного устранения сбоев к проактивному управлению требует внедрения правильных метрик. Утилита varnishstat предоставляет сырые данные, которые необходимо интерпретировать в контексте бизнес-логики.

### **7.1. Матрица критических метрик**

В таблице ниже представлены ключевые счетчики, мониторинг которых обязателен для диагностики описанных проблем.

| Метрика (Counter) | Описание | Интерпретация для RunRepeat | Порог тревоги |
| :---- | :---- | :---- | :---- |
| **SMA.s0.g_bytes** | Байты в основном хранилище | Должна выходить на плато у лимита -s. Если падает резко — возможен перезапуск. | > 95% от лимита |
| **SMA.Transient.g_bytes** | Байты во временном хранилище | **Главный индикатор утечки.** Неконтролируемый рост указывает на проблему unbounded storage. | > 1-2 ГБ |
| **n_lru_nuked** | Принудительно удаленные объекты | Индикатор Cache Bloat. Высокая скорость роста означает, что полезный кэш вымывается мусорными вариациями. | Рост > 100/сек |
| **n_object** | Количество объектов | Сравнить с каталогом товаров. Если n_object >> кол-ва товаров * вариации, значит нормализация не работает. | Аномальный рост |
| **cache_hit** / **cache_miss** | Попадания/Промахи | Hit Rate = hits / (hits + misses). Низкий Hit Rate при высоком n_object подтверждает проблему дубликатов. | < 60-70% |
| **sess_dropped** | Сброшенные сессии | Нехватка потоков или перегрузка CPU. | > 0 |

21

### **7.2. Интерпретация сценариев сбоя**

* **Сценарий А: OOM Killer убивает Varnish.**  
  * Проверка: Если SMA.s0.g_bytes стабилен, а системный RAM исчерпан, виноват либо glibc (фрагментация), либо SMA.Transient (скрытый рост).  
  * Действие: Сверить графики RSS процесса и SMA.Transient.g_bytes.  
* **Сценарий Б: Низкая производительность, высокий Backend Load.**  
  * Проверка: Высокий n_lru_nuked. Varnish "молотит" память, постоянно записывая и удаляя объекты.  
  * Действие: Внедрить нормализацию Query String.

## ---

**8. Перспективы Enterprise-решений: MSE и Memory Governor**

В контексте долгосрочной стратегии развития RunRepeat.com стоит рассмотреть возможности коммерческой версии Varnish Enterprise, которая предлагает архитектурные решения описанных проблем "из коробки".

### **8.1. Massive Storage Engine (MSE)**

В отличие от malloc (память) и file (файл с mmap), движок MSE разработан для работы с большими наборами данных (dataset), превышающими объем RAM. Он использует собственную систему аллокации, которая полностью устраняет проблему фрагментации, присущую glibc. Кроме того, MSE поддерживает персистентность (сохранение кэша при перезагрузке), что критично для минимизации нагрузки на бэкенд при обслуживании ("Cache Warming").8

### **8.2. Memory Governor**

Функция Memory Governor в Varnish Enterprise динамически управляет размером кэша. Вместо жесткого лимита на *объекты*, администратор задает целевой объем памяти для *всего процесса*. Memory Governor автоматически уменьшает размер хранилища объектов, если растут накладные расходы или потребление Transient Storage, гарантируя, что процесс никогда не выйдет за пределы выделенного бюджета памяти и не будет убит OOM Killer.16

## ---

**9. Стратегический план ремедиации (Remediation Roadmap)**

На основании проведенного аудита предлагается следующий пошаговый план действий для стабилизации инфраструктуры RunRepeat.com.

### **Фаза 1: Немедленная стабилизация (Infrastructure & Config)**

1. **Замена Аллокатора:**  
   * Проверить текущий линковщик: ldd /usr/sbin/varnishd.  
   * Внедрить jemalloc. Если используется systemd, добавить в override.conf:  
     Environment="LD_PRELOAD=/usr/lib64/libjemalloc.so.2" (путь может отличаться).  
   * Это решит проблему фрагментации и снизит RSS на 15-30%.9  
2. **Ограничение Transient Storage:**  
   * Изменить параметры запуска varnishd.  
   * Было: -s malloc,24G (пример).  
   * Стало: -s malloc,20G -s Transient=malloc,2G.  
   * Это предотвратит OOM при атаках на некэшируемый контент.  
3. **Корректировка параметров потоков:**  
   * Установить thread_pool_min=500.

### **Фаза 2: Логическая оптимизация (VCL)**

1. **Нормализация запросов (Query Sort):**  
   * Внедрить модуль std или vmod_querystring.  
   * Добавить в vcl_recv: set req.url = std.querysort(req.url);.  
   * Реализовать удаление utm_* меток.  
2. **Управление Vary:**  
   * Проанализировать заголовки бэкенда.  
   * Удалить или нормализовать Vary: User-Agent.  
   * Заменить на Vary: X-UA-Device с предварительным детектированием устройства в VCL.

### **Фаза 3: Мониторинг и валидация**

1. **Настройка Dashboard:**  
   * Вывести графики SMA.Transient.g_bytes и n_lru_nuked в систему мониторинга (Grafana/Datadog).  
   * Настроить алертинг на превышение 80% заполнения Transient Storage.  
2. **Стресс-тестирование:**  
   * Провести нагрузочное тестирование с использованием рандомизированных URL (имитация ботов) для проверки эффективности нормализации и стабильности памяти при новом аллокаторе.

Реализация данного плана трансформирует Varnish Cache из источника нестабильности в надежный и предсказуемый слой акселерации, способный эффективно справляться с высокой кардинальностью данных проекта RunRepeat.

#### **Works cited**

1. RunRepeat: 1000+ shoes reviewed and cut in half, accessed December 11, 2025, [https://runrepeat.com/](https://runrepeat.com/)  
2. 100+ Running Shoe Reviews - RunRepeat, accessed December 11, 2025, [https://runrepeat.com/catalog/running-shoes](https://runrepeat.com/catalog/running-shoes)  
3. libmalloc, jemalloc, tcmalloc, mimalloc - Exploring Different Memory Allocators, accessed December 11, 2025, [https://dev.to/frosnerd/libmalloc-jemalloc-tcmalloc-mimalloc-exploring-different-memory-allocators-4lp3](https://dev.to/frosnerd/libmalloc-jemalloc-tcmalloc-mimalloc-exploring-different-memory-allocators-4lp3)  
4. Solving unbounded Java Process memory growth using JEMalloc - Medium, accessed December 11, 2025, [https://medium.com/@sohelcts/solving-unbounded-java-process-memory-growth-using-jemalloc-a43de47e5d0b](https://medium.com/@sohelcts/solving-unbounded-java-process-memory-growth-using-jemalloc-a43de47e5d0b)  
5. Storage backends - Varnish Cache - Read the Docs, accessed December 11, 2025, [https://varnish-cache.readthedocs.io/users-guide/storage-backends.html](https://varnish-cache.readthedocs.io/users-guide/storage-backends.html)  
6. Varnish memory usage keeps increasing - Stack Overflow, accessed December 11, 2025, [https://stackoverflow.com/questions/76209998/varnish-memory-usage-keeps-increasing](https://stackoverflow.com/questions/76209998/varnish-memory-usage-keeps-increasing)  
7. Example VCL template - Varnish Developer Portal, accessed December 11, 2025, [https://www.varnish-software.com/developers/tutorials/example-vcl-template/](https://www.varnish-software.com/developers/tutorials/example-vcl-template/)  
8. Understanding Varnish Cache Memory Usage - Resources, accessed December 11, 2025, [https://info.varnish-software.com/blog/understanding-varnish-cache-memory-usage](https://info.varnish-software.com/blog/understanding-varnish-cache-memory-usage)  
9. jemalloc vs glibc malloc: Memory Allocation Performance Comparison | by Binita Bharati, accessed December 11, 2025, [https://medium.com/@binitabharati/jemalloc-vs-glibc-malloc-memory-allocation-performance-comparison-fbaeda1740de](https://medium.com/@binitabharati/jemalloc-vs-glibc-malloc-memory-allocation-performance-comparison-fbaeda1740de)  
10. Picking a global allocator : r/rust - Reddit, accessed December 11, 2025, [https://www.reddit.com/r/rust/comments/1ifjzvv/picking_a_global_allocator/](https://www.reddit.com/r/rust/comments/1ifjzvv/picking_a_global_allocator/)  
11. Background · jemalloc/jemalloc Wiki - GitHub, accessed December 11, 2025, [https://github.com/jemalloc/jemalloc/wiki/Background](https://github.com/jemalloc/jemalloc/wiki/Background)  
12. How to trace the fragmentation? · Issue #2850 · jemalloc/jemalloc - GitHub, accessed December 11, 2025, [https://github.com/jemalloc/jemalloc/issues/2850](https://github.com/jemalloc/jemalloc/issues/2850)  
13. Jemalloc Memory Analysis - Apache Doris, accessed December 11, 2025, [https://doris.apache.org/docs/3.x/admin-manual/trouble-shooting/memory-management/memory-analysis/jemalloc-memory-analysis/](https://doris.apache.org/docs/3.x/admin-manual/trouble-shooting/memory-management/memory-analysis/jemalloc-memory-analysis/)  
14. 1656034 – Varnish is compiled without jemalloc. jemalloc is missing. - Red Hat Bugzilla, accessed December 11, 2025, [https://bugzilla.redhat.com/show_bug.cgi?id=1656034](https://bugzilla.redhat.com/show_bug.cgi?id=1656034)  
15. Varnish duplicate process 170 once - Unix & Linux Stack Exchange, accessed December 11, 2025, [https://unix.stackexchange.com/questions/632427/varnish-duplicate-process-170-once](https://unix.stackexchange.com/questions/632427/varnish-duplicate-process-170-once)  
16. Two-Minute Tech Tuesdays - Memory Governor - Resources - Varnish Software, accessed December 11, 2025, [https://info.varnish-software.com/blog/two-minute-tech-tuesdays-memory-governor](https://info.varnish-software.com/blog/two-minute-tech-tuesdays-memory-governor)  
17. Parameters — Varnish version 4.0.5 documentation, accessed December 11, 2025, [https://varnish-cache.org/docs/4.0/users-guide/params.html](https://varnish-cache.org/docs/4.0/users-guide/params.html)  
18. Storage backends — Varnish version trunk documentation, accessed December 11, 2025, [https://varnish-cache.org/docs/trunk/users-guide/storage-backends.html](https://varnish-cache.org/docs/trunk/users-guide/storage-backends.html)  
19. Storage backends - malloc - Varnish Cache, accessed December 11, 2025, [https://varnish-cache.org/docs/4.1/users-guide/storage-backends.html](https://varnish-cache.org/docs/4.1/users-guide/storage-backends.html)  
20. varnishd — Varnish version trunk documentation, accessed December 11, 2025, [https://varnish-cache.org/docs/trunk/reference/varnishd.html](https://varnish-cache.org/docs/trunk/reference/varnishd.html)  
21. varnish-counters — Varnish version trunk documentation, accessed December 11, 2025, [https://varnish-cache.org/docs/trunk/reference/varnish-counters.html](https://varnish-cache.org/docs/trunk/reference/varnish-counters.html)  
22. VSV00002 Data leak - '-sfile' Stevedore transient objects — Varnish HTTP Cache, accessed December 11, 2025, [https://varnish-cache.org/security/VSV00002.html](https://varnish-cache.org/security/VSV00002.html)  
23. Varnish crashes on bigger files - cache - Server Fault, accessed December 11, 2025, [https://serverfault.com/questions/1031656/varnish-crashes-on-bigger-files](https://serverfault.com/questions/1031656/varnish-crashes-on-bigger-files)  
24. Limiting memory for varnish process - caching - Stack Overflow, accessed December 11, 2025, [https://stackoverflow.com/questions/58909821/limiting-memory-for-varnish-process](https://stackoverflow.com/questions/58909821/limiting-memory-for-varnish-process)  
25. 90+ Knit Running Shoe Reviews - RunRepeat, accessed December 11, 2025, [https://runrepeat.com/catalog/knit-running-shoes](https://runrepeat.com/catalog/knit-running-shoes)  
26. Performance Boosting with Varnish Cache - maxcluster, accessed December 11, 2025, [https://maxcluster.de/en/knowledge/blog/article/performance-page-speed-boosting-varnish-cache](https://maxcluster.de/en/knowledge/blog/article/performance-page-speed-boosting-varnish-cache)  
27. Varnish monitoring - Varnish Developer Portal, accessed December 11, 2025, [https://www.varnish-software.com/developers/tutorials/varnish-monitoring/](https://www.varnish-software.com/developers/tutorials/varnish-monitoring/)  
28. Top Varnish performance metrics | Datadog, accessed December 11, 2025, [https://www.datadoghq.com/blog/top-varnish-performance-metrics/](https://www.datadoghq.com/blog/top-varnish-performance-metrics/)  
29. querystring.sort | Fastly Documentation, accessed December 11, 2025, [https://www.fastly.com/documentation/reference/vcl/functions/query-string/querystring-sort/](https://www.fastly.com/documentation/reference/vcl/functions/query-string/querystring-sort/)  
30. Vary — Varnish version 3.0.7 documentation, accessed December 11, 2025, [https://varnish-cache.org/docs/3.0/tutorial/vary.html](https://varnish-cache.org/docs/3.0/tutorial/vary.html)  
31. 5 Don'ts When Caching with Varnish - Resources, accessed December 11, 2025, [https://info.varnish-software.com/blog/5-varnish-donts](https://info.varnish-software.com/blog/5-varnish-donts)  
32. Varnish Using Significantly More Memory than Cache? - Stack Overflow, accessed December 11, 2025, [https://stackoverflow.com/questions/78379910/varnish-using-significantly-more-memory-than-cache](https://stackoverflow.com/questions/78379910/varnish-using-significantly-more-memory-than-cache)  
33. Varnish Cache extension — Dynatrace Docs, accessed December 11, 2025, [https://docs.dynatrace.com/docs/observe/infrastructure-observability/databases/extensions/varnish-cache-1](https://docs.dynatrace.com/docs/observe/infrastructure-observability/databases/extensions/varnish-cache-1)

# 12.
## 12.1.
`D𐊑⠿` ≔ ⠿~ (Заблуждения `ꆜ` относительно `P⁎`)

## 12.2.
`D𐊑ᵢ` : `D𐊑⠿`

## 12.3.
`Pⰳ(D𐊑ᵢ)` ≔
```
Правдоподобность `D𐊑ᵢ`.
Правдоподобность заблуждения `D𐊑ᵢ` означает оценку того, насколько утверждение `D𐊑ᵢ` действительно является заблуждением `ꆜ`. 
```

# 13. Анализ `D𐊑⠿` (выполнен Gemini Deep Think)
https://gemini.google.com/share/8d6a27ba5b92

## 2.1. Идентификация `D𐊑⠿`
Основываясь на глубоком анализе описания проблемы `PD` и онтологии `O.md` (в частности, разделов §10 и §11), я выделяю следующее множество заблуждений `ꆜ` (`D𐊑⠿`), которые блокируют решение задачи `P⁎`:

*   **`D𐊑₁`**: «Наблюдаемый рост потребления памяти является программным сбоем («утечкой»), а не следствием архитектурного устройства Varnish (Overhead + Transient)».
*   **`D𐊑₂`**: «Параметр запуска `-s malloc,SIZE` устанавливает жесткий физический лимит («стену») для процесса Varnish, который тот не может превысить при штатной работе».
*   **`D𐊑₃`**: «Проблема высокой вариативности запросов (фильтры, реклама) решается настройкой политик вытеснения (cache policies/eviction strategies), а не предварительной нормализацией входящих данных».
*   **`D𐊑₄`**: «Выбор системного аллокатора памяти (стандартный `glibc` vs `jemalloc`) не является критическим фактором на архитектуре AWS Graviton (ARM64)».

## 2.2. Анализ `D𐊑⠿`

### Анализ `D𐊑₁` (Миф об утечке)
**Суть:** `ꆜ` трактует постоянный рост потребления RAM («repeatedly grows the memory») как аномалию или баг, который нужно «диагностировать», тогда как это ожидаемое поведение при текущей конфигурации.

#### 2.2.1. Доводы за `Pⰳ(D𐊑₁)`
*   **Свидетельства веры клиента:** В `PD` клиент пишет о «persistent memory issues» и «performance degradation», явно ожидая, что память должна быть стабильной.
*   **Техническое опровержение веры:** В реальности память потребляется легитимно двумя механизмами, о которых клиент не подозревает:
    1.  **Transient Storage:** Временное хранилище для объектов `hit-for-miss` (создаются при наличии cookies/рекламных меток) по умолчанию **не ограничено** (unbounded). Оно может занимать всю свободную память сервера.
    2.  **Overhead:** Метаданные (структуры `struct obj`) занимают ~1 КБ на объект. При миллионах объектов (High Cardinality) это гигабайты неучтенной памяти.

#### 2.2.2. Доводы против `Pⰳ(D𐊑₁)`
*   Теоретически возможна реальная утечка памяти в конкретной версии Varnish или VMOD, но вероятность этого исчезающе мала по сравнению с архитектурными причинами.

#### 2.3. Оценка `Pⰳ(D𐊑₁)`
**95**

---

### Анализ `D𐊑₂` (Миф о жестком лимите)
**Суть:** `ꆜ` убежден, что настройка `-s` (Storage) должна гарантировать потребление памяти в заданных пределах.

#### 2.2.1. Доводы за `Pⰳ(D𐊑₂)`
*   **Свидетельства веры клиента:** Фраза «regardless of what config we've tried» подразумевает, что они пытались менять размеры хранилища, но RSS процесса все равно уходил за пределы.
*   **Техническое опровержение веры:** Параметр `-s malloc` ограничивает только **Payload** (тело объектов). Он игнорирует фрагментацию памяти (Heap Fragmentation), память потоков (Thread Stacks) и, самое главное, накладные расходы на огромное количество мелких объектов, генерируемых фильтрами сайта.

#### 2.2.2. Доводы против `Pⰳ(D𐊑₂)`
*   Отсутствуют. Это классическое заблуждение администраторов, не знакомых с внутренним устройством аллокации памяти в Varnish.

#### 2.3. Оценка `Pⰳ(D𐊑₂)`
**98**

---

### Анализ `D𐊑₃` (Миф об Eviction vs Normalization)
**Суть:** Клиент ищет спасение в настройке правил удаления старых объектов («eviction strategies»), вместо того чтобы предотвращать создание дубликатов.

#### 2.2.1. Доводы за `Pⰳ(D𐊑₃)`
*   **Свидетельства веры клиента:** Прямой запрос в описании задачи: «We need help with... eviction strategies».
*   **Техническое опровержение веры:** Сайт `RunRepeat.com` использует фасетный поиск (цвет, размер) и рекламные метки (`gclid`, `utm`). Это создает комбинаторный взрыв URL (Cache Bloat). Varnish по умолчанию считает `/shoe?color=red` и `/shoe?gclid=123` разными объектами. Если не делать агрессивную **нормализацию** (очистку и сортировку параметров) *до* кэширования, память будет забиваться "мусором" быстрее, чем любые политики eviction смогут её освободить.

#### 2.2.2. Доводы против `Pⰳ(D𐊑₃)`
*   Возможно, клиент понимает необходимость нормализации, но включает её в широкое понятие «VCL configuration». Однако акцент на eviction выдает неверный вектор мышления.

#### 2.3. Оценка `Pⰳ(D𐊑₃)`
**90**

---

### Анализ `D𐊑₄` (Игнорирование системного уровня)
**Суть:** Клиент не осознает связь между архитектурой CPU (Graviton) и выбором аллокатора памяти.

#### 2.2.1. Доводы за `Pⰳ(D𐊑₄)`
*   **Свидетельства веры клиента:** Упоминание «Gravitron CPU» идет просто как факт конфигурации. Нет запроса на системный тюнинг (Linux tuning).
*   **Техническое опровержение веры:** Стандартный аллокатор `glibc` на Linux склонен к сильной фрагментации памяти при работе с Varnish, особенно на ARM64 (Graviton), где размер страниц памяти может отличаться (64k vs 4k). Без перехода на **jemalloc** (который эффективно борется с фрагментацией) процесс Varnish будет занимать гораздо больше памяти, чем реально использует, из-за «дыр» в куче.

#### 2.2.2. Доводы против `Pⰳ(D𐊑₄)`
*   Возможно, в их сборке OS `jemalloc` уже является дефолтным, хотя это редкость для стандартных дистрибутивов.

#### 2.3. Оценка `Pⰳ(D𐊑₄)`
**85**

## 2.4. Вердикт
Клиент `ꆜ` находится в плену **«Конфигурационной иллюзии»**. Он пытается решить проблему **архитектурного несоответствия** (High Cardinality Data vs Standard Memory Allocator) методами **прикладной настройки** (VCL Eviction Policies).

`ꆜ` ошибочно полагает, что Varnish «течет» или сломан (`D𐊑₁`), в то время как система работает технически корректно в условиях **Cache Bloat** (взрывного роста дубликатов кэша), усугубленного отсутствием лимитов на временное хранилище (`Transient`) и использованием неэффективного аллокатора (`glibc`) на архитектуре Graviton. Решение лежит не в подборе параметров кэша, а в **санитизации трафика** (нормализация URL) и **системном тюнинге** (переход на jemalloc).

# 14. Анализ `D𐊑⠿` (выполнен Gemini Deep Research)
https://gemini.google.com/share/614be88df46e

**1. Анализ заблуждения D𐊑₁: Иллюзия детерминированного лимитирования памяти параметром -s malloc**

Центральным элементом в понимании проблем проекта P⁎ является интерпретация того, как Varnish управляет выделением памяти. Клиент ꆜ в описании проблемы (PD) указывает на то, что потребление памяти растет «regardless of what config we've tried». Это свидетельствует о наличии устойчивого заблуждения D𐊑₁, согласно которому параметр конфигурации -s malloc,SIZE воспринимается как жесткий, физический ограничитель (hard limit) для всего процесса демона.

### **1.1. Доводы в пользу правдоподобности заблуждения (Pⰳ(D𐊑₁))**

Анализ технической документации и архитектурных принципов Varnish Cache позволяет с высокой точностью реконструировать логику возникновения этого заблуждения и подтвердить его критическое влияние на эксплуатацию системы.

**Архитектурная дихотомия: Хранилище данных против Метаданных**

Фундаментальная ошибка заключается в непонимании того, что параметр -s в Varnish ограничивает исключительно пространство, выделяемое под *тела* кэшируемых объектов (Object Payload).1 В экосистеме Varnish память расходуется по двум основным векторам, из которых -s контролирует только первый:

1. **Storage Memory (Управляемая):** Это байты, составляющие контент (HTML, изображения, JSON), которые сервер отдает клиенту. Именно этот объем регулируется параметром -s malloc,25G.  
2. **Overhead Memory (Неуправляемая):** Это память, необходимая для поддержания структур данных, обеспечивающих функционирование кэша. Сюда входят хеш-таблицы, списки LRU (Least Recently Used), структуры объектов (struct obj), заголовки (struct objhead) и ссылки (struct objcore).2

В контексте проекта RunRepeat с его фасетной навигацией и высокой посещаемостью (4 млн сессий), количество объектов в кэше может достигать экстремальных значений. Исследования показывают, что накладные расходы (overhead) на один объект в Varnish составляют приблизительно 1 КБ.1 Это значение кажется незначительным для единичного объекта, но масштабируется линейно.

Рассмотрим математическую модель потребления памяти для P⁎:  
Предположим, что из-за вариативности URL (см. анализ D𐊑₅) в кэше находится 15 миллионов объектов.

$$text{Memory}_{text{overhead}} approx N_{text{objects}} times 1 text{ KB}$$

$$text{Memory}_{text{overhead}} approx 15,000,000 times 1024 text{ bytes} approx 14.3 text{ GB}$$  
Если клиент выделил под хранилище данных 25 ГБ (-s malloc,25G) на сервере с 32 ГБ RAM, то реальное потребление памяти процессом составит:

$$text{Total RAM} = text{Storage} (25 text{ GB}) + text{Overhead} (14.3 text{ GB}) + text{System} approx 39.3 text{ GB}$$  
Это значение превышает физически доступную память (32 ГБ), что неизбежно приводит к вмешательству механизма OOM Killer (Out-Of-Memory Killer) операционной системы, который принудительно завершает процесс varnishd.1 Клиент, наблюдая это, интерпретирует ситуацию как «утечку», не осознавая, что система ведет себя абсолютно корректно в рамках заданных (ошибочных) ограничений.

**Скрытое потребление: Рабочие области и Потоки**

Помимо метаданных объектов, значительный объем памяти расходуется на инфраструктуру обработки запросов. Varnish использует многопоточную архитектуру, где каждый запрос обрабатывается отдельным потоком (worker thread).

* **Thread Stack:** Каждый поток требует собственного стека. Параметр thread_pool_stack (по умолчанию часто 48-52 КБ) определяет этот размер.5  
* **Workspace Memory:** Для обработки HTTP-заголовков, выполнения VCL-логики и манипуляций с данными каждому потоку выделяются рабочие области: workspace_client (память для запроса клиента), workspace_backend (память для ответа бэкенда) и workspace_session.5

В конфигурации по умолчанию или при агрессивном тюнинге под высокую нагрузку (например, thread_pool_max=5000), суммарное потребление памяти потоками может быть значительным:

$$text{Memory}_{text{threads}} = N_{text{threads}} times (text{stack} + text{workspace}_{text{client}} + text{workspace}_{text{backend}})$$

$$text{Memory}_{text{threads}} approx 5000 times (48text{K} + 64text{K} + 64text{K}) approx 880 text{ MB}$$  
Хотя 1 ГБ кажется небольшим объемом по сравнению с 32 ГБ, в условиях, когда память уже исчерпана данными и метаданными, этот гигабайт становится критическим фактором нестабильности.7 Клиент ꆜ, вероятно, не учитывает эти расходы в своей калькуляции ресурсов, полагая, что -s malloc охватывает все потребности процесса.

### **1.2. Доводы против правдоподобности заблуждения (Pⰳ(D𐊑₁))**

Единственным сценарием, при котором данное утверждение не являлось бы заблуждением, было бы использование клиентом специализированных версий Varnish Enterprise с включенным механизмом **Memory Governor**.

Технология Memory Governor, являющаяся частью движка Massive Storage Engine (MSE), фундаментально меняет парадигму управления памятью. В этом режиме администратор задает не размер кэша, а целевой лимит потребления памяти для всего процесса (Memory Target). Движок автоматически масштабирует размер хранилища объектов, уменьшая его при росте накладных расходов или потребления временного хранилища, гарантируя, что процесс никогда не выйдет за пределы установленного лимита.8

Однако в описании задачи (PD) и онтологии (O.md) отсутствуют какие-либо указания на использование коммерческой лицензии Varnish Enterprise. Напротив, описание проблем («Varnish repeatedly grows...») прямо противоречит логике работы Memory Governor, который призван предотвращать именно такое поведение. Следовательно, использование стандартной Community-версии (Varnish Cache) является практически достоверным фактом, что делает заблуждение D𐊑₁ высоковероятным.

### **1.3. Вердикт и оценка правдоподобности**

**Оценка Pⰳ(D𐊑₁): 95/100.**

Анализ подтверждает, что клиент ꆜ находится в плену иллюзии полного контроля над памятью через параметр -s malloc. Это заблуждение является корневой причиной неправильной оценки необходимых ресурсов. Вместо того чтобы оставить запас памяти (Headroom) в размере 25-30% для метаданных и операционных расходов, клиент, вероятно, устанавливает лимит хранилища близко к физическому объему RAM, провоцируя нестабильность.

Рекомендация по устранению данного заблуждения заключается в пересмотре формулы расчета памяти:

$$text{Malloc Limit} = (text{Total RAM} - text{System Reserved} - text{Transient Max}) times 0.75$$

Для сервера с 32 ГБ RAM безопасным значением параметра -s malloc будет не 25G, а диапазон 16G - 18G.

## ---

**2. Анализ заблуждения D𐊑₂: Ложная идентификация утечки памяти (Memory Leak) вместо Фрагментации (Fragmentation)**

Вторым критическим заблуждением является классификация проблемы. Клиент описывает ситуацию терминами «persistent memory issues» и «grows memory», подразумевая утечку памяти (Memory Leak) — ошибку программирования, при которой выделенная память не освобождается. Однако глубокий анализ среды исполнения (AWS Graviton, Linux) указывает на совершенно иную природу феномена: **фрагментацию кучи** (Heap Fragmentation).

### **2.1. Доводы в пользу правдоподобности заблуждения (Pⰳ(D𐊑₂))**

Фрагментация памяти в контексте Varnish — это сложный процесс взаимодействия прикладного ПО и системного аллокатора, который внешне (для утилит мониторинга типа top или htop) неотличим от утечки.

**Аллокатор glibc vs jemalloc: Битва за эффективность**

Стандартным аллокатором памяти в большинстве дистрибутивов Linux (включая Amazon Linux 2023 и RHEL 9, используемых на AWS) является реализация malloc из библиотеки glibc (основанная на ptmalloc). Этот аллокатор оптимизирован для универсальных задач, но демонстрирует низкую эффективность в сценариях, характерных для Varnish:

* Высокая конкурентность (тысячи потоков).  
* Интенсивная аллокация и деаллокация мелких объектов разного размера.  
* Долгоживущий процесс.10

В многопоточной среде glibc создает множество арен (memory arenas) для снижения блокировок (lock contention). Когда память освобождается (free()) внутри Varnish, она возвращается в конкретную арену аллокатора, но далеко не всегда возвращается операционной системе. Образуются «дыры» — фрагментированные участки свободной памяти внутри процесса, которые слишком малы для размещения новых объектов, но удерживают целые страницы памяти от возврата ОС.

В результате метрика RSS (Resident Set Size) процесса растет, хотя внутренние счетчики Varnish (varnishstat) показывают наличие свободного места в хранилище (SMA.s0.g_space). Клиент видит рост потребления RAM и делает вывод об утечке, хотя технически вся память учтена, но не может быть эффективно использована.11

**Критический фактор среды AWS Graviton**

Ситуация усугубляется спецификой современных дистрибутивов Linux на архитектуре ARM64. В старых версиях Varnish или в других дистрибутивах аллокатор jemalloc часто поставлялся как зависимость или был слинкован статически. jemalloc (разработанный Джейсоном Эвансом) де-факто является стандартом для приложений типа Varnish, Redis и браузеров, так как он использует изощренные стратегии (size classes, runs, chunks) для минимизации фрагментации.5

Однако, как показывают отчеты сообщества 5, на новых платформах (RHEL 9, Amazon Linux 2023) бинарный файл varnishd часто слинкован с glibc по умолчанию. Пользователи, не знающие об этом нюансе, запускают Varnish «из коробки» и сталкиваются с двукратным (и более) ростом потребления памяти по сравнению с ожидаемым.

Источник 5 приводит прямой эмпирический опыт: «I've installed version 6.0.13... it looks like varnish is using glibc's malloc... Memory usage for a 1GB cache has gone down from ~3.7GB to ~2GB [after installing jemalloc]». Это подтверждает, что разница в потреблении памяти между glibc и jemalloc может достигать **100% от полезной нагрузки**.

### **2.2. Доводы против правдоподобности заблуждения (Pⰳ(D𐊑₂))**

Теоретически возможно, что клиент столкнулся с реальным багом в коде Varnish (software defect). Например, известная уязвимость CVE-2017-8807 14 приводила к утечке данных и памяти при некорректной обработке синтетических объектов в Transient Storage. Также существуют редкие баги, связанные с JIT-компиляцией PCRE (регулярных выражений) на специфических платформах.13

Однако вероятность столкнуться с неизвестным багом ядра Varnish (проект с более чем 15-летней историей стабильности) на порядки ниже, чем вероятность эксплуатации неоптимизированного аллокатора. Фраза клиента «regardless of what config we've tried» указывает на перебор параметров конфигурации (.vcl, -p), но не на системные изменения уровня линковки библиотек (LD_PRELOAD), что усиливает гипотезу о заблуждении.

### **2.3. Вердикт и оценка правдоподобности**

**Оценка Pⰳ(D𐊑₂): 90/100.**

Клиент ꆜ, с высокой долей вероятности, не различает истинную утечку памяти (потерю указателей на выделенные блоки) и внешнюю фрагментацию аллокатора. Отсутствие явного упоминания jemalloc в описании проблемы является сильным индикатором того, что Varnish работает на дефолтном glibc.

Рекомендация:  
Для устранения этой проблемы необходимо не «искать утечку» в VCL, а изменить среду исполнения:

1. Установить пакет jemalloc (например, dnf install jemalloc на Amazon Linux).  
2. Настроить systemd юнит для предзагрузки библиотеки:  
   Environment="LD_PRELOAD=/usr/lib64/libjemalloc.so.2"  
3. Перезапустить сервис и мониторить метрику RSS. Ожидается снижение потребления памяти на 30-50%.5

## ---

**3. Анализ заблуждения D𐊑₃: Игнорирование опасности и природы Transient Storage**

Третье заблуждение касается компонента Varnish, который часто остается «в слепой зоне» администраторов — Временного Хранилища (Transient Storage). Клиент, фокусируясь на настройках основного кэша (-s malloc), упускает из виду механизм, способный потребить всю память сервера за считанные минуты.

### **3.1. Доводы в пользу правдоподобности заблуждения (Pⰳ(D𐊑₃))**

Transient Storage предназначено для хранения короткоживущих объектов (чей TTL меньше параметра shortlived, по умолчанию 10 секунд) и объектов, созданных в результате решений о некэшируемости (hit-for-miss, hit-for-pass).16

**Архитектурная ловушка: Unbounded by Default**

Критическая особенность Transient Storage заключается в его конфигурации по умолчанию. Если администратор явно не задает параметры для Transient Storage (через -s Transient=...), Varnish автоматически создает для него хранилище на базе malloc, которое **не имеет лимита по размеру** (unbounded).5

В документации это описано так: «If no Transient storage is defined, the default is an unbound malloc storage». Это означает, что Varnish будет запрашивать у ОС память под временные объекты бесконечно, пока не исчерпает физические ресурсы, игнорируя любые ограничения, установленные для основного кэша.

**Механизм катастрофы: Hit-For-Miss шторм**

Проект RunRepeat имеет характеристики, делающие его чрезвычайно уязвимым для этой архитектурной особенности:

1. **Высокая посещаемость (4M сессий):** Огромный поток запросов.  
2. **Наличие рекламы и трекинга:** Ссылки с метками gclid, fbclid, utm_* часто обрабатываются бэкендом с установкой cookies или заголовков Cache-Control: private.  
3. **Логика Varnish:** Когда Varnish получает ответ с Set-Cookie или запретом кэширования, он создает специальный объект hit-for-miss (или hit-for-pass в старых версиях).18 Этот объект служит маркером: «не отправляй запросы на этот URL в очередь (request coalescing), а пропускай сразу на бэкенд».  
4. **Лавинообразный эффект:** Поскольку каждый запрос с уникальным gclid является уникальным URL, Varnish создает уникальную запись hit-for-miss для каждого клика по рекламе. Если TTL этих записей (по умолчанию 120 секунд) попадает под критерий shortlived или если они явно помещаются в Transient, память начинает заполняться миллионами мелких служебных объектов.

В ситуации RunRepeat, где трафик интенсивен, а нормализация URL (вероятно) отсутствует, Transient Storage может разрастись до нескольких гигабайт за минуты. Клиент видит, что основной кэш заполнен лишь частично, но память сервера исчерпана. Жалоба «config changes haven't helped» идеально укладывается в этот сценарий: клиент меняет параметры *основного* хранилища, которые никак не влияют на *временное*.

### **3.2. Доводы против правдоподобности заблуждения (Pⰳ(D𐊑₃))**

Единственным аргументом против может быть наличие в конфигурации явного ограничения (например, -s Transient=malloc,1G). Однако, если бы такое ограничение было установлено, Varnish начал бы применять LRU-вытеснение к временным объектам при достижении лимита, а не падал бы с OOM. Симптоматика «неконтролируемого роста» однозначно указывает на отсутствие лимита (unbounded nature).

### **3.3. Вердикт и оценка правдоподобности**

**Оценка Pⰳ(D𐊑₃): 95/100.**

Клиент с вероятностью, близкой к 100%, не осведомлен о существовании или принципах работы Transient Storage. Это «тихий убийца» производительности Varnish в e-commerce проектах.

Рекомендация:  
Необходимо изменить строку запуска демона varnishd, явно ограничив временное хранилище:  
-s malloc,18G -s Transient=malloc,2G  
Это создаст жесткий барьер для роста временных объектов. При достижении 2 ГБ старые временные объекты будут удаляться, освобождая место новым, но процесс Varnish останется в рамках выделенного бюджета памяти.

## ---

**4. Анализ заблуждения D𐊑₄: Игнорирование специфики управления памятью на архитектуре ARM64 (Graviton)**

Четвертое заблуждение связано с аппаратной платформой. Клиент упоминает использование «Gravitron CPU» (правильно: Graviton) как данность, но, по всей видимости, не связывает выбор архитектуры процессора с необходимостью низкоуровневого тюнинга операционной системы.

### **4.1. Доводы в пользу правдоподобности заблуждения (Pⰳ(D𐊑₄))**

Архитектура ARM64 (aarch64), на которой построены процессоры AWS Graviton, имеет существенные отличия от традиционной x86_64 в работе подсистемы управления памятью (MMU - Memory Management Unit).

**Проблема размера страниц (Page Size): 4k vs 64k**

В операционных системах Linux память управляется страницами. Стандартный размер страницы для x86_64 и большинства дефолтных ядер ARM64 составляет 4 КБ (4k pages). Для трансляции виртуальных адресов в физические процессор использует таблицу страниц (Page Table) и кэш трансляций (TLB - Translation Lookaside Buffer).20

При использовании 32 ГБ RAM и приложения типа Varnish, которое активно обращается к огромным массивам памяти в случайном порядке (random access pattern к объектам в куче), использование 4k страниц создает колоссальную нагрузку на TLB.

* Количество записей в TLB ограничено.  
* При 4k страницах 32 ГБ памяти требуют $32 times 1024^3 / 4096 approx 8,388,608$ записей в таблице страниц.  
* Это приводит к высокому уровню промахов TLB (TLB misses). При каждом промахе процессор вынужден выполнять дорогостоящую операцию «прогулки по таблице страниц» (page table walk), что увеличивает латентность доступа к памяти и нагрузку на CPU.20

**Решение: 64k Pages**

Архитектура ARM64 оптимизирована для работы со страницами размером 64 КБ. Использование ядра с поддержкой 64k pages:

1. Увеличивает охват памяти одной записью TLB в 16 раз.  
2. Радикально снижает количество промахов TLB.  
3. Уменьшает размер самой таблицы страниц, освобождая системную память.  
4. Улучшает производительность дискового ввода-вывода и DMA операций, так как снижается количество пересечений границ страниц.5

Большинство пользователей, мигрирующих с x86, просто не знают об этом нюансе. Стандартные AMI (Amazon Machine Images) часто поставляются с ядром 4k для максимальной совместимости.

### **4.2. Доводы против правдоподобности заблуждения (Pⰳ(D𐊑₄))**

Можно возразить, что Varnish способен работать и на 4k страницах. Это так, но в условиях «борьбы за каждый байт» и высокой нагрузки (4M сессий) игнорирование этой оптимизации является технической халатностью. Влияние 64k страниц на фрагментацию также может быть положительным, так как аллокации становятся более крупнулярными.

### **4.3. Вердикт и оценка правдоподобности**

**Оценка Pⰳ(D𐊑₄): 75/100.**

Клиент, вероятно, использует стандартное ядро Linux (4k pages), упуская возможность бесплатной оптимизации производительности и снижения накладных расходов системы. Хотя это не является единственной причиной «утечки», это важный фактор общей неэффективности системы.

Рекомендация:  
Проверить текущий размер страниц командой getconf PAGESIZE. Если результат 4096, рассмотреть переход на ядро с поддержкой 64k (например, установка пакета kernel-64k в Amazon Linux 2023 или использование соответствующего AMI Ubuntu arm64+largemem).22

## ---

**5. Анализ заблуждения D𐊑₅: Приоритет инфраструктурного тюнинга над нормализацией данных (Cache Bloat)**

Пятое и, возможно, самое разрушительное заблуждение касается уровня приложения. Клиент ищет решение проблемы в «memory allocation» и «server-setup», в то время как первопричиной является бизнес-логика сайта, генерирующая «мусорный» трафик.

### **5.1. Доводы в пользу правдоподобности заблуждения (Pⰳ(D𐊑₅))**

Проблема проекта RunRepeat классифицируется как **Cache Bloat** (Раздувание кэша) вследствие **High Cardinality** (Высокой кардинальности) запросов.

**Комбинаторный взрыв URL**

Сайт использует фасетную навигацию с фильтрами по полу, размеру, цвету и другим параметрам.

$$text{URL} = text{/shoes?color=red&size=42&gender=men}$$

$$text{URL} = text{/shoes?size=42&gender=men&color=red}$$  
Для Varnish эти два URL — это **два разных объекта**, требующих раздельного кэширования, хранения метаданных и памяти. Количество возможных перестановок параметров растет факториально. При наличии 10 активных фильтров количество уникальных URL может исчисляться миллиардами. Поисковые боты и сканеры часто перебирают эти фильтры в хаотичном порядке, заполняя кэш дубликатами одного и того же контента.23

**Маркетинговый шум**

Клиент упоминает наличие рекламы («We also have ads»). Это означает приход пользователей по ссылкам с метками:  
?utm_source=google&utm_campaign=summer&gclid=ABC...  
Поскольку gclid (Google Click ID) уникален для каждого клика, каждый визит пользователя создает новую копию страницы в кэше.  
Если на сайте 4 миллиона сессий в месяц, и значительная часть трафика приходит с рекламы или использует фильтры, Varnish вынужден создавать миллионы объектов. Это приводит к:

1. Исчерпанию памяти под метаданные (см. D𐊑₁).  
2. Высокой фрагментации памяти из-за постоянной записи и удаления (Eviction) объектов (см. D𐊑₂).  
3. Заполнению Transient Storage объектами hit-for-miss (см. D𐊑₃).

Клиент фокусируется на том, как *вместить* эти объекты в память (увеличивая -s malloc), вместо того чтобы *предотвратить* их создание.

### **5.2. Доводы против правдоподобности заблуждения (Pⰳ(D𐊑₅))**

В описании задачи (PD) клиент пишет: «We need help with VCL configuration». Это указывает на понимание того, что VCL играет роль. Однако контекст перечисления («cache policies, proper memory allocation...») говорит о том, что они видят VCL как инструмент настройки *кэширования*, а не *нормализации*. Если бы они понимали масштаб проблемы Cache Bloat, они бы упомянули «URL normalization» или «parameter stripping» как приоритетные задачи.

### **5.3. Вердикт и оценка правдоподобности**

**Оценка Pⰳ(D𐊑₅): 85/100.**

Клиент недооценивает тот факт, что никакое количество RAM (даже 128 ГБ) не спасет от комбинаторного взрыва URL без строгой нормализации на уровне VCL.

Рекомендация:  
Внедрить агрессивную нормализацию в процедуре vcl_recv:

1. **Сортировка параметров:** Использовать std.querysort(req.url) для приведения параметров к каноническому порядку.14  
2. **Санитизация:** Удалять все маркетинговые метки (utm_*, gclid, fbclid) из req.url перед хэшированием. Эти параметры нужны только клиентскому JavaScript (Google Analytics), бэкенду для генерации страницы они не требуются.  
3. **Нормализация User-Agent:** Приводить заголовок User-Agent к ограниченному набору значений (mobile/desktop) перед добавлением в Vary, чтобы избежать кэширования версий для каждого минорного релиза браузера.19

## ---

**6. Синтез и итоговая стратегия ремедиации**

Проведенный анализ (᛭T) показал, что критическая ситуация в проекте RunRepeat обусловлена не единичной ошибкой, а системным эффектом наложения пяти фундаментальных заблуждений. Клиент пытается решить проблему переполнения памяти («Memory Leak»), не понимая, что его конфигурация сама провоцирует это переполнение через множественные векторы (Overhead, Fragmentation, Transient, Cache Bloat).

### **Сводная таблица диагноза**

| Заблуждение (D𐊑ᵢ) | Реальная проблема | Вклад в сбой | Оценка Pⰳ |
| :---- | :---- | :---- | :---- |
| **D𐊑₁ (Hard Limit)** | Игнорирование Overhead (1KB/obj) | Критический | 95/100 |
| **D𐊑₂ (Leak vs Frag)** | Фрагментация glibc vs jemalloc | Высокий | 90/100 |
| **D𐊑₃ (Safe Transient)** | Unbounded Transient Storage | Критический | 95/100 |
| **D𐊑₄ (Arch Neutral)** | 4k pages on ARM64 | Средний | 75/100 |
| **D𐊑₅ (Infra Priority)** | Cache Bloat / High Cardinality | Высокий | 85/100 |

### **План действий для эксперта (Action Plan)**

Для успешного выполнения консалтингового проекта P⁎ необходимо реализовать следующую стратегию:

1. **Инфраструктурный слой:**  
   * Проверить текущий аллокатор: ldd /usr/sbin/varnishd.  
   * Установить и активировать **jemalloc** через systemd override (LD_PRELOAD).  
   * (Опционально) Мигрировать на ядро с поддержкой **64k pages** для AWS Graviton.  
2. **Конфигурационный слой:**  
   * Пересчитать лимиты памяти. Установить -s malloc с запасом на overhead (например, 18GB).  
   * **Жестко ограничить Transient Storage:** Добавить флаг -s Transient=malloc,2G. Это предотвратит падение сервера при атаках и всплесках некэшируемого трафика.  
   * Оптимизировать параметры потоков (thread_pool_min/max) и workspaces под реальную нагрузку.  
3. **Прикладной слой (VCL):**  
   * Написать логику нормализации Query String (сортировка + очистка мусорных параметров).  
   * Настроить нормализацию заголовка Vary: User-Agent.  
   * Реализовать защиту от создания hit-for-miss объектов для уникальных, но бесполезных запросов.

Только комплексное устранение всех пяти заблуждений позволит стабилизировать работу Varnish на проекте RunRepeat и вернуть производительность к приемлемым показателям.

#### **Works cited**

1. Why isn't varnish taking into account the malloc limit? - Stack Overflow, accessed December 11, 2025, [https://stackoverflow.com/questions/16693677/why-isnt-varnish-taking-into-account-the-malloc-limit](https://stackoverflow.com/questions/16693677/why-isnt-varnish-taking-into-account-the-malloc-limit)  
2. Understanding Varnish Cache Memory Usage - Resources, accessed December 11, 2025, [https://info.varnish-software.com/blog/understanding-varnish-cache-memory-usage](https://info.varnish-software.com/blog/understanding-varnish-cache-memory-usage)  
3. Understanding Varnish Cache Memory Usage, accessed December 11, 2025, [https://varnish-software.medium.com/understanding-varnish-cache-memory-usage-6f1cab5e20ff](https://varnish-software.medium.com/understanding-varnish-cache-memory-usage-6f1cab5e20ff)  
4. Varnish crashes on bigger files - cache - Server Fault, accessed December 11, 2025, [https://serverfault.com/questions/1031656/varnish-crashes-on-bigger-files](https://serverfault.com/questions/1031656/varnish-crashes-on-bigger-files)  
5. Varnish Using Significantly More Memory than Cache? - Stack Overflow, accessed December 11, 2025, [https://stackoverflow.com/questions/78379910/varnish-using-significantly-more-memory-than-cache](https://stackoverflow.com/questions/78379910/varnish-using-significantly-more-memory-than-cache)  
6. varnishd — Varnish version 6.5.2 documentation, accessed December 11, 2025, [https://varnish-cache.org/docs/6.5/reference/varnishd.html](https://varnish-cache.org/docs/6.5/reference/varnishd.html)  
7. Varnish duplicate process 170 once - Unix & Linux Stack Exchange, accessed December 11, 2025, [https://unix.stackexchange.com/questions/632427/varnish-duplicate-process-170-once](https://unix.stackexchange.com/questions/632427/varnish-duplicate-process-170-once)  
8. Two-Minute Tech Tuesdays - Memory Governor - Resources - Varnish Software, accessed December 11, 2025, [https://info.varnish-software.com/blog/two-minute-tech-tuesdays-memory-governor](https://info.varnish-software.com/blog/two-minute-tech-tuesdays-memory-governor)  
9. Auto-scaling memory usage to increase cache size in Varnish - Resources, accessed December 11, 2025, [https://info.varnish-software.com/blog/auto-scaling-memory-usage-to-increase-cache-size-in-varnish](https://info.varnish-software.com/blog/auto-scaling-memory-usage-to-increase-cache-size-in-varnish)  
10. Improve MySQL and MariaDB performance with memory allocators like Jemalloc and TCMalloc - Managed Server, accessed December 11, 2025, [https://www.managedserver.eu/Improve-mysql-and-mariadb-performance-with-memory-allocators-like-jemalloc-and-tcmalloc/](https://www.managedserver.eu/Improve-mysql-and-mariadb-performance-with-memory-allocators-like-jemalloc-and-tcmalloc/)  
11. jemalloc vs glibc malloc: Memory Allocation Performance Comparison | by Binita Bharati, accessed December 11, 2025, [https://medium.com/@binitabharati/jemalloc-vs-glibc-malloc-memory-allocation-performance-comparison-fbaeda1740de](https://medium.com/@binitabharati/jemalloc-vs-glibc-malloc-memory-allocation-performance-comparison-fbaeda1740de)  
12. How glibc Memory Handling Affects Java Applications: The Hidden Cost of Fragmentation | by Daniyal Hassan | Medium, accessed December 11, 2025, [https://medium.com/@daniyal.hass/how-glibc-memory-handling-affects-java-applications-the-hidden-cost-of-fragmentation-8e666ee6e000](https://medium.com/@daniyal.hass/how-glibc-memory-handling-affects-java-applications-the-hidden-cost-of-fragmentation-8e666ee6e000)  
13. 1656034 – Varnish is compiled without jemalloc. jemalloc is missing. - Red Hat Bugzilla, accessed December 11, 2025, [https://bugzilla.redhat.com/show_bug.cgi?id=1656034](https://bugzilla.redhat.com/show_bug.cgi?id=1656034)  
14. VSV00002 Data leak - '-sfile' Stevedore transient objects — Varnish HTTP Cache, accessed December 11, 2025, [https://varnish-cache.org/security/VSV00002.html](https://varnish-cache.org/security/VSV00002.html)  
15. Reducing Rails Memory Use on Amazon Linux with Jemalloc - HackerNoon, accessed December 11, 2025, [https://hackernoon.com/reducing-rails-memory-use-on-amazon-linux-with-jemalloc](https://hackernoon.com/reducing-rails-memory-use-on-amazon-linux-with-jemalloc)  
16. Storage backends — Varnish version @VERSION@ documentation, accessed December 11, 2025, [https://varnish-cache.readthedocs.io/users-guide/storage-backends.html](https://varnish-cache.readthedocs.io/users-guide/storage-backends.html)  
17. Storage backends — Varnish version 7.3.2 documentation, accessed December 11, 2025, [https://varnish-cache.org/docs/7.3/users-guide/storage-backends.html](https://varnish-cache.org/docs/7.3/users-guide/storage-backends.html)  
18. Achieving a high hitrate — Varnish version 6.1.1 documentation, accessed December 11, 2025, [https://varnish-cache.org/docs/6.1/users-guide/increasing-your-hitrate.html](https://varnish-cache.org/docs/6.1/users-guide/increasing-your-hitrate.html)  
19. 10 Varnish Cache mistakes and how to avoid them, accessed December 11, 2025, [https://varnish-software.medium.com/10-varnish-cache-mistakes-and-how-to-avoid-them-d240f452ab35](https://varnish-software.medium.com/10-varnish-cache-mistakes-and-how-to-avoid-them-d240f452ab35)  
20. Improve Performance with 64K Memory Pages on AWS Graviton ..., accessed December 11, 2025, [https://dev.to/aws-builders/improve-performance-with-64k-memory-pages-on-aws-graviton-processors-ifa](https://dev.to/aws-builders/improve-performance-with-64k-memory-pages-on-aws-graviton-processors-ifa)  
21. AWS Graviton4 demonstrates leading performance for HPC - Arm Developer, accessed December 11, 2025, [https://developer.arm.com/community/arm-community-blogs/b/servers-and-cloud-computing-blog/posts/leading-hpc-performance-with-graviton4](https://developer.arm.com/community/arm-community-blogs/b/servers-and-cloud-computing-blog/posts/leading-hpc-performance-with-graviton4)  
22. Choose between the arm64 and arm64+largemem installer options - Ubuntu documentation, accessed December 11, 2025, [https://documentation.ubuntu.com/server/how-to/installation/choosing-between-the-arm64-and-arm64-largemem-installer-options/](https://documentation.ubuntu.com/server/how-to/installation/choosing-between-the-arm64-and-arm64-largemem-installer-options/)  
23. Achieving a high hitrate — Varnish version 6.0.16 documentation, accessed December 11, 2025, [https://varnish-cache.org/docs/6.0/users-guide/increasing-your-hitrate.html](https://varnish-cache.org/docs/6.0/users-guide/increasing-your-hitrate.html)  
24. Example VCL template - Varnish Developer Portal, accessed December 11, 2025, [https://www.varnish-software.com/developers/tutorials/example-vcl-template/](https://www.varnish-software.com/developers/tutorials/example-vcl-template/)  
25. 10 Varnish Cache mistakes and how to avoid them - Resources, accessed December 11, 2025, [https://info.varnish-software.com/blog/10-varnish-cache-mistakes-and-how-avoid-them](https://info.varnish-software.com/blog/10-varnish-cache-mistakes-and-how-avoid-them)

# 15.
## 15.1.
`Cᛘ⠿` ≔ ⠿~ (Возможные причины `P†`)

## 15.2.
`Cᛘᵢ` : `Cᛘ⠿`

## 15.3.
? `Cᛘᵢ`

## 15.4.
`Pⰳ(Cᛘᵢ)` ≔ (Правдоподобность гипотезы `Cᛘᵢ`)

# 16. Анализ `Cᛘ⠿` (выполнен Gemini Deep Think)
https://gemini.google.com/share/c5d510ff758a

## Cᛘ₁: Комбинаторный взрыв кэша (Cache Bloat)

### Суть
Фундаментальной причиной сбоев является отсутствие нормализации URL-адресов в конфигурации VCL, что приводит к созданию миллионов дубликатов объектов в памяти.
В условиях фасетной навигации (фильтры по размеру, цвету) и наличия рекламных меток (`gclid`, `utm`) каждый уникальный запрос сохраняется Varnish как отдельный объект.
Это вызывает экспоненциальный рост количества записей в кэше, вытесняя полезные данные и потребляя ресурсы на хранение ключей.

### Оценка
100

### Доводы за
В описании проекта прямо указано наличие множественных фильтров («users can filter by gender, size, color») и рекламного трафика.
Без явной сортировки параметров строки запроса Varnish по умолчанию считает ссылки `?a=1&b=2` и `?b=2&a=1` разными объектами.
Высокая посещаемость сайта (4 млн сессий) гарантирует постоянный приток уникальных комбинаций URL, которые невозможно эффективно кэшировать без очистки.
Жалоба клиента на деградацию производительности коррелирует с перегрузкой структур данных, отвечающих за поиск и вытеснение объектов (LRU).

### Доводы против
Отсутствуют, так как это стандартное поведение Varnish Cache, которое гарантированно приводит к исчерпанию ресурсов без специальной настройки VCL.

## Cᛘ₂: Неограниченное временное хранилище (Unbounded Transient Storage)

### Суть
Varnish использует специальное хранилище `Transient` для короткоживущих объектов и технических записей `hit-for-miss`, создаваемых при невозможности кэширования.
По умолчанию это хранилище использует системный аллокатор `malloc` и не имеет ограничения по максимальному объему потребляемой памяти.
При наплыве трафика с уникальными метками или Cookies, которые бэкенд помечает как `private`, Varnish бесконтрольно заполняет RAM этими временными записями до полного падения сервера (OOM).

### Оценка
98

### Доводы за
Официальная документация подтверждает, что если параметр `-s Transient` не задан явно, используется «unbound malloc storage».
Симптомы, описанные клиентом («changes haven't helped»), указывают на то, что лимитирование основного хранилища не влияет на источник утечки.
Рекламный трафик генерирует массовое создание объектов `hit-for-miss` для предотвращения блокировок очередей запросов.
Этот механизм является «тихим убийцей» памяти, так как он работает параллельно с основным кэшем и часто игнорируется при настройке.

### Доводы против
Существует незначительная вероятность, что в используемом клиентом дистрибутиве (пакете) настройки по умолчанию изменены на безопасные.

## Cᛘ₃: Скрытые накладные расходы на метаданные (Metadata Overhead)

### Суть
Параметр конфигурации `-s malloc,SIZE` ограничивает только объем памяти для тела объектов, но игнорирует затраты на их метаданные.
Каждый объект в кэше требует около 1 КБ оперативной памяти для служебных структур (`struct obj`, `objcore`), хранящихся вне лимитируемой области.
Из-за проблемы `Cᛘ₁` количество объектов может достигать десятков миллионов, что приводит к потреблению десятков гигабайт памяти исключительно на метаданные.

### Оценка
95

### Доводы за
Математическая модель показывает, что 15 миллионов мелких объектов займут около 15 ГБ RAM сверх выделенного лимита хранилища.
Для сервера с 32 ГБ RAM такой неучтенный расход является критическим и неизбежно ведет к исчерпанию физической памяти.
Клиент демонстрирует непонимание этого механизма, полагая, что Varnish должен укладываться в заданные конфигом рамки.
Это объясняет «постоянный рост памяти» по мере наполнения кэша новыми уникальными ссылками.

### Доводы против
Данная проблема является вторичной и проявляется только при аномально большом количестве объектов в кэше.

## Cᛘ₄: Фрагментация памяти (Heap Fragmentation)

### Суть
Стандартный системный аллокатор `glibc`, используемый в Linux по умолчанию, неэффективен для многопоточной работы Varnish с частым выделением памяти.
Это приводит к внешней фрагментации кучи, когда операционная система считает память занятой процессом, хотя внутри она свободна, но разбита на мелкие участки.
На архитектуре AWS Graviton (ARM64) проблема фрагментации `glibc` проявляется особенно остро, вызывая рост RSS процесса.

### Оценка
90

### Доводы за
Инфраструктура клиента работает на процессорах Graviton, где выбор аллокатора критичен для производительности.
Многие стандартные образы OS не включают оптимизированный аллокатор `jemalloc` по умолчанию.
Сообщество пользователей Varnish подтверждает, что переход на `jemalloc` снижает потребление памяти на 30-50% за счет дефрагментации.
Симптомы «утечки», которую невозможно устранить настройками VCL, полностью соответствуют картине фрагментации памяти.

### Доводы против
Некоторые современные облачные образы (AMI) могут иметь предустановленный и настроенный `jemalloc`.

## Cᛘ₅: Неоптимальный размер страниц памяти (Page Size Mismatch)

### Суть
Процессоры AWS Graviton показывают значительно лучшую производительность при использовании страниц памяти размером 64 КБ (64k pages).
Стандартные ядра Linux используют страницы 4 КБ, что при больших объемах RAM увеличивает нагрузку на буфер трансляции адресов (TLB).
Это приводит к дополнительным накладным расходам и деградации производительности при произвольном доступе к памяти.

### Оценка
75

### Доводы за
Официальные рекомендации AWS для Graviton настоятельно советуют использовать 64k pages для нагрузок типа кэширования.
Использование 4k pages увеличивает размер таблиц страниц в памяти и количество промахов TLB.
Это объясняет часть проблем с производительностью, на которые жалуется клиент.

### Доводы против
Данный фактор влияет на производительность и латентность, но редко является прямой причиной аварийного завершения процесса из-за нехватки памяти.

## Вердикт

Проблема `P†` вызвана системным сочетанием критических архитектурных упущений.
Первопричиной является **Cache Bloat (`Cᛘ₁`)**, генерирующий миллионы паразитных объектов из-за отсутствия нормализации URL.
Это запускает механизмы **Metadata Overhead (`Cᛘ₃`)** и **Unbounded Transient Storage (`Cᛘ₂`)**, которые бесконтрольно потребляют оперативную память сверх установленных лимитов.
Ситуация усугубляется использованием неэффективного аллокатора **glibc (`Cᛘ₄`)**, который фрагментирует оставшиеся ресурсы.
Для решения задачи необходимо внедрить нормализацию запросов, жестко ограничить временное хранилище и переключиться на аллокатор `jemalloc`.

# 17. Анализ `Cᛘ⠿` (выполнен экземпляром №1 Gemini Deep Research)
https://gemini.google.com/share/0bd6830b26e3


## **Cᛘ1: Критический рост потребления памяти Transient-хранилища вследствие архитектурных особенностей механизма Hit-for-Miss**

### **Суть**

Архитектура Varnish Cache в своей основе опирается на модульную систему управления памятью, где различные стратегии хранения данных реализуются через интерфейсы, называемые «stevedores».  
Одним из фундаментальных, но часто недооцененных компонентов этой системы является хранилище типа Transient, которое играет роль буфера для объектов с коротким жизненным циклом.  
В контексте операционной системы Amazon Linux 2023, функционирующей на вычислительных мощностях AWS Graviton, поведение этого хранилища приобретает критическое значение для стабильности процесса varnishd.  
Согласно спецификациям 1, хранилище Transient используется по умолчанию для размещения объектов, которые движок Varnish классифицирует как не подлежащие длительному кэшированию.  
К этой категории относятся объекты, имеющие время жизни (Time To Live, TTL), меньшее, чем значение глобального параметра shortlived, который по умолчанию установлен на отметку в 10 секунд.2  
Однако наиболее коварным сценарием использования Transient является обслуживание механизма синхронизации запросов, известного как Hit-for-Miss.3  
Механизм Hit-for-Miss был внедрен в архитектуру Varnish начиная с ветки 4.0 как эволюционное развитие предыдущей концепции Hit-for-Pass, призванное устранить недостатки в обработке конкурентных запросов к одному и тому же ресурсу.3  
Основная задача этого механизма заключается в предотвращении эффекта «thundering herd» (проблемы грочущего стада), когда множество клиентов одновременно запрашивают контент, который бэкенд-сервер не может или не хочет кэшировать.  
В штатном режиме работы Varnish пытается объединить идентичные запросы (request coalescing), отправляя на бэкенд только один запрос и раздавая полученный ответ всем ожидающим клиентам.  
Если бэкенд возвращает ответ, который технически невозможно сохранить в кэше (например, ответ содержит заголовок Set-Cookie или директиву Cache-Control: private), Varnish должен принять решение о том, как обрабатывать последующие запросы к этому URL.  
В старой модели Hit-for-Pass Varnish создавал запись, которая безусловно отправляла все будущие запросы в обход кэша (pass) на определенное время, что снижало эффективность при изменении состояния бэкенда.  
Новая модель Hit-for-Miss создает в кэше специальный маркерный объект, который инструктирует Varnish обрабатывать последующие запросы как «промахи» (miss), позволяя тем самым предпринимать попытки кэширования в будущем, но отключая ожидание (coalescing) для текущего момента.3  
Критическая уязвимость данной схемы заключается в том, что этот маркерный объект Hit-for-Miss физически сохраняется в хранилище Transient.4  
Стандартная конфигурация VCL (Varnish Configuration Language), поставляемая вместе с дистрибутивом, содержит логику, которая автоматически переводит транзакцию в режим Hit-for-Miss при обнаружении заголовка Set-Cookie в ответе бэкенда.5  
Это поведение зафиксировано в процедуре vcl_backend_response и является предопределенным стандартом безопасности, предотвращающим случайное кэширование персональных сессионных данных пользователей.  
Проблема масштабируется из-за того, что время жизни (TTL) для таких объектов Hit-for-Miss по умолчанию жестко задано на уровне 120 секунд.6  
В условиях современного веб-трафика, насыщенного динамическими параметрами и трекинговыми метками, количество уникальных URL, генерирующих ответы с Set-Cookie, может исчисляться десятками тысяч в секунду.  
Каждый такой запрос инициирует создание отдельного объекта в памяти Varnish, который, несмотря на малый размер полезной нагрузки (метаданные), потребляет ресурсы оперативной памяти.  
Ситуация усугубляется тем, что хранилище Transient в Varnish реализовано через системный аллокатор памяти (обычно malloc) и, в отличие от явно конфигурируемых хранилищ (например, -s file или -s malloc,SIZE), не имеет встроенного верхнего предела потребления памяти по умолчанию.7  
Документация явно указывает, что если администратор не определил параметры Transient хранилища вручную, Varnish считает его безграничным («unbounded»).2  
Это создает опасную иллюзию контроля: администратор может ограничить основное хранилище кэша значением, например, 8 ГБ, полагая, что потребление памяти процессом не превысит 10-12 ГБ с учетом накладных расходов.  
Однако при активном создании объектов Hit-for-Miss реальное потребление памяти может линейно расти вплоть до физического предела RAM сервера, игнорируя настройки основного хранилища.8  
На архитектуре ARM64, используемой в инстансах AWS Graviton, эффективность управления памятью через стандартные аллокаторы может отличаться от x86_64, но логическая ошибка отсутствия лимита остается первичной причиной.  
Объекты Hit-for-Miss, накапливаясь в Transient хранилище, не вытесняются по алгоритму LRU (Least Recently Used) так же агрессивно, как объекты в основном хранилище, поскольку они считаются служебными и короткоживущими.  
Каждый объект в Varnish требует создания структур данных objecthead (заголовок объекта) и objectcore (ядро объекта), которые занимают около 1 КБ памяти, независимо от размера самого объекта.9  
При атаке или всплеске трафика, генерирующего 50 000 некэшируемых запросов в секунду, за двухминутное окно TTL в памяти будет создано 6 миллионов объектов.  
Простая арифметика показывает, что 6 миллионов объектов умноженные на 1 КБ накладных расходов дают 6 ГБ занятой памяти только под метаданные, не считая возможного сохранения тел ответов.  
Если бэкенд при этом отдает небольшие тела ошибок или заглушек, которые также попадают в Transient, объем потребления возрастает многократно.  
В логах varnishlog данное явление можно идентифицировать по массовому появлению тегов HitMiss и записей Storage: Transient.10  
Метрика SMA.Transient.g_bytes в утилите мониторинга varnishstat будет демонстрировать неуклонный рост, коррелирующий с количеством входящих запросов, даже если основное хранилище s0 остается полупустым.11  
Особую опасность представляет сочетание этой особенности с использованием фреймворков, которые устанавливают cookies на каждый ответ (например, PHP session start, CSRF токены), если VCL не настроен на их удаление для статики.  
Отсутствие явного лимита на Transient в строке запуска демона является распространенной ошибкой конфигурации, которая на платформе Amazon Linux 2023 проявляется особенно остро из-за высокой производительности сетевого стека, позволяющего пропускать огромный объем трафика.12  
Механизм Hit-for-Miss, задуманный как средство защиты, в данной конфигурации превращается в вектор отказа в обслуживании (DoS) через исчерпание ресурсов (Resource Exhaustion).  
Внутренние счетчики Varnish могут показывать, что система работает штатно, так как аллокации проходят успешно, пока не вмешивается OOM-killer ядра Linux.8  
Таким образом, гипотеза Cᛘ1 постулирует, что корневой причиной проблемы является архитектурное решение Varnish по использованию безлимитного хранилища для временных объектов в сочетании с агрессивной политикой создания HfM-маркеров.

### **Оценка**

95

### **Доводы за**

Документация проекта Varnish Cache недвусмысленно подтверждает, что хранилище Transient не имеет ограничений по размеру в дефолтной конфигурации, что является фундаментальным риском для любой инсталляции.2  
Многочисленные отчеты инженеров эксплуатации на платформах StackOverflow и ServerFault описывают сценарии, идентичные наблюдаемым симптомам: неконтролируемый рост потребления памяти процессом varnishd при фиксированном размере основного кэша.8  
Стандартный файл конфигурации VCL (builtin.vcl), поставляемый с пакетами Varnish, содержит логику, которая форсирует создание объектов Hit-for-Miss при наличии заголовка Set-Cookie, что делает эту проблему актуальной для большинства "коробочных" установок.5  
Значение TTL по умолчанию в 120 секунд для объектов Hit-for-Miss, зашитое в исходный код и документацию, создает достаточно широкое временное окно для накопления критической массы объектов при высокой интенсивности запросов.6  
Технический анализ накладных расходов памяти показывает, что структуры objecthead и objectcore потребляют значительный объем RAM (до 1 КБ на объект), который часто не учитывается при планировании мощностей (capacity planning).9  
В условиях облачной инфраструктуры AWS, где трафик может масштабироваться мгновенно, отсутствие жестких лимитов на служебные буферы памяти является критической уязвимостью архитектуры.12  
Появление тегов HitMiss в логах транзакций VSL является прямым доказательством работы данного механизма и позволяет однозначно связать рост памяти с конкретными типами запросов.10  
Коммерческая версия Varnish Enterprise внедрила функцию "Memory Governor" именно для решения проблемы непредсказуемого потребления памяти процессом, что косвенно подтверждает наличие этой проблемы в Open Source версии.16  
Ошибки, связанные с утечками памяти в Transient хранилище, регулярно фиксировались в баг-трекере проекта (например, issue #2654), что указывает на сложность корректного управления этим ресурсом.17  
Специфика работы с cookies в современных веб-приложениях делает сценарий Hit-for-Miss не исключением, а правилом для значительной части трафика, если не применяется агрессивная нормализация VCL.18

### **Доводы против**

Опытные системные администраторы могут предотвратить эту проблему путем явного задания параметров размера Transient хранилища в аргументах запуска демона (-s Transient=malloc,2G), что переводит проблему из разряда "утечка" в разряд "вытеснение кэша".7  
Если VCL настроен корректно и удаляет заголовок Set-Cookie для статических ресурсов и изображений, то создание объектов Hit-for-Miss для основного объема трафика будет предотвращено.19  
Современные версии Varnish включают улучшения в управлении памятью и могут использовать более агрессивные стратегии очистки короткоживущих объектов, если система находится под давлением памяти, хотя это и зависит от используемого аллокатора.20  
При использовании аллокатора jemalloc фрагментация памяти в Transient хранилище должна быть минимальной (около 20%), что позволяет эффективно переиспользовать освобожденные блоки памяти.20  
В некоторых сценариях проблема может быть вызвана не логикой Hit-for-Miss, а ошибками в модулях VMOD или утечками памяти в пользовательском C-коде, подключенном через inline C.21  
Если трафик на сайт имеет низкую кардинальность (мало уникальных URL) и высокий Hit Rate, то количество объектов Hit-for-Miss будет незначительным, и они не смогут исчерпать память современного сервера.22  
Проблема может быть ложно диагностирована как HfM, в то время как реальной причиной является буферизация больших тел ответов при медленных клиентах, что также использует Transient, но по другому механизму.11

## **Cᛘ2: Фрагментация кучи процесса вследствие неоптимальной работы аллокатора glibc на многоядерной архитектуре ARM64**

### **Суть**

Вторая критическая гипотеза переносит фокус анализа с логического уровня Varnish на системный уровень управления памятью в среде Linux, специфичный для архитектуры ARM64.  
Varnish Cache является высокопроизводительным многопоточным приложением, которое осуществляет миллионы операций выделения и освобождения памяти (malloc/free) в секунду для обработки HTTP-запросов и хранения объектов.  
Эффективность этих операций напрямую зависит от используемого системного аллокатора памяти (memory allocator).  
Стандартным аллокатором в большинстве дистрибутивов Linux, включая Amazon Linux 2023, является ptmalloc, входящий в состав стандартной библиотеки C (glibc).23  
Аллокатор glibc исторически оптимизирован для универсальных задач, но имеет известные архитектурные недостатки при работе в высоконагруженных многопоточных средах.  
Для уменьшения конкуренции потоков за блокировки (lock contention) glibc создает отдельные области памяти, называемые аренами (arenas), для каждого потока или группы потоков.24  
Инстансы AWS Graviton, построенные на архитектуре ARM64, характеризуются большим количеством физических ядер (до 64 ядер на Graviton2 и больше на последующих поколениях).12  
Поскольку Varnish масштабирует количество своих рабочих потоков (thread_pools и thread_pool_max) в зависимости от доступных ядер CPU, на мощных инстансах создаются сотни и тысячи потоков.15  
Это приводит к созданию огромного количества арен памяти в glibc, каждая из которых резервирует адресное пространство и физическую память.  
Основная проблема glibc в данном контексте — это фрагментация памяти (heap fragmentation).  
Когда Varnish освобождает память (удаляет объект из кэша), glibc помечает этот блок как свободный внутри конкретной арены, но не обязательно возвращает его операционной системе немедленно.23  
Если другой поток, привязанный к другой арене, запрашивает память, он не может использовать свободное место из первой арены и вынужден запрашивать новые страницы у ядра ОС.  
В результате процесс varnishd может удерживать значительный объем памяти (высокий RSS), которая внутри аллокатора считается свободной, но недоступна для системы.  
На архитектуре ARM64 в облаке AWS ситуация усугубляется особенностями управления страницами виртуальной памяти.  
Для повышения производительности и снижения нагрузки на TLB (Translation Lookaside Buffer), ядра Linux на Graviton часто настраиваются на использование страниц размером 64 КБ вместо стандартных для x86 4 КБ.25  
Увеличенный размер страницы означает, что минимальный квант выделения памяти, который аллокатор запрашивает у ядра (через mmap), составляет 64 КБ.  
Если Varnish необходимо сохранить объект размером 2 КБ, и аллокатор не находит места в текущих страницах, он запрашивает новую страницу на 64 КБ, используя лишь 3% её объема.  
Это явление называется внутренней фрагментацией, и оно значительно усиливает накладные расходы на память при работе с большим количеством мелких объектов, характерных для веб-кэша.  
В дистрибутиве Amazon Linux 2023, который отличается от Amazon Linux 2 обновленной пакетной базой и разрывом совместимости, пакет varnish может поставляться без жесткой привязки к альтернативному аллокатору jemalloc.26  
Аллокатор jemalloc (Jason Evans' malloc) является де-факто стандартом для Varnish, так как он специально спроектирован для минимизации фрагментации и эффективной работы на многоядерных системах.20  
Согласно тестам, jemalloc удерживает фрагментацию на уровне не более 20%, тогда как glibc в худших сценариях может потреблять в 2-3 раза больше памяти, чем реально необходимо приложению.20  
Отсутствие jemalloc в цепочке зависимостей пакета Varnish на AL2023 приводит к тому, что демон запускается с дефолтным glibc, что является «тихой» проблемой конфигурации.  
Пользователи, столкнувшиеся с этой проблемой, отмечают, что мониторинг Varnish (varnishstat) показывает корректное использование памяти кэшем (SMA.g_bytes), но системный мониторинг (top, ps) фиксирует постоянный рост RSS процесса вплоть до срабатывания OOM-killer.8  
В логах системы ldd для бинарного файла varnishd можно обнаружить отсутствие линковки с libjemalloc.so, что подтверждает использование системного аллокатора.2  
Настройка параметров glibc, таких как MALLOC_ARENA_MAX, может лишь частично смягчить проблему ценой падения производительности из-за блокировок, но не решает её корневую причину.28  
Таким образом, гипотеза Cᛘ2 утверждает, что исчерпание памяти вызвано не логической утечкой данных, а неэффективностью системного программного обеспечения (glibc) на специфической аппаратной платформе (ARM64/Graviton) при работе с паттерном нагрузки Varnish.

### **Оценка**

85

### **Доводы за**

Сравнительные тесты производительности и потребления памяти однозначно показывают преимущество jemalloc над glibc для приложений класса Varnish, особенно в долгоживущих процессах.20  
Существуют документированные подтверждения от пользователей RHEL 9 (близкого родственника AL2023), которые фиксировали трехкратное снижение потребления памяти после принудительного переключения Varnish на jemalloc.2  
Архитектура процессоров AWS Graviton с их большим количеством ядер создает экстремальную нагрузку на механизм арен памяти в glibc, провоцируя максимальную фрагментацию.12  
Использование страниц памяти размером 64 КБ на ARM64 является документированной оптимизацией в AWS, которая технически неизбежно увеличивает гранулярность выделения памяти и способствует росту потребления RAM для мелких объектов.25  
Изменения в репозиториях и политиках поддержки пакетов Amazon Linux 2023 создают реальную вероятность того, что зависимости пакета Varnish были изменены или упрощены, исключив jemalloc из установки по умолчанию.26  
Симптоматика проблемы (расхождение между метриками Varnish и системными метриками памяти) полностью соответствует картине фрагментации кучи, когда приложение "думает", что память свободна, а ОС видит её занятой.29  
Официальные рекомендации Varnish Software настоятельно советуют использовать jemalloc для предотвращения проблем с памятью, признавая glibc субоптимальным выбором.20  
Проблема "retained memory" в glibc является известным багом/особенностью, которая особенно ярко проявляется в контейнеризированных средах и на виртуальных машинах с ограниченными ресурсами.23  
В баг-трекерах RedHat и Fedora присутствуют тикеты, обсуждающие проблемы сборки jemalloc и Varnish для aarch64 (ARM64), что указывает на наличие специфических платформенных сложностей.30  
Практика использования переменных окружения типа MALLOC_CONF для тюнинга памяти в Varnish показывает, что проблема лежит именно в плоскости аллокатора.28

### **Доводы против**

Если установка Varnish производилась из официальных репозиториев varnish-cache.org или с использованием официального Docker-образа, то jemalloc обычно включен в сборку статически или настроен корректно, независимо от дистрибутива.31  
Современные версии glibc (начиная с 2.26 и выше) включают механизм tcache (thread local cache), который улучшает производительность, хотя и может способствовать дополнительному потреблению памяти, но разработчики библиотеки активно работают над уменьшением фрагментации.29  
Многие крупные инсталляции успешно работают на ARM64 без ручного вмешательства в аллокатор, что говорит о том, что проблема может проявляться только при специфических паттернах нагрузки (например, очень высокая частота аллокации/освобождения).27  
Настройка ядра Linux (например, отключение Transparent Huge Pages) может оказывать более значительное влияние на память, чем выбор между glibc и jemalloc.28  
Если проблема вызвана бесконечным ростом Transient хранилища (Cᛘ1), то смена аллокатора не решит проблему, а лишь немного отсрочит наступление OOM, так как утечка носит логический характер.8  
Диагностика через varnishstat может быть неправильно интерпретирована пользователем; высокий g_bytes в Transient — это не фрагментация, а занятая память, и аллокатор здесь ни при чем.11

## **Cᛘ3: Масштабное раздувание метаданных кэша вследствие высокой кардинальности входящих запросов**

### **Суть**

Третья гипотеза рассматривает проблему исчерпания памяти как следствие феномена "Cache Bloat" (раздувание кэша), вызванного отсутствием надлежащей нормализации запросов на уровне VCL.  
Varnish Cache идентифицирует объекты в памяти по хэш-ключу, который вычисляется в процедуре vcl_hash на основе URL запроса, заголовка Host и, опционально, других факторов.7  
В современном интернет-ландшафте URL-адреса часто содержат параметры, которые уникальны для каждого пользователя или перехода, но не влияют на содержание отдаваемого контента.  
Типичными примерами являются маркетинговые метки (Google Analytics utm_*, Facebook fbclid), идентификаторы сессий, передаваемые в строке запроса (jsessionid), или случайные параметры, добавляемые клиентами для обхода браузерного кэширования (?nocache=RANDOM).32  
Если конфигурация VCL не содержит правил для очистки этих параметров перед хэшированием, Varnish будет воспринимать каждый такой запрос как уникальный объект, подлежащий кэшированию.  
При высокой посещаемости ресурса или при активности поисковых ботов и сканеров, генерирующих миллионы уникальных ссылок, количество объектов в кэше начинает расти экспоненциально.22  
Даже если сами закэшированные страницы имеют небольшой размер, или если Varnish сохраняет только факт отсутствия контента (Hit-for-Miss), каждый объект требует выделения служебных структур данных.  
Внутренняя архитектура Varnish оперирует структурами objecthead (запись в глобальной хэш-таблице) и objectcore (описание состояния объекта, ссылки на хранилище), а также другими метаданными.33  
Совокупный размер этих накладных расходов (overhead) составляет приблизительно 1 КБ на каждый объект.9  
Это означает, что один миллион уникальных "мусорных" объектов займет в оперативной памяти около 1 ГБ, даже если полезная нагрузка равна нулю.  
В сценариях массированной атаки или неконтролируемого сканирования количество объектов может достигать десятков миллионов, что приводит к потреблению десятков гигабайт RAM исключительно на метаданные.15  
Этот оверхед обычно аллоцируется через системный malloc и не всегда учитывается в лимитах, заданных параметром -s malloc,SIZE, который ограничивает только объем данных объектов.9  
Еще одним мощным вектором раздувания кэша является некорректное использование заголовка Vary.  
Если бэкенд-сервер возвращает заголовок Vary: User-Agent (что часто встречается в дефолтных настройках веб-серверов Apache и Nginx), Varnish обязан хранить отдельную копию страницы для каждой уникальной строки User-Agent.34  
Учитывая огромное разнообразие версий браузеров, операционных систем и мобильных устройств, это приводит к фрагментации кэша на тысячи вариаций одного и того же контента.  
На платформе Amazon Linux 2023 с мощными процессорами Graviton Varnish способен обрабатывать гигантские потоки запросов, что позволяет процессу "накачивания" кэша происходить очень быстро, опережая механизмы вытеснения устаревших данных (LRU Expiry).  
Ситуация усложняется тем, что эти объекты могут попадать как в основное хранилище, так и в Transient (если они классифицированы как HfM из-за cookies), создавая комплексную нагрузку на подсистему памяти.18  
Диагностика данной проблемы требует анализа метрики MAIN.n_object в varnishstat, которая будет показывать аномально высокие значения, и использования утилиты varnishtop -i BereqURL для выявления паттернов запросов с высокой кардинальностью.22  
Решением проблемы является строгая нормализация входящих запросов в vcl_recv: удаление известных трекинговых параметров из req.url, сортировка query arguments и нормализация заголовка User-Agent перед хэшированием.32  
Без этих мер Varnish на мощном оборудовании превращается в эффективный инструмент для потребления собственной памяти.

### **Оценка**

70

### **Доводы за**

Проблема "Cache Bloat" из-за query parameters является одной из самых распространенных причин деградации производительности Varnish, подробно описанной в руководствах по эксплуатации.35  
Техническая документация подтверждает наличие фиксированного оверхеда в 1 КБ на объект, что делает хранение миллионов мелких объектов экономически неэффективным и опасным для стабильности памяти.9  
Логи веб-серверов повсеместно демонстрируют наличие "паразитного" трафика с уникальными параметрами (utm marks, click IDs), который без фильтрации гарантированно попадает в кэш как уникальный контент.32  
Механизм Vary: User-Agent является известной ловушкой для администраторов, способной увеличить потребление памяти в сотни раз без видимых причин в логике приложения.34  
Инструменты мониторинга Varnish предоставляют четкие индикаторы этой проблемы: высокий n_object, низкий cache_hit rate и большое разнообразие URL в логах.22  
В контексте AWS Graviton высокая производительность CPU позволяет Varnish обрабатывать и аллоцировать эти объекты с огромной скоростью, быстрее приводя к OOM по сравнению с более медленными системами.12  
Существуют специализированные VMOD и стандартные VCL-сниппеты, направленные именно на решение этой проблемы, что говорит о её индустриальной значимости.32  
Если "мусорные" запросы также содержат cookies, они создают объекты Hit-for-Miss, которые попадают в безлимитный Transient, объединяя риски Cᛘ1 и Cᛘ3.19

### **Доводы против**

Varnish имеет встроенный механизм LRU (Least Recently Used), который должен автоматически удалять старые и редко используемые объекты, когда выделенная под хранилище память заканчивается.18  
Если администратор корректно настроил лимит -s malloc, Varnish должен удерживать потребление памяти в заданных рамках, жертвуя Hit Rate, но не падая с OOM (за исключением оверхеда, который должен быть учтен в "запасе" памяти).37  
Для того чтобы оверхед в 1 КБ съел всю память сервера (например, 32 ГБ), нужно создать около 30 миллионов объектов, что является экстремальным значением и будет заметно в любой системе мониторинга.15  
Проблема раздувания кэша чаще приводит к снижению эффективности кэширования (thrashing), чем к полной остановке сервиса, так как Varnish агрессивно "nukes" (удаляет) объекты при нехватке места.31  
Эта гипотеза не объясняет специфику проблем именно на Amazon Linux 2023 по сравнению с другими дистрибутивами, так как логика хэширования универсальна для всех версий Varnish.

## **Cᛘ4: Исчерпание памяти транзитными буферами при обработке больших объектов или медленных клиентов**

### **Суть**

Четвертая гипотеза связывает утечку памяти с механизмами буферизации данных, передаваемых через Varnish.  
Varnish Cache выполняет роль посредника между клиентом и бэкендом, и его задача — передать контент максимально эффективно.  
Существует два основных режима передачи: буферизация (store-and-forward) и потоковая передача (streaming).3  
В режиме буферизации Varnish полностью загружает объект от бэкенда в свое хранилище, и только после завершения загрузки начинает отдавать его клиенту.  
В режиме стриминга (beresp.do_stream = true) передача клиенту начинается сразу же по мере поступления первых байтов от бэкенда.11  
Однако, если объект классифицирован как некэшируемый (uncacheable), или если Varnish решил не кэшировать его (Hit-for-Pass/Hit-for-Miss), данные все равно должны где-то храниться в процессе передачи.  
Для этих целей используется все то же хранилище Transient.1  
Проблема возникает, когда размер передаваемого объекта велик (сотни мегабайт или гигабайты), а скорость клиента значительно ниже скорости получения данных от бэкенда.  
В облачной среде AWS внутренняя сеть между инстансами (например, между EC2 с Varnish и S3 или другим EC2) имеет огромную пропускную способность (до 25-100 Гбит/с).12  
Varnish вычитывает данные от бэкенда с максимальной скоростью и заполняет ими буферы в памяти Transient.  
Если клиент подключен через мобильную сеть 3G/4G, он не может принять эти данные с такой скоростью.  
В результате Varnish вынужден хранить разницу ("backpressure") в своей оперативной памяти.  
Параметр beresp.transit_buffer предназначен для ограничения объема этой буферизации, но по умолчанию он может быть не настроен или настроен на большие значения.38  
Документация указывает "правило большого пальца" для расчета памяти под некэшируемые объекты: n * transit_buffer, где n — количество конкурентных запросов.1  
При одновременной загрузке нескольких больших файлов (например, обновлений ПО, видеофайлов) потребление памяти может мгновенно вырасти на несколько гигабайт.  
Поскольку Transient хранилище не ограничено (как выяснено в Cᛘ1), Varnish будет аллоцировать память до тех пор, пока она есть физически.  
Особый случай — когда администратор пытается ограничить кэширование больших файлов через VCL (например, if (beresp.http.Content-Length > 20MB) { set beresp.uncacheable = true; }), но не включает return(pipe) в vcl_recv.13  
В этом случае Varnish все равно пропускает трафик через свой процесс ("fetch processor"), аллоцируя память под транзитные буферы.  
На системах с ARM64 процессорами Graviton, которые часто используются для задач с высокой пропускной способностью (High Throughput), риск возникновения таких ситуаций повышается из-за способности оборудования обрабатывать огромные потоки данных.39  
Симптомы данной проблемы включают резкие скачки потребления памяти (spikes), совпадающие по времени с запросами к большим файлам, и последующее падение по OOM.2  
В статистике varnishstat это отражается в метриках SMA.Transient.c_bytes (общий объем аллоцированных байт) и SMA.Transient.g_bytes (текущий занятый объем).15  
Решением является использование механизма pipe для больших объектов, который замыкает сокет клиента напрямую на сокет бэкенда, минуя память Varnish, или тщательная настройка параметров стриминга.31

### **Оценка**

60

### **Доводы за**

Пользователи часто сообщают о падении Varnish (OOM) при попытке скачать файлы размером несколько гигабайт, если конфигурация не предусматривает использование pipe.13  
Метрика SMA.Transient.c_bytes позволяет точно отследить объем данных, проходящих через транзитное хранилище, и корреляция этой метрики с OOM является сильным индикатором проблемы.11  
Архитектура Varnish официально использует Transient для буферизации некэшируемого контента, и документация предупреждает о необходимости учета этого фактора при сайзинге памяти.1  
Высокоскоростная сетевая инфраструктура AWS способствует быстрому заполнению буферов, делая проблему более явной, чем в медленных сетях.12  
Механизм буферизации для медленных клиентов является классической проблемой прокси-серверов, и Varnish здесь не исключение.38  
В баг-трекере Varnish присутствуют обсуждения, касающиеся "висящих" транзакций Hit-for-Miss, которые удерживают буферы памяти дольше необходимого при обрыве связи клиентом.40

### **Доводы против**

В современных версиях Varnish (6.0+) механизм потоковой передачи (do_stream) включен по умолчанию для некэшируемых объектов, что должно предотвращать полную буферизацию тела ответа в память.11  
Для возникновения OOM требуется совпадение нескольких факторов: наличие очень больших файлов, медленных клиентов и высокой конкурентности запросов; для типичных веб-сайтов (e-commerce, новости) это нехарактерный профиль нагрузки.8  
Стандартной практикой администрирования Varnish является использование return(pipe) для любого контента, превышающего определенный размер, что полностью исключает этот вектор утечки.31  
Проблема носит эпизодический характер (во время загрузки), тогда как утечка памяти (memory leak) обычно характеризуется монотонным, постоянным ростом потребления ресурсов в течение длительного времени.11  
Гипотеза не объясняет, почему проблема стала острой именно на Amazon Linux 2023, если только не изменились дефолтные параметры сети или ядра, влияющие на буферизацию сокетов.

#### **Works cited**

1. Storage backends — Varnish version trunk documentation, accessed December 11, 2025, [https://varnish-cache.org/docs/trunk/users-guide/storage-backends.html](https://varnish-cache.org/docs/trunk/users-guide/storage-backends.html)  
2. Varnish Using Significantly More Memory than Cache? - Stack Overflow, accessed December 11, 2025, [https://stackoverflow.com/questions/78379910/varnish-using-significantly-more-memory-than-cache](https://stackoverflow.com/questions/78379910/varnish-using-significantly-more-memory-than-cache)  
3. The difference between Hit-for-Miss and Hit-for-Pass - Resources - Varnish Software, accessed December 11, 2025, [https://info.varnish-software.com/blog/the-difference-between-hit-for-miss-and-hit-for-pass](https://info.varnish-software.com/blog/the-difference-between-hit-for-miss-and-hit-for-pass)  
4. varnishd — Varnish version trunk documentation, accessed December 11, 2025, [https://varnish-cache.org/docs/trunk/reference/varnishd.html](https://varnish-cache.org/docs/trunk/reference/varnishd.html)  
5. varnish-cache/doc/sphinx/users-guide/increasing-your-hitrate.rst at master - GitHub, accessed December 11, 2025, [https://github.com/varnishcache/varnish-cache/blob/master/doc/sphinx/users-guide/increasing-your-hitrate.rst](https://github.com/varnishcache/varnish-cache/blob/master/doc/sphinx/users-guide/increasing-your-hitrate.rst)  
6. Under the hood - Varnish Software Documentation, accessed December 11, 2025, [https://docs.varnish-software.com/book/what-is-varnish/under-the-hood/](https://docs.varnish-software.com/book/what-is-varnish/under-the-hood/)  
7. varnishd — Varnish version 7.7.3 documentation, accessed December 11, 2025, [https://varnish-cache.org/docs/7.7/reference/varnishd.html](https://varnish-cache.org/docs/7.7/reference/varnishd.html)  
8. Why does Varnish eat up all memory despite having both transient and malloc limits?, accessed December 11, 2025, [https://serverfault.com/questions/1035846/why-does-varnish-eat-up-all-memory-despite-having-both-transient-and-malloc-limi](https://serverfault.com/questions/1035846/why-does-varnish-eat-up-all-memory-despite-having-both-transient-and-malloc-limi)  
9. Sizing your cache — Varnish version 7.4.3 documentation, accessed December 11, 2025, [https://varnish-cache.org/docs/7.4/users-guide/sizing-your-cache.html](https://varnish-cache.org/docs/7.4/users-guide/sizing-your-cache.html)  
10. Logging cache hits and misses - Varnish Developer Portal, accessed December 11, 2025, [https://www.varnish-software.com/developers/tutorials/logging-cache-hits-misses-varnish/](https://www.varnish-software.com/developers/tutorials/logging-cache-hits-misses-varnish/)  
11. Varnish memory usage keeps increasing - Stack Overflow, accessed December 11, 2025, [https://stackoverflow.com/questions/76209998/varnish-memory-usage-keeps-increasing](https://stackoverflow.com/questions/76209998/varnish-memory-usage-keeps-increasing)  
12. AWS Graviton4-based Amazon EC2 R8g instances: best price performance in Amazon EC2, accessed December 11, 2025, [https://aws.amazon.com/blogs/aws/aws-graviton4-based-amazon-ec2-r8g-instances-best-price-performance-in-amazon-ec2/](https://aws.amazon.com/blogs/aws/aws-graviton4-based-amazon-ec2-r8g-instances-best-price-performance-in-amazon-ec2/)  
13. limit readahead for private objects · Issue #2964 · varnishcache/varnish-cache - GitHub, accessed December 11, 2025, [https://github.com/varnishcache/varnish-cache/issues/2964](https://github.com/varnishcache/varnish-cache/issues/2964)  
14. Achieving a high hitrate — Varnish version 7.5.0 documentation, accessed December 11, 2025, [https://varnish-cache.org/docs/7.5/users-guide/increasing-your-hitrate.html](https://varnish-cache.org/docs/7.5/users-guide/increasing-your-hitrate.html)  
15. Varnish duplicate process 170 once - Unix & Linux Stack Exchange, accessed December 11, 2025, [https://unix.stackexchange.com/questions/632427/varnish-duplicate-process-170-once](https://unix.stackexchange.com/questions/632427/varnish-duplicate-process-170-once)  
16. Two-Minute Tech Tuesdays - Memory Governor - Resources - Varnish Software, accessed December 11, 2025, [https://info.varnish-software.com/blog/two-minute-tech-tuesdays-memory-governor](https://info.varnish-software.com/blog/two-minute-tech-tuesdays-memory-governor)  
17. Overuse of Transient storage with hit-for-miss objects · Issue #2654 · varnishcache/varnish-cache - GitHub, accessed December 11, 2025, [https://github.com/varnishcache/varnish-cache/issues/2654](https://github.com/varnishcache/varnish-cache/issues/2654)  
18. Troubleshooting Varnish - Varnish Developer Portal, accessed December 11, 2025, [https://www.varnish-software.com/developers/tutorials/troubleshooting-varnish/](https://www.varnish-software.com/developers/tutorials/troubleshooting-varnish/)  
19. how to use varnish cache with set-cookie named mp3list and phpsessionid - Server Fault, accessed December 11, 2025, [https://serverfault.com/questions/649629/how-to-use-varnish-cache-with-set-cookie-named-mp3list-and-phpsessionid](https://serverfault.com/questions/649629/how-to-use-varnish-cache-with-set-cookie-named-mp3list-and-phpsessionid)  
20. Understanding Varnish Cache Memory Usage - Resources, accessed December 11, 2025, [https://info.varnish-software.com/blog/understanding-varnish-cache-memory-usage](https://info.varnish-software.com/blog/understanding-varnish-cache-memory-usage)  
21. Reduce concurrency when using glibc-based Linux without jemalloc to help prevent memory fragmentation · Issue #2607 · lovell/sharp - GitHub, accessed December 11, 2025, [https://github.com/lovell/sharp/issues/2607](https://github.com/lovell/sharp/issues/2607)  
22. Achieving a high cache hit rate with Varnish - Resources, accessed December 11, 2025, [https://info.varnish-software.com/blog/high-hit-rate-with-varnish](https://info.varnish-software.com/blog/high-hit-rate-with-varnish)  
23. How glibc Memory Handling Affects Java Applications: The Hidden Cost of Fragmentation | by Daniyal Hassan | Medium, accessed December 11, 2025, [https://medium.com/@daniyal.hass/how-glibc-memory-handling-affects-java-applications-the-hidden-cost-of-fragmentation-8e666ee6e000](https://medium.com/@daniyal.hass/how-glibc-memory-handling-affects-java-applications-the-hidden-cost-of-fragmentation-8e666ee6e000)  
24. Why does the default glibc allocator have relatively poor performance? (What mak... | Hacker News, accessed December 11, 2025, [https://news.ycombinator.com/item?id=8612645](https://news.ycombinator.com/item?id=8612645)  
25. Improve Performance with 64K Memory Pages on AWS Graviton Processors, accessed December 11, 2025, [https://dev.to/aws-builders/improve-performance-with-64k-memory-pages-on-aws-graviton-processors-ifa](https://dev.to/aws-builders/improve-performance-with-64k-memory-pages-on-aws-graviton-processors-ifa)  
26. Package support statements - Amazon Linux 2023, accessed December 11, 2025, [https://docs.aws.amazon.com/linux/al2023/release-notes/support-info-by-support-statement.html](https://docs.aws.amazon.com/linux/al2023/release-notes/support-info-by-support-statement.html)  
27. CPU and memory usage of jemalloc as compared to glibc malloc - Stack Overflow, accessed December 11, 2025, [https://stackoverflow.com/questions/13027475/cpu-and-memory-usage-of-jemalloc-as-compared-to-glibc-malloc](https://stackoverflow.com/questions/13027475/cpu-and-memory-usage-of-jemalloc-as-compared-to-glibc-malloc)  
28. Varnish 6 LTS /w CentOS 8 not respecting memory limits? - Stack Overflow, accessed December 11, 2025, [https://stackoverflow.com/questions/65450044/varnish-6-lts-w-centos-8-not-respecting-memory-limits](https://stackoverflow.com/questions/65450044/varnish-6-lts-w-centos-8-not-respecting-memory-limits)  
29. Handling native memory fragmentation of glibc - Brice Dutheil, accessed December 11, 2025, [https://blog.arkey.fr/drafts/2021/01/22/native-memory-fragmentation-with-glibc/](https://blog.arkey.fr/drafts/2021/01/22/native-memory-fragmentation-with-glibc/)  
30. 1545539 – jemalloc(aarch64): munmap - Invalid Argument - build-time pagesize 4k != Fedora kernel (64k) - Red Hat Bugzilla, accessed December 11, 2025, [https://bugzilla.redhat.com/show_bug.cgi?id=1545539](https://bugzilla.redhat.com/show_bug.cgi?id=1545539)  
31. Varnish crashes on bigger files - cache - Server Fault, accessed December 11, 2025, [https://serverfault.com/questions/1031656/varnish-crashes-on-bigger-files](https://serverfault.com/questions/1031656/varnish-crashes-on-bigger-files)  
32. Stripping out select querystring attribute/value pairs so varnish will not vary cache by them, accessed December 11, 2025, [https://stackoverflow.com/questions/13144172/stripping-out-select-querystring-attribute-value-pairs-so-varnish-will-not-vary](https://stackoverflow.com/questions/13144172/stripping-out-select-querystring-attribute-value-pairs-so-varnish-will-not-vary)  
33. varnish-counters — Varnish version trunk documentation, accessed December 11, 2025, [https://varnish-cache.org/docs/trunk/reference/varnish-counters.html](https://varnish-cache.org/docs/trunk/reference/varnish-counters.html)  
34. Achieving a high hitrate — Varnish version 7.4.3 documentation, accessed December 11, 2025, [https://varnish-cache.org/docs/7.4/users-guide/increasing-your-hitrate.html](https://varnish-cache.org/docs/7.4/users-guide/increasing-your-hitrate.html)  
35. Stripping query strings in Varnish | Acquia Product Documentation, accessed December 11, 2025, [https://docs.acquia.com/acquia-cloud-platform/stripping-query-strings-varnish](https://docs.acquia.com/acquia-cloud-platform/stripping-query-strings-varnish)  
36. What are the commands to get top MISSES and HITS from Varnish 4? - Server Fault, accessed December 11, 2025, [https://serverfault.com/questions/649268/what-are-the-commands-to-get-top-misses-and-hits-from-varnish-4](https://serverfault.com/questions/649268/what-are-the-commands-to-get-top-misses-and-hits-from-varnish-4)  
37. 10 Varnish Cache mistakes and how to avoid them, accessed December 11, 2025, [https://varnish-software.medium.com/10-varnish-cache-mistakes-and-how-to-avoid-them-d240f452ab35](https://varnish-software.medium.com/10-varnish-cache-mistakes-and-how-to-avoid-them-d240f452ab35)  
38. Two-Minute Tech Tuesdays - Transit Buffer - Resources - Varnish Software, accessed December 11, 2025, [https://info.varnish-software.com/blog/two-minute-tech-tuesdays-transit-buffer](https://info.varnish-software.com/blog/two-minute-tech-tuesdays-transit-buffer)  
39. AWS Graviton Performance Testing: Tips for Independent Software Vendors - AWS Whitepaper - AWS Documentation, accessed December 11, 2025, [https://docs.aws.amazon.com/pdfs/whitepapers/latest/aws-graviton-performance-testing/aws-graviton-performance-testing.pdf](https://docs.aws.amazon.com/pdfs/whitepapers/latest/aws-graviton-performance-testing/aws-graviton-performance-testing.pdf)  
40. Changelog - Varnish Enterprise, accessed December 11, 2025, [https://docs.varnish-software.com/varnish-enterprise/changelog/](https://docs.varnish-software.com/varnish-enterprise/changelog/)

# 18. Анализ `Cᛘ⠿` (выполнен экземпляром №5 Gemini Deep Research)
https://gemini.google.com/share/d5ef05331eb4

## **Cᛘ₁: Взрыв кэша из-за высокой кардинальности запросов**

### **Суть**

Данная гипотеза постулирует, что исчерпание оперативной памяти сервера вызвано комбинаторным взрывом количества уникальных объектов кэша, возникающим вследствие отсутствия агрессивной нормализации URL-адресов в условиях фасетной навигации и активного рекламного трафика.  
Ключевым механизмом, лежащим в основе этой проблемы, является дефолтное поведение Varnish Cache, который использует полную строку URL, включая все параметры запроса (query string), в качестве ключа для вычисления хэша объекта, что при малейшем изменении порядка параметров или их состава приводит к созданию новой записи в памяти.1  
В контексте проекта RunRepeat.com, архитектура которого включает фильтрацию товаров по полу, размеру и цвету, количество возможных перестановок параметров (например, /shoe?size=42&color=red против /shoe?color=red&size=42) растет факториально, создавая множественные копии одного и того же контента.1  
Ситуация критически усугубляется наличием рекламного трафика, о чем свидетельствует упоминание клиента «We also have ads», что неизбежно привносит в URL уникальные идентификаторы кликов, такие как gclid (Google Click ID), fbclid (Facebook Click ID) и различные utm_* метки.3  
Эти метки, предназначенные исключительно для клиентской аналитики или трекинга на стороне сервера, делают каждый входящий запрос технически уникальным с точки зрения Varnish, заставляя его сохранять копию страницы для каждого отдельного перехода пользователя по рекламе.3  
Даже если сам размер кэшируемых данных (HTML-тела страницы) ограничен параметром запуска -s malloc,SIZE, каждый создаваемый объект требует выделения структур метаданных, таких как struct obj и struct objcore, которые хранятся в оперативной памяти вне области, отведенной под хранилище данных (storage payload).6  
Согласно технической документации, накладные расходы (overhead) на один объект составляют приблизительно 1 КБ памяти, которая аллоцируется системным malloc и не учитывается в лимитах -s, задаваемых администратором при старте демона.6  
При сценарии, когда сайт получает около 4 миллионов сессий в месяц, и значительная часть этого трафика является рекламной или создается ботами, перебирающими фильтры, количество мелких объектов в памяти может достигать десятков миллионов.6  
Это приводит к тому, что метаданные начинают занимать гигабайты оперативной памяти (например, 10 миллионов объектов потребуют около 10 ГБ RAM только под структуры управления), что в условиях 32 ГБ общей памяти сервера создает критическое давление на ресурсы.6  
Более того, огромное количество объектов в хэш-таблице замедляет операции поиска (HSH_Lookup), увеличивает длину цепочек коллизий и создает дополнительную нагрузку на процессор, что клиент описывает как «performance degradation».7  
Отсутствие в описании проблемы упоминаний о применении модуля vmod_std и функции std.querysort для сортировки параметров или регулярных выражений для очистки трекинговых меток делает эту гипотезу наиболее вероятной технической причиной наблюдаемого поведения.10  
Если VCL (Varnish Configuration Language) не содержит явных инструкций по нормализации req.url до этапа vcl_hash, Varnish будет послушно кэшировать бесконечное множество вариаций одного URL, быстро исчерпывая физическую память сервера, независимо от того, какой лимит установлен для полезной нагрузки.12

### **Оценка**

95

### **Доводы за**

Фундаментальная архитектура E-commerce проектов с фасетным поиском («users can filter by gender, size, color») является хрестоматийным примером уязвимости к проблеме Cache Bloat, так как количество возможных комбинаций фильтров стремится к бесконечности.8  
Прямое указание клиента на наличие рекламы («We also have ads») служит практически гарантией присутствия в запросах высокоэнтропийных параметров отслеживания (gclid, utm), которые без специальной обработки приводят к коэффициенту кэширования (Hit Rate) близкому к нулю и переполнению памяти уникальными объектами.3  
Техническая спецификация Varnish Cache подтверждает наличие неустранимых накладных расходов в размере ~1 КБ на объект, которые находятся вне контроля параметра -s malloc, что полностью объясняет симптом «Varnish repeatedly grows the memory... regardless of what config we've tried».6  
Клиент отмечает, что «pages are not fully static», что подразумевает высокую динамику генерации контента и, вероятно, использование различных параметров запроса для управления отображением, что усиливает риск дублирования кэша [O.md §2.3].  
Отсутствие сортировки параметров запроса (std.querysort) приводит к тому, что идентичные по семантике запросы /A?x=1&y=2 и /A?y=2&x=1 обрабатываются как разные сущности, что эффективно удваивает потребление памяти для популярных страниц категорий.10  
Масштаб трафика в 4 миллиона сессий в месяц является достаточным для того, чтобы даже небольшой процент "мусорных" запросов (например, от поисковых ботов, сканирующих все комбинации фильтров) привел к созданию миллионов объектов за короткий промежуток времени.15  
Указание на то, что «config changes haven't helped», свидетельствует о том, что администраторы пытаются тюнить параметры размера хранилища, не понимая, что утечка происходит через метаданные объектов, количество которых не ограничено стандартными настройками.6  
В документации Varnish Enterprise проблема управления памятью через Massive Storage Engine (MSE) и Memory Governor выделяется как ключевое преимущество перед Open Source версией именно в сценариях с большим количеством объектов, что косвенно подтверждает уязвимость бесплатной версии к таким проблемам.14  
Использование Graviton CPU с большим количеством ядер (8 Cores) позволяет обрабатывать запросы параллельно с высокой скоростью, что может ускорить процесс заполнения памяти «мусорными» объектами при DDoS-подобной активности ботов [O.md §2.3].  
Существующие в открытом доступе рекомендации по настройке Varnish для Magento и других E-commerce платформ часто упускают нюансы глубокой очистки URL, ограничиваясь лишь базовыми правилами, что оставляет систему уязвимой для специфических трекеров.13

### **Доводы против**

Если команда разработчика клиента использует профессионально подготовленные шаблоны VCL для E-commerce (например, официальный VCL для Magento 2), то базовые правила нормализации URL и удаления технических параметров (utm_source и т.д.) могут быть уже включены в конфигурацию по умолчанию.13  
Механизм LRU (Least Recently Used), встроенный в Varnish, предназначен для автоматического удаления старых объектов при исчерпании выделенного лимита хранилища, что теоретически должно стабилизировать потребление памяти на заданном уровне, если только рост метаданных не происходит быстрее, чем процесс очистки.6  
В некоторых случаях, если сайт использует Vary заголовки корректно, Varnish может эффективно управлять вариациями контента без создания полностью независимых объектов, хотя это требует сложной настройки бэкенда.18  
Если бы проблема заключалась исключительно в дублировании URL, логи доступа (varnishlog) показали бы очевидную картину с огромным количеством уникальных ключей, что квалифицированный специалист должен был заметить на ранних этапах диагностики.19  
Утверждение клиента о «persistent memory issues» может указывать на то, что память не освобождается даже при снижении трафика, что более характерно для утечек памяти (memory leaks) в коде или фрагментации, чем для простого заполнения кэша, который должен реагировать на команды очистки или перезагрузки.14

## **Cᛘ₂: Неограниченное потребление памяти во временном хранилище**

### **Суть**

Гипотеза Cᛘ₂ утверждает, что наблюдаемая «утечка» памяти на самом деле является штатным, но неконтролируемым накоплением данных во временном хранилище (Transient Storage), которое в архитектуре Varnish Cache спроектировано как неограниченное по размеру пространство.  
Временное хранилище используется Varnish для размещения объектов с очень коротким временем жизни (определяется параметром shortlived, по умолчанию 10 секунд), а также для транзитных объектов, которые не подлежат длительному кэшированию.14  
Критически важным аспектом является механизм обработки ответов, которые нельзя кэшировать (uncacheable): когда Varnish решает не помещать объект в основной кэш (например, из-за наличия заголовка Set-Cookie или Cache-Control: private), он создает специальную запись hit-for-miss или hit-for-pass.21  
Эти технические записи, предназначенные для предотвращения "thundering herd" проблемы (когда множество запросов одновременно идут на бэкенд), сохраняются именно в Transient хранилище.22  
В сценарии E-commerce с активной рекламой, каждый переход пользователя по ссылке с gclid часто инициирует создание новой сессии на бэкенде, который отвечает установкой Set-Cookie.17  
В результате, Varnish вынужден создавать уникальный hit-for-miss объект для каждого такого запроса, сохраняя его в Transient хранилище на время действия TTL (по умолчанию 120 секунд для hit-for-miss).22  
Поскольку Transient хранилище по умолчанию использует системный аллокатор malloc без ограничения максимального размера (unbounded), при высокой интенсивности трафика (4 млн сессий) объем накопленных транзитных объектов может расти лавинообразно.14  
Этот рост происходит параллельно с использованием основного хранилища (определенного через -s malloc,SIZE), и суммарное потребление памяти процессом varnishd становится равным Storage Size + Transient Size + Overhead.7  
Клиент, наблюдая рост памяти, может пытаться уменьшить основной кэш, но это не влияет на Transient, что объясняет фразу «regardless of what config we've tried».14  
Особенно опасна ситуация с медленными клиентами или большими объемами передаваемых данных, так как Varnish буферизирует тело ответа в Transient хранилище во время его передачи от бэкенда к клиенту (streaming/buffering), и память освобождается только после полного завершения передачи.14  
Если на сайте присутствуют большие страницы или файлы, и множество пользователей с медленным интернетом (например, мобильных) одновременно загружают их, объем занятой в Transient памяти может достигать гигантских значений.14  
Данная проблема является архитектурной особенностью Open Source версии Varnish, где отсутствуют продвинутые механизмы управления памятью, доступные в Enterprise версии (Memory Governor), которые могли бы лимитировать Transient.14  
Таким образом, «утечка» памяти является фактически накоплением легитимных, но короткоживущих данных, которые система не успевает освобождать или накапливает в объемах, превышающих физические возможности сервера.22

### **Оценка**

90

### **Доводы за**

Документация Varnish Cache и многочисленные обсуждения в сообществе (StackOverflow, mailing lists) однозначно определяют Transient Storage как «unbounded memory space», что является известным источником проблем стабильности (OOM).14  
Анализ реальных инцидентов показывает, что метрика SMA.Transient.c_bytes может многократно превышать размер основного хранилища SMA.s0.c_bytes в ситуациях с высоким трафиком и некорректной политикой кэширования.22  
Клиентская жалоба на неэффективность изменений конфигурации («config changes haven't helped») прямо указывает на то, что проблема находится вне зоны действия стандартного параметра -s, который ограничивает только основной кэш.14  
Наличие на сайте рекламы и динамического контента («users can filter... ads on the site») генерирует паттерн трафика, богатый запросами, которые нельзя кэшировать (из-за кук или уникальности), что массово порождает объекты hit-for-miss в Transient.3  
Механизм hit-for-pass (в старых версиях) и hit-for-miss (в новых) специально разработан для защиты бэкенда, но ценой потребления памяти Varnish, что при атаке или всплеске трафика перекладывает нагрузку с CPU бэкенда на RAM прокси.21  
При 4 миллионах сессий в месяц, даже небольшой процент запросов, попадающих в Transient (например, корзина, чекаут, личный кабинет), создает постоянный базовый уровень потребления памяти, который может иметь пики, превышающие доступные 32 ГБ.7  
Отсутствие явного указания параметра -s Transient=malloc,SIZE в стандартных конфигурациях означает, что в 99% случаев эта настройка остается дефолтной (неограниченной), оставляя систему уязвимой.23  
Проблема усугубляется, если используются медленные бэкенды, так как объекты задерживаются в Transient на время ожидания и передачи, увеличивая время жизни аллокаций.14

### **Доводы против**

Теоретически, объекты в Transient хранилище имеют короткий жизненный цикл и должны освобождаться автоматически и быстро, что должно приводить к пилообразному графику потребления памяти, а не к постоянному линейному росту, описываемому клиентом.14  
В современных версиях Varnish (6.0+) механизм обработки hit-for-miss был оптимизирован по сравнению со старым hit-for-pass, чтобы уменьшить накладные расходы и время жизни записей, что должно снижать остроту проблемы.24  
Если сайт обслуживает преимущественно мелкие страницы (HTML), то буферизация ответов не должна занимать гигабайты памяти, если только не происходит массовая загрузка больших медиа-файлов через Varnish (что обычно выносится на CDN).14  
Клиент может использовать параметр shortlived с очень маленьким значением, что заставляет Varnish агрессивнее считать объекты транзитными, но это обычно требует осознанной настройки, а не происходит само собой.20

## **Cᛘ₃: Фрагментация памяти из-за системного аллокатора**

### **Суть**

Гипотеза Cᛘ₃ фокусируется на проблеме внутренней и внешней фрагментации оперативной памяти, возникающей из-за взаимодействия Varnish Cache с системным аллокатором памяти (glibc malloc) на операционной системе Linux.  
Varnish Cache работает по модели интенсивного выделения и освобождения памяти: миллионы объектов создаются, живут разное время и удаляются, что создает колоссальную нагрузку на аллокатор памяти.7  
Стандартный аллокатор glibc (ptmalloc), используемый по умолчанию в большинстве дистрибутивов Linux (RHEL, CentOS, Amazon Linux), исторически плохо справляется с паттерном нагрузки, характеризующимся высокой конкурентностью потоков и множеством мелких разнородных аллокаций.25  
В результате работы glibc образуется фрагментация кучи (heap fragmentation): память, освобожденная процессом (free()), остается закрепленной за процессом и не возвращается операционной системе, при этом она может быть разбита на мелкие блоки, непригодные для повторного использования под крупные объекты.7  
Это приводит к ситуации, когда метрика RSS (Resident Set Size) процесса Varnish постоянно растет, создавая видимость утечки памяти, хотя внутри самого Varnish (по метрикам счетчиков) объем используемых данных может быть стабильным.7  
Документация Varnish Software настоятельно рекомендует использовать альтернативный аллокатор jemalloc, который специально оптимизирован для предотвращения фрагментации и лучшей работы в многопоточных средах.7  
jemalloc использует механизм арен (arenas) и экстентов (extents), что позволяет удерживать уровень фрагментации на уровне не более 20% в худшем случае, тогда как для glibc этот показатель может быть значительно выше и непредсказуем.7  
Однако, в дистрибутивах семейства Red Hat (к которым относится Amazon Linux), jemalloc часто не является аллокатором по умолчанию и даже может отсутствовать в зависимостях пакета, требуя ручной установки и настройки через переменную окружения LD_PRELOAD или конфигурацию systemd.27  
На архитектуре ARM64 (Graviton), которая имеет отличную от x86 модель памяти и примитивы синхронизации, проблемы с блокировками (lock contention) и управлением памятью в glibc могут проявляться более остро, влияя не только на потребление памяти, но и на производительность CPU.25  
Клиент упоминает использование «Gravitron CPU» и «persistent memory issues», что делает версию с неэффективным аллокатором крайне правдоподобной, особенно если используется стандартный образ ОС без тюнинга [O.md §2.3].  
Важно отметить, что Varnish выделяет память не только под объекты, но и под рабочие пространства потоков (workspace_client, workspace_backend), размер которых также влияет на общую картину потребления и фрагментации.30  
Если фрагментация достигает 50% и более (что возможно с glibc в долгосрочной перспективе), сервер с 32 ГБ RAM может исчерпать память при реальном объеме полезных данных всего в 15-20 ГБ.7

### **Оценка**

85

### **Доводы за**

Официальный блог Varnish Software и документация прямо указывают на то, что jemalloc является рекомендованным стандартом, и использование других аллокаторов чревато высокой фрагментацией.7  
В release notes для Red Hat Enterprise Linux 10 интеграция jemalloc 5.3.0 в пакет Varnish подается как исправление критической проблемы «excessive memory usage... despite setting explicit memory limits», что подтверждает массовый характер проблемы на системах RHEL/Amazon Linux с glibc.27  
Бенчмарки баз данных (MySQL) и других кэширующих систем показывают, что переход с glibc на jemalloc может снизить потребление RSS в 2 раза при той же полезной нагрузке, что доказывает масштаб влияния аллокатора.25  
Проблема фрагментации объясняет «бесконечный» рост памяти: по мере работы процесса куча становится все более фрагментированной, и аллокатор вынужден запрашивать новые страницы у ОС, увеличивая RSS, даже если старые страницы формально свободны (но фрагментированы).7  
На Amazon Linux (основанном на RHEL/Fedora) пакет jemalloc может не быть установлен или активирован по умолчанию для Varnish, что является частой ловушкой для инженеров, мигрирующих с Debian/Ubuntu, где это часто сделано из коробки.27  
Специфика архитектуры Graviton (ARM64) может усугублять накладные расходы glibc из-за особенностей реализации спинлоков и атомарных операций, что коррелирует с жалобой на деградацию производительности.29

### **Доводы против**

Если клиент использует Varnish Enterprise или грамотно собранный Docker-контейнер, вероятность того, что jemalloc уже настроен, высока, так как это best practice.14  
В последних версиях glibc (начиная с 2.26) был внедрен per-thread cache (tcache), который значительно улучшил производительность и уменьшил фрагментацию, приблизив показатели к jemalloc в некоторых сценариях.25  
Проблема фрагментации обычно приводит к выходу на "плато" потребления памяти (saturation point), а не к бесконечному линейному росту до OOM, если только нагрузка не растет постоянно.26  
Диагностировать эту проблему достаточно легко с помощью утилит типа pmap или встроенных счетчиков jemalloc (если он подключен), и квалифицированный разработчик мог бы заметить разницу между g_bytes и RSS.7

## **Cᛘ₄: Неэффективность размера страниц памяти на архитектуре ARM64**

### **Суть**

Гипотеза Cᛘ₄ связывает проблемы производительности и, косвенно, управления памятью с использованием субоптимального размера страниц памяти (page size) на архитектуре процессоров AWS Graviton (ARM64).  
В отличие от архитектуры x86_64, где размер страницы памяти жестко зафиксирован на уровне 4 КБ (с опциональными Huge Pages), архитектура ARM64 поддерживает выбор размера страницы на уровне ядра ОС: 4 КБ, 16 КБ или 64 КБ.32  
Стандартные образы операционных систем (Amazon Linux 2, RHEL 8, Ubuntu) для ARM64 часто поставляются с ядром, настроенным на использование страниц 4 КБ для обеспечения максимальной совместимости с программным обеспечением.33  
Однако для приложений с интенсивным использованием памяти, таких как Varnish Cache (выделенный объем 32 ГБ), использование мелких страниц 4 КБ создает колоссальную нагрузку на подсистему управления памятью процессора (MMU) и буфер ассоциативной трансляции (TLB - Translation Lookaside Buffer).32  
При объеме памяти 32 ГБ и размере страницы 4 КБ таблица страниц (page table) может содержать миллионы записей, которые не помещаются в TLB, вызывая частые промахи (TLB misses).35  
Каждый промах TLB заставляет процессор выполнять дорогостоящую процедуру "прогулки по таблице страниц" (page walk), затрачивая циклы CPU и увеличивая латентность доступа к памяти.35  
Это явление напрямую коррелирует с жалобой клиента на «performance degradation», так как процессор тратит значительное время на обслуживание памяти, а не на обработку запросов.34  
Переход на ядро с поддержкой страниц 64 КБ (kernel-64k) позволяет уменьшить размер таблицы страниц в 16 раз и значительно повысить эффективность TLB, покрывая больший объем памяти меньшим количеством записей.33  
Хотя использование страниц 64 КБ может привести к некоторому увеличению потребления памяти для очень мелких файлов (внутренняя фрагментация, так как минимальный аллоцируемый блок равен 64 КБ), для Varnish, который управляет памятью большими чанками внутри malloc, это влияние нивелируется общим выигрышем в производительности.32  
Amazon Linux 2023 и RHEL 9 предоставляют пакет kernel-64k как опцию для высоконагруженных систем, баз данных и кэшей, работающих на Graviton.33  
Если клиент использует стандартное ядро 4 КБ на мощном инстансе Graviton с 32 ГБ памяти, он искусственно ограничивает пропускную способность системы и создает предпосылки для нестабильной работы под нагрузкой.34

### **Оценка**

60

### **Доводы за**

Документация Red Hat и Amazon AWS явно рекомендует использование kernel-64k для «memory-intensive workloads» и «large datasets» на платформе ARM64, к которым безусловно относится кэширующий сервер.33  
Независимые тесты производительности (Phoronix) демонстрируют значительный прирост производительности и снижение системных накладных расходов при переходе с 4 КБ на 64 КБ страницы на процессорах ARM64 серверного класса.34  
Проблема TLB Misses является классическим «бутылочным горлышком» для приложений с произвольным доступом к большим массивам памяти, что характерно для алгоритмов работы хэш-таблиц Varnish.35  
Упоминание клиентом конкретной аппаратной платформы «Gravitron CPU» (вероятно, опечатка от Graviton) намекает на то, что проблема может иметь аппаратно-зависимый характер, который не проявлялся бы на x86 [O.md §2.3].  
Снижение нагрузки на CPU за счет уменьшения page walks освобождает ресурсы для обработки большего количества запросов и сборки мусора, что может косвенно помочь в стабилизации памяти.35

### **Доводы против**

Данная проблема объясняет в первую очередь деградацию производительности (CPU/Latency), а не физическое исчерпание памяти (Memory Leak/Growth), которое является основной жалобой клиента [O.md §2.3].  
Использование страниц 64 КБ может увеличить потребление памяти операционной системой (kernel structures) и усилить внутреннюю фрагментацию для мелких системных файлов, хотя для самого Varnish это менее критично.32  
Переход на kernel-64k требует смены ядра и перезагрузки, а также потенциально может вызвать проблемы совместимости с некоторыми инструментами мониторинга или старым ПО, не готовым к такому размеру страниц.33  
Если Varnish настроен с использованием jemalloc и transparent huge pages (THP), операционная система может частично компенсировать недостатки 4 КБ страниц, объединяя их в большие страницы.32

## **Cᛘ₅: Отсутствие нормализации HTTP-заголовков и сжатия**

### **Суть**

Гипотеза Cᛘ₅ рассматривает вклад отсутствия нормализации ключевых HTTP-заголовков (User-Agent, Accept-Encoding, Cookie) в процесс неконтролируемого раздувания кэша.  
Varnish Cache использует механизм Vary для создания вариаций одного и того же объекта (URL) для разных клиентов, что необходимо для отдачи, например, сжатого (gzip) или несжатого контента, или мобильной версии сайта.1  
Критическая уязвимость возникает, если бэкенд приложение (RunRepeat.com) отправляет заголовок Vary: User-Agent, инструктируя Varnish хранить отдельную копию страницы для каждого уникального User-Agent.37  
Учитывая, что существует тысячи вариаций строк User-Agent (разные версии браузеров, ОС, устройства, боты), это приводит к катастрофическому дублированию контента: один URL может иметь сотни копий в кэше, каждая из которых потребляет память и метаданные.18  
Аналогичная проблема возможна с заголовком Accept-Encoding: если не нормализовать его в vcl_recv (приводя к единому виду gzip), Varnish может кэшировать отдельные копии для клиентов, присылающих gzip, deflate, deflate, gzip или просто gzip.1  
Кроме того, отсутствие правильной обработки заголовка Cookie в vcl_recv (например, удаление кук для статики или для страниц, не требующих авторизации) приводит к тому, что Varnish считает запросы персонализированными и либо не кэширует их вообще (passing), либо кэширует как уникальные вариации.39  
Клиент не упоминает о наличии специального кода VCL для нормализации заголовков, но упоминает, что «users can filter by gender...», что подразумевает сложную логику на бэкенде, которая может ошибочно выставлять широкие Vary заголовки [O.md §2.3].  
Также, если Varnish не настроен на хранение объектов в сжатом виде (gzip), он будет хранить несжатый HTML, который занимает в 5-10 раз больше места в оперативной памяти, что при больших объемах трафика существенно сокращает эффективную емкость кэша.38  
В совокупности эти факторы приводят к неэффективному использованию доступной памяти (хранение дубликатов и "воздуха"), что выглядит как быстрый рост потребления памяти при увеличении разнообразия клиентских устройств и ботов.

### **Оценка**

70

### **Доводы за**

Использование Vary: User-Agent является распространенной ошибкой конфигурации веб-серверов (Apache/Nginx) и CMS, которая при установке Varnish превращается в "бомбу замедленного действия" для памяти.18  
Современный трафик характеризуется огромным разнообразием User-Agent (мобильные приложения, встроенные браузеры, боты), что делает стратегию кэширования по User-Agent разрушительной без нормализации до групп (например, "Mobile", "Desktop").12  
Отсутствие сжатия объектов в памяти (хранение plain text) является расточительством ресурсов, и без явной настройки (do_gzip, do_stream) Varnish может работать в субоптимальном режиме.38  
Проблемы с Cookie («We also have ads») могут приводить к тому, что запросы с рекламными куками не попадают в кэш или создают вариации, если бэкенд добавляет Vary: Cookie.39  
Нормализация заголовков является стандартной практикой в профессиональных VCL, но часто отсутствует в базовых примерах или "быстрых стартах", которыми мог воспользоваться клиент.10

### **Доводы против**

Varnish версии 4.0 и выше имеет встроенную интеллектуальную обработку Accept-Encoding, автоматически выбирая лучшую схему сжатия, что снижает вероятность проблем с этим конкретным заголовком.38  
Большинство современных CMS (включая Magento, WordPress) научились избегать Vary: User-Agent в пользу адаптивной верстки или отдельных заголовков типа X-UA-Device, что снижает риск этой конкретной ошибки.18  
Даже при наличии множества вариаций, механизм LRU должен вытеснять наименее востребованные из них, предотвращая полный крах памяти, если только поток новых уникальных User-Agent не является непрерывным (атака ботов).6  
Эта проблема чаще проявляется как низкий Hit Rate, а не как бесконечный рост памяти, так как вариации являются частью одного объекта (hash), и их жизненный цикл связан.37

## **Вердикт**

Проведенный комплексный анализ ситуации, описанной клиентом ꆜ (проект P⁎), позволяет с высокой степенью уверенности идентифицировать причины нестабильности Varnish Cache.  
Ситуация классифицируется как мультифакторная проблема, где архитектурные особенности проекта накладываются на дефолтное поведение программного обеспечения и аппаратные нюансы.  
**Основные причины (P†):**

1. **Высокая кардинальность и рекламный трафик (Cᛘ₁ + Cᛘ₂):** Это доминирующий фактор. Комбинация фасетных фильтров и рекламных меток (gclid, utm) создает миллионы уникальных URL.  
   * Каждый уникальный URL порождает объект метаданных (overhead ~1KB), потребляющий память вне основного хранилища (-s malloc).  
   * Каждый рекламный переход с установкой Set-Cookie порождает объект hit-for-miss в **неограниченном** (unbounded) временном хранилище (Transient Storage).  
   * Это объясняет жалобу «changes in config haven't helped» — клиент ограничивает основной кэш, но утечка происходит через метаданные и Transient.  
2. **Проблемы аллокации и фрагментации (Cᛘ₃):** Использование системного аллокатора glibc (стандарт для Amazon Linux/RHEL) вместо рекомендованного jemalloc приводит к фрагментации памяти.  
   * Это создает видимость утечки (рост RSS), так как освобожденная память не возвращается ОС.  
   * На архитектуре Graviton (ARM64) glibc может работать менее эффективно из-за особенностей синхронизации.  
3. **Аппаратная неэффективность (Cᛘ₄):** Использование страниц памяти 4 КБ на 32 ГБ RAM для ARM64 создает высокую нагрузку на TLB, что является прямой причиной «performance degradation» и задержек в обработке памяти.

**Стратегия устранения (Action Plan):**

1. **VCL Нормализация (Critical):**  
   * Внедрить агрессивную очистку req.url в vcl_recv. Необходимо удалять все метки отслеживания (gclid, fbclid, utm_*) *до* хэширования.  
   * Использовать std.querysort(req.url) для нормализации порядка параметров фильтров.  
   * Пример:  
     Code snippet  
     import std;  
     sub vcl_recv {  
         # Удаление Google Analytics и других меток  
         set req.url = regsuball(req.url, "(?|&)(gclid|utm_[a-z]+|fbclid)=[-_A-z0-9+()%.]+&?", "");  
         set req.url = regsub(req.url, "[?|&]+$", "");  
         # Сортировка параметров  
         set req.url = std.querysort(req.url);  
     }

2. **Ограничение Transient Storage (Critical):**  
   * Изменить параметры запуска varnishd, явно ограничив временное хранилище.  
   * Добавить: -s Transient=malloc,2G (или другое разумное значение, например 10-15% от RAM). Это предотвратит OOM при атаках или всплесках hit-for-miss.  
3. **Оптимизация Аллокатора (High):**  
   * Убедиться, что используется jemalloc.  
   * Для Amazon Linux 2/2023: установить пакет jemalloc (dnf install jemalloc) и настроить systemd unit для Varnish, добавив Environment="LD_PRELOAD=/usr/lib64/libjemalloc.so.2".  
   * Это снизит фрагментацию и стабилизирует потребление памяти.  
4. **Тюнинг Graviton (Medium/High):**  
   * Если используется Amazon Linux 2023 или RHEL 9, рассмотреть установку ядра kernel-64k.  
   * Это существенно снизит TLB misses и повысит общую отзывчивость системы при работе с большими объемами кэша.  
5. **Мониторинг:**  
   * Настроить отслеживание метрик SMA.Transient.c_bytes, SMA.s0.g_bytes, MAIN.n_object, MAIN.n_vampireobject.  
   * Это позволит подтвердить теорию о том, какое именно хранилище растет.

#### **Works cited**

1. Varnish Explained - Mattias Geniar, accessed December 11, 2025, [https://ma.ttias.be/varnish-explained/](https://ma.ttias.be/varnish-explained/)  
2. PSA: You don't need that many regexes - Resources - Varnish Software, accessed December 11, 2025, [https://info.varnish-software.com/blog/psa-you-dont-need-that-many-regexes](https://info.varnish-software.com/blog/psa-you-dont-need-that-many-regexes)  
3. Strip query parameters with Varnish | by Danila Vershinin - Medium, accessed December 11, 2025, [https://medium.com/@getpagespeed/strip-query-parameters-with-varnish-bf3cb2877530](https://medium.com/@getpagespeed/strip-query-parameters-with-varnish-bf3cb2877530)  
4. How to strip UTM tags in Varnish without stripping queries I want? - Stack Overflow, accessed December 11, 2025, [https://stackoverflow.com/questions/75871726/how-to-strip-utm-tags-in-varnish-without-stripping-queries-i-want](https://stackoverflow.com/questions/75871726/how-to-strip-utm-tags-in-varnish-without-stripping-queries-i-want)  
5. Stripping out select querystring attribute/value pairs so varnish will not vary cache by them, accessed December 11, 2025, [https://stackoverflow.com/questions/13144172/stripping-out-select-querystring-attribute-value-pairs-so-varnish-will-not-vary](https://stackoverflow.com/questions/13144172/stripping-out-select-querystring-attribute-value-pairs-so-varnish-will-not-vary)  
6. Sizing your cache — Varnish version 6.0.16 documentation, accessed December 11, 2025, [https://varnish-cache.org/docs/6.0/users-guide/sizing-your-cache.html](https://varnish-cache.org/docs/6.0/users-guide/sizing-your-cache.html)  
7. Understanding Varnish Cache Memory Usage - Resources, accessed December 11, 2025, [https://info.varnish-software.com/blog/understanding-varnish-cache-memory-usage](https://info.varnish-software.com/blog/understanding-varnish-cache-memory-usage)  
8. arbal/awesome-stars: Top 18K of GitHub's finest., accessed December 11, 2025, [https://github.com/arbal/awesome-stars](https://github.com/arbal/awesome-stars)  
9. Assert in HSH_Lookup with Varnish 7.2.1 · Issue #3879 - GitHub, accessed December 11, 2025, [https://github.com/varnishcache/varnish-cache/issues/3879](https://github.com/varnishcache/varnish-cache/issues/3879)  
10. Example VCL template - Varnish Developer Portal, accessed December 11, 2025, [https://www.varnish-software.com/developers/tutorials/example-vcl-template/](https://www.varnish-software.com/developers/tutorials/example-vcl-template/)  
11. Varnish VCL "Symbol not found: std.querysort" - Stack Overflow, accessed December 11, 2025, [https://stackoverflow.com/questions/36012266/varnish-vcl-symbol-not-found-std-querysort](https://stackoverflow.com/questions/36012266/varnish-vcl-symbol-not-found-std-querysort)  
12. Hashing — Varnish version trunk documentation, accessed December 11, 2025, [https://varnish-cache.org/docs/trunk/users-guide/vcl-hashing.html](https://varnish-cache.org/docs/trunk/users-guide/vcl-hashing.html)  
13. Configuring Varnish for Magento - Varnish Developer Portal, accessed December 11, 2025, [https://www.varnish-software.com/developers/tutorials/configuring-varnish-magento/](https://www.varnish-software.com/developers/tutorials/configuring-varnish-magento/)  
14. Varnish memory usage keeps increasing - Stack Overflow, accessed December 11, 2025, [https://stackoverflow.com/questions/76209998/varnish-memory-usage-keeps-increasing](https://stackoverflow.com/questions/76209998/varnish-memory-usage-keeps-increasing)  
15. Introduction | HAProxy Enterprise 3.0r1, accessed December 11, 2025, [https://www.haproxy.com/documentation/haproxy-configuration-manual/new/3-0r1/intro/](https://www.haproxy.com/documentation/haproxy-configuration-manual/new/3-0r1/intro/)  
16. Two-Minute Tech Tuesdays - Memory Governor - Resources - Varnish Software, accessed December 11, 2025, [https://info.varnish-software.com/blog/two-minute-tech-tuesdays-memory-governor](https://info.varnish-software.com/blog/two-minute-tech-tuesdays-memory-governor)  
17. 4 Varnish Enterprise Features That Will Improve the Caching of Your Magento Store, accessed December 11, 2025, [https://info.varnish-software.com/blog/4-varnish-enterprise-features-that-will-improve-the-caching-of-your-magento-store](https://info.varnish-software.com/blog/4-varnish-enterprise-features-that-will-improve-the-caching-of-your-magento-store)  
18. varnish-book.pdf - HubSpot, accessed December 11, 2025, [https://cdn2.hubspot.net/hubfs/209523/The_Varnish_Book/varnish-book.pdf](https://cdn2.hubspot.net/hubfs/209523/The_Varnish_Book/varnish-book.pdf)  
19. Command line utilities - Lib.rs, accessed December 11, 2025, [https://lib.rs/command-line-utilities](https://lib.rs/command-line-utilities)  
20. Varnish Using Significantly More Memory than Cache? - Stack Overflow, accessed December 11, 2025, [https://stackoverflow.com/questions/78379910/varnish-using-significantly-more-memory-than-cache](https://stackoverflow.com/questions/78379910/varnish-using-significantly-more-memory-than-cache)  
21. varnish-counters — Varnish version trunk documentation, accessed December 11, 2025, [https://varnish-cache.org/docs/trunk/reference/varnish-counters.html](https://varnish-cache.org/docs/trunk/reference/varnish-counters.html)  
22. Transient storage killing memory - Varnish Cache, accessed December 11, 2025, [https://varnish-cache.org/lists/pipermail/varnish-misc/2016-November/025451.html](https://varnish-cache.org/lists/pipermail/varnish-misc/2016-November/025451.html)  
23. careful selection of hitpass vs hitmiss · Issue #2865 · varnishcache/varnish-cache - GitHub, accessed December 11, 2025, [https://github.com/varnishcache/varnish-cache/issues/2865](https://github.com/varnishcache/varnish-cache/issues/2865)  
24. Upgrading to Varnish 7.0, accessed December 11, 2025, [https://varnish-cache.org/docs/7.0/whats-new/upgrading-7.0.html](https://varnish-cache.org/docs/7.0/whats-new/upgrading-7.0.html)  
25. Concurrent large allocations: glibc malloc, jemalloc and tcmalloc - Small Datum, accessed December 11, 2025, [http://smalldatum.blogspot.com/2017/11/concurrent-large-allocations-glibc.html](http://smalldatum.blogspot.com/2017/11/concurrent-large-allocations-glibc.html)  
26. CPU and memory usage of jemalloc as compared to glibc malloc - Stack Overflow, accessed December 11, 2025, [https://stackoverflow.com/questions/13027475/cpu-and-memory-usage-of-jemalloc-as-compared-to-glibc-malloc](https://stackoverflow.com/questions/13027475/cpu-and-memory-usage-of-jemalloc-as-compared-to-glibc-malloc)  
27. Red Hat Enterprise Linux 10 10.1 Release Notes, accessed December 11, 2025, [https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/10/pdf/10.1_release_notes/%3Ctba%3E](https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/10/pdf/10.1_release_notes/%3Ctba%3E)  
28. Newest 'jemalloc' Questions - Stack Overflow, accessed December 11, 2025, [https://stackoverflow.com/questions/tagged/jemalloc?tab=Newest](https://stackoverflow.com/questions/tagged/jemalloc?tab=Newest)  
29. jemalloc vs glibc malloc: Memory Allocation Performance Comparison | by Binita Bharati, accessed December 11, 2025, [https://medium.com/@binitabharati/jemalloc-vs-glibc-malloc-memory-allocation-performance-comparison-fbaeda1740de](https://medium.com/@binitabharati/jemalloc-vs-glibc-malloc-memory-allocation-performance-comparison-fbaeda1740de)  
30. Tuning Varnish, accessed December 11, 2025, [https://docs.varnish-software.com/book/operations/tuning-varnish/](https://docs.varnish-software.com/book/operations/tuning-varnish/)  
31. Install Varnish Cache For Wordpress - Apache - Amazon Linux - Blog - Lawrence McDaniel, accessed December 11, 2025, [https://blog.lawrencemcdaniel.com/install-varnish-cache-on-amazon-linux/](https://blog.lawrencemcdaniel.com/install-varnish-cache-on-amazon-linux/)  
32. Understanding Memory Page Sizes on Arm64 - SitePoint, accessed December 11, 2025, [https://www.sitepoint.com/memory-page-sizes-on-arm64/](https://www.sitepoint.com/memory-page-sizes-on-arm64/)  
33. Chapter 2. The 64k page size kernel | Managing, monitoring, and updating the kernel | Red Hat Enterprise Linux | 9, accessed December 11, 2025, [https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9/html/managing_monitoring_and_updating_the_kernel/what-is-kernel-64k_managing-monitoring-and-updating-the-kernel](https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9/html/managing_monitoring_and_updating_the_kernel/what-is-kernel-64k_managing-monitoring-and-updating-the-kernel)  
34. 64K Kernel Page Size Performance Benefits For HPC Shown With NVIDIA's GH200 Grace CPU - Phoronix, accessed December 11, 2025, [https://www.phoronix.com/review/aarch64-64k-kernel-perf](https://www.phoronix.com/review/aarch64-64k-kernel-perf)  
35. 64K Memory page sizes - any experiences to share? - General Discussion, accessed December 11, 2025, [https://community.amperecomputing.com/t/64k-memory-page-sizes-any-experiences-to-share/2730](https://community.amperecomputing.com/t/64k-memory-page-sizes-any-experiences-to-share/2730)  
36. Setup Docker on Amazon Linux 2023 - GitHub Gist, accessed December 11, 2025, [https://gist.github.com/thimslugga/36019e15b2a47a48c495b661d18faa6d?permalink_comment_id=5057205](https://gist.github.com/thimslugga/36019e15b2a47a48c495b661d18faa6d?permalink_comment_id=5057205)  
37. Purging and banning — Varnish version 4.0.5 documentation, accessed December 11, 2025, [https://varnish-cache.org/docs/4.0/users-guide/purging.html](https://varnish-cache.org/docs/4.0/users-guide/purging.html)  
38. Varnish Administrator documentation - Read the Docs, accessed December 11, 2025, [https://readthedocs.org/projects/varnish-cache/downloads/pdf/readthedocs/](https://readthedocs.org/projects/varnish-cache/downloads/pdf/readthedocs/)  
39. Removing cookies in Varnish - Varnish Developer Portal, accessed December 11, 2025, [https://www.varnish-software.com/developers/tutorials/removing-cookies-varnish/](https://www.varnish-software.com/developers/tutorials/removing-cookies-varnish/)

# 19.
## 19.1.
`Mᚖ⠿` ≔ ⠿~ (Способы устранения `P†`)

## 19.2.
`Mᚖᵢ` : `Mᚖ⠿`

# 20. Анализ `Mᚖ⠿` (выполнен Gemini Deep Think)
https://gemini.google.com/share/787b519b6c5c

## Mᚖ₁: Агрессивная нормализация запросов и заголовков (VCL Sanitization)

### Суть
Данный метод заключается во внедрении в процедуру `vcl_recv` строгой логики очистки `req.url` от маркетинговых меток (gclid, fbclid, utm_*) и уникальных идентификаторов сессий перед вычислением хэша.
Для реализации необходимо использовать модуль `vmod_std` (функция `std.querysort`) или `vmod_querystring` для алфавитной сортировки параметров запроса, что приводит их к каноническому виду.
Дополнительно требуется нормализовать заголовок `User-Agent` до ограниченного набора групп (например, mobile/desktop) и удалять заголовок `Cookie` для статических ресурсов.
Это действие предотвращает комбинаторный взрыв кэша («Cache Bloat»), превращая миллионы потенциальных дубликатов в единичные экземпляры объектов в памяти.
Метод устраняет первопричину генерации избыточных метаданных, которые неявно потребляют оперативную память сверх установленного лимита хранилища.

### Оценка
100

### Достоинства
Метод устраняет фундаментальную причину исчерпания памяти, останавливая бесконечную генерацию накладных расходов (overhead) на метаданные объектов.
Реализация не требует изменения аппаратной конфигурации, установки системных пакетов или перезагрузки сервера, так как выполняется на уровне VCL.
Значительно повышается коэффициент попадания в кэш (Hit Rate), поскольку пользователи с разными рекламными метками получают один и тот же кэшированный объект.
Удаление уникальных параметров предотвращает массовое создание записей `hit-for-miss` в транзитном хранилище, снижая риск его переполнения.
Нормализация снижает нагрузку на бэкенд, так как идентичные по сути запросы перестают считаться уникальными.

### Недостатки
Некорректная настройка регулярных выражений может привести к случайному удалению функционально важных параметров фильтрации, нарушив работу сайта.
Требуется глубокое понимание бизнес-логики приложения и аудит всех используемых параметров для формирования безопасных списков исключений.
Сортировка параметров добавляет незначительные вычислительные накладные расходы на каждый запрос в фазе `vcl_recv`.
Изменения вступают в силу только для новых запросов и не очищают мгновенно уже существующий мусор в кэше без полного перезапуска.

## Mᚖ₂: Явное ограничение временного хранилища (Transient Storage Bounding)

### Суть
Метод предполагает изменение параметров запуска демона `varnishd` путем добавления явного флага `-s Transient=malloc,SIZE` (например, `-s Transient=malloc,2G`).
В стандартной конфигурации Varnish использует для временных объектов (hit-for-miss, shortlived) неограниченное хранилище, которое при атаках или сбоях занимает всю доступную память.
Установка жесткого лимита заставляет Varnish применять алгоритм вытеснения (LRU) к временным объектам при достижении порога, вместо аллокации новых страниц памяти.
Это создает гарантированный аварийный барьер, предотвращающий падение сервера (OOM) даже при шквале запросов с `Set-Cookie` или уникальными параметрами.
Метод компенсирует архитектурную уязвимость Varnish, связанную с `unbounded` природой транзитного хранилища по умолчанию.

### Оценка
98

### Достоинства
Это единственная гарантированная защита от исчерпания физической памяти в сценариях, когда бэкенд или трафик массово генерируют некэшируемые ответы.
Метод обеспечивает предсказуемость потребления ресурсов процессом Varnish, четко разделяя память на основной кэш и технический буфер.
Реализация требует минимальных усилий по правке файла сервиса systemd и не зависит от сложности кода VCL.
Защита работает автономно и спасает сервер даже в случае ошибок конфигурации на стороне веб-приложения или бэкенда.
Позволяет избежать ситуации «Thundering Herd» при перезапуске, сохраняя работоспособность при заполненном транзитном буфере.

### Недостатки
Установка слишком малого лимита может привести к преждевременному удалению записей `hit-for-miss`, что вызовет увеличение нагрузки на бэкенд.
Метод является средством сдерживания последствий, а не устранения причины возникновения паразитного трафика.
Для применения настройки требуется перезапуск процесса Varnish, что влечет за собой сброс всего накопленного кэша.
Необходимо экспериментально подобрать оптимальный размер хранилища, исходя из профиля трафика и размера передаваемых объектов.

## Mᚖ₃: Замена системного аллокатора на jemalloc (Allocator Swap)

### Суть
Данный метод заключается в принудительном переводе процесса `varnishd` на использование библиотеки `jemalloc` вместо стандартного системного аллокатора `glibc`.
Это достигается путем установки пакета `jemalloc` и настройки переменной окружения `LD_PRELOAD` или параметров линковки в unit-файле systemd.
Аллокатор `jemalloc` использует эффективные алгоритмы управления памятью (арены, классы размеров), минимизируя внешнюю фрагментацию кучи в многопоточных приложениях.
Особенно критично это решение для архитектуры ARM64 (AWS Graviton), где стандартный аллокатор `glibc` демонстрирует низкую эффективность утилизации памяти.
Метод устраняет разрыв между потреблением памяти, фиксируемым Varnish, и реальным резидентным размером процесса (RSS).

### Оценка
90

### Достоинства
Метод радикально снижает уровень фрагментации памяти, освобождая от 20% до 40% RAM, которая ранее терялась в «дырах» кучи.
Устраняется ложная диагностика «утечки памяти», делая мониторинг ресурсов прозрачным и понятным.
Повышается общая производительность системы и снижается нагрузка на CPU за счет уменьшения конкуренции за блокировки (lock contention).
Является официально рекомендованной практикой («Best Practice») от разработчиков Varnish Software для высоконагруженных систем.
Решает проблему на низком системном уровне, работая прозрачно для любой конфигурации VCL.

### Недостатки
Требует вмешательства в системные зависимости и конфигурацию загрузки сервиса, что сложнее правки VCL.
В дистрибутивах типа Amazon Linux 2023 пакет может требовать подключения дополнительных репозиториев (EPEL) или ручной сборки.
Эффект стабилизации памяти проявляется на длительной дистанции работы процесса, а не мгновенно.
Существует небольшой риск несовместимости с конкретными версиями библиотек ОС, требующий предварительного тестирования.

## Mᚖ₄: Корректировка лимитов основного хранилища (Headroom Adjustment)

### Суть
Метод подразумевает уменьшение значения параметра `-s malloc,SIZE` до уровня, оставляющего достаточный запас (headroom) для метаданных и операционных расходов.
Для сервера с 32 ГБ RAM безопасным значением является 18-20 ГБ, а не 25-28 ГБ, как часто ошибочно устанавливают администраторы.
Расчет должен учитывать формулу: RAM минус резерв ОС, минус лимит Transient, минус память под метаданные (1 КБ на объект).
Это действие устраняет самообман администратора, полагающего, что параметр `-s` контролирует абсолютно всё потребление памяти процесса.
Метод гарантирует наличие свободной памяти для стеков потоков и служебных структур ядра Varnish.

### Оценка
85

### Достоинства
Предотвращает срабатывание OOM Killer в штатном режиме работы за счет честного учета всех потребителей памяти внутри процесса.
Является неинвазивным методом, который реализуется изменением одной цифры в конфигурации запуска без установки ПО.
Позволяет системе работать стабильно даже в моменты пиковых нагрузок по количеству объектов, амортизируя рост накладных расходов.
Обеспечивает пространство для маневра при временном увеличении потребления памяти рабочими пространствами (workspace).
Простота реализации позволяет быстро применить меру как временное решение для стабилизации.

### Недостатки
Уменьшается объем полезной памяти, доступной для хранения контента, что может незначительно снизить Hit Rate.
Это пассивная мера, которая не решает проблемы утечек или фрагментации, а лишь отодвигает момент сбоя.
Без устранения `Cache Bloat` свободное место в «запасе» все равно будет быстро заполнено метаданными миллионов мусорных объектов.
Требует перезапуска сервиса для применения новых лимитов.

## Mᚖ₅: Оптимизация размера страниц ядра (Kernel 64k Pages)

### Суть
Способ заключается в миграции операционной системы на ядро, скомпилированное с поддержкой страниц памяти размером 64 КБ (вместо стандартных 4 КБ) на архитектуре AWS Graviton.
Использование страниц 64 КБ на ARM64 значительно снижает нагрузку на буфер ассоциативной трансляции (TLB) процессора при работе с большими объемами памяти.
Это уменьшает количество промахов TLB (TLB misses) и сокращает накладные расходы операционной системы на управление таблицами страниц.
Метод направлен на устранение аппаратных узких мест производительности, упоминаемых в задаче как «performance degradation».
Оптимизация позволяет процессору тратить больше времени на обработку запросов, а не на обслуживание памяти.

### Оценка
65

### Достоинства
Обеспечивает аппаратное ускорение операций с памятью, повышая общую отзывчивость системы и пропускную способность.
Снижает системные накладные расходы (system CPU time), освобождая ресурсы процессора для приложения.
Является официальной рекомендацией AWS для высоконагруженных приложений с интенсивным использованием памяти на Graviton.
Может косвенно уменьшить фрагментацию на уровне ядра ОС за счет более крупной гранулярности аллокаций.
Повышает эффективность работы с большими непрерывными блоками памяти.

### Недостатки
Требует замены ядра операционной системы и перезагрузки сервера, что является сложной административной процедурой.
Может незначительно увеличить потребление памяти из-за внутренней фрагментации (когда маленькие файлы занимают целую страницу 64 КБ).
Не решает проблему логического исчерпания памяти из-за дубликатов кэша или `Transient` хранилища напрямую.
Существует риск несовместимости с инструментами мониторинга, жестко завязанными на размер страницы 4 КБ.

## Вердикт
Проблема `P†` является результатом системного взаимодействия трёх факторов: **Cache Bloat** (взрывной рост объектов), **неограниченного транзитного хранилища** и **фрагментации памяти** на ARM64.
Клиент `ꆜ` ошибочно интерпретирует штатное поведение системы как утечку памяти, пытаясь лечить симптомы, а не причину.
Наивысший приоритет имеет внедрение **`Mᚖ₁`**, так как без нормализации запросов генерация мусорных объектов будет продолжать истощать ресурсы сервера.
Для обеспечения эксплуатационной надежности необходимо обязательно применить **`Mᚖ₂`** и **`Mᚖ₄`**, создав жесткие рамки потребления памяти.
Учитывая использование платформы Graviton, настоятельно рекомендуется внедрение **`Mᚖ₃`** для устранения неэффективности системного аллокатора.
Рекомендуется реализовать комплекс из методов `Mᚖ₁`, `Mᚖ₂`, `Mᚖ₃` и `Mᚖ₄` для полного и окончательного устранения проблемы.

# 21. Анализ `Mᚖ⠿` (выполнен экземпляром №1 Gemini Deep Research)
https://gemini.google.com/share/7c393b061bd6


**M1: Переход на страницы памяти размером 64 КБ (64k Page Size)**

### **7.2.1) Суть**

Фундаментальная проблема управления памятью на архитектуре ARM64 в контексте высоконагруженных приложений, интенсивно работающих с памятью, заключается в неэффективности использования стандартных страниц памяти размером 4 КБ.2  
Процессор AWS Graviton использует блок управления памятью (MMU), который транслирует виртуальные адреса, используемые приложением (Varnish), в физические адреса оперативной памяти, используя для этого таблицу страниц (page table).2  
Для ускорения этого процесса процессоры используют буфер ассоциативной трансляции (TLB — Translation Lookaside Buffer), который кэширует последние использованные трансляции адресов, однако размер этого буфера аппаратно ограничен.2  
При использовании страниц размером 4 КБ и общем объёме памяти 32 ГБ, количество записей в таблице страниц становится огромным, что приводит к быстрому переполнению TLB и частым промахам (TLB misses).2  
Каждый промах TLB вынуждает процессор выполнять дорогостоящую операцию «прогулки по таблице страниц» (page table walk), что не только снижает производительность CPU, но и увеличивает латентность доступа к памяти.2  
В контексте Varnish, который использует аллокатор jemalloc, малый размер страницы приводит к тому, что аллокатор вынужден дробить память на мелкие чанки, что увеличивает метаданные аллокатора и способствует фрагментации адресного пространства.4  
Суть предлагаемого решения M1 заключается в переключении ядра операционной системы Linux на использование страниц памяти размером 64 КБ, что поддерживается архитектурой ARMv8.2+ и процессорами Graviton.2  
Использование страниц 64 КБ уменьшает количество записей в таблице страниц в 16 раз по сравнению со стандартом 4 КБ, что радикально снижает давление на TLB и повышает вероятность попадания в кэш трансляции адресов.2  
Это изменение позволяет jemalloc (системному аллокатору памяти Varnish) выделять память более крупными, естественными для архитектуры блоками, что снижает внутреннюю фрагментацию и упрощает управление свободными блоками.5  
Реализация данного решения требует установки специализированного ядра (например, kernel-64k в Amazon Linux 2023 или RHEL) или использования AMI, предварительно настроенного на работу с 64k pages.2  
Данный подход является инфраструктурной оптимизацией, которая действует прозрачно для прикладного программного обеспечения: Varnish не требует перекомпиляции, так как jemalloc определяет размер страницы во время выполнения через системный вызов sysconf(_SC_PAGESIZE).5  
Тесты производительности, проведённые инженерными командами AWS и сообществом, демонстрируют прирост производительности до 30% и значительную стабилизацию потребления памяти для приложений класса in-memory cache на инстансах Graviton.2  
Переход на 64k pages также улучшает эффективность операций ввода-вывода и прямого доступа к памяти (DMA), так как за одну операцию передаётся больший блок данных, снижая количество прерываний.2  
Это решение устраняет корневую причину неэффективности подсистемы памяти на аппаратном уровне, создавая прочный фундамент для дальнейших оптимизаций на уровне приложения.  
Для Amazon Linux 2023 процедура включает установку пакета kernel-64k, обновление конфигурации загрузчика GRUB и перезагрузку инстанса, что является стандартной административной процедурой.2

### **7.2.2) Оценка**

95

### **7.2.3) Достоинства**

Главным стратегическим преимуществом данного метода является устранение фундаментального архитектурного несоответствия между аппаратной платформой ARM64 и настройками ОС по умолчанию, что обеспечивает долгосрочную стабильность системы.2  
Решение обеспечивает комплексное повышение производительности всей системы, снижая нагрузку на CPU (system time) за счёт уменьшения количества операций по управлению страницами памяти (page faults).15  
Значительное снижение фрагментации памяти достигается автоматически, так как аллокатор получает возможность оперировать блоками, соответствующими физической гранулярности памяти, что уменьшает количество "неиспользуемых дыр" в адресном пространстве.4  
Внедрение этого решения не требует внесения изменений в логику работы Varnish (VCL), что исключает риск появления логических ошибок или регрессий в обработке HTTP-запросов.2  
Решение официально поддерживается и рекомендуется компанией AWS для рабочих нагрузок типа "базы данных и кэши" на процессорах Graviton, что гарантирует наличие обновлений безопасности и совместимости.18  
Увеличение размера страницы способствует более эффективному использованию кэша инструкций и данных процессора (L1/L2 cache) благодаря лучшей локальности данных.2  
Стабилизация латентности (jitter) является важным побочным эффектом, критичным для высоконагруженного веб-ресурса, где важна предсказуемость времени ответа.20  
Масштабируемость решения абсолютна: оно будет работать ещё эффективнее при возможном будущем увеличении объёма RAM или переходе на более мощные инстансы (например, R8g).17  
Снижается вероятность срабатывания OOM Killer из-за фрагментации, когда система видит свободную память, но не может выделить непрерывный блок нужного размера.8

### **7.2.4) Недостатки**

Основным операционным недостатком является необходимость перезагрузки сервера (reboot) для смены ядра, что неизбежно влечёт за собой временную недоступность сервиса или требует сложной процедуры переключения трафика (failover).2  
Процесс установки нестандартного ядра (kernel-64k) в некоторых дистрибутивах Linux может быть нетривиальным и требовать внимательного разрешения зависимостей пакетов, особенно если используются проприетарные драйверы или модули ядра.16  
Существует теоретический риск увеличения потребления памяти (memory footprint) для процессов, оперирующих огромным количеством очень маленьких файлов (менее 64 КБ), из-за эффекта "внутренней фрагментации страницы", когда файл занимает полную страницу.3  
Не все инструменты мониторинга и отладки (особенно устаревшие или проприетарные агенты) могут корректно интерпретировать метрики памяти на системе с нестандартным размером страницы, что может потребовать обновления инструментария.16  
В случае возникновения проблем откат изменений (rollback) также потребует перезагрузки и манипуляций с загрузчиком, что увеличивает время восстановления (RTO).2  
На Amazon Linux 2023 пакеты ядра 64k могут иметь иной график обновлений безопасности по сравнению со стандартным ядром, что требует дополнительного внимания со стороны службы безопасности.16  
Решение является "всё или ничего": невозможно применить страницы 64 КБ только к процессу Varnish, это глобальная настройка операционной системы, влияющая на все запущенные сервисы.3

## ---

**M2: Ограничение размера транзитного хранилища (Transient Storage)**

### **7.2.1) Суть**

В архитектуре Varnish Cache существует специальный механизм хранения объектов, именуемый Transient Storage, который предназначен для содержания объектов с очень коротким временем жизни (short-lived objects).10  
Varnish автоматически классифицирует объект как "транзитный", если его вычисленное время жизни (TTL + grace + keep) меньше значения параметра shortlived, который по умолчанию составляет 10 секунд.10  
Критически важно, что транзитное хранилище также используется для временного хранения объектов, создаваемых в результате решений hit-for-miss (когда Varnish запоминает, что запрос нельзя кэшировать) и hit-for-pass.13  
По умолчанию Varnish не накладывает никаких ограничений на объём памяти, который может использовать Transient Storage, и применяет для него стандартный бэкенд malloc, который запрашивает память у системы по мере необходимости.10  
Это поведение создаёт серьезную уязвимость: в случае атаки или всплеска трафика с уникальными, некэшируемыми запросами (например, рандомизированные query-параметры), транзитное хранилище начинает бесконтрольно расти, потребляя всю доступную оперативную память.22  
Поскольку транзитные объекты часто создаются для каждого уникального запроса, приводящего к промаху мимо кэша, их количество может исчисляться миллионами, и каждый из них потребляет минимум 1 КБ накладных расходов памяти.1  
Суть решения M2 заключается в явном ограничении размера транзитного хранилища путём задания параметра запуска демона varnishd с флагом -s Transient=malloc,SIZE (например, -s Transient=malloc,2G).11  
Установка жесткого лимита переводит транзитное хранилище из режима "бесконечного роста" в режим "кольцевого буфера" с вытеснением: при достижении лимита Varnish начинает принудительно удалять (nuke) самые старые транзитные объекты, чтобы освободить место для новых.11  
Это действие гарантирует, что даже при самых неблагоприятных сценариях нагрузки объём памяти, занятый служебными транзитными объектами, никогда не превысит заданного администратором значения.8  
Для применения этого изменения необходимо отредактировать файл конфигурации systemd (обычно через systemctl edit varnish) или параметры командной строки в /etc/varnish/varnish.params (в зависимости от дистрибутива) и перезапустить сервис.25  
Это решение является критически важным предохранителем (safety net), который защищает процесс Varnish от аварийного завершения системой (OOM Kill) и обеспечивает предсказуемость потребления ресурсов.8  
В дополнение к лимитированию, рекомендуется мониторить счётчик SMA.Transient.g_bytes и n_lru_nuked, чтобы оценивать, насколько часто происходит вытеснение, и при необходимости корректировать размер лимита.26

### **7.2.2) Оценка**

90

### **7.2.3) Достоинства**

Данный метод обеспечивает математически гарантированную защиту от исчерпания памяти (Out Of Memory) по вине транзитных объектов, что является одной из самых частых причин падения Varnish.11  
Реализация решения предельно проста и требует изменения всего одной строки в конфигурации запуска, что делает его доступным для немедленного внедрения.25  
Введение лимита заставляет Varnish агрессивно очищать память от устаревших записей о промахах (hit-for-miss), предотвращая накопление бесполезных данных, которые могли бы висеть в памяти часами.26  
Позволяет системным администраторам точно планировать аллокацию памяти на сервере, чётко разделяя бюджет памяти между основным кэшем (Main Storage) и транзитным буфером.1  
Повышает устойчивость системы к DDoS-атакам уровня приложений (Layer 7), направленным на переполнение кэша случайными запросами (random query string attack).28  
Устраняет риск того, что транзитное хранилище начнет конкурировать за память с основным хранилищем кэша, что могло бы привести к преждевременному вытеснению полезного контента.8  
Обеспечивает стабильность работы даже в условиях некорректной настройки бэкенда, когда приложение начинает генерировать множество некэшируемых ответов с разными заголовками Vary.6

### **7.2.4) Недостатки**

Если установленный лимит транзитного хранилища окажется слишком мал для текущего профиля нагрузки, это может привести к невозможности обработки больших некэшируемых ответов, если не включен механизм потоковой передачи (streaming).25  
При частом достижении лимита и агрессивном вытеснении (nuking) объектов hit-for-miss, Varnish может "забыть", что определённый запрос нельзя кэшировать, и снова отправить запрос на бэкенд, увеличивая нагрузку на базу данных (request coalescing breakdown).26  
Подбор оптимального размера лимита требует эмпирического анализа метрик: слишком маленький лимит вызовет ошибки, слишком большой — оставит риск OOM.25  
В старых версиях Varnish или при определённых настройках, переполнение транзитного хранилища могло приводить к ошибкам 503 (Service Unavailable) для клиентов, чьи запросы требовали создания транзитного объекта.25  
Решение борется со следствием проблемы (ростом памяти), а не с её причиной (появлением избыточного количества транзитных объектов), поэтому оно должно применяться только в комплексе с оптимизацией VCL.22  
Необходимо настроить отдельный мониторинг для SMA.Transient, так как стандартные дашборды часто показывают только общее потребление памяти, скрывая проблему переполнения транзитного буфера.26

## ---

**M3: Нормализация заголовка User-Agent (Снижение кардинальности)**

### **7.2.1) Суть**

Заголовок HTTP-запроса User-Agent (UA) исторически является источником огромной энтропии (вариативности) в веб-трафике, содержа детальную информацию о браузере, операционной системе, версии движка и модели устройства.6  
Современные браузеры и боты генерируют тысячи уникальных строк UA, отличающихся лишь минорными версиями билдов (например, Chrome/120.0.6099.109 vs Chrome/120.0.6099.110), что не влияет на отображение контента, но критично для кэширования.6  
Если конфигурация Varnish (VCL) или бэкенд-приложение (через заголовок Vary: User-Agent) инструктируют кэш сохранять разные версии страницы для разных UA, Varnish создаёт отдельный объект в памяти для каждой уникальной строки.6  
Это явление, известное как «комбинаторный взрыв кэша» (cache variation explosion), приводит к тому, что вместо одной копии страницы в памяти хранятся тысячи её дубликатов, каждый из которых потребляет 1 КБ на метаданные плюс объём самого контента.1  
В контексте RunRepeat.com, где пользователи заходят с множества мобильных и десктопных устройств, отсутствие нормализации UA является одной из главных причин неэффективного использования памяти.7  
Суть решения M3 заключается в принудительной нормализации заголовка User-Agent на ранней стадии обработки запроса (vcl_recv) путём приведения его к ограниченному набору значений (buckets), например: mobile, tablet, desktop, bot.29  
Для реализации используется логика VCL, применяющая регулярные выражения (regex) или специализированные модули (VMOD, например devicedetect), чтобы определить класс устройства и перезаписать заголовок.30  
Нормализованный заголовок (часто сохраняемый как X-UA-Device) затем используется для формирования хэша кэширования (vcl_hash) и в логике Vary, что позволяет схлопнуть тысячи вариаций в 2-3 физических объекта в памяти.29  
Важным аспектом является также очистка заголовка Vary в ответе бэкенда (vcl_backend_response): если бэкенд по-прежнему присылает Vary: User-Agent, Varnish должен заменить его на Vary: X-UA-Device, чтобы нормализация сработала корректно.32  
Для предотвращения проблем с downstream-кэшами (CDN, браузеры), в процедуре vcl_deliver нормализованный заголовок Vary часто восстанавливается или маскируется, чтобы внешние системы не получали неправильный контент.29  
Это решение позволяет освободить гигабайты оперативной памяти, ранее занятой дубликатами, и значительно повысить коэффициент попадания в кэш (hit rate), так как пользователи с разными версиями одного браузера теперь получают общий кэшированный объект.29

### **7.2.2) Оценка**

85

### **7.2.3) Достоинства**

Метод обеспечивает радикальное снижение количества объектов в кэше (кардинальности), что напрямую трансформируется в освобождение значительного объёма оперативной памяти.1  
Существенно повышается эффективность кэширования (Hit Rate), так как вероятность того, что объект для категории mobile уже находится в кэше, намного выше, чем для конкретной версии Android 14.1.2.29  
Снижается нагрузка на вычислительные мощности бэкенда, так как приложению не нужно регенерировать страницу для каждого нового минорного обновления браузера Chrome или Safari.33  
Позволяет реализовать корректную логику адаптивной выдачи контента (например, WebP изображений или мобильной верстки) без риска переполнения памяти.29  
Решение полностью реализуется на уровне конфигурации Varnish (VCL) и не требует изменений в коде приложения или настройки серверов.31  
Улучшается защита от ботов-скраперов, которые часто используют уникальные или ротируемые User-Agent, так как они будут получать общий кэшированный ответ.29

### **7.2.4) Недостатки**

Некорректно составленные регулярные выражения могут привести к ложноположительным или ложноотрицательным срабатываниям (например, планшет будет определён как десктоп), что ухудшит пользовательский опыт.7  
Поддержка актуальной базы сигнатур устройств требует постоянного ручного обновления VCL или использования сторонних поддерживаемых библиотек (например, uap-core), так как производители устройств постоянно меняют формат UA.35  
Грубая нормализация может нарушить работу специфической функциональности сайта, если она полагается на точное определение версии браузера на стороне сервера (например, для полифилов старых браузеров).35  
Существует риск искажения аналитических данных, собираемых на стороне сервера (server-side analytics), так как оригинальный User-Agent заменяется на обобщённый (решается сохранением оригинала в отдельный заголовок X-Original-UA).29  
Сложность отладки: если пользователь сообщает о проблеме на конкретном устройстве, инженерам сложнее воспроизвести ситуацию, так как Varnish маскирует детали устройства перед бэкендом.7  
Некоторые CDN и прокси-серверы могут некорректно кэшировать контент, если заголовок Vary был модифицирован неправильно, что может привести к тому, что десктопные пользователи увидят мобильную версию.6

## ---

**M4: Очистка Query-параметров (Устранение маркетингового шума)**

### **7.2.1) Суть**

URL-адреса веб-страниц часто содержат параметры запроса (Query Parameters), которые используются исключительно для маркетинговой атрибуции и аналитики, но не влияют на содержание отображаемого контента.12  
Примеры таких параметров включают метки Google (gclid), Facebook (fbclid), UTM-метки (utm_source, utm_medium, utm_campaign) и множество других трекеров (mc_eid, _ga).36  
По умолчанию Varnish Cache использует полный URL, включая всю строку запроса, для вычисления хэш-ключа (hash key) объекта, что означает, что адреса page?utm_id=1 и page?utm_id=2 считаются абсолютно разными объектами.12  
В условиях активных рекламных кампаний или вирусного распространения ссылок в социальных сетях, количество уникальных комбинаций параметров может достигать миллионов, что приводит к созданию миллионов идентичных копий одной страницы в кэше.28  
Это явление называется «отравлением кэша» (cache pollution) маркетинговыми параметрами и является одной из самых распространённых причин исчерпания памяти в Varnish.28  
Суть решения M4 заключается в использовании функционала VCL для санитарной обработки req.url в процедуре vcl_recv перед тем, как запрос будет передан на хэширование.28  
С помощью функции regsuball (регулярная замена всех вхождений) из URL вырезаются известные маркетинговые параметры, оставляя только функционально значимые (например, id, category, sort).36  
После очистки URL, Varnish вычисляет хэш на основе «чистого» адреса, что позволяет закэшировать страницу один раз и отдавать её всем пользователям, независимо от того, с какой рекламной меткой они перешли на сайт.28  
Список исключаемых параметров должен быть максимально полным и включать метки всех используемых рекламных платформ, при этом он требует регулярной актуализации.37  
Для сохранения возможности аналитики параметры могут быть не удалены бесследно, а перемещены в заголовки или оставлены для клиентской JS-аналитики (которая считывает window.location в браузере, игнорируя то, что получил сервер).36  
Внедрение этого решения не требует установки дополнительного ПО, но требует тщательной проработки регулярных выражений, чтобы случайно не удалить части других параметров или не оставить «висячие» амперсанды (&) или вопросы (?).28  
Также рекомендуется сортировать оставшиеся параметры по алфавиту, чтобы порядок параметров (например, ?a=1&b=2 vs ?b=2&a=1) не приводил к дублированию кэша (query string normalization).12

### **7.2.2) Оценка**

92

### **7.2.3) Достоинства**

Обеспечивает наиболее существенное сокращение потребления памяти для сайтов с активным маркетинговым трафиком, устраняя тысячи дубликатов на каждую популярную страницу.28  
Драматически повышает коэффициент попадания в кэш (Hit Rate), так как пользователи из разных источников трафика (Email, Facebook, Google) начинают получать один и тот же кэшированный объект.28  
Защищает инфраструктуру от примитивных атак на отказ в обслуживании (DoS), когда злоумышленники добавляют случайные параметры к URL (?random=123), пытаясь обойти кэш и положить бэкенд.28  
Снижает нагрузку на базу данных и приложение, так как запросы с новыми UTM-метками больше не инициируют генерацию страницы с нуля.  
Является стандартом индустрии и «лучшей практикой» (best practice) для конфигурации Varnish, поддерживаемой обширной документацией и сообществом.12  
Позволяет избежать использования дорогостоящего транзитного хранилища для хранения миллионов одноразовых копий страниц.

### **7.2.4) Недостатки**

Ошибка в регулярном выражении может привести к удалению функциональных параметров (например, параметра пагинации page или фильтра color), что сломает навигацию по сайту для пользователей.12  
Необходимо постоянное сопровождение списка блокируемых параметров, так как рекламные сети часто меняют форматы меток (например, появление gbraid и wbraid у Google).37  
Удаление параметров на уровне Varnish делает их недоступными для серверной аналитики (backend logs), что может потребовать перестройки системы сбора данных на клиентскую (JS) или использование логов самого Varnish.36  
Сложность реализации корректной сортировки параметров (normalization) требует использования модуля vmod_std или сложной логики VCL, что увеличивает риск ошибок конфигурации.12  
Если сайт использует параметры для управления состоянием (например, сессионные токены в URL, что само по себе плохая практика), данное решение может привести к утечке данных между пользователями.38

## ---

**M5: Тюнинг аллокатора Jemalloc (Runtime Configuration)**

### **7.2.1) Суть**

jemalloc — это современный аллокатор памяти общего назначения, который используется по умолчанию в Varnish Cache (и многих других высокопроизводительных системах) благодаря своей эффективности в многопоточных средах.1  
Однако стандартная конфигурация jemalloc оптимизирована для баланса между производительностью CPU и потреблением памяти в широком спектре приложений, что не всегда идеально подходит для специфического паттерна работы Varnish (долгоживущий процесс, высокая частота аллокаций/деаллокаций, фрагментация).1  
На архитектуре ARM64 с использованием страниц памяти 4 КБ проблема фрагментации стоит особенно остро: jemalloc создает "арены" (arenas) и "чанки" (chunks), которые могут неоптимально заполняться мелкими объектами Varnish, оставляя "дыры", которые операционная система считает занятыми (Dirty Pages).1  
Суть решения M5 заключается в тонкой настройке внутренних параметров jemalloc через переменную окружения MALLOC_CONF или конфигурационный файл /etc/malloc.conf для изменения стратегии управления памятью.1  
Ключевой параметр lg_dirty_mult (по умолчанию 3) контролирует соотношение активных и грязных страниц: увеличение этого значения (например, до 8) заставляет jemalloc реже возвращать неиспользуемую память ядру, предпочитая переиспользовать её внутри процесса, что снижает фрагментацию за счет увеличения виртуального потребления.1  
Другой важный параметр lg_chunk определяет размер виртуального блока памяти, который запрашивает аллокатор (по умолчанию 4 МБ или выше); его уменьшение или адаптация (например, до 18, что равно 256 КБ) может помочь лучше упаковывать мелкие объекты Varnish.1  
В среде Amazon Linux 2023, использующей systemd, эти настройки необходимо внедрять через создание override-файла для сервиса (systemctl edit varnish), добавляя строку Environment="MALLOC_CONF=lg_dirty_mult:8,lg_chunk:18".39  
Также необходимо убедиться, что библиотека jemalloc корректно загружена: на некоторых системах требуется явная установка пакета (dnf install jemalloc) и подгрузка через LD_PRELOAD, если Varnish скомпилирован с glibc malloc по умолчанию.40  
Тюнинг jemalloc позволяет "лечить" симптомы фрагментации на уровне пользовательского пространства (user space), не прибегая к смене ядра, что делает его менее инвазивным методом по сравнению с M1.1  
Эффективность тюнинга напрямую зависит от профиля нагрузки: то, что работает для одного сайта, может ухудшить показатели для другого, поэтому требуется этап тестирования (A/B testing).1

### **7.2.2) Оценка**

75

### **7.2.3) Достоинства**

Предоставляет мощный инструмент для оптимизации работы с памятью без необходимости вносить рискованные изменения в инфраструктуру (смена ядра ОС) или пересобирать приложение.1  
Позволяет значительно снизить внутреннюю фрагментацию, которая является основной причиной "невидимых" утечек памяти, когда Varnish сообщает о свободном месте, а top показывает полное исчерпание RAM.9  
Дает возможность гибко управлять компромиссом между потреблением памяти и нагрузкой на CPU: можно пожертвовать тактами процессора ради экономии памяти или наоборот.1  
Является официально задокументированным способом оптимизации Varnish Enterprise и Varnish Cache, подтвержденным опытом эксплуатации крупных инсталляций.1  
Изменения конфигурации применяются через простой перезапуск сервиса (systemctl restart varnish), что минимизирует время простоя.

### **7.2.4) Недостатки**

Эффект от настройки параметров часто бывает непредсказуемым и сильно зависит от специфики трафика; неправильные значения могут привести к деградации производительности или ускоренному исчерпанию памяти.1  
Настройка lg_dirty_mult в сторону увеличения заставляет процесс удерживать память дольше, что может выглядеть для систем мониторинга как утечка памяти (увеличение RES), вызывая ложные срабатывания алертов.1  
В Amazon Linux 2023 и RHEL-подобных системах процесс корректного проброса переменных окружения в systemd часто вызывает трудности у администраторов (ошибки синтаксиса, игнорирование файлов /etc/sysconfig).40  
Тюнинг аллокатора лишь смягчает последствия использования 4 КБ страниц на ARM64, но не устраняет физическую причину проблемы (нагрузку на TLB), в отличие от решения M1.5  
Требует глубокого понимания внутреннего устройства jemalloc и метрик профилирования памяти, что повышает порог входа для инженеров поддержки.  
Существует риск конфликтов с другими библиотеками, если LD_PRELOAD используется некорректно, что может привести к нестабильности процесса.41

## ---

**Вердикт**

Проведённый глубинный анализ ситуации с проектом RunRepeat.com на платформе AWS Graviton позволяет сделать однозначный вывод: наблюдаемая проблема «утечки памяти» является системным результатом синергии трёх негативных факторов: **архитектурной неэффективности** (страницы 4 КБ на ARM64), **комбинаторного взрыва объектов** (отсутствие нормализации запросов) и **отсутствия предохранителей** (нелимитированное транзитное хранилище).

**Стратегический план действий (Mᚖ⠿):**

1. **Наивысший приоритет (Quick Wins):** Немедленно внедрить решения **M4 (Очистка Query-параметров)** и **M3 (Нормализация User-Agent)**.  
   * *Обоснование:* Эти меры устраняют саму причину генерации миллионов паразитных объектов. Без этого шага любая оптимизация памяти будет борьбой с симптомами. Это освободит до 60-80% памяти, занятой дубликатами.  
   * *Действие:* Обновить VCL, добавив регулярные выражения для gclid, utm_* и нормализацию UA в vcl_recv.  
2. **Критическая защита (Safety Net):** Внедрить решение **M2 (Ограничение Transient Storage)**.  
   * *Обоснование:* Это создаст жесткий барьер для потребления памяти служебными объектами, предотвращая падение сервера (OOM) даже в случае атаки или ошибки конфигурации.  
   * *Действие:* Изменить параметры запуска varnishd, добавив -s Transient=malloc,2G (размер подобрать эмпирически, 10-15% от RAM).  
3. **Фундаментальная оптимизация (Infrastructure):** Запланировать переход на **M1 (64k Pages)**.  
   * *Обоснование:* Для Graviton это единственное правильное архитектурное решение. Оно устранит фрагментацию на физическом уровне и повысит производительность на 20-30%.  
   * *Действие:* Установить ядро kernel-64k на Amazon Linux 2023 во время ближайшего окна технического обслуживания.  
4. **Тонкая настройка (Optional):** Использовать **M5 (Тюнинг Jemalloc)** только как временную меру или дополнение, если M1 по каким-то причинам невозможен.

**Итоговая рекомендация:** Комплексное применение M4+M3 (на уровне VCL) и M2 (на уровне конфига) решит проблему переполнения памяти «здесь и сейчас». Переход на M1 закрепит успех и обеспечит запас производительности на будущее.

#### **Works cited**

1. Understanding Varnish Cache Memory Usage - Resources, accessed December 11, 2025, [https://info.varnish-software.com/blog/understanding-varnish-cache-memory-usage](https://info.varnish-software.com/blog/understanding-varnish-cache-memory-usage)  
2. Improve Performance with 64K Memory Pages on AWS Graviton ..., accessed December 11, 2025, [https://dev.to/aws-builders/improve-performance-with-64k-memory-pages-on-aws-graviton-processors-ifa](https://dev.to/aws-builders/improve-performance-with-64k-memory-pages-on-aws-graviton-processors-ifa)  
3. Understanding Memory Page Sizes on Arm64 - SitePoint, accessed December 11, 2025, [https://www.sitepoint.com/memory-page-sizes-on-arm64/](https://www.sitepoint.com/memory-page-sizes-on-arm64/)  
4. CPU and memory usage of jemalloc as compared to glibc malloc - Stack Overflow, accessed December 11, 2025, [https://stackoverflow.com/questions/13027475/cpu-and-memory-usage-of-jemalloc-as-compared-to-glibc-malloc](https://stackoverflow.com/questions/13027475/cpu-and-memory-usage-of-jemalloc-as-compared-to-glibc-malloc)  
5. 1545539 – jemalloc(aarch64): munmap - Invalid Argument - build-time pagesize 4k != Fedora kernel (64k) - Red Hat Bugzilla, accessed December 11, 2025, [https://bugzilla.redhat.com/show_bug.cgi?id=1545539](https://bugzilla.redhat.com/show_bug.cgi?id=1545539)  
6. Vary — Varnish version 3.0.7 documentation, accessed December 11, 2025, [https://varnish-cache.org/docs/3.0/tutorial/vary.html](https://varnish-cache.org/docs/3.0/tutorial/vary.html)  
7. 5 Don'ts When Caching with Varnish - Resources, accessed December 11, 2025, [https://info.varnish-software.com/blog/5-varnish-donts](https://info.varnish-software.com/blog/5-varnish-donts)  
8. Varnish 6 LTS /w CentOS 8 not respecting memory limits? - Stack Overflow, accessed December 11, 2025, [https://stackoverflow.com/questions/65450044/varnish-6-lts-w-centos-8-not-respecting-memory-limits](https://stackoverflow.com/questions/65450044/varnish-6-lts-w-centos-8-not-respecting-memory-limits)  
9. Why does the default glibc allocator have relatively poor performance? (What mak... | Hacker News, accessed December 11, 2025, [https://news.ycombinator.com/item?id=8612645](https://news.ycombinator.com/item?id=8612645)  
10. Storage backends — Varnish version trunk documentation, accessed December 11, 2025, [https://varnish-cache.org/docs/trunk/users-guide/storage-backends.html](https://varnish-cache.org/docs/trunk/users-guide/storage-backends.html)  
11. BY EXAMPLE - G2, accessed December 11, 2025, [https://images.g2crowd.com/uploads/attachment/file/141471/Varnish-6-by-Example.pdf](https://images.g2crowd.com/uploads/attachment/file/141471/Varnish-6-by-Example.pdf)  
12. Example VCL template - Varnish Developer Portal, accessed December 11, 2025, [https://www.varnish-software.com/developers/tutorials/example-vcl-template/](https://www.varnish-software.com/developers/tutorials/example-vcl-template/)  
13. varnishd — Varnish version 6.5.2 documentation, accessed December 11, 2025, [https://varnish-cache.org/docs/6.5/reference/varnishd.html](https://varnish-cache.org/docs/6.5/reference/varnishd.html)  
14. careful selection of hitpass vs hitmiss · Issue #2865 · varnishcache/varnish-cache - GitHub, accessed December 11, 2025, [https://github.com/varnishcache/varnish-cache/issues/2865](https://github.com/varnishcache/varnish-cache/issues/2865)  
15. 64K Memory page sizes - any experiences to share? - General Discussion, accessed December 11, 2025, [https://community.amperecomputing.com/t/64k-memory-page-sizes-any-experiences-to-share/2730](https://community.amperecomputing.com/t/64k-memory-page-sizes-any-experiences-to-share/2730)  
16. (aarch64) 64k Base Page Size on Arm - Oracle Help Center, accessed December 11, 2025, [https://docs.oracle.com/en/operating-systems/uek/8/relnotes8.0/uek8.0-DefaultPageSizeonArmPlatform.html](https://docs.oracle.com/en/operating-systems/uek/8/relnotes8.0/uek8.0-DefaultPageSizeonArmPlatform.html)  
17. AWS Graviton4-based Amazon EC2 R8g instances: best price performance in Amazon EC2, accessed December 11, 2025, [https://aws.amazon.com/blogs/aws/aws-graviton4-based-amazon-ec2-r8g-instances-best-price-performance-in-amazon-ec2/](https://aws.amazon.com/blogs/aws/aws-graviton4-based-amazon-ec2-r8g-instances-best-price-performance-in-amazon-ec2/)  
18. aws-graviton-getting-started/perfrunbook/optimization_recommendation.md at main - GitHub, accessed December 11, 2025, [https://github.com/aws/aws-graviton-getting-started/blob/main/perfrunbook/optimization_recommendation.md](https://github.com/aws/aws-graviton-getting-started/blob/main/perfrunbook/optimization_recommendation.md)  
19. AWS Graviton Performance Testing: Tips for Independent Software Vendors - AWS Whitepaper - AWS Documentation, accessed December 11, 2025, [https://docs.aws.amazon.com/pdfs/whitepapers/latest/aws-graviton-performance-testing/aws-graviton-performance-testing.pdf](https://docs.aws.amazon.com/pdfs/whitepapers/latest/aws-graviton-performance-testing/aws-graviton-performance-testing.pdf)  
20. Compare Varnish Cache performance on x86_64 and aarch64 CPU architectures | by Martin Grigorov, accessed December 11, 2025, [https://martin-grigorov.medium.com/compare-varnish-cache-performance-on-x86-64-and-aarch64-cpu-architectures-cef5ad5fee5f](https://martin-grigorov.medium.com/compare-varnish-cache-performance-on-x86-64-and-aarch64-cpu-architectures-cef5ad5fee5f)  
21. Moderate: Red Hat Security Advisory: kernel security update - Vulners.com, accessed December 11, 2025, [https://vulners.com/redhat/RHSA-2025:21112?utm_source=rss&utm_medium=rss&utm_campaign=rss&utm_source=feedly](https://vulners.com/redhat/RHSA-2025:21112?utm_source=rss&utm_medium=rss&utm_campaign=rss&utm_source=feedly)  
22. Overuse of Transient storage with hit-for-miss objects · Issue #2654 · varnishcache/varnish-cache - GitHub, accessed December 11, 2025, [https://github.com/varnishcache/varnish-cache/issues/2654](https://github.com/varnishcache/varnish-cache/issues/2654)  
23. Why does Varnish eat up all memory despite having both transient and malloc limits?, accessed December 11, 2025, [https://serverfault.com/questions/1035846/why-does-varnish-eat-up-all-memory-despite-having-both-transient-and-malloc-limi](https://serverfault.com/questions/1035846/why-does-varnish-eat-up-all-memory-despite-having-both-transient-and-malloc-limi)  
24. varnish-counters — Varnish version trunk documentation, accessed December 11, 2025, [https://varnish-cache.org/docs/trunk/reference/varnish-counters.html](https://varnish-cache.org/docs/trunk/reference/varnish-counters.html)  
25. Configuring Varnish, accessed December 11, 2025, [https://docs.varnish-software.com/book/operations/configuring-varnish/](https://docs.varnish-software.com/book/operations/configuring-varnish/)  
26. Why my Varnish hitrate is so low (around 30%)? - Stack Overflow, accessed December 11, 2025, [https://stackoverflow.com/questions/76318328/why-my-varnish-hitrate-is-so-low-around-30](https://stackoverflow.com/questions/76318328/why-my-varnish-hitrate-is-so-low-around-30)  
27. Configuring Varnish systemd services - Varnish Developer Portal, accessed December 11, 2025, [https://www.varnish-software.com/developers/tutorials/configuring-varnish-systemd-services/](https://www.varnish-software.com/developers/tutorials/configuring-varnish-systemd-services/)  
28. Strip query parameters with Varnish | by Danila Vershinin - Medium, accessed December 11, 2025, [https://medium.com/@getpagespeed/strip-query-parameters-with-varnish-bf3cb2877530](https://medium.com/@getpagespeed/strip-query-parameters-with-varnish-bf3cb2877530)  
29. Device detection — Varnish version 3.0.7 documentation, accessed December 11, 2025, [https://varnish-cache.org/docs/3.0/tutorial/devicedetection.html](https://varnish-cache.org/docs/3.0/tutorial/devicedetection.html)  
30. Configuring Varnish Cache to Work with Mobile Devices - Atomic Spin, accessed December 11, 2025, [https://spin.atomicobject.com/varnish-cache-mobile-devices/](https://spin.atomicobject.com/varnish-cache-mobile-devices/)  
31. Magento varnish user-agent issue - cache, accessed December 11, 2025, [https://magento.stackexchange.com/questions/108774/magento-varnish-user-agent-issue](https://magento.stackexchange.com/questions/108774/magento-varnish-user-agent-issue)  
32. varnish mixing up user agent in requests - Stack Overflow, accessed December 11, 2025, [https://stackoverflow.com/questions/25380071/varnish-mixing-up-user-agent-in-requests](https://stackoverflow.com/questions/25380071/varnish-mixing-up-user-agent-in-requests)  
33. Magento 2: Varnish is caching for individual user, accessed December 11, 2025, [https://magento.stackexchange.com/questions/374909/magento-2-varnish-is-caching-for-individual-user](https://magento.stackexchange.com/questions/374909/magento-2-varnish-is-caching-for-individual-user)  
34. Magento 2 : Varnish Cache based on user agents - Stack Overflow, accessed December 11, 2025, [https://stackoverflow.com/questions/49775906/magento-2-varnish-cache-based-on-user-agents](https://stackoverflow.com/questions/49775906/magento-2-varnish-cache-based-on-user-agents)  
35. Device Detection and Varnish: 3 Approaches - Resources, accessed December 11, 2025, [https://info.varnish-software.com/blog/your-blog-post-device-detection-and-varnish-3-approaches](https://info.varnish-software.com/blog/your-blog-post-device-detection-and-varnish-3-approaches)  
36. Stripping out select querystring attribute/value pairs so varnish will not vary cache by them, accessed December 11, 2025, [https://stackoverflow.com/questions/13144172/stripping-out-select-querystring-attribute-value-pairs-so-varnish-will-not-vary](https://stackoverflow.com/questions/13144172/stripping-out-select-querystring-attribute-value-pairs-so-varnish-will-not-vary)  
37. Ignoring GET parameters in Varnish VCL - Server Fault, accessed December 11, 2025, [https://serverfault.com/questions/112531/ignoring-get-parameters-in-varnish-vcl](https://serverfault.com/questions/112531/ignoring-get-parameters-in-varnish-vcl)  
38. Performance Boosting with Varnish Cache - maxcluster, accessed December 11, 2025, [https://maxcluster.de/en/knowledge/blog/article/performance-page-speed-boosting-varnish-cache](https://maxcluster.de/en/knowledge/blog/article/performance-page-speed-boosting-varnish-cache)  
39. Limiting process resource usage in AL2023 using systemd - Amazon Linux 2023, accessed December 11, 2025, [https://docs.aws.amazon.com/linux/al2023/ug/resource-limiting-systemd.html](https://docs.aws.amazon.com/linux/al2023/ug/resource-limiting-systemd.html)  
40. Can't enable jemalloc for MySQL 5.7 - Stack Overflow, accessed December 11, 2025, [https://stackoverflow.com/questions/66314933/cant-enable-jemalloc-for-mysql-5-7](https://stackoverflow.com/questions/66314933/cant-enable-jemalloc-for-mysql-5-7)  
41. MariaDB & Amazon Linux 2: ERROR: ld.so: object '/usr/lib64/libjemalloc.so.1' from LD_PRELOAD cannot be preloaded, accessed December 11, 2025, [https://unix.stackexchange.com/questions/677387/mariadb-amazon-linux-2-error-ld-so-object-usr-lib64-libjemalloc-so-1-fro](https://unix.stackexchange.com/questions/677387/mariadb-amazon-linux-2-error-ld-so-object-usr-lib64-libjemalloc-so-1-fro)

# 22. Анализ `Mᚖ⠿` (выполнен экземпляром №5 Gemini Deep Research)
https://gemini.google.com/share/7a5ce182ad61


## **Введение**

В современной экосистеме облачных вычислений эффективность доставки контента определяется не только скоростью сети, но и глубокой интеграцией программного обеспечения с аппаратной архитектурой. Данный отчет представляет собой исчерпывающий анализ стратегий оптимизации Varnish Cache в среде Amazon Web Services (AWS), с особым акцентом на использование процессоров AWS Graviton (архитектура ARM64) и операционной системы Amazon Linux 2023 (AL2023). Исследование направлено на решение проблемы (P†), заключающейся в нестабильности потребления ресурсов, непредсказуемой латентности и риске исчерпания памяти (OOM) в высоконагруженных системах.

Мы проанализируем пять ключевых методов устранения этих проблем (Mᚖ⠿), оценив их эффективность, архитектурные последствия и сложность внедрения. Анализ базируется на эмпирических данных, технической документации и лучших практиках индустрии, с целью формирования эталонной архитектуры для систем с экстремальными требованиями к производительности.

## **Раздел 1. Аппаратная парадигма: Переход на AWS Graviton и ARM64**

### **1.1. Эволюция архитектуры процессоров в облаке**

Переход от архитектуры x86_64 к ARM64 в серверном сегменте, возглавляемый процессорами AWS Graviton, знаменует собой фундаментальный сдвиг в подходе к вычислениям, ориентированным на обработку данных. Процессоры Graviton, основанные на ядрах ARM Neoverse, предлагают уникальный баланс между производительностью и энергоэффективностью, что критически важно для приложений типа "in-memory cache", таких как Varnish.1 В отличие от традиционных архитектур, ориентированных на сложные инструкции (CISC), RISC-архитектура ARM позволяет оптимизировать конвейер исполнения команд, что в сочетании с высокоскоростной памятью DDR5 обеспечивает существенный прирост пропускной способности.3

### **1.2. Проблема трансляции адресов в кэширующих системах**

Varnish Cache функционирует как высокоскоростной интерфейс между оперативной памятью и сетевым вводом-выводом, оперируя миллионами объектов. Ключевым узким местом в таких системах становится блок управления памятью (MMU) и буфер ассоциативной трансляции (TLB). При использовании стандартного размера страницы памяти в 4 КБ (4096 байт) для адресации 100 ГБ кэша требуется создание более 26 миллионов записей в таблице страниц. Это создает колоссальное давление на TLB (TLB pressure), так как кэш TLB имеет ограниченный размер и не может вместить все трансляции.4 Частые промахи TLB (TLB misses) вынуждают процессор выполнять дорогостоящие операции обхода таблиц страниц (page walk) в основной памяти, что приводит к задержкам (stalls) в конвейере процессора и снижению количества инструкций, выполняемых за такт (IPC).5

## **Раздел 2. Анализ метода Mᚖ₁: Переход на страницы памяти 64 КБ**

### **2.1. Механизм действия и теоретическое обоснование**

Метод Mᚖ₁ предполагает переключение ядра операционной системы Amazon Linux 2023 на использование страниц памяти размером 64 КБ вместо стандартных 4 КБ. Архитектура ARMv8.2+, используемая в процессорах Graviton2 и новее, аппаратно поддерживает гранулярность страниц 4 КБ, 16 КБ и 64 КБ.5 Увеличение размера страницы в 16 раз (с 4096 до 65536 байт) пропорционально сокращает количество записей в таблице страниц, необходимых для адресации того же объема памяти. Это значительно повышает вероятность попадания в TLB (TLB hit rate), так как одна запись TLB теперь покрывает гораздо больший диапазон виртуальных адресов.5

### **2.2. Реализация в Amazon Linux 2023**

В дистрибутиве Amazon Linux 2023 (AL2023) поддержка страниц 64 КБ реализована на уровне специализированного ядра. В отличие от некоторых других дистрибутивов, где требуется сложная перекомпиляция, AL2023 предоставляет готовый пакет kernel-64k в своих репозиториях.8 Процесс внедрения сводится к установке пакета и обновлению конфигурации загрузчика grubby.

После установки пакета командой dnf install kernel-64k администратор должен явно указать системе использовать это ядро при следующей загрузке. Проверка текущего режима работы осуществляется командой getconf PAGESIZE, которая должна вернуть значение 65536.8 Важно отметить, что поддержка 64 КБ страниц является особенностью именно ARM-архитектуры в контексте AL2023; для архитектуры x86_64 такая опция в стандартных репозиториях обычно отсутствует или требует специфической конфигурации.11

### **2.3. Оценка метода Mᚖ₁**

| Критерий | Характеристика |
| :---- | :---- |
| **Достоинства** | **Снижение Latency:** Радикальное уменьшение "хвоста" латентности (p99) за счет минимизации промахов TLB.5 **Производительность:** Увеличение пропускной способности памяти и снижение накладных расходов CPU на управление памятью без изменения кода приложения.5 **Простота:** Внедрение через стандартный менеджер пакетов dnf в AL2023.9 |
| **Недостатки** | **Внутренняя фрагментация:** Для очень маленьких файлов (менее 64 КБ) использование полной страницы может привести к потере полезного объема памяти (internal fragmentation).4 **Совместимость:** Некоторые проприетарные драйверы или старые приложения могут жестко зависеть от 4 КБ страниц (хотя для Varnish это неактуально). |
| **Оценка (0-100)** | **95** |

**Вердикт по Mᚖ₁:** Это фундаментальная оптимизация для высоконагруженных инстансов Varnish на Graviton. Выигрыш в производительности подсистемы памяти перевешивает незначительные риски внутренней фрагментации, особенно при работе с большими объемами кэша.

## **Раздел 3. Анализ метода Mᚖ₂: Замена аллокатора памяти на Jemalloc**

### **3.1. Проблематика стандартного аллокатора glibc**

По умолчанию Varnish использует системный аллокатор памяти, предоставляемый библиотекой glibc (malloc). glibc является универсальным аллокатором, оптимизированным для широкого спектра задач, но не для специфических паттернов нагрузки высоконагруженного кэша. В условиях интенсивного создания и удаления объектов разного размера (что типично для HTTP-трафика) glibc склонен к внешней фрагментации памяти.12 Это приводит к явлению, известному как "memory bloat", когда процесс потребляет у операционной системы значительно больше физической памяти (RSS), чем фактически необходимо для хранения данных. В долгосрочной перспективе это может вызвать срабатывание механизма OOM Killer и падение сервиса.14

### **3.2. Преимущества Jemalloc**

jemalloc (Jason Evans' malloc) — это специализированный аллокатор, разработанный с упором на предотвращение фрагментации и масштабируемость в многопоточных средах. Он использует концепцию "арен" (arenas), позволяющую распределять память независимо для разных потоков процессора, что снижает конкуренцию за блокировки (lock contention).12 В контексте Varnish и архитектуры Graviton с большим количеством ядер (например, 64 vCPU на c7g.16xlarge), способность jemalloc эффективно масштабироваться по потокам становится критическим преимуществом. Эмпирические тесты показывают, что при длительной работе под нагрузкой инстансы с jemalloc демонстрируют стабильное потребление памяти, в то время как инстансы с glibc показывают неуклонный рост RSS.13

### **3.3. Интеграция в Amazon Linux 2023**

В AL2023 пакет jemalloc доступен для установки через dnf install jemalloc.16 Однако Varnish не переключается на него автоматически. Для активации необходимо использовать механизм предварительной загрузки библиотек (LD_PRELOAD) или перекомпилировать Varnish (что не рекомендуется при использовании пакетной версии). Наиболее надежный метод — модификация юнита systemd для сервиса Varnish:

Ini, TOML

Environment="LD_PRELOAD=/usr/lib64/libjemalloc.so.2"

Это гарантирует, что символы malloc, free и realloc будут перехвачены библиотекой jemalloc при запуске процесса.16

### **3.4. Оценка метода Mᚖ₂**

| Критерий | Характеристика |
| :---- | :---- |
| **Достоинства** | **Стабильность памяти:** Предотвращение фрагментации и утечек памяти при длительной работе (uptime > месяцев).12 **Интроспекция:** Богатые возможности профилирования памяти для отладки.19 **Масштабируемость:** Лучшая работа на многоядерных процессорах Graviton. |
| **Недостатки** | **Сложность настройки:** Требует явного вмешательства в конфигурацию systemd и понимания путей к библиотекам. **Накладные расходы:** В редких сценариях однопоточной нагрузки может незначительно уступать glibc, но для Varnish это неактуально. |
| **Оценка (0-100)** | **90** |

**Вердикт по Mᚖ₂:** Использование jemalloc является обязательным стандартом ("must-have") для производственных инсталляций Varnish, планируемых к длительной эксплуатации без перезагрузок. Это ключевой фактор стабильности.

## **Раздел 4. Анализ метода Mᚖ₃: Управление транзитным хранилищем (Transient Storage)**

### **4.1. Архитектурная уязвимость Transient Storage**

Varnish разделяет хранилище объектов на основное (обычно задается параметром -s malloc,SIZE) и транзитное (Transient). Транзитное хранилище используется для короткоживущих объектов (время жизни меньше параметра shortlived, по умолчанию 10с) и, что более критично, для объектов, которые по каким-то причинам не могут быть закэшированы, но требуют буферизации для передачи клиенту (например, при стриминге или ожидании тела ответа).20

По умолчанию Varnish использует для транзитного хранилища **неограниченный** аллокатор malloc. Это создает критическую уязвимость: если бэкенд начинает отдавать большие объемы некэшируемых данных, или если из-за ошибки в VCL множество запросов попадают в категорию hit-for-miss (когда решение "не кэшировать" само кэшируется), транзитное хранилище начинает бесконтрольно потреблять оперативную память.22 В условиях ограниченных ресурсов это неизбежно приводит к исчерпанию памяти и аварийному завершению процесса.14

### **4.2. Стратегия ограничения и защиты**

Решение заключается в явном определении и ограничении размера транзитного хранилища при запуске демона varnishd. Использование аргумента -s Transient=malloc,2G устанавливает жесткий лимит (например, 2 ГБ). Если потребность в транзитной памяти превышает этот лимит, Varnish активирует механизм вытеснения (nuke), удаляя старые транзитные объекты, или, в крайнем случае, разрывает соединение, но сохраняет работоспособность самого сервиса.15

Дополнительно, необходимо тщательно настраивать параметры shortlived и логику hit-for-miss в VCL, чтобы минимизировать попадание объектов в транзитную зону. Рекомендуется выделять под основное хранилище около 75-80% доступной RAM, оставляя резерв под транзитное хранилище и нужды ядра ОС.19

### **4.3. Оценка метода Mᚖ₃**

| Критерий | Характеристика |
| :---- | :---- |
| **Достоинства** | **Отказоустойчивость:** Гарантированная защита от OOM (Out of Memory) при всплесках некэшируемого трафика.24 **Предсказуемость:** Четкое разделение ресурсов между долговременным кэшем и временными буферами. |
| **Недостатки** | **Риск сброса соединений:** При слишком жестком лимите возможны ошибки 503 или обрывы соединений для легитимных тяжелых запросов. **Сложность планирования:** Требует точного расчета доступной памяти с учетом накладных расходов на структуры данных (overhead).20 |
| **Оценка (0-100)** | **92** |

**Вердикт по Mᚖ₃:** Явное ограничение Transient хранилища является критически важной мерой безопасности. Отсутствие этого ограничения в продакшене — это "бомба замедленного действия".

## **Раздел 5. Анализ метода Mᚖ₄: Нормализация строк запроса (Query String)**

### **5.1. Проблема загрязнения кэша параметрами**

Эффективность кэширования (Cache Hit Ratio) напрямую зависит от уникальности ключа кэширования. URL с различными параметрами запроса (Query String) воспринимаются Varnish как разные объекты. Маркетинговые метки (utm_source, gclid, fbclid), добавляемые к URL, уникальны для каждого пользователя или перехода, но часто не влияют на генерируемый бэкендом контент. Без нормализации кэш заполняется тысячами дубликатов одной и той же страницы, вытесняя полезные данные и увеличивая нагрузку на бэкенд.25

### **5.2. Сравнительный анализ методов нормализации**

Существует три основных подхода к решению этой проблемы:

1. **VCL Regex (regsuball):** Использование встроенных функций регулярных выражений для удаления параметров.  
   * *Код:* set req.url = regsuball(req.url, "(utm_[a-z]+|gclid)=...", "");  
   * *Анализ:* Гибко, но крайне ресурсоемко. Функция regsuball пересобирает строку при каждом совпадении, что создает высокую нагрузку на CPU при длинных URL и сложных регулярных выражениях.27  
2. **Сортировка (std.querysort):** Встроенная функция модуля std, которая сортирует параметры по алфавиту.  
   * *Код:* set req.url = std.querysort(req.url);  
   * *Анализ:* Решает проблему перестановки параметров (?a=1&b=2 vs ?b=2&a=1), но не удаляет мусорные параметры. Полезна как дополнение, но не как самостоятельное решение.29  
3. **Модуль vmod_querystring:** Специализированный VMOD, написанный на C, для парсинга и фильтрации параметров.  
   * *Анализ:* Обеспечивает наивысшую производительность. Позволяет использовать стратегии "keep-list" (оставить только известные параметры) или "drop-list" (удалить известные мусорные). Работает значительно быстрее регулярных выражений, так как не требует компиляции и исполнения regex-машины для каждого запроса.28

### **5.3. Оценка метода Mᚖ₄ (на примере vmod_querystring)**

| Критерий | Характеристика |
| :---- | :---- |
| **Достоинства** | **Максимальный Hit Ratio:** Устраняет дублирование кэша, существенно разгружая бэкенд. **Производительность CPU:** vmod_querystring минимизирует накладные расходы на процессор по сравнению с regsuball.28 **Безопасность:** Стратегия "белого списка" (whitelist) защищает от атак cache poisoning через неизвестные параметры. |
| **Недостатки** | **Зависимость:** Требует компиляции и установки дополнительного модуля, что усложняет поддержку и обновления Varnish.30 |
| **Оценка (0-100)** | **88** |

**Вердикт по Mᚖ₄:** Для высоконагруженных проектов использование vmod_querystring с белым списком параметров является предпочтительным. Если установка модулей невозможна, следует использовать оптимизированные regex (удаляющие параметры группами), но быть готовым к росту CPU Usage.

## **Раздел 6. Анализ метода Mᚖ₅: Управление заголовками Vary и User-Agent**

### **6.1. Фрагментация по User-Agent**

Заголовок Vary: User-Agent, отправляемый бэкендом, инструктирует Varnish хранить отдельную копию страницы для каждого уникального заголовка User-Agent. Учитывая, что современные браузеры и устройства генерируют тысячи вариаций этой строки (разные версии OS, билды браузера), это приводит к катастрофической фрагментации кэша. Фактически, кэширование становится бесполезным, так как вероятность совпадения User-Agent стремится к нулю.31

### **6.2. Стратегия нормализации (Binning)**

Решение заключается в "нормализации" заголовка User-Agent на уровне vcl_recv перед вычислением хэша запроса. Вместо сохранения полной строки, Varnish анализирует её и заменяет на упрощенный маркер: mobile, tablet или desktop.

Code snippet

if (req.http.User-Agent ~ "Mobile|Android") {  
    set req.http.User-Agent = "mobile";  
} else {  
    set req.http.User-Agent = "desktop";  
}

Более радикальный и эффективный подход для адаптивных сайтов (Responsive Design) — полное удаление заголовка User-Agent из ключа кэширования и удаление Vary: User-Agent из ответа бэкенда.33 Это позволяет отдавать один и тот же кэшированный объект всем пользователям, полагаясь на CSS и JS для адаптации отображения на клиенте.

### **6.3. Оценка метода Mᚖ₅**

| Критерий | Характеристика |
| :---- | :---- |
| **Достоинства** | **Критическое влияние на Hit Ratio:** Без этой меры кэширование динамического контента для мобильных устройств практически не работает. **Экономия памяти:** Хранение одной копии вместо тысяч вариаций. **Простота:** Реализуется стандартными средствами VCL без внешних зависимостей.35 |
| **Недостатки** | **Риск ошибок отображения:** Некорректная нормализация может привести к выдаче десктопной версии сайта на мобильном устройстве, если бэкенд реально зависит от UA (серверный рендеринг).36 |
| **Оценка (0-100)** | **98** |

**Вердикт по Mᚖ₅:** Нормализация User-Agent или полное игнорирование этого заголовка (при адаптивной верстке) является обязательным требованием. Отсутствие этой настройки — одна из самых частых причин низкой эффективности кэша.

## **Раздел 7. Итоговый вердикт и эталонная архитектура**

### **7.1. Сводная оценка методов**

На основании проведенного анализа, методы оптимизации ранжируются следующим образом по степени критичности и влиянию на устранение проблем производительности (P†):

1. **Mᚖ₅ (Header Normalization) — Оценка 98/100.** Без этого кэш просто не работает эффективно. Это логическая основа кэширования.  
2. **Mᚖ₁ (64k Pages on Graviton) — Оценка 95/100.** Фундаментальная аппаратная оптимизация, дающая "бесплатный" прирост производительности и стабильности латентности. Уникальное преимущество платформы AL2023/ARM64.  
3. **Mᚖ₃ (Transient Limits) — Оценка 92/100.** Критически важная страховка от аварий (OOM). Обязательна для стабильности (Availability).  
4. **Mᚖ₂ (Jemalloc) — Оценка 90/100.** Ключ к долговременной стабильности памяти. Обязательна для систем с высоким uptime.  
5. **Mᚖ₄ (Query String Optimization) — Оценка 88/100.** Важна для разгрузки бэкенда, но зависит от специфики трафика.

### **7.2. Эталонная конфигурация (Reference Architecture)**

Для построения высоконагруженной системы Varnish на AWS рекомендуется следующая конфигурация, интегрирующая все проанализированные методы:

* **Инстанс:** Семейство AWS Graviton (например, r7g.xlarge или c7g.2xlarge) для доступа к архитектуре ARMv8.2+.  
* **ОС:** Amazon Linux 2023 с установленным ядром kernel-64k.  
* **Системное окружение:** Активация jemalloc через systemd override (LD_PRELOAD).  
* **Параметры запуска (varnishd):**  
  * Основное хранилище: -s main=malloc,80%_RAM.  
  * Транзитное хранилище: -s Transient=malloc,2G (или 5-10% от RAM, но строго лимитировано).  
* **VCL Логика:**  
  * Использование vmod_querystring для белого списка параметров.  
  * Агрессивная нормализация User-Agent (сведение к 2-3 группам) и удаление Vary: User-Agent из ответов бэкенда.

### **Заключение**

Комплексное применение описанных методов (Mᚖ⠿) позволяет трансформировать Varnish из простого кэширующего прокси в надежную, предсказуемую и экстремально быструю платформу доставки контента. Синергия аппаратных возможностей Graviton (64k pages) и программных оптимизаций (jemalloc, VCL normalization) устраняет узкие места (P†) на всех уровнях: от процессорного конвейера до прикладной логики обработки HTTP-запросов. Игнорирование любого из этих уровней приведет к субоптимальной производительности, тогда как их интеграция гарантирует максимальную отдачу от инвестиций в облачную инфраструктуру.

#### **Works cited**

1. AWS Graviton Processor - Amazon EC2, accessed December 11, 2025, [https://aws.amazon.com/ec2/graviton/](https://aws.amazon.com/ec2/graviton/)  
2. AWS Graviton4-based Amazon EC2 R8g instances: best price performance in Amazon EC2, accessed December 11, 2025, [https://aws.amazon.com/blogs/aws/aws-graviton4-based-amazon-ec2-r8g-instances-best-price-performance-in-amazon-ec2/](https://aws.amazon.com/blogs/aws/aws-graviton4-based-amazon-ec2-r8g-instances-best-price-performance-in-amazon-ec2/)  
3. AWS Graviton4 demonstrates leading performance for HPC - Arm Developer, accessed December 11, 2025, [https://developer.arm.com/community/arm-community-blogs/b/servers-and-cloud-computing-blog/posts/leading-hpc-performance-with-graviton4](https://developer.arm.com/community/arm-community-blogs/b/servers-and-cloud-computing-blog/posts/leading-hpc-performance-with-graviton4)  
4. Overview | Arm Learning Paths, accessed December 11, 2025, [https://learn.arm.com/learning-paths/servers-and-cloud-computing/arm_linux_page_size/overview/](https://learn.arm.com/learning-paths/servers-and-cloud-computing/arm_linux_page_size/overview/)  
5. Improve Performance with 64K Memory Pages on AWS Graviton Processors, accessed December 11, 2025, [https://dev.to/aws-builders/improve-performance-with-64k-memory-pages-on-aws-graviton-processors-ifa](https://dev.to/aws-builders/improve-performance-with-64k-memory-pages-on-aws-graviton-processors-ifa)  
6. AL2023 system requirements - Amazon Linux 2023, accessed December 11, 2025, [https://docs.aws.amazon.com/linux/al2023/ug/system-requirements.html](https://docs.aws.amazon.com/linux/al2023/ug/system-requirements.html)  
7. aws-graviton-getting-started/perfrunbook/optimization_recommendation.md at main - GitHub, accessed December 11, 2025, [https://github.com/aws/aws-graviton-getting-started/blob/main/perfrunbook/optimization_recommendation.md](https://github.com/aws/aws-graviton-getting-started/blob/main/perfrunbook/optimization_recommendation.md)  
8. Install 64k page kernel on ARM64 instances - Ubuntu on AWS documentation, accessed December 11, 2025, [https://documentation.ubuntu.com/aws/aws-how-to/instances/install-64k-kernel/](https://documentation.ubuntu.com/aws/aws-how-to/instances/install-64k-kernel/)  
9. Updating the Linux kernel on AL2023 - AWS Documentation, accessed December 11, 2025, [https://docs.aws.amazon.com/linux/al2023/ug/kernel-update.html](https://docs.aws.amazon.com/linux/al2023/ug/kernel-update.html)  
10. How to get page size programmatically within Linux kernel module code - Stack Overflow, accessed December 11, 2025, [https://stackoverflow.com/questions/4888067/how-to-get-page-size-programmatically-within-linux-kernel-module-code](https://stackoverflow.com/questions/4888067/how-to-get-page-size-programmatically-within-linux-kernel-module-code)  
11. AL2023 kernel changes from AL2 - Amazon Linux 2023 - AWS Documentation, accessed December 11, 2025, [https://docs.aws.amazon.com/linux/al2023/ug/compare-with-al2-kernel.html](https://docs.aws.amazon.com/linux/al2023/ug/compare-with-al2-kernel.html)  
12. jemalloc vs glibc malloc: Memory Allocation Performance Comparison | by Binita Bharati, accessed December 11, 2025, [https://medium.com/@binitabharati/jemalloc-vs-glibc-malloc-memory-allocation-performance-comparison-fbaeda1740de](https://medium.com/@binitabharati/jemalloc-vs-glibc-malloc-memory-allocation-performance-comparison-fbaeda1740de)  
13. CPU and memory usage of jemalloc as compared to glibc malloc - Stack Overflow, accessed December 11, 2025, [https://stackoverflow.com/questions/13027475/cpu-and-memory-usage-of-jemalloc-as-compared-to-glibc-malloc](https://stackoverflow.com/questions/13027475/cpu-and-memory-usage-of-jemalloc-as-compared-to-glibc-malloc)  
14. limit readahead for private objects · Issue #2964 · varnishcache/varnish-cache - GitHub, accessed December 11, 2025, [https://github.com/varnishcache/varnish-cache/issues/2964](https://github.com/varnishcache/varnish-cache/issues/2964)  
15. Varnish Using Significantly More Memory than Cache? - Stack Overflow, accessed December 11, 2025, [https://stackoverflow.com/questions/78379910/varnish-using-significantly-more-memory-than-cache](https://stackoverflow.com/questions/78379910/varnish-using-significantly-more-memory-than-cache)  
16. MariaDB & Amazon Linux 2: ERROR: ld.so: object '/usr/lib64/libjemalloc.so.1' from LD_PRELOAD cannot be preloaded, accessed December 11, 2025, [https://unix.stackexchange.com/questions/677387/mariadb-amazon-linux-2-error-ld-so-object-usr-lib64-libjemalloc-so-1-fro](https://unix.stackexchange.com/questions/677387/mariadb-amazon-linux-2-error-ld-so-object-usr-lib64-libjemalloc-so-1-fro)  
17. Extra Packages for Enterprise Linux (EPEL) - Amazon Linux 2023 - AWS Documentation, accessed December 11, 2025, [https://docs.aws.amazon.com/linux/al2023/ug/epel.html](https://docs.aws.amazon.com/linux/al2023/ug/epel.html)  
18. Limiting process resource usage in AL2023 using systemd - Amazon Linux 2023, accessed December 11, 2025, [https://docs.aws.amazon.com/linux/al2023/ug/resource-limiting-systemd.html](https://docs.aws.amazon.com/linux/al2023/ug/resource-limiting-systemd.html)  
19. Understanding Varnish Cache Memory Usage - Resources, accessed December 11, 2025, [https://info.varnish-software.com/blog/understanding-varnish-cache-memory-usage](https://info.varnish-software.com/blog/understanding-varnish-cache-memory-usage)  
20. Storage backends — Varnish version trunk documentation, accessed December 11, 2025, [https://varnish-cache.org/docs/trunk/users-guide/storage-backends.html](https://varnish-cache.org/docs/trunk/users-guide/storage-backends.html)  
21. Storage backends - malloc - Varnish Cache, accessed December 11, 2025, [https://varnish-cache.org/docs/4.1/users-guide/storage-backends.html](https://varnish-cache.org/docs/4.1/users-guide/storage-backends.html)  
22. Troubleshooting Varnish - Varnish Developer Portal, accessed December 11, 2025, [https://www.varnish-software.com/developers/tutorials/troubleshooting-varnish/](https://www.varnish-software.com/developers/tutorials/troubleshooting-varnish/)  
23. Overuse of Transient storage with hit-for-miss objects · Issue #2654 · varnishcache/varnish-cache - GitHub, accessed December 11, 2025, [https://github.com/varnishcache/varnish-cache/issues/2654](https://github.com/varnishcache/varnish-cache/issues/2654)  
24. Configuring Varnish, accessed December 11, 2025, [https://docs.varnish-software.com/book/operations/configuring-varnish/](https://docs.varnish-software.com/book/operations/configuring-varnish/)  
25. Configuring Varnish for WordPress - Varnish Developer Portal, accessed December 11, 2025, [https://www.varnish-software.com/developers/tutorials/configuring-varnish-wordpress/](https://www.varnish-software.com/developers/tutorials/configuring-varnish-wordpress/)  
26. Example VCL template - Varnish Developer Portal, accessed December 11, 2025, [https://www.varnish-software.com/developers/tutorials/example-vcl-template/](https://www.varnish-software.com/developers/tutorials/example-vcl-template/)  
27. Varnish: what does regsuball do? - Stack Overflow, accessed December 11, 2025, [https://stackoverflow.com/questions/69343718/varnish-what-does-regsuball-do](https://stackoverflow.com/questions/69343718/varnish-what-does-regsuball-do)  
28. Strip query parameters with Varnish | by Danila Vershinin - Medium, accessed December 11, 2025, [https://medium.com/@getpagespeed/strip-query-parameters-with-varnish-bf3cb2877530](https://medium.com/@getpagespeed/strip-query-parameters-with-varnish-bf3cb2877530)  
29. VMOD std - Varnish Standard Module, accessed December 11, 2025, [https://varnish-cache.org/docs/trunk/reference/vmod_std.html](https://varnish-cache.org/docs/trunk/reference/vmod_std.html)  
30. The essential vmods all Varnish users should know about - Resources, accessed December 11, 2025, [https://info.varnish-software.com/blog/essential-vmods-all-varnish-users-should-know-about](https://info.varnish-software.com/blog/essential-vmods-all-varnish-users-should-know-about)  
31. 5 Don'ts When Caching with Varnish - Resources, accessed December 11, 2025, [https://info.varnish-software.com/blog/5-varnish-donts](https://info.varnish-software.com/blog/5-varnish-donts)  
32. Vary — Varnish version 3.0.7 documentation, accessed December 11, 2025, [https://varnish-cache.org/docs/3.0/tutorial/vary.html](https://varnish-cache.org/docs/3.0/tutorial/vary.html)  
33. Best practices for using the Vary header - Fastly, accessed December 11, 2025, [https://www.fastly.com/blog/best-practices-using-vary-header](https://www.fastly.com/blog/best-practices-using-vary-header)  
34. Varnish custom html based on User Agent - Stack Overflow, accessed December 11, 2025, [https://stackoverflow.com/questions/52184292/varnish-custom-html-based-on-user-agent](https://stackoverflow.com/questions/52184292/varnish-custom-html-based-on-user-agent)  
35. Device detection — Varnish version 3.0.7 documentation, accessed December 11, 2025, [https://varnish-cache.org/docs/3.0/tutorial/devicedetection.html](https://varnish-cache.org/docs/3.0/tutorial/devicedetection.html)  
36. A Complete Guide to the Vary HTTP Header - BrowserStack, accessed December 11, 2025, [https://www.browserstack.com/guide/what-is-vary-header](https://www.browserstack.com/guide/what-is-vary-header)

# 23.
## 23.1.
`R⬆⠿` ≔ ⠿~ ⟨ Рекомендации для моего ответа `ꆜ` на `P⁎` ⟩

## 23.2.
`R⬆ᵢ` : `R⬆⠿`

# 24. Анализ `R⬆⠿` (выполнен Gemini Deep Think)
https://gemini.google.com/share/d74df08f2942

## R⬆₁: Агрессивная нормализация запросов и заголовков (VCL Sanitization)

### Суть
Данная рекомендация заключается во внедрении в процедуру `vcl_recv` строгой логики очистки `req.url` от маркетинговых меток и сортировки параметров запроса.
Мера направлена на устранение комбинаторного взрыва кэша («Cache Bloat»), который возникает из-за уникальности ссылок с параметрами отслеживания и является первопричиной генерации миллионов избыточных объектов метаданных.
Дополнительно рекомендация включает нормализацию заголовка `User-Agent` до ограниченного набора групп и удаление заголовка `Vary: User-Agent` из ответов бэкенда для предотвращения фрагментации кэша.
Для реализации используются возможности языка VCL, включая регулярные выражения `regsuball` и функции модуля `std` или `vmod_querystring`.
Это действие блокирует бесконечный рост потребления памяти на уровне логики приложения, предотвращая попадание мусорных объектов в хранилище.

### Оценка
100

### Достоинства
Этот метод устраняет фундаментальную причину исчерпания памяти, останавливая генерацию паразитной нагрузки до того, как она затронет подсистему аллокации.
Реализация выполняется полностью средствами конфигурации VCL и не требует простоя сервера, смены ядра или установки системных пакетов.
Значительно повышается коэффициент попадания в кэш (Hit Rate), так как пользователи из разных рекламных каналов начинают получать один и тот же кэшированный объект.
Снижается нагрузка на бэкенд, поскольку Varnish перестает запрашивать генерацию уникальных страниц для каждого клика по рекламе.
Мера предотвращает массовое создание записей `hit-for-miss` в транзитном хранилище, снижая риск его переполнения.

### Недостатки
Некорректно составленные регулярные выражения несут риск случайного удаления функционально важных параметров фильтрации, что может нарушить работу навигации на сайте.
Требуется глубокий аудит используемых приложением параметров для формирования безопасного списка исключений.
Внедрение логики сортировки и очистки добавляет незначительные вычислительные накладные расходы на процессор при обработке каждого запроса.
Изменения применяются только к новым запросам и не очищают автоматически уже накопленный в памяти мусор без перезагрузки сервиса.

## R⬆₂: Явное ограничение размера временного хранилища (Transient Storage Bounding)

### Суть
Рекомендация предписывает изменить параметры запуска демона `varnishd`, добавив явный флаг `-s Transient=malloc,SIZE` с жестким лимитом (например, 2 ГБ).
В стандартной конфигурации Varnish использует для временных объектов (hit-for-miss, shortlived) неограниченное хранилище, которое при атаках или сбоях занимает всю доступную память сервера.
Установка лимита переводит механизм работы транзитного буфера в режим вытеснения (LRU), заставляя систему удалять старые записи вместо бесконечной аллокации новых страниц.
Это создает гарантированный предохранитель от аварийного завершения процесса (OOM Killer) даже в ситуациях массовой генерации некэшируемых ответов с заголовками `Set-Cookie`.
Данная мера компенсирует архитектурную особенность Varnish, которая по умолчанию не ограничивает потребление памяти для служебных нужд.

### Оценка
98

### Достоинства
Это единственная гарантированная защита от падения сервера из-за исчерпания памяти по вектору транзитных объектов, обеспечивающая стабильность процесса.
Метод обеспечивает предсказуемость потребления ресурсов, четко разделяя бюджет памяти между основным контентом и техническими буферами.
Реализация требует минимальных усилий по правке файла сервиса systemd и не зависит от сложности кода VCL.
Защита работает автономно и спасает доступность сервиса даже в случае логических ошибок на стороне веб-приложения или бэкенда.
Решение позволяет избежать эффекта «Thundering Herd» при рестартах, сохраняя работоспособность системы даже при заполненном транзитном буфере.

### Недостатки
Установка слишком малого лимита может привести к преждевременному удалению записей о пропусках кэширования, что увеличит нагрузку на бэкенд.
Метод является средством сдерживания последствий, а не устранения причины возникновения паразитного трафика.
Для применения настройки требуется перезапуск процесса Varnish, что влечет за собой полный сброс накопленного кэша.
Необходимо экспериментально подобрать оптимальный размер хранилища, чтобы не нарушить передачу больших файлов медленным клиентам.

## R⬆₃: Замена системного аллокатора на jemalloc (Allocator Swap)

### Суть
Данная рекомендация заключается в принудительном переключении процесса `varnishd` на использование библиотеки `jemalloc` вместо стандартного системного аллокатора `glibc`.
Это достигается путем установки пакета `jemalloc` и настройки переменной окружения `LD_PRELOAD` в конфигурации systemd сервиса Varnish.
Аллокатор `jemalloc` использует эффективные алгоритмы управления памятью (арены), минимизируя внешнюю фрагментацию кучи в многопоточных приложениях.
Особенно критично это решение для архитектуры ARM64 (AWS Graviton), где стандартный `glibc` демонстрирует низкую эффективность утилизации памяти.
Метод устраняет разрыв между потреблением памяти, фиксируемым внутренними счетчиками Varnish, и реальным резидентным размером процесса (RSS).

### Оценка
95

### Достоинства
Метод радикально снижает уровень фрагментации памяти, освобождая от 20% до 40% RAM, которая ранее терялась в дырах кучи.
Устраняется ложная диагностика утечки памяти, делая мониторинг потребления ресурсов прозрачным и соответствующим реальности.
Повышается общая производительность системы и снижается нагрузка на CPU за счет уменьшения конкуренции потоков за блокировки памяти.
Является официально рекомендованной практикой от разработчиков Varnish Software для высоконагруженных промышленных систем.
Решает проблему на низком системном уровне, работая прозрачно для любой конфигурации VCL.

### Недостатки
Требует вмешательства в системные зависимости и конфигурацию загрузки сервиса, что технически сложнее правки VCL.
В дистрибутиве Amazon Linux 2023 пакет может требовать подключения дополнительных репозиториев или ручной установки.
Эффект стабилизации памяти проявляется на длительной дистанции работы процесса, а не мгновенно.
Существует небольшой риск несовместимости с конкретными версиями системных библиотек, требующий предварительного тестирования.

## R⬆₄: Корректировка лимитов основного хранилища (Headroom Adjustment)

### Суть
Рекомендация сводится к пересчету параметра `-s malloc,SIZE` с учетом реальных накладных расходов на метаданные (около 1 КБ на объект) и резерва для ОС.
Для сервера с 32 ГБ RAM безопасный лимит составляет не более 18-20 ГБ, чтобы оставить запас под ядро, транзитное хранилище и стеки потоков.
Игнорирование накладных расходов при установке лимита (например, установка 28 ГБ на 32 ГБ RAM) гарантированно приводит к OOM при заполнении кэша миллионами мелких объектов.
Данная мера является необходимой корректировкой ожиданий клиента относительно реальной емкости сервера в условиях высокой кардинальности данных.
Это действие устраняет самообман администратора, полагающего, что параметр `-s` контролирует абсолютно всё потребление памяти процесса.

### Оценка
85

### Достоинства
Предотвращает вытеснение полезных процессов и срабатывание OOM Killer за счет честного учета всех потребителей ресурсов.
Обеспечивает необходимый запас памяти (headroom) для пиковых нагрузок и временных всплесков потребления рабочими пространствами.
Является простой и быстрой мерой стабилизации, которую можно применить немедленно до внедрения более сложных архитектурных изменений.
Повышает общую стабильность операционной системы, оставляя ресурсы для сетевого стека и дискового кэша.
Легко объясняется клиенту через простую математику умножения количества объектов на размер метаданных.

### Недостатки
Уменьшение лимита сокращает объем полезного кэша, что может незначительно снизить Hit Rate и увеличить нагрузку на бэкенд.
Мера является пассивной защитой и не решает проблемы неэффективного использования памяти (дубликатов или фрагментации).
Без устранения причины раздувания кэша (Cache Bloat) освобожденный запас памяти будет быстро заполнен метаданными мусорных объектов.
Требует перезапуска сервиса для вступления новых лимитов в силу.
Необходимо периодически пересматривать размер резерва при изменении профиля трафика или количества объектов.

## Вердикт

### Суть
Проведенный анализ показывает, что проблемы клиента `ꆜ` вызваны сложным взаимодействием архитектурной уязвимости (Cache Bloat), отсутствием предохранителей (Unbounded Transient) и неэффективностью системного окружения (glibc/4k pages).
Клиент ошибочно интерпретирует ситуацию как программную утечку памяти, пытаясь решить ее тюнингом параметров вытеснения, которые бессильны против потока уникальных метаданных.
Наивысший приоритет имеет внедрение **R⬆₁**, так как без нормализации запросов система будет продолжать генерировать мусорные данные быстрее, чем любые механизмы очистки смогут их удалять.
Критически важным для эксплуатационной надежности является немедленное применение **R⬆₂**, создающего жесткий барьер от полного исчерпания памяти и падения сервера.
Для долгосрочной стабильности и производительности на платформе Graviton настоятельно рекомендуется внедрить **R⬆₃** и рассмотреть корректировку лимитов согласно **R⬆₄**.

# 25. Анализ `R⬆⠿` (выполнен экземпляром №5 Gemini Deep Research)
https://gemini.google.com/share/614528e2e886

## **Анализ рекомендации R⬆₁: Переход на ядро с размером страницы 64k**

### **Суть**

Рекомендация R⬆₁ заключается в фундаментальном изменении конфигурации управления памятью операционной системы путем замены стандартного ядра Linux с размером страницы 4 КБ на ядро, скомпилированное с поддержкой страниц размером 64 КБ (kernel-64k).1  
Архитектура процессоров AWS Graviton (основанная на ядрах ARM Neoverse N1 и V1) аппаратно поддерживает работу с гранулярностью страниц памяти 64 КБ, что теоретически позволяет снизить накладные расходы на трансляцию виртуальных адресов в физические.2  
Основной технической целью данного изменения является уменьшение нагрузки на буфер ассоциативной трансляции (TLB — Translation Lookaside Buffer) процессора, который представляет собой кэш для хранения недавних трансляций адресов.  
При работе с большими объемами оперативной памяти, характерными для серверов кэширования Varnish (десятки и сотни гигабайт), стандартный размер страницы 4 КБ приводит к необходимости хранения огромного количества записей в таблицах страниц (Page Tables).  
Увеличение размера страницы до 64 КБ позволяет одной записью TLB охватывать в 16 раз больший объем памяти, существенно снижая вероятность промахов кэша TLB (TLB miss) и уменьшая количество дорогостоящих операций обхода страниц (page walks).1  
Это изменение позиционируется как способ повышения пропускной способности памяти и снижения латентности для приложений с интенсивным использованием RAM, таких как базы данных (PostgreSQL, Redis) и кэширующие прокси (Varnish).3  
В контексте Amazon Linux 2023 реализация этой рекомендации подразумевает поиск и установку специализированного пакета ядра или использование альтернативного AMI (Amazon Machine Image), поддерживающего данную конфигурацию.

### **Оценка**

10

### **Достоинства**

Главным преимуществом использования страниц памяти размером 64 КБ является существенное снижение давления на подсистему управления памятью процессора (MMU) при работе с большими наборами данных (large working sets).1  
Уменьшение количества промахов TLB напрямую транслируется в снижение количества циклов процессора, затрачиваемых на ожидание доступа к памяти, что повышает общую производительность системы (IPC — Instructions Per Cycle).  
Для приложений, использующих последовательный доступ к большим блокам памяти, таких как Varnish при чтении и записи объектов в кэш, это может дать прирост производительности в диапазоне 10-20% в зависимости от паттерна нагрузки.1  
Снижение количества уровней в таблице страниц (page table levels) уменьшает латентность при обработке исключений отсутствия страницы (page faults).  
Использование 64k страниц позволяет более эффективно использовать предвыборку данных (prefetching) процессорами Graviton, оптимизируя работу с кэшем L1 и L2.  
В сценариях с высокой конкуренцией за ресурсы памяти между потоками Varnish уменьшение накладных расходов на управление страницами освобождает ресурсы для обработки непосредственно HTTP-запросов.

### **Недостатки**

Критическим недостатком данной рекомендации в контексте Amazon Linux 2023 является отсутствие штатной поддержки пакета kernel-64k в официальных репозиториях дистрибутива на текущий момент.4  
В отличие от Red Hat Enterprise Linux 9 (RHEL9) или Ubuntu 22.04/24.04, где пакеты kernel-64k или linux-aws-64k доступны для установки через стандартные менеджеры пакетов, AL2023 поставляет только стандартные ядра версии 6.1 и 6.12 с размером страницы 4 КБ.5  
Попытка выполнить команду dnf install kernel-64k в AL2023 приведет к ошибке отсутствия пакета, так как архитектура репозиториев AL2023 отличается от RHEL и CentOS Stream.7  
Самостоятельная компиляция ядра с флагом CONFIG_ARM64_64K_PAGES нарушает принцип использования управляемой ОС, лишает систему автоматических обновлений безопасности и выводит инфраструктуру из-под условий стандартной поддержки AWS.9  
Использование страниц 64 КБ приводит к увеличению внутренней фрагментации памяти (internal fragmentation), так как любой файл или объект размером менее 64 КБ все равно будет занимать полную страницу памяти.  
Для Varnish, который часто кэширует множество мелких объектов (CSS, JS, иконки), это может привести к неэффективному расходованию оперативной памяти и снижению эффективной емкости кэша.  
Существует риск несовместимости с некоторыми бинарными приложениями и библиотеками мониторинга, которые жестко завязаны на размер страницы 4 КБ (например, старые версии инструментов трассировки или специфичные модули Python).10  
Отсутствие готового и поддерживаемого AWS механизма переключения на ядро 64k в AL2023 делает эту рекомендацию практически невыполнимой без миграции на другую операционную систему, что выходит за рамки задачи оптимизации текущего стека.  
Файловая система и дисковые операции ввода-вывода могут демонстрировать неожиданное поведение или снижение производительности, если размер блока файловой системы не выровнен по границе 64 КБ.

## **Анализ рекомендации R⬆₂: Принудительное использование аллокатора jemalloc**

### **Суть**

Рекомендация R⬆₂ предписывает замену стандартного системного аллокатора памяти glibc malloc, используемого по умолчанию в большинстве дистрибутивов Linux, на альтернативный аллокатор jemalloc (Jason Evans' malloc) для процесса varnishd.11  
Varnish Cache интенсивно работает с динамической памятью, постоянно выделяя и освобождая блоки различного размера для хранения HTTP-объектов, заголовков и служебных структур.  
Стандартный аллокатор glibc оптимизирован для универсальных задач, но в условиях высокой многопоточной нагрузки (multithreaded workload), характерной для Varnish, он склонен к проблеме фрагментации кучи (heap fragmentation) и высокой конкуренции за блокировки (lock contention).12  
jemalloc использует дизайн, основанный на множественных аренах (arenas) и локальных кэшах потоков (thread-local cache - tcache), что позволяет минимизировать блокировки и более эффективно переиспользовать освобожденную память.11  
Внедрение jemalloc в Amazon Linux 2023 подразумевает установку соответствующей библиотеки и настройку Varnish на ее использование, так как пакет Varnish в репозиториях AL2023 может не быть слинкован с ней по умолчанию.14  
Суть рекомендации заключается в предотвращении постепенного роста потребления резидентной памяти (RSS creeping), который часто ошибочно принимают за утечку памяти, и в стабилизации работы сервиса под нагрузкой.

### **Оценка**

95

### **Достоинства**

Использование jemalloc доказало свою эффективность в борьбе с фрагментацией памяти в Varnish, позволяя поддерживать потребление RAM на уровне, близком к заданному параметром -s malloc.11  
Архитектура jemalloc значительно снижает накладные расходы на синхронизацию потоков при выделении памяти, что критично для Varnish, запускающего сотни worker-потоков на многоядерных процессорах Graviton.16  
Аллокатор предоставляет расширенные возможности профилирования и интроспекции памяти, что позволяет инженерам детально анализировать паттерны потребления ресурсов.  
jemalloc активно возвращает неиспользуемые страницы памяти операционной системе (через madvise), предотвращая ситуацию, когда процесс удерживает гигабайты свободной памяти, недоступной другим приложениям.17  
В тестах производительности на Linux-системах jemalloc демонстрирует более предсказуемую латентность и меньшее количество пауз, связанных с управлением памятью, по сравнению с glibc.11  
Возможность тонкой настройки поведения аллокатора через переменную окружения MALLOC_CONF (например, параметры dirty_decay_ms и muzzy_decay_ms) позволяет адаптировать стратегию освобождения памяти под конкретный профиль нагрузки.18  
Использование jemalloc является рекомендованной практикой ("best practice") от разработчиков Varnish Software и широкого сообщества пользователей высоконагруженных систем.11

### **Недостатки**

В дистрибутиве Amazon Linux 2023 пакет jemalloc присутствует в репозиториях, но не устанавливается автоматически как зависимость пакета varnish, требуя явных действий администратора.14  
Если используемая версия Varnish была скомпилирована без явной поддержки jemalloc на этапе сборки (static linking), простого наличия библиотеки в системе недостаточно для ее активации.  
Неправильная конфигурация параметров jemalloc (например, слишком агрессивный возврат памяти OS) может привести к увеличению нагрузки на CPU из-за частых системных вызовов (system calls) и page faults.  
Отладка проблем с памятью может усложниться, так как стандартные инструменты диагностики glibc (например, mtrace) не будут работать с jemalloc.  
Существует риск конфликта версий, если сторонние VMOD (модули Varnish) были скомпилированы с расчетом на другой аллокатор, хотя это случается крайне редко.  
Необходимо внедрение механизма проверки того, что Varnish действительно использует jemalloc после перезапуска (например, через анализ /proc/<pid>/smaps), так как тихий отказ (silent failure) вернет систему к использованию glibc.20

## **Анализ рекомендации R⬆₃: Инъекция jemalloc через Systemd Override и LD_PRELOAD**

### **Суть**

Данная рекомендация описывает конкретный технический метод реализации предыдущей рекомендации (R⬆₂) в условиях операционной системы AL2023, использующей систему инициализации systemd.  
Поскольку пересборка RPM-пакета Varnish из исходных кодов для линковки с jemalloc является трудоемкой и усложняет процесс обновлений, предлагается использовать механизм динамической подгрузки библиотек LD_PRELOAD.21  
Переменная окружения LD_PRELOAD указывает динамическому загрузчику (dynamic linker) на необходимость загрузить указанную разделяемую библиотеку (shared object) перед всеми остальными, что позволяет перехватить вызовы функций malloc, calloc, realloc и free.  
Для реализации этого метода в контексте systemd используется команда systemctl edit varnish, которая создает файл переопределения (drop-in override file), например /etc/systemd/system/varnish.service.d/override.conf.22  
В этом файле прописывается директива Environment="LD_PRELOAD=/usr/lib64/libjemalloc.so.2", указывающая путь к библиотеке, установленной из репозитория AL2023.23  
Этот подход позволяет внедрить jemalloc в процесс varnishd без модификации бинарных файлов и без изменения основного юнит-файла сервиса, который может быть перезаписан при обновлении пакета.

### **Оценка**

90

### **Достоинства**

Метод LD_PRELOAD является универсальным и работает с любыми динамически скомпонованными бинарными файлами, что делает его применимым к стандартным пакетам Varnish в AL2023.  
Использование systemd drop-in replacement обеспечивает персистентность конфигурации: настройки сохраняются даже после обновления пакета varnish через dnf update.24  
Позволяет гибко управлять версией используемой библиотеки jemalloc, просто меняя путь в файле конфигурации, независимо от версии самого Varnish.  
Данный метод не требует установки инструментов компиляции (gcc, make) и заголовочных файлов на продакшн-серверах, что повышает безопасность системы.  
Конфигурация легко обратима: достаточно удалить файл override или закомментировать строку, чтобы вернуться к стандартному аллокатору glibc в случае возникновения проблем.  
Позволяет передавать дополнительные параметры настройки jemalloc через переменную окружения MALLOC_CONF в том же файле конфигурации systemd.18

### **Недостатки**

Критически важно указать правильный абсолютный путь к библиотеке libjemalloc.so, который может различаться в зависимости от архитектуры (aarch64 vs x86_64) и версии пакета в AL2023 (/usr/lib64/ vs /usr/lib/).23  
Ошибка в пути к файлу в LD_PRELOAD может привести к тому, что библиотека не будет загружена (игнорируется линковщиком), при этом сервис запустится с glibc без явных ошибок, создавая ложное чувство защищенности.25  
В системах с включенным SELinux (который в AL2023 по умолчанию находится в режиме Permissive, но может быть переведен в Enforcing) инъекция библиотек может блокироваться политиками безопасности, требуя настройки контекстов.26  
Если бинарный файл varnishd запускается через промежуточные скрипты-обертки или с использованием смены идентификатора пользователя (SUID), переменная LD_PRELOAD может быть очищена системой безопасности ядра.28  
Обновление пакета jemalloc в системе может изменить имя файла библиотеки (например, libjemalloc.so.2 станет libjemalloc.so.3), что потребует ручного обновления конфигурации systemd, иначе сервис может не запуститься.  
Необходимость проверки логов (journalctl) и карт памяти процесса (/proc/.../maps) после настройки для подтверждения успешной подгрузки библиотеки.20

## **Анализ рекомендации R⬆₄: Очистка Query String от трекинговых параметров (UTM, gclid)**

### **Суть**

Рекомендация R⬆₄ направлена на оптимизацию коэффициента попадания в кэш (Cache Hit Rate) путем нормализации URL входящих запросов на уровне VCL (Varnish Configuration Language).  
Маркетинговые платформы (Google Ads, Facebook, Email-рассылки) добавляют к URL уникальные параметры запроса, такие как gclid, fbclid, utm_source, utm_medium и mc_eid, для отслеживания эффективности рекламы.29  
По умолчанию Varnish считает полные URL (включая строку запроса) уникальными ключами кэширования, поэтому запросы /page?gclid=A и /page?gclid=B будут считаться разными объектами, вызывая дублирование кэша и лишние запросы к бэкенду.31  
Суть рекомендации заключается в использовании функции regsuball внутри подпрограммы vcl_recv для удаления этих параметров из req.url до того, как будет вычислен хэш запроса.32  
Поскольку эти параметры обычно обрабатываются клиентским JavaScript (например, скриптом Google Analytics) в браузере пользователя, их удаление на стороне прокси-сервера не влияет на корректность сбора статистики, но критически важно для эффективности кэширования.

### **Оценка**

100

### **Достоинства**

Реализация данной рекомендации обеспечивает кардинальное повышение эффективности кэширования для трафика, приходящего из рекламных каналов и социальных сетей.  
Устраняется проблема "cache bloat" (раздувание кэша), когда оперативная память сервера забивается миллионами копий одной и той же страницы, отличающихся только метками трекинга.29  
Снижается нагрузка на бэкенд-серверы (PHP, Python, Node.js), так как Varnish начинает отдавать закэшированный контент для всех пользователей рекламной кампании, вместо того чтобы проксировать каждый уникальный клик.34  
Улучшается время отклика (TTFB) для пользователей, переходящих по рекламе, так как вероятность попадания в "горячий" кэш значительно возрастает.  
Решение реализуется полностью на уровне конфигурации Varnish, не требуя изменений в коде приложения.  
Гибкость VCL позволяет настроить список удаляемых параметров (белый или черный список), сохраняя функциональные параметры, необходимые приложению (например, page, sort, filter).35

### **Недостатки**

Написание регулярных выражений (regex) требует высокой точности: ошибка в синтаксисе может привести к удалению нужных параметров или формированию некорректных URL (например, оставшиеся висячие символы ? или &).37  
Список маркетинговых параметров постоянно расширяется (например, появление ttclid от TikTok или wbraid), что требует регулярного обновления конфигурации VCL для поддержания эффективности.32  
Использование сложных регулярных выражений на каждом входящем запросе создает небольшую дополнительную нагрузку на CPU, хотя в Varnish 7.x движок PCRE JIT работает чрезвычайно быстро.39  
Если бэкенд-приложение использует серверную логику, зависящую от UTM-меток (например, подмена контента для конкретной рекламной кампании на сервере), удаление этих параметров сломает эту функциональность.  
Необходимо тщательное тестирование, чтобы убедиться, что удаление параметров не затрагивает функциональные параметры с похожими именами (ложные срабатывания).

## **Анализ рекомендации R⬆₅: Нормализация заголовка User-Agent**

### **Суть**

Рекомендация R⬆₅ касается обработки заголовка User-Agent (UA), который браузеры отправляют с каждым запросом, сообщая информацию о версии браузера, операционной системе и типе устройства.  
Строки User-Agent обладают чрезвычайно высокой вариативностью (тысячи уникальных комбинаций версий Chrome, Safari, Android и т.д.), что делает их непригодными для прямого использования в ключе кэширования.40  
Если бэкенд-приложение отдает разный HTML-код для мобильных и десктопных устройств и использует заголовок Vary: User-Agent для управления кэшированием, Varnish будет создавать отдельную копию страницы для каждого уникального UA, что приведет к катастрофическому падению hit rate.41  
Суть рекомендации заключается в "нормализации" заголовка User-Agent в vcl_recv: анализ исходной строки и замена её на упрощенный маркер, например, "mobile", "tablet" или "desktop".40  
Затем этот нормализованный заголовок (часто сохраняемый как X-UA-Device) используется для формирования ключа кэша или передается на бэкенд, позволяя кэшировать всего 2-3 вариации страницы вместо тысяч.

### **Оценка**

98

### **Достоинства**

Нормализация User-Agent является единственным способом обеспечить эффективное кэширование для сайтов, использующих технику RESS (Responsive Server Side) или отдающих различный контент в зависимости от типа устройства.43  
Позволяет защитить кэш от фрагментации, вызванной обновлением версий браузеров у пользователей (например, выход нового Chrome не инвалидирует кэш для всех пользователей Chrome).  
Упрощает логику на стороне бэкенда, который получает чистый и понятный заголовок типа X-UA-Device вместо необходимости парсить сложные строки UA самостоятельно.44  
Позволяет реализовать логику перенаправления мобильных пользователей на поддомен (m.example.com) или выбора другого бэкенда на уровне Varnish с высокой производительностью.40  
Существуют готовые модули (VMODs) и VCL-снппеты (например, devicedetect.vcl), облегчающие внедрение этой функциональности.45

### **Недостатки**

Поддержание актуальной базы сигнатур User-Agent (regex) для определения новых устройств и браузеров требует постоянных усилий и обновлений конфигурации.  
Ошибка в логике детектирования может привести к тому, что десктопный пользователь получит мобильную версию сайта (или наоборот), и эта ошибка будет закэширована для всех пользователей данной группы.47  
Процесс сопоставления User-Agent с большим списком регулярных выражений потребляет ресурсы CPU на каждом запросе.  
Если веб-сайт использует современный адаптивный дизайн (Responsive Web Design), отдавая абсолютно одинаковый HTML-код для всех устройств и управляя отображением только через CSS/Media Queries, данная рекомендация является избыточной и ненужной.48  
Искусственное добавление вариативности (Vary: X-UA-Device) там, где она не нужна, снижает эффективность использования памяти кэша.

## **Анализ рекомендации R⬆₆: Сортировка параметров запроса (std.querysort)**

### **Суть**

Рекомендация R⬆₆ предлагает использовать функцию std.querysort(req.url) из стандартного модуля Varnish (vmod_std) для алфавитной сортировки параметров в строке запроса (Query String) перед кэшированием.32  
По стандарту HTTP порядок параметров в URL не должен влиять на семантику запроса (т.е. /api?a=1&b=2 и /api?b=2&a=1 должны возвращать один и тот же результат).  
Однако для Varnish эти две строки являются разными ключами, что приводит к созданию двух разных объектов в кэше.  
Такая ситуация часто возникает при генерации ссылок различными фронтенд-компонентами, внешними системами или при ручном вводе.  
Применение std.querysort приводит параметры к каноническому (алфавитному) порядку, гарантируя, что семантически идентичные запросы будут соответствовать одному и тому же объекту в кэше.50

### **Оценка**

90

### **Достоинства**

Устраняет неявное дублирование кэша, вызванное хаотичным порядком параметров, что особенно актуально для API-эндпоинтов и сложных поисковых фильтров.31  
Повышает коэффициент попадания в кэш (Hit Rate) за счет нормализации запросов.  
Является нативной функцией Varnish, написанной на C, поэтому работает значительно быстрее и надежнее, чем попытки реализовать сортировку с помощью регулярных выражений в VCL.39  
Внедрение требует минимальных усилий: достаточно одной строки в конфигурации vcl_recv (после импорта модуля std).51  
Помогает защитить бэкенд от атак типа "cache busting" с использованием перестановки параметров.

### **Недостатки**

Существует теоретический риск нарушения работы бэкенд-приложений, которые некорректно реализованы и полагаются на фиксированный порядок параметров (например, ожидают ?id=1&action=delete именно в таком порядке), хотя это противоречит стандартам веб-разработки.35  
Требует обязательного наличия import std; в начале VCL-файла, отсутствие которого приведет к ошибке компиляции конфигурации и отказу сервиса при перезапуске.51  
Функция сортирует все параметры, поэтому, если какие-то параметры должны быть удалены (как в рекомендации R⬆₄), сортировку лучше выполнять после очистки, чтобы не тратить ресурсы на сортировку мусорных данных.39  
Для статического контента без параметров запроса вызов функции является лишней операцией, хотя накладные расходы минимальны.

## **Вердикт**

На основании детального анализа представленных рекомендаций в контексте эксплуатации Varnish Cache на Amazon Linux 2023 (Graviton/ARM64), экспертное заключение сводится к следующему.

Рекомендации по управлению памятью имеют наивысший приоритет, но требуют адаптации к реалиям AL2023.  
Внедрение jemalloc (R⬆₂, R⬆₃) является критически важным и обязательным шагом.  
Стандартный аллокатор glibc демонстрирует неприемлемые показатели фрагментации на многопоточных нагрузках, что гарантированно приведет к нестабильности сервиса.  
Поскольку пакет varnish в AL2023 может не иметь встроенной поддержки jemalloc, использование метода инъекции через systemd override с переменной LD_PRELOAD признается наиболее надежным, безопасным и поддерживаемым способом реализации («best practice» для данного окружения).  
Рекомендации по оптимизации VCL (R⬆₄, R⬆₆) являются стандартом де-факто для любой публичной инсталляции Varnish.  
Очистка трекинговых параметров и нормализация запросов — это фундаментальные гигиенические меры, без которых кэш будет неэффективен из-за дублирования контента.  
Эти настройки должны быть применены в первую очередь.  
Рекомендация по нормализации User-Agent (R⬆₅) является условно полезной.  
Она обязательна только в том случае, если бэкенд действительно отдает разный контент для разных устройств.  
В противном случае она вносит избыточную сложность.  
Рекомендация по переходу на ядро 64k (R⬆₁) признана нецелесообразной для текущей версии Amazon Linux 2023.  
Несмотря на теоретические преимущества архитектуры Graviton, экосистема AL2023 на данный момент не предоставляет готовых инструментов (пакетов ядра) для безопасного и поддерживаемого внедрения этого изменения.  
Риски, связанные с самостоятельной сборкой ядра и поддержкой нестандартной конфигурации, многократно перевешивают потенциальный выигрыш в производительности.  
Инженерам рекомендуется оставаться на стандартном ядре 4k, сосредоточившись на оптимизации на уровне приложения (Varnish) и аллокатора памяти.

#### **Works cited**

1. Improve Performance with 64K Memory Pages on AWS Graviton Processors, accessed December 11, 2025, [https://dev.to/aws-builders/improve-performance-with-64k-memory-pages-on-aws-graviton-processors-ifa](https://dev.to/aws-builders/improve-performance-with-64k-memory-pages-on-aws-graviton-processors-ifa)  
2. AWS Graviton Processor - Amazon EC2, accessed December 11, 2025, [https://aws.amazon.com/ec2/graviton/](https://aws.amazon.com/ec2/graviton/)  
3. Install 64k page kernel on ARM64 instances - Ubuntu on AWS documentation, accessed December 11, 2025, [https://documentation.ubuntu.com/aws/aws-how-to/instances/install-64k-kernel/](https://documentation.ubuntu.com/aws/aws-how-to/instances/install-64k-kernel/)  
4. Graviton arm64 / aarch64 EC2 instance types with 64k pagesize? - AWS re:Post, accessed December 11, 2025, [https://repost.aws/questions/QUlK_MQuthTKWWlviBv2xv8g/graviton-arm64-aarch64-ec2-instance-types-with-64k-pagesize](https://repost.aws/questions/QUlK_MQuthTKWWlviBv2xv8g/graviton-arm64-aarch64-ec2-instance-types-with-64k-pagesize)  
5. Updating the Linux kernel on AL2023 - AWS Documentation, accessed December 11, 2025, [https://docs.aws.amazon.com/linux/al2023/ug/kernel-update.html](https://docs.aws.amazon.com/linux/al2023/ug/kernel-update.html)  
6. All Amazon Linux 2023 packages, accessed December 11, 2025, [https://docs.aws.amazon.com/linux/al2023/release-notes/all-packages.html](https://docs.aws.amazon.com/linux/al2023/release-notes/all-packages.html)  
7. Driver Installation Guide | PDF | Linux - Scribd, accessed December 11, 2025, [https://www.scribd.com/document/934953239/Driver-Installation-Guide](https://www.scribd.com/document/934953239/Driver-Installation-Guide)  
8. Moderate: Red Hat Security Advisory: kernel security update - Vulners.com, accessed December 11, 2025, [https://vulners.com/redhat/RHSA-2025:21112?utm_source=rss&utm_medium=rss&utm_campaign=rss&utm_source=feedly](https://vulners.com/redhat/RHSA-2025:21112?utm_source=rss&utm_medium=rss&utm_campaign=rss&utm_source=feedly)  
9. AL2023 kernel changes from AL2 - Amazon Linux 2023 - AWS Documentation, accessed December 11, 2025, [https://docs.aws.amazon.com/linux/al2023/ug/compare-with-al2-kernel.html](https://docs.aws.amazon.com/linux/al2023/ug/compare-with-al2-kernel.html)  
10. mmap fails on 64k page aarch64 systems for AOTI model loading · Issue #145610 - GitHub, accessed December 11, 2025, [https://github.com/pytorch/pytorch/issues/145610](https://github.com/pytorch/pytorch/issues/145610)  
11. Understanding Varnish Cache Memory Usage - Resources, accessed December 11, 2025, [https://info.varnish-software.com/blog/understanding-varnish-cache-memory-usage](https://info.varnish-software.com/blog/understanding-varnish-cache-memory-usage)  
12. jemalloc vs glibc malloc: Memory Allocation Performance Comparison | by Binita Bharati, accessed December 11, 2025, [https://medium.com/@binitabharati/jemalloc-vs-glibc-malloc-memory-allocation-performance-comparison-fbaeda1740de](https://medium.com/@binitabharati/jemalloc-vs-glibc-malloc-memory-allocation-performance-comparison-fbaeda1740de)  
13. CPU and memory usage of jemalloc as compared to glibc malloc - Stack Overflow, accessed December 11, 2025, [https://stackoverflow.com/questions/13027475/cpu-and-memory-usage-of-jemalloc-as-compared-to-glibc-malloc](https://stackoverflow.com/questions/13027475/cpu-and-memory-usage-of-jemalloc-as-compared-to-glibc-malloc)  
14. Amazon Linux 2023 version 2023.0.20230503 release notes, accessed December 11, 2025, [https://docs.aws.amazon.com/linux/al2023/release-notes/relnotes-2023.0.20230503.html](https://docs.aws.amazon.com/linux/al2023/release-notes/relnotes-2023.0.20230503.html)  
15. Understanding Varnish Cache Memory Usage, accessed December 11, 2025, [https://varnish-software.medium.com/understanding-varnish-cache-memory-usage-6f1cab5e20ff](https://varnish-software.medium.com/understanding-varnish-cache-memory-usage-6f1cab5e20ff)  
16. Varnish duplicate process 170 once - Unix & Linux Stack Exchange, accessed December 11, 2025, [https://unix.stackexchange.com/questions/632427/varnish-duplicate-process-170-once](https://unix.stackexchange.com/questions/632427/varnish-duplicate-process-170-once)  
17. Switching to jemalloc instantly fixed an irksome memory leak in an embedded Linu... | Hacker News, accessed December 11, 2025, [https://news.ycombinator.com/item?id=44265524](https://news.ycombinator.com/item?id=44265524)  
18. Varnish 6 LTS /w CentOS 8 not respecting memory limits? - Stack Overflow, accessed December 11, 2025, [https://stackoverflow.com/questions/65450044/varnish-6-lts-w-centos-8-not-respecting-memory-limits](https://stackoverflow.com/questions/65450044/varnish-6-lts-w-centos-8-not-respecting-memory-limits)  
19. 1656034 – Varnish is compiled without jemalloc. jemalloc is missing. - Red Hat Bugzilla, accessed December 11, 2025, [https://bugzilla.redhat.com/show_bug.cgi?id=1656034](https://bugzilla.redhat.com/show_bug.cgi?id=1656034)  
20. Verify jemalloc in use at runtime? · Issue #388 - GitHub, accessed December 11, 2025, [https://github.com/jemalloc/jemalloc/issues/388](https://github.com/jemalloc/jemalloc/issues/388)  
21. Getting Started · jemalloc/jemalloc Wiki - GitHub, accessed December 11, 2025, [https://github.com/jemalloc/jemalloc/wiki/getting-started](https://github.com/jemalloc/jemalloc/wiki/getting-started)  
22. Configuring Varnish systemd services - Varnish Developer Portal, accessed December 11, 2025, [https://www.varnish-software.com/developers/tutorials/configuring-varnish-systemd-services/](https://www.varnish-software.com/developers/tutorials/configuring-varnish-systemd-services/)  
23. MariaDB & Amazon Linux 2: ERROR: ld.so: object '/usr/lib64/libjemalloc.so.1' from LD_PRELOAD cannot be preloaded, accessed December 11, 2025, [https://unix.stackexchange.com/questions/677387/mariadb-amazon-linux-2-error-ld-so-object-usr-lib64-libjemalloc-so-1-fro](https://unix.stackexchange.com/questions/677387/mariadb-amazon-linux-2-error-ld-so-object-usr-lib64-libjemalloc-so-1-fro)  
24. Configuring systemd services - Varnish Developer Portal, accessed December 11, 2025, [https://www.varnish-software.com/developers/tutorials/configuring-systemd-services/](https://www.varnish-software.com/developers/tutorials/configuring-systemd-services/)  
25. MySQL ignore LD_PRELOAD - Unix & Linux Stack Exchange, accessed December 11, 2025, [https://unix.stackexchange.com/questions/755151/mysql-ignore-ld-preload](https://unix.stackexchange.com/questions/755151/mysql-ignore-ld-preload)  
26. AL2023 Kernel Hardening - Amazon Linux 2023, accessed December 11, 2025, [https://docs.aws.amazon.com/linux/al2023/ug/kernel-hardening.html](https://docs.aws.amazon.com/linux/al2023/ug/kernel-hardening.html)  
27. 1892552 – vanish fails to start with default configuration (VCL compilation failed) - Red Hat Bugzilla, accessed December 11, 2025, [https://bugzilla.redhat.com/show_bug.cgi?id=1892552](https://bugzilla.redhat.com/show_bug.cgi?id=1892552)  
28. How to set LD_PRELOAD in systemd - linux - Stack Overflow, accessed December 11, 2025, [https://stackoverflow.com/questions/72020602/how-to-set-ld-preload-in-systemd](https://stackoverflow.com/questions/72020602/how-to-set-ld-preload-in-systemd)  
29. Stripping query strings in Varnish | Acquia Product Documentation, accessed December 11, 2025, [https://docs.acquia.com/acquia-cloud-platform/stripping-query-strings-varnish](https://docs.acquia.com/acquia-cloud-platform/stripping-query-strings-varnish)  
30. Strip marketing or analytics query parameters with Varnish - GetPageSpeed, accessed December 11, 2025, [https://www.getpagespeed.com/server-setup/varnish/strip-query-parameters-varnish](https://www.getpagespeed.com/server-setup/varnish/strip-query-parameters-varnish)  
31. Tweaking the Varnish Cache - 8th Light, accessed December 11, 2025, [https://8thlight.com/insights/tweaking-the-varnish-cache](https://8thlight.com/insights/tweaking-the-varnish-cache)  
32. Example VCL template - Varnish Developer Portal, accessed December 11, 2025, [https://www.varnish-software.com/developers/tutorials/example-vcl-template/](https://www.varnish-software.com/developers/tutorials/example-vcl-template/)  
33. Strip query parameters with Varnish | by Danila Vershinin - Medium, accessed December 11, 2025, [https://medium.com/@getpagespeed/strip-query-parameters-with-varnish-bf3cb2877530](https://medium.com/@getpagespeed/strip-query-parameters-with-varnish-bf3cb2877530)  
34. 5 Don'ts When Caching with Varnish - Resources, accessed December 11, 2025, [https://info.varnish-software.com/blog/5-varnish-donts](https://info.varnish-software.com/blog/5-varnish-donts)  
35. Best Practices for Caching a Paginated Blog Search Results Page with Varnish, accessed December 11, 2025, [https://serverfault.com/questions/1168034/best-practices-for-caching-a-paginated-blog-search-results-page-with-varnish](https://serverfault.com/questions/1168034/best-practices-for-caching-a-paginated-blog-search-results-page-with-varnish)  
36. Stripping out select querystring attribute/value pairs so varnish will not vary cache by them, accessed December 11, 2025, [https://stackoverflow.com/questions/13144172/stripping-out-select-querystring-attribute-value-pairs-so-varnish-will-not-vary](https://stackoverflow.com/questions/13144172/stripping-out-select-querystring-attribute-value-pairs-so-varnish-will-not-vary)  
37. How to strip UTM tags in Varnish without stripping queries I want? - Stack Overflow, accessed December 11, 2025, [https://stackoverflow.com/questions/75871726/how-to-strip-utm-tags-in-varnish-without-stripping-queries-i-want](https://stackoverflow.com/questions/75871726/how-to-strip-utm-tags-in-varnish-without-stripping-queries-i-want)  
38. Varnish VCL: does not exclude Google Campaign URLS · Issue #10087 · magento/magento2 - GitHub, accessed December 11, 2025, [https://github.com/magento/magento2/issues/10087](https://github.com/magento/magento2/issues/10087)  
39. PSA: You don't need that many regexes - Resources - Varnish Software, accessed December 11, 2025, [https://info.varnish-software.com/blog/psa-you-dont-need-that-many-regexes](https://info.varnish-software.com/blog/psa-you-dont-need-that-many-regexes)  
40. Configuring Varnish Cache to Work with Mobile Devices - Atomic Spin, accessed December 11, 2025, [https://spin.atomicobject.com/varnish-cache-mobile-devices/](https://spin.atomicobject.com/varnish-cache-mobile-devices/)  
41. 10 Varnish Cache mistakes and how to avoid them, accessed December 11, 2025, [https://varnish-software.medium.com/10-varnish-cache-mistakes-and-how-to-avoid-them-d240f452ab35](https://varnish-software.medium.com/10-varnish-cache-mistakes-and-how-to-avoid-them-d240f452ab35)  
42. Device detection — Varnish version 3.0.7 documentation, accessed December 11, 2025, [https://varnish-cache.org/docs/3.0/tutorial/devicedetection.html](https://varnish-cache.org/docs/3.0/tutorial/devicedetection.html)  
43. Magento 2 : Varnish Cache based on user agents - Stack Overflow, accessed December 11, 2025, [https://stackoverflow.com/questions/49775906/magento-2-varnish-cache-based-on-user-agents](https://stackoverflow.com/questions/49775906/magento-2-varnish-cache-based-on-user-agents)  
44. willemk/varnish-mobiletranslate: Tool to translate the latest mobile detect script into varnish, accessed December 11, 2025, [https://github.com/willemk/varnish-mobiletranslate](https://github.com/willemk/varnish-mobiletranslate)  
45. INSTALL.rst - varnishcache/varnish-devicedetect - GitHub, accessed December 11, 2025, [https://github.com/varnishcache/varnish-devicedetect/blob/master/INSTALL.rst](https://github.com/varnishcache/varnish-devicedetect/blob/master/INSTALL.rst)  
46. Device detection — Varnish version 4.0.5 documentation, accessed December 11, 2025, [https://varnish-cache.org/docs/4.0/users-guide/devicedetection.html](https://varnish-cache.org/docs/4.0/users-guide/devicedetection.html)  
47. Magento 2 Varnish Device Detection, accessed December 11, 2025, [https://www.scommerce-mage.com/blog/magento-2-varnish-device-detection.html](https://www.scommerce-mage.com/blog/magento-2-varnish-device-detection.html)  
48. Vary — Varnish version 3.0.7 documentation, accessed December 11, 2025, [https://varnish-cache.org/docs/3.0/tutorial/vary.html](https://varnish-cache.org/docs/3.0/tutorial/vary.html)  
49. vmod_std — Varnish version 6.0.16 documentation, accessed December 11, 2025, [https://varnish-cache.org/docs/6.0/reference/vmod_generated.html](https://varnish-cache.org/docs/6.0/reference/vmod_generated.html)  
50. Varnish Explained - Mattias Geniar, accessed December 11, 2025, [https://ma.ttias.be/varnish-explained/](https://ma.ttias.be/varnish-explained/)  
51. Varnish VCL "Symbol not found: std.querysort" - Stack Overflow, accessed December 11, 2025, [https://stackoverflow.com/questions/36012266/varnish-vcl-symbol-not-found-std-querysort](https://stackoverflow.com/questions/36012266/varnish-vcl-symbol-not-found-std-querysort)  
52. Varnish Configuration Language (VCL) - Varnish Developer Portal, accessed December 11, 2025, [https://www.varnish-software.com/developers/tutorials/varnish-configuration-language-vcl/](https://www.varnish-software.com/developers/tutorials/varnish-configuration-language-vcl/)

# 26. Анализ `R⬆⠿` (выполнен экземпляром №2 Gemini Deep Research)
https://gemini.google.com/share/bd60eae2f0fe

## **Рекомендация 1: Переход на использование страниц памяти размером 64KB на уровне ядра Linux (ARM64 Optimization)**

### **Суть**

Данная стратегическая рекомендация предписывает фундаментальное изменение конфигурации операционной системы, обеспечивающей работу Varnish Cache, посредством замены стандартного ядра Linux с размером страницы памяти 4KB на специализированное ядро, скомпилированное с поддержкой страниц размером 64KB, что является нативной и высокоэффективной опцией для архитектуры ARM64 (AWS Graviton).1  
Центральный процессор Graviton, базирующийся на микроархитектуре Neoverse N1, обладает усовершенствованным блоком управления памятью (MMU), который аппаратно поддерживает множественные размеры страниц, однако стандартные дистрибутивы, такие как Amazon Linux 2023, по умолчанию используют консервативный размер 4KB для обеспечения максимальной совместимости с legacy-приложениями.1  
Механизм виртуальной памяти в операционных системах Linux опирается на иерархические таблицы страниц для трансляции виртуальных адресов процесса в физические адреса оперативной памяти, и эффективность этого процесса критически зависит от работы буфера ассоциативной трансляции (TLB).4  
При эксплуатации Varnish Cache на сервере с 32GB оперативной памяти использование стандартных страниц размером 4KB приводит к необходимости создания и обслуживания миллионов записей в таблицах страниц, что вызывает феномен "загрязнения" TLB (TLB pollution).4  
Высокая частота промахов TLB (TLB misses) вынуждает процессор выполнять дорогостоящие операции обхода таблиц страниц (page table walks), которые могут занимать сотни процессорных тактов, отнимая ресурсы у основного потока обработки HTTP-запросов.1  
Переход на использование страниц размером 64KB позволяет одной записи в буфере TLB покрывать непрерывный участок памяти, который в 16 раз превышает стандартный объем, что приводит к радикальному снижению давления на подсистему трансляции адресов.7  
Эта архитектурная оптимизация особенно критична для приложений класса in-memory cache, таких как Varnish, которые характеризуются паттернами произвольного доступа к огромным массивам памяти (Random Access Memory patterns) и высокой интенсивностью аллокаций.4  
Внедрение данного изменения требует установки пакета kernel-64k для Amazon Linux 2023 или linux-aws-64k для Ubuntu, последующего обновления конфигурации загрузчика GRUB и полной перезагрузки инстанса.8  
Важно понимать, что данная мера является оптимизацией "нулевого уровня", которая улучшает производительность всей системы ввода-вывода и подсистемы памяти, создавая фундамент для дальнейших настроек на уровне приложения.1  
Увеличение размера страницы также способствует повышению эффективности операций прямого доступа к памяти (DMA) и снижает накладные расходы на обработку прерываний при сетевом вводе-выводе, что критично для высоконагруженного веб-сервера.1

### **Оценка**

95

### **Достоинства**

Главным преимуществом является существенное снижение накладных расходов процессора на управление виртуальной памятью, что подтверждается многочисленными бенчмарками на архитектуре AArch64.1  
Улучшение показателя TLB hit rate приводит к снижению латентности при доступе к объектам в кэше, что особенно заметно на больших объемах памяти (32GB и выше), используемых в проекте RunRepeat.4  
Оптимизация не требует внесения изменений в исходный код Varnish Cache или модификации VCL-логики, являясь полностью прозрачной для прикладного уровня.1  
Использование страниц 64KB обеспечивает прирост производительности в диапазоне 10-20% для широкого спектра нагрузок, связанных с базами данных и кэшированием, что фактически является "бесплатным" увеличением мощности имеющегося оборудования.7  
Снижение количества страничных ошибок (page faults) уменьшает вероятность возникновения микро-задержек (jitter), обеспечивая более предсказуемое время отклика (Time to First Byte) для конечных пользователей.5  
Решение официально поддерживается Amazon Web Services и включено в репозитории Amazon Linux 2023 как рекомендованная опция для высокопроизводительных вычислений.2  
Улучшенная смежность физической памяти (physical contiguity) при использовании больших страниц повышает эффективность аппаратных префетчеров процессора Graviton.5  
Это решение устраняет узкое место на аппаратном уровне, которое невозможно компенсировать никакими программными настройками самого Varnish.4

### **Недостатки**

Основным технологическим недостатком является неизбежное увеличение внутренней фрагментации памяти (internal fragmentation), поскольку минимальной единицей выделения памяти становится блок в 64KB.4  
Для Varnish Cache, который часто оперирует мелкими объектами (заголовки, небольшие JSON-ответы), это может привести к росту видимого потребления памяти (RSS), так как даже объект размером 1 байт займет целую страницу.4  
Этот эффект, однако, частично нивелируется использованием современных аллокаторов памяти (таких как jemalloc), которые умеют эффективно управлять пулами внутри больших страниц, но риск повышенного потребления RAM остается.12  
Внедрение требует обязательной перезагрузки сервера, что влечет за собой необходимость планирования окна обслуживания и полную потерю "прогретого" кэша, если не используется персистентное хранилище.9  
Некоторые старые инструменты мониторинга или специфические драйверы могут некорректно интерпретировать статистику памяти при использовании нестандартного размера страницы, что может затруднить диагностику.7  
Существует теоретическая вероятность несовместимости с проприетарным ПО, которое жестко завязано на размер страницы 4KB, хотя для экосистемы Linux на ARM64 это становится все большей редкостью.1  
Если файловая система на диске была создана с размером блока 4KB, возможны накладные расходы при операциях чтения-записи, не выровненных по границе 64KB, хотя современные файловые системы (XFS, EXT4) обычно справляются с этим корректно.5  
В случае использования Varnish с хранилищем file, увеличение размера страницы может привести к более агрессивному использованию page cache операционной системой, что требует более тщательного мониторинга свободной памяти.13

## **Рекомендация 2: Замена системного аллокатора памяти glibc на jemalloc**

### **Суть**

Данная рекомендация предполагает замену стандартного системного аллокатора памяти glibc malloc, который используется Varnish Cache по умолчанию, на специализированный аллокатор jemalloc, разработанный для высоконагруженных многопоточных систем.12  
Стандартный аллокатор glibc использует механизм "арен" (arenas) для управления памятью в многопоточной среде, создавая по умолчанию 8 арен на каждое процессорное ядро, что на 8-ядерном процессоре Graviton приводит к созданию до 64 арен.12  
Такая архитектура в условиях высокой конкуренции потоков (high concurrency), характерной для Varnish, приводит к значительной фрагментации кучи (heap fragmentation), когда освобожденные блоки памяти не могут быть эффективно возвращены операционной системе из-за блокировки соседними занятыми чанками.15  
Varnish Cache, работающий с миллионами мелких объектов, создает идеальный шторм для glibc: постоянные циклы аллокации и деаллокации (malloc/free) приводят к тому, что показатель RSS (Resident Set Size) процесса непрерывно растет, несмотря на то, что полезный объем данных в кэше остается стабильным.17  
Аллокатор jemalloc применяет принципиально иную стратегию, используя классы размеров (size classes) и отдельные кэши для потоков (tcache), что позволяет группировать объекты схожего размера и минимизировать внешнюю фрагментацию.14  
Jemalloc активно использует системный вызов madvise с флагом MADV_DONTNEED, принудительно возвращая неиспользуемые страницы памяти ядру операционной системы, что предотвращает ложные срабатывания OOM-killer.15  
Для внедрения jemalloc на Amazon Linux 2023 требуется подключение репозитория EPEL или ручная компиляция, так как пакет может отсутствовать в базовой поставке.18  
Активация нового аллокатора осуществляется через переменную окружения LD_PRELOAD в unit-файле systemd, указывающую на библиотеку libjemalloc.so, либо через пересборку Varnish с прямой линковкой.20  
Jemalloc предоставляет расширенные возможности профилирования памяти, которые позволяют детально анализировать структуру потребления RAM и выявлять утечки на уровне отдельных функций, что критически важно для диагностики проблем, описанных клиентом.12  
Использование jemalloc является признанным индустриальным стандартом для инсталляций Varnish Enterprise и высоконагруженных Open Source сборок, рекомендованным разработчиками Varnish Software.17

### **Оценка**

98

### **Достоинства**

Ключевым преимуществом является радикальное снижение фрагментации памяти, что напрямую устраняет проблему "бесконечного роста памяти", на которую жалуется клиент RunRepeat.com.11  
Стабилизация потребления памяти позволяет безопасно увеличить размер кэша (-s malloc), минимизируя необходимый "запас" (headroom) и повышая эффективность использования доступных 32GB RAM.17  
Уменьшение конкуренции за блокировки (lock contention) в jemalloc обеспечивает прирост производительности CPU в многопоточных сценариях, что особенно актуально для многоядерной архитектуры Graviton.14  
Механизм thread-local cache (tcache) в jemalloc значительно ускоряет операции выделения памяти для короткоживущих объектов, характерных для HTTP-запросов.14  
Наличие встроенной статистики (malloc_stats_print) дает администраторам прозрачный инструмент для мониторинга здоровья подсистемы памяти без необходимости использования внешних дебаггеров.12  
Jemalloc демонстрирует лучшую масштабируемость при росте количества ядер CPU, что делает это решение перспективным с учетом возможного масштабирования инфраструктуры клиента.11  
Снижение фрагментации уменьшает нагрузку на подсистему виртуальной памяти ядра Linux, что косвенно улучшает отзывчивость всей системы.15

### **Недостатки**

Внедрение jemalloc на Amazon Linux 2023 сопряжено с определенными административными сложностями, так как требует установки пакетов из сторонних репозиториев (EPEL), поддержка которых может быть ограничена.19  
Некорректная настройка путей в LD_PRELOAD может привести к тому, что Varnish продолжит использовать glibc без каких-либо предупреждений, создавая иллюзию решения проблемы.20  
В некоторых синтетических тестах с однопоточной нагрузкой jemalloc может показывать незначительно большее потребление CPU по сравнению с glibc из-за более сложной логики управления метаданными.11  
Смена аллокатора памяти является глубоким вмешательством в среду выполнения (runtime environment) и теоретически может выявить скрытые ошибки работы с памятью (memory corruption bugs) в сторонних VMOD, если таковые используются.12  
Процедура обновления библиотеки jemalloc требует перезапуска процесса Varnish, что усложняет обслуживание по сравнению с обновлением системной glibc.18  
Настройка параметров самого jemalloc (через переменную MALLOC_CONF) может потребовать экспертных знаний для достижения оптимального баланса между производительностью и потреблением памяти в специфических условиях.17

## **Рекомендация 3: Нормализация Query String и устранение проблемы "Взрыва кэша" (Cache Bloat)**

### **Суть**

Данная рекомендация направлена на устранение фундаментальной причины избыточного потребления памяти — высокой вариативности (cardinality) ключей кэширования, вызванной наличием множества параметров в строке запроса (Query String).23  
Архитектура сайта RunRepeat.com включает фасетный поиск с фильтрами (gender, size, color) и использует рекламные метки, что приводит к генерации тысяч уникальных URL для одного и того же контента (например, ?size=42&color=red и ?color=red&size=42), каждый из которых Varnish по умолчанию считает отдельным объектом.23  
Каждый объект, сохраненный в кэше, потребляет около 1KB оперативной памяти исключительно на хранение метаданных (struct objcore, struct objhead), независимо от размера самого объекта.16  
Наличие миллиона уникальных вариаций URL, созданных ботами или рекламным трафиком, приводит к потреблению 1GB RAM только на метаданные, вызывая быстрое исчерпание ресурсов и принудительное вытеснение полезных данных (LRU nuking).16  
Решение заключается в реализации строгой логики нормализации в процедуре vcl_recv, которая должна приводить все входящие URL к каноническому виду до начала процесса поиска в кэше (hash lookup).24  
Необходимо безусловно удалять все маркетинговые параметры (такие как gclid, fbclid, utm_*), так как они используются исключительно клиентским JavaScript (Google Analytics) и не влияют на генерацию HTML-страницы на бэкенде.25  
Оставшиеся функциональные параметры (фильтры поиска) должны быть отсортированы в алфавитном порядке, чтобы гарантировать, что любой порядок следования параметров в запросе приводил к идентичному хэшу.26  
Для реализации этой логики настоятельно рекомендуется использовать специализированный модуль vmod_querystring (или std.querysort в новых версиях Varnish), так как попытки реализовать сортировку с помощью регулярных выражений (regsuball) крайне неэффективны с точки зрения CPU и сложны в поддержке.26  
Эффективный подход предполагает использование стратегии "белого списка" (whitelisting), когда в запросе оставляются только явно разрешенные параметры, необходимые приложению, а все остальные удаляются.29  
Также критически важно нормализовать заголовок Vary: User-Agent, который часто устанавливается бэкендом и приводит к дублированию кэша для каждой версии браузера; его следует либо удалять, либо приводить к ограниченному набору значений (например, Mobile и Desktop).30

### **Оценка**

100

### **Достоинства**

Нормализация URL устраняет первопричину (root cause) проблемы утечки памяти, сокращая количество объектов в кэше на порядки и высвобождая гигабайты RAM для полезных данных.23  
Драматическое повышение коэффициента попадания в кэш (Hit Rate) снижает нагрузку на бэкенд-серверы, позволяя им быстрее обрабатывать действительно уникальные запросы.23  
Использование белых списков параметров повышает безопасность приложения, защищая его от атак типа "Cache Poisoning" и "Cache Busting" с использованием случайных параметров.29  
Реализация данной логики происходит полностью на уровне VCL и не требует простоя серверов или изменения конфигурации инфраструктуры, вступая в силу мгновенно после перезагрузки правил.24  
Снижение количества объектов в кэше уменьшает накладные расходы на работу внутренних механизмов Varnish, таких как сборщик мусора (expiry thread) и LRU-списки.23  
Улучшение пользовательского опыта за счет того, что посетители, пришедшие по разным рекламным ссылкам, получают мгновенный ответ из кэша.32

### **Недостатки**

Существует риск нарушения функциональности сайта, если в процессе нормализации будут случайно удалены параметры, необходимые для работы приложения (например, параметры пагинации или AJAX-запросов).33  
Удаление маркетинговых меток (utm_*) на уровне Varnish делает невозможным анализ источников трафика через серверные логи (access logs), что требует полного перехода на клиентскую аналитику.33  
Использование vmod_querystring требует установки дополнительного модуля, который может отсутствовать в стандартной поставке Varnish, требуя компиляции под конкретную версию.28  
Сложная логика нормализации может незначительно увеличить время обработки запроса (processing latency) в Varnish, однако этот оверхед ничтожен по сравнению с выигрышем от кэширования.23  
Необходимость постоянного обновления "белого списка" параметров при изменении функционала сайта требует синхронизации работы разработчиков и администраторов Varnish.26

## **Рекомендация 4: Контроль временного хранилища (Transient Storage) и предотвращение утечек Hit-for-Miss**

### **Суть**

Данная рекомендация адресована проблеме неконтролируемого роста потребления памяти во временном хранилище (Transient Storage), которое в Varnish по умолчанию не имеет ограничений по объему (unbounded).34  
Transient Storage используется для хранения короткоживущих объектов (чей TTL меньше значения параметра shortlived, по умолчанию 10с) и, что более важно, для хранения технических записей hit-for-miss и hit-for-pass.35  
Записи hit-for-miss создаются Varnish автоматически, когда бэкенд возвращает ответ с заголовками, запрещающими кэширование (например, Set-Cookie или Cache-Control: private), но Varnish должен запомнить этот факт, чтобы предотвратить "слияние запросов" (request coalescing) для данного URL.35  
В условиях проекта RunRepeat.com, где присутствует множество запросов с уникальными рекламными метками, бэкенд, вероятно, устанавливает индивидуальные куки для каждого такого запроса, заставляя Varnish создавать миллионы записей hit-for-miss.37  
Поскольку Transient Storage использует malloc и не ограничено по размеру, накопление этих записей приводит к исчерпанию всей доступной памяти сервера и аварийному завершению процесса (crash), даже если основное хранилище настроено корректно.34  
Для устранения этой уязвимости необходимо жестко ограничить размер Transient хранилища при запуске демона, добавив параметр -s Transient=malloc,2G (размер следует подобрать эмпирически), что заставит Varnish принудительно удалять старые записи при переполнении.13  
Дополнительно следует оптимизировать логику в vcl_backend_response: для ответов, которые гарантированно не должны кэшироваться, можно явно устанавливать set beresp.uncacheable = false;, превращая их в hit-for-pass с коротким TTL, или полностью отключать создание таких записей, если риск перегрузки бэкенда (thundering herd) минимален.37  
Также необходимо провести аудит бэкенда и принудительно удалять заголовок Set-Cookie в VCL для публичного контента, чтобы предотвратить создание некэшируемых ответов там, где это не требуется.23  
Мониторинг счетчиков SMA.Transient.c_bytes и SMA.Transient.g_bytes через утилиту varnishstat является обязательным для контроля эффективности принятых мер.35

### **Оценка**

90

### **Достоинства**

Установка жесткого лимита на Transient Storage действует как "аварийный клапан", гарантируя, что Varnish никогда не потребит больше памяти, чем выделено, предотвращая падение сервера.35  
Оптимизация обработки hit-for-miss объектов снижает количество метаданных в памяти и уменьшает нагрузку на хэш-таблицы, повышая общую производительность системы.36  
Предотвращение создания hit-for-miss записей для уникальных одноразовых запросов освобождает ресурсы для кэширования действительно востребованного контента.37  
Удаление лишних кук (Set-Cookie) может значительно повысить Hit Rate, превращая ранее некэшируемый трафик в кэшируемый.23  
Понимание механики Transient Storage позволяет администраторам принимать осознанные решения о балансе между защитой бэкенда и потреблением памяти.37

### **Недостатки**

При достижении лимита Transient Storage новые записи не смогут быть созданы, что может привести к изменению поведения Varnish: запросы будут проходить на бэкенд без защиты от слияния (request coalescing), что может вызвать кратковременные пики нагрузки на базу данных.35  
Отключение логики hit-for-miss требует осторожности, так как в случае атаки на "тяжелый" URL все запросы пройдут на бэкенд одновременно, что может привести к отказу в обслуживании (DoS).37  
Ошибочное удаление заголовка Set-Cookie для критически важных страниц (корзина, личный кабинет) нарушит пользовательские сессии и функционал сайта.23  
Диагностика переполнения Transient Storage может быть неочевидной, так как стандартные инструменты не всегда явно показывают, какие именно URL занимают это пространство.35

## **Рекомендация 5: Тонкая настройка параметров запуска Varnish (Threads & Workspace)**

### **Суть**

Данная рекомендация фокусируется на оптимизации параметров времени выполнения (runtime parameters) Varnish, которые определяют статическое потребление памяти (overhead), не связанное с хранением данных кэша.38  
Каждый рабочий поток (worker thread) в Varnish потребляет оперативную память на собственный стек и на специализированные рабочие области (workspaces): workspace_client для обработки запроса, workspace_backend для ответа сервера и workspace_session для данных сессии.39  
В конфигурации по умолчанию Varnish может создавать тысячи потоков (thread_pool_max часто установлен в 5000), что при значениях workspace_client (например, 96KB) может привести к потреблению сотен мегабайт памяти только на пустые структуры потоков.39  
На 8-ядерном процессоре Graviton рекомендуется ограничить максимальное количество потоков разумным значением (например, thread_pool_max=2000) и использовать два пула потоков (thread_pools=2), чтобы избежать избыточных переключений контекста и неконтролируемого роста потребления RAM при штормах трафика.35  
Размеры рабочих областей (workspace_*) должны быть тщательно откалиброваны: они должны быть достаточными для работы всех VMOD и обработки длинных заголовков, но не чрезмерными, так как эта память выделяется для каждого активного запроса.40  
Недостаточный размер workspace приводит к ошибкам "workspace overflow" и сбоям обработки запросов (503 Guru Meditation), в то время как избыточный размер — к пустой трате памяти.35  
Важно также настроить параметр lru_interval, чтобы оптимизировать частоту обновления списков LRU и снизить конкуренцию за блокировки (lock contention) в многопоточной среде.41  
Регулярный мониторинг метрик MAIN.threads, MAIN.threads_failed и SMA.Transient.g_bytes необходим для валидации выбранных настроек.23

### **Оценка**

85

### **Достоинства**

Оптимизация пулов потоков предотвращает сценарий "thread pile-up", когда замедление бэкенда вызывает лавинообразный рост числа потоков Varnish, окончательно исчерпывающий память сервера.35  
Корректная настройка workspace параметров обеспечивает стабильную работу сложных VCL-логик и VMOD, предотвращая трудноуловимые ошибки обработки запросов.35  
Снижение накладных расходов на управление потоками освобождает процессорное время для полезной работы, повышая общую пропускную способность системы.39  
Предсказуемое потребление памяти служебными структурами позволяет точнее планировать размер основного кэша.40

### **Недостатки**

Слишком агрессивное ограничение thread_pool_max может привести к тому, что Varnish начнет сбрасывать входящие соединения (drop connections) во время легитимных пиков трафика, вызывая отказ в обслуживании.35  
Поиск оптимальных значений для workspace параметров требует итеративного подхода и анализа логов ошибок, так как универсальных значений не существует.35  
Неправильная настройка thread_pools может привести к неравномерному распределению нагрузки между ядрами процессора.39

## **Рекомендация 6: Внедрение Memory Governor (Varnish Enterprise Feature)**

### **Суть**

Данная рекомендация рассматривает возможность миграции на коммерческую версию Varnish Enterprise для использования функции Memory Governor, которая автоматизирует управление памятью.38  
В Open Source версии администратор вынужден вручную рассчитывать распределение памяти между хранилищем объектов (malloc) и накладными расходами, оставляя значительный "запас" (headroom) на случай непредвиденных всплесков, что неэффективно.38  
Технология Massive Storage Engine (MSE) в версии Enterprise включает компонент Memory Governor, который позволяет задать единый лимит памяти для всего процесса (например, memory_target=90%), динамически регулируя размер кэша в зависимости от текущих накладных расходов.38  
Это позволяет безопасно использовать практически всю доступную оперативную память сервера, не опасаясь OOM-сбоев, так как система сама агрессивно уменьшит кэш при росте потребления памяти потоками или transient-объектами.38  
Для бизнеса масштаба RunRepeat.com стоимость лицензии может быть оправдана снижением операционных рисков и доступом к премиальной поддержке.43

### **Оценка**

80

### **Достоинства**

Полная автоматизация управления памятью устраняет человеческий фактор и необходимость сложного ручного тюнинга параметров, обеспечивая высокую стабильность работы.42  
Более эффективная утилизация аппаратных ресурсов позволяет хранить больше объектов в кэше на том же оборудовании, повышая Hit Rate.38  
Доступ к профессиональной поддержке вендора и расширенным функциям безопасности (WAF, SSL/TLS).43

### **Недостатки**

Внедрение требует финансовых затрат на лицензирование, что может быть не предусмотрено бюджетом проекта.22  
Использование проприетарных технологий (MSE) создает зависимость от вендора (vendor lock-in) и усложняет возможный возврат к Open Source решениям.44  
Данное решение является скорее "страховкой", чем исправлением корневых проблем архитектуры (таких как дублирование URL), которые все равно требуют устранения.38

## **Вердикт**

Анализ инфраструктуры RunRepeat.com показывает, что проблемы с памятью вызваны сочетанием архитектурных особенностей (Graviton CPU, высокая кардинальность URL) и дефолтных настроек Varnish.

1. **Рекомендация 3 (Нормализация Query String)** является критической и обязательной к исполнению, так как устраняет первопричину раздувания кэша.  
2. **Рекомендация 4 (Контроль Transient Storage)** и **Рекомендация 2 (Jemalloc)** обеспечат техническую стабильность и защиту от утечек памяти.  
3. **Рекомендация 1 (64k Pages)** даст системный прирост производительности на платформе ARM64.  
4. **Рекомендация 5** и **Рекомендация 6** служат дополнительными мерами тонкой настройки и стратегического развития.

#### **Works cited**

1. Improve Performance with 64K Memory Pages on AWS Graviton Processors, accessed December 11, 2025, [https://dev.to/aws-builders/improve-performance-with-64k-memory-pages-on-aws-graviton-processors-ifa](https://dev.to/aws-builders/improve-performance-with-64k-memory-pages-on-aws-graviton-processors-ifa)  
2. (aarch64) 64k Base Page Size on Arm - Oracle Help Center, accessed December 11, 2025, [https://docs.oracle.com/en/operating-systems/uek/8/relnotes8.0/uek8.0-DefaultPageSizeonArmPlatform.html](https://docs.oracle.com/en/operating-systems/uek/8/relnotes8.0/uek8.0-DefaultPageSizeonArmPlatform.html)  
3. Graviton arm64 / aarch64 EC2 instance types with 64k pagesize? - AWS re:Post, accessed December 11, 2025, [https://repost.aws/questions/QUlK_MQuthTKWWlviBv2xv8g/graviton-arm64-aarch64-ec2-instance-types-with-64k-pagesize](https://repost.aws/questions/QUlK_MQuthTKWWlviBv2xv8g/graviton-arm64-aarch64-ec2-instance-types-with-64k-pagesize)  
4. Understanding Memory Page Sizes on Arm64 - Ampere Computing, accessed December 11, 2025, [https://amperecomputing.com/tuning-guides/understanding-memory-page-sizes-on-arm64](https://amperecomputing.com/tuning-guides/understanding-memory-page-sizes-on-arm64)  
5. Efficient Use of the Page Cache with 64 KB Pages - The Linux Kernel Archives, accessed December 11, 2025, [https://www.kernel.org/doc/ols/2006/ols2006v2-pages-73-78.pdf](https://www.kernel.org/doc/ols/2006/ols2006v2-pages-73-78.pdf)  
6. Operating System Settings — NVIDIA Grace Performance Tuning Guide, accessed December 11, 2025, [https://docs.nvidia.com/grace-perf-tuning-guide/os-settings.html](https://docs.nvidia.com/grace-perf-tuning-guide/os-settings.html)  
7. 64K Kernel Page Size Performance Benefits For HPC Shown With NVIDIA's GH200 Grace CPU - Phoronix, accessed December 11, 2025, [https://www.phoronix.com/review/aarch64-64k-kernel-perf](https://www.phoronix.com/review/aarch64-64k-kernel-perf)  
8. Install 64k page kernel on ARM64 instances - Ubuntu on AWS documentation, accessed December 11, 2025, [https://documentation.ubuntu.com/aws/aws-how-to/instances/install-64k-kernel/](https://documentation.ubuntu.com/aws/aws-how-to/instances/install-64k-kernel/)  
9. Updating the Linux kernel on AL2023 - AWS Documentation, accessed December 11, 2025, [https://docs.aws.amazon.com/linux/al2023/ug/kernel-update.html](https://docs.aws.amazon.com/linux/al2023/ug/kernel-update.html)  
10. AWS Graviton: Best Price Performance, accessed December 11, 2025, [https://aws.amazon.com/awstv/watch/acde308f81f/](https://aws.amazon.com/awstv/watch/acde308f81f/)  
11. CPU and memory usage of jemalloc as compared to glibc malloc - Stack Overflow, accessed December 11, 2025, [https://stackoverflow.com/questions/13027475/cpu-and-memory-usage-of-jemalloc-as-compared-to-glibc-malloc](https://stackoverflow.com/questions/13027475/cpu-and-memory-usage-of-jemalloc-as-compared-to-glibc-malloc)  
12. Java in K8s: how we've reduced memory usage without changing any code | by Mickael Jeanroy | malt-engineering, accessed December 11, 2025, [https://blog.malt.engineering/java-in-k8s-how-weve-reduced-memory-usage-without-changing-any-code-cbef5d740ad](https://blog.malt.engineering/java-in-k8s-how-weve-reduced-memory-usage-without-changing-any-code-cbef5d740ad)  
13. Storage backends — Varnish version trunk documentation, accessed December 11, 2025, [https://varnish-cache.org/docs/trunk/users-guide/storage-backends.html](https://varnish-cache.org/docs/trunk/users-guide/storage-backends.html)  
14. Why does the default glibc allocator have relatively poor performance? (What mak... | Hacker News, accessed December 11, 2025, [https://news.ycombinator.com/item?id=8612645](https://news.ycombinator.com/item?id=8612645)  
15. How glibc Memory Handling Affects Java Applications: The Hidden Cost of Fragmentation | by Daniyal Hassan | Medium, accessed December 11, 2025, [https://medium.com/@daniyal.hass/how-glibc-memory-handling-affects-java-applications-the-hidden-cost-of-fragmentation-8e666ee6e000](https://medium.com/@daniyal.hass/how-glibc-memory-handling-affects-java-applications-the-hidden-cost-of-fragmentation-8e666ee6e000)  
16. Why isn't varnish taking into account the malloc limit? - Stack Overflow, accessed December 11, 2025, [https://stackoverflow.com/questions/16693677/why-isnt-varnish-taking-into-account-the-malloc-limit](https://stackoverflow.com/questions/16693677/why-isnt-varnish-taking-into-account-the-malloc-limit)  
17. Understanding Varnish Cache Memory Usage - Resources, accessed December 11, 2025, [https://info.varnish-software.com/blog/understanding-varnish-cache-memory-usage](https://info.varnish-software.com/blog/understanding-varnish-cache-memory-usage)  
18. jemalloc/INSTALL.md at dev - GitHub, accessed December 11, 2025, [https://github.com/jemalloc/jemalloc/blob/dev/INSTALL.md](https://github.com/jemalloc/jemalloc/blob/dev/INSTALL.md)  
19. Extra Packages for Enterprise Linux (EPEL) - Amazon Linux 2023 - AWS Documentation, accessed December 11, 2025, [https://docs.aws.amazon.com/linux/al2023/ug/epel.html](https://docs.aws.amazon.com/linux/al2023/ug/epel.html)  
20. How to install jemalloc on AWS Elastic Beanstalk - Matthew Lein, accessed December 11, 2025, [https://matthewlein.com/articles/install-jemalloc-elastic-beanstalk](https://matthewlein.com/articles/install-jemalloc-elastic-beanstalk)  
21. Configuring Varnish systemd services - Varnish Developer Portal, accessed December 11, 2025, [https://www.varnish-software.com/developers/tutorials/configuring-varnish-systemd-services/](https://www.varnish-software.com/developers/tutorials/configuring-varnish-systemd-services/)  
22. How to install varnish cache in Amazon Linux 2023? - Server Fault, accessed December 11, 2025, [https://serverfault.com/questions/1137676/how-to-install-varnish-cache-in-amazon-linux-2023](https://serverfault.com/questions/1137676/how-to-install-varnish-cache-in-amazon-linux-2023)  
23. Achieving a high cache hit rate with Varnish - Resources, accessed December 11, 2025, [https://info.varnish-software.com/blog/high-hit-rate-with-varnish](https://info.varnish-software.com/blog/high-hit-rate-with-varnish)  
24. Achieving a high hitrate — Varnish version 7.4.3 documentation, accessed December 11, 2025, [https://varnish-cache.org/docs/7.4/users-guide/increasing-your-hitrate.html](https://varnish-cache.org/docs/7.4/users-guide/increasing-your-hitrate.html)  
25. Varnish: Normalizing / Normalising the url - Richy's Random Ramblings, accessed December 11, 2025, [https://blog.rac.me.uk/2010/03/03/normalizing_the_url_in_varnish/](https://blog.rac.me.uk/2010/03/03/normalizing_the_url_in_varnish/)  
26. The essential vmods all Varnish users should know about - Resources, accessed December 11, 2025, [https://info.varnish-software.com/blog/essential-vmods-all-varnish-users-should-know-about](https://info.varnish-software.com/blog/essential-vmods-all-varnish-users-should-know-about)  
27. Stripping out select querystring attribute/value pairs so varnish will not vary cache by them, accessed December 11, 2025, [https://stackoverflow.com/questions/13144172/stripping-out-select-querystring-attribute-value-pairs-so-varnish-will-not-vary](https://stackoverflow.com/questions/13144172/stripping-out-select-querystring-attribute-value-pairs-so-varnish-will-not-vary)  
28. Strip query parameters with Varnish | by Danila Vershinin - Medium, accessed December 11, 2025, [https://medium.com/@getpagespeed/strip-query-parameters-with-varnish-bf3cb2877530](https://medium.com/@getpagespeed/strip-query-parameters-with-varnish-bf3cb2877530)  
29. vmod_querystring: Varnish Query-String Module | Man Page | Library Functions | vmod-querystring | ManKier, accessed December 11, 2025, [https://www.mankier.com/3/vmod_querystring](https://www.mankier.com/3/vmod_querystring)  
30. How to Speed Up Varnish Cache and Prevent Hangs : r/programming - Reddit, accessed December 11, 2025, [https://www.reddit.com/r/programming/comments/1k0az4g/how_to_speed_up_varnish_cache_and_prevent_hangs/](https://www.reddit.com/r/programming/comments/1k0az4g/how_to_speed_up_varnish_cache_and_prevent_hangs/)  
31. 10 Varnish Cache mistakes and how to avoid them, accessed December 11, 2025, [https://varnish-software.medium.com/10-varnish-cache-mistakes-and-how-to-avoid-them-d240f452ab35](https://varnish-software.medium.com/10-varnish-cache-mistakes-and-how-to-avoid-them-d240f452ab35)  
32. How to Enable 'Ignore Query String' for Varnish Cache | Cloudways Help Center, accessed December 11, 2025, [https://support.cloudways.com/en/articles/8437462-how-to-enable-ignore-query-string-for-varnish-cache](https://support.cloudways.com/en/articles/8437462-how-to-enable-ignore-query-string-for-varnish-cache)  
33. Stripping query strings in Varnish | Acquia Product Documentation, accessed December 11, 2025, [https://docs.acquia.com/acquia-cloud-platform/stripping-query-strings-varnish](https://docs.acquia.com/acquia-cloud-platform/stripping-query-strings-varnish)  
34. Overuse of Transient storage with hit-for-miss objects · Issue #2654 · varnishcache/varnish-cache - GitHub, accessed December 11, 2025, [https://github.com/varnishcache/varnish-cache/issues/2654](https://github.com/varnishcache/varnish-cache/issues/2654)  
35. Varnish memory usage keeps increasing - Stack Overflow, accessed December 11, 2025, [https://stackoverflow.com/questions/76209998/varnish-memory-usage-keeps-increasing](https://stackoverflow.com/questions/76209998/varnish-memory-usage-keeps-increasing)  
36. careful selection of hitpass vs hitmiss · Issue #2865 · varnishcache/varnish-cache - GitHub, accessed December 11, 2025, [https://github.com/varnishcache/varnish-cache/issues/2865](https://github.com/varnishcache/varnish-cache/issues/2865)  
37. Hit-for-Miss AND why a NULL TTL is bad for you - Resources - Varnish Software, accessed December 11, 2025, [https://info.varnish-software.com/blog/hit-for-miss-and-why-a-null-ttl-is-bad-for-you](https://info.varnish-software.com/blog/hit-for-miss-and-why-a-null-ttl-is-bad-for-you)  
38. Two-Minute Tech Tuesdays - Memory Governor - Resources - Varnish Software, accessed December 11, 2025, [https://info.varnish-software.com/blog/two-minute-tech-tuesdays-memory-governor](https://info.varnish-software.com/blog/two-minute-tech-tuesdays-memory-governor)  
39. Understanding how Varnish works (Part 1) - Nick Tailor's Technical Blog, accessed December 11, 2025, [https://www.nicktailor.com/varnish-and-how-it-works/](https://www.nicktailor.com/varnish-and-how-it-works/)  
40. Varnish Using Significantly More Memory than Cache? - Stack Overflow, accessed December 11, 2025, [https://stackoverflow.com/questions/78379910/varnish-using-significantly-more-memory-than-cache](https://stackoverflow.com/questions/78379910/varnish-using-significantly-more-memory-than-cache)  
41. VMOD std - Varnish Standard Module, accessed December 11, 2025, [https://varnish-cache.org/docs/trunk/reference/vmod_std.html](https://varnish-cache.org/docs/trunk/reference/vmod_std.html)  
42. Auto-scaling memory usage to increase cache size in Varnish - Resources, accessed December 11, 2025, [https://info.varnish-software.com/blog/auto-scaling-memory-usage-to-increase-cache-size-in-varnish](https://info.varnish-software.com/blog/auto-scaling-memory-usage-to-increase-cache-size-in-varnish)  
43. AWS Marketplace: Varnish Enterprise 6 (Red Hat) - Amazon.com, accessed December 11, 2025, [https://aws.amazon.com/marketplace/pp/prodview-nqecedatdopwg](https://aws.amazon.com/marketplace/pp/prodview-nqecedatdopwg)  
44. Varnish Enterprise 6 (Ubuntu) - AWS Marketplace, accessed December 11, 2025, [https://aws.amazon.com/marketplace/pp/prodview-atq2qasjkejio](https://aws.amazon.com/marketplace/pp/prodview-atq2qasjkejio)


~~~~~~

# 4. `T.md`
~~~~~~markdown
# 1.
`Aᨀ` ≔ ⟪ мой proposal `ꆜ` для `P⁎` ⟫
~~~markdown
STUB
~~~

# 2. 
## 2.1.
`𐒌⠿` ≔ ⠿~ ⟨ недостатки `Aᨀ` ⟩ 
```
STUB
```

## 2.2.
`𐒌ᵢ` : `𐒌⠿`

## 2.3.
`𐒌(i)` ≔ ⟨ Недостаток под номером `i` из `𐒌⠿` ⟩ 

# 3. `᛭T`
Предложи конкретные правки к `Aᨀ` для устранения `𐒌⠿`.

# 4. Источники информации
## 4.1.
Используй все предыдущие пункты моего запроса для понимания обсуждаемой в `Aᨀ` предметной области.

## 4.2.
Используй авторитетные источники информации на английском языке, относящиеся к предметной области `P⁎` и `P†`.

## 4.3.
В первую очередь используй официальные источники.

# 5. Порядок работы
## 5.1.
Обязательно используй свой режим «Deep Research».
Твой ответ без режима «Deep Research» — гарантированно неверный.

## 5.2.
В первую очередь используй официальные источники.

# 6. Правила ответа
## 6.1.
Отвечай на русском языке.
Исключением являются точные официальные термины: смотри пункт 6.2 ниже.

## 6.2.
При обсуждении программного обеспечения используй точные официальные термины на английском языке: именно в том виде, как они указаны в официальной англоязычной документации к этому программному обеспечению.

## 6.3.
Не используй выделение жирным (`**`) и курсив (`*`).

## 6.4.
Названия файлов заключай в backticks.
Например: `header.php`.

## 6.5.
Названия элементов интерфейса заключай в угловые кавычки (`«»`).

## 6.6.
Для путей в интерфейсе используй `→`.
Например: «Current User» → «Personal».

## 6.7.
Не используй жаргон.
Вместо этого используй официальные термины.

### 6.7.1.
В частности, фразы в кавычках используй только в том случае, когда они являются точными цитатами.
Не используй фразы в кавычках для применения жаргонных фраз.
Например, следующий фрагмент текста недопустим, потому что там используется жаргонная фраза «пролетел»: 
```
Например, код, который пушит данные о покупке, подключён асинхронно и загружается с небольшой задержкой, а триггер уже «пролетел».
```

## 6.8.
Не используй самовольно «you need» и другие подобные обращённые к `ꆜ` фразы, перекладывающие действия на него, если в исходном тексте явно не сказано подобное (типа «вы должны»).
Помни: я пишу `ꆜ`.
Делать в любом случае буду я, а не `ꆜ`.
Именно за то, что описываемую работу делать буду я, `ꆜ` мне будет платить.
Моя задача — показать мою компетенцию и предложить `ꆜ` решение его проблемы, а не переложить решение проблемы на `ꆜ`.

## 6.9.
Мой вопрос не пересказывай.

## 6.10.
Уже сформулированную мной информацию не пересказывай.

## 6.11.
Писать свою версию `Aᨀ` не нужно: просто укажи конкретные точечные правки по пунктам.

## 6.12.
До и после списка правок ничего не пиши.

## 6.13.
Нумерация замечаний должна быть сквозной.

## 6.14.
Форматируй текст своих правок в точности как оригинал (`Aᨀ`). 
В частности:
*) каждый абзац должен содержать ровно одно предложение
*) между абзацами не должно оставаться пустых строк.
*) кавычки используй те же, что и в оригинале: «» и ``.

## 6.15.
В тексте правки не ссылайся на `𐒌ᵢ`.
Указание на `𐒌ᵢ` должно стоять до текста правки, а не находиться в самом тексте правки.

## 6.16.
Все числительные должны писаться цифрами (а не прописью).

## 6.17.
Текст правок должен быть как можно более кратким.
Концентрация смысла в словах должна быть максимальной.
При этом, разумеется, текст правок должен:
- быть корректным 
- содержать самое главное
- устранять указанные замечания и не порождать новые ошибки и замечания.

# 7. Правила ответа / Для правок на английском языке
## 7.1.
Не используй сокращения типа «don't». Все подобные фразы пиши полностью: «do not».

## 7.2.
Никогда не переводи понятие «сайт» / «веб-сайт» как «site». 
Вместо этого используй форму «website»: это является более профессиональным.

## 7.3.
### 7.3.1.
Никогда не переводи понятие «пункт нумерованного списка» как «item».
### 7.3.2.
Для пунктов нормативных актов вместо «item» используй тот термин, который принято использовать в данном юридическом контексте: «paragraph», «section» и т.п.
### 7.3.3.
Для всех остальных текстов переводи «item» как «point».

## 7.4.
Вместо «for example» в тексте на английском языке используй «e.g.».
При этом не забывай, что в начале предложения эта фраза должна начинатся с заглавной буквы: «E.g.»
~~~~~~