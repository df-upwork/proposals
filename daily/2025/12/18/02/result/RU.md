1) Обе рассматриваемые вами option являются некачественными.
I outline их недостатки в пунктах 4 и 5 ниже.
В пунктах 6 и 7 я outline 2 качественных способа решения вашей задачи.

2) Key definitions used in my analysis:
- Репликация данных: `R᛭`
- Your «Option 1» (использование `R᛭`): `⌖1`
- Your «Option 2» («a scheduled backend job»): `⌖2`
- «a naive scheduled job could be intensive and create heavy IO load on production if it scans across all entities»: `P1†`
- «our current setup may limit built in replication support»: `P2†`
- Ваша информационная система в целом: `S༄`
- Bubble.io: `Bᨀ`
- React: `Rᨀ`
- PostgreSQL: `Pᨀ`
- Supabase: `Sᨀ`
- Tinybird: `Tᨀ`
- Write-Ahead Log: `WAL`

3) Мои предположения о `S༄` на основе анализа ваших проектов на Upwork
3.1) Предполагаемая суть `S༄`
Скорее всего, `S༄` представляет собой B2C-платформу для алгоритмической дистрибуции коротких игровых видео (клипов), агрегируемых через Twitch API.
Система реализует механику бесконечной ленты («TikTok для геймеров»), где ИИ (OpenAI) ранжирует контент на основе предпочтений пользователя.
Зрители потребляют контент через высокопроизводительный веб-интерфейс (`Rᨀ`), генерируя поток событий: «views» (просмотр), «skips» (пропуск) и «saves» (сохранение).
Владельцы платформы предоставляют аналитику авторам контента (стримерам), монетизируя сервис через подписку или рекламу.
3.2) Предполагаемая архитектура `S༄`
Система `S༄` базируется на бэкенде `Bᨀ`, который создает текущие архитектурные ограничения по репликации и IO, и использует современный фронтенд на `Rᨀ` для взаимодействия с пользователями.

4) Недостатки `⌖1`
4.1) В классической архитектуре баз данных золотым стандартом для построения аналитических хранилищ является `R᛭`.
`Bᨀ` использует `Pᨀ`. 
Однако, архитектура платформы является многопользовательской (Multi-tenant). 
Тысячи приложений могут делить один кластер базы данных.   
Предоставление прямого доступа к `WAL` или replication slots невозможно из соображений безопасности, так как это дало бы доступ к данным других клиентов (noisy neighbors).
Поэтому вы физически лишен доступа к низкоуровневым механизмам синхронизации. 
4.2) API Polling
Поскольку прямая `R᛭` невозможна, часто рассматривается вариант периодического опроса API (Polling) для выгрузки новых данных. 
Анализ источников выявляет критические недостатки этого метода для задачи: 
4.2.1) Алгоритмическая сложность пагинации.
Data API `Bᨀ` использует стандартную пагинацию (limit/offset или cursor).
Для выгрузки 100,000 событий, накопившихся за день, системе потребуется выполнить серию запросов.
Проблема Offset: В `Pᨀ` (и других RDBMS) запрос `OFFSET 50000 LIMIT 100` требует от базы данных прочитать 50,100 строк, отбросить первые 50,000 и вернуть последние 100. 
Чем "глубже" мы уходим в историю событий, тем медленнее работает каждый следующий запрос.
 Это создает нагрузку `O(N^2)` при полной выгрузке таблицы, что катастрофически сказывается на производительности при больших объемах данных.
4.2.2) Согласно документации, `Bᨀ` накладывает жесткие лимиты на количество запросов к API.
Тариф Starter: 15,000 запросов в минуту (совокупно для Workflow API и Data API).
Тариф Growth: 25,000 запросов.
Хотя эти цифры кажутся большими, реальная пропускная способность ограничивается временем обработки каждого запроса на стороне сервера (server-side processing time). 
Тяжелые запросы на чтение данных с фильтрацией могут потреблять значительную долю "Capacity", что приведет к тайм-аутам (код 503) задолго до достижения лимита по количеству запросов.
4.2.3) При выгрузке данных страницами через API (особенно если процесс занимает минуты или часы) невозможно гарантировать snapshot isolation. 
Если во время выгрузки 50-й страницы пользователь добавит новое событие, которое должно было попасть на 1-ю страницу (из-за сортировки), это событие может быть пропущено или привести к сдвигу смещения, вызывая дублирование данных. 
Это прямо противоречит вашему требованию «the job must be accurate».
Нативная функция экспорта в `Bᨀ` имеет серьезные ограничения:   
Лимиты строк: Пользователи сообщают о сбоях и тайм-аутах при попытке экспортировать более 10,000 - 50,000 строк за раз.
Отсутствие автоматизации: Нативный экспорт часто требует ручного запуска из редактора, что нарушает требование "low maintenance".
Плагины: Использование плагинов (например, "1T CSV Creator" ) переносит нагрузку генерации файла на браузер клиента или на серверные мощности приложения (Server-Side Actions), что возвращает нас к проблеме потребления ресурсов (Capacity) и рискам `P2†`.   

5) Недостатки `⌖2`
5.1) Экономика Workload Units (WU) и стоимость вычислений
С 2023 года `Bᨀ` перешел на модель тарификации на основе Workload Units (WU). Каждая операция с базой данных (создание, поиск, изменение) имеет свою "цену" в WU.   
Стоимость поиска (Search): Поиск по базе данных является одной из самых дорогих операций, особенно если он включает сложные фильтры ("Constraint") или сортировку.
Стоимость агрегации: Операции типа "Count", "Sum", выполняемые над списком результатов поиска, потребляют WU пропорционально количеству обрабатываемых записей.
Сценарий клиента: Ежедневный джоб, который должен просканировать, например, 100,000 событий для 5,000 пользователей, вызовет лавинообразный расход WU.
Если стоимость обработки одной сущности составляет, скажем, 0.5 WU (оптимистичная оценка), то ежедневная обработка будет стоить 50,000 WU.
В месяц это 1.5 млн WU, что может потребовать перехода на дорогостоящие тарифные планы (от $300-$500/мес и выше), делая аналитику непропорционально дорогой по сравнению с прямым доходом от клиента ($1300 total spent).
5.2)  Алгоритмическая ловушка `O(N)` и Recursive Workflows
Для обработки больших списков в `Bᨀ` используется паттерн "Recursive Backend Workflows" (рекурсивные бэкенд-процессы), так как цикл Schedule API Workflow on a list имеет лимит на 100,000 элементов и может работать нестабильно на больших объемах.
Рекурсивный процесс обрабатывает одну запись (или пакет записей), а затем вызывает сам себя для следующей.
Такой процесс создает `P2†`. 
Если обработка занимает 3 часа, то в течение этих 3 часов база данных находится под постоянным давлением операций чтения/записи.
Блокировки: Источники подтверждают, что при высокой утилизации Capacity ("app too busy") запросы от реальных пользователей начинают замедляться. Это классическая проблема конкуренции ресурсов (Resource Contention), когда аналитическая задача (низкий приоритет) мешает транзакционной задаче (высокий приоритет).
5.3) Анализ источников  вскрывает еще одну фундаментальную проблему, которая делает опцию O⌖2 технически несостоятельной, даже если бы ресурсов было достаточно.   
Лимит 10,000 элементов: Поле типа List в `Bᨀ` не может надежно хранить более 10,000 элементов.
Сценарий: Если мы попытаемся хранить список "Просмотров" (Views) прямо внутри объекта "Статья" (Article) для удобства подсчета, популярная статья исчерпает этот лимит за несколько дней или недель.
Последствия: При превышении лимита операции добавления в список начинают сбоить или замедляться до неприемлемых значений. 
Это вынуждает разработчика создавать отдельные таблицы-связки (join tables), что возвращает нас к проблеме медленного поиска по миллионам строк.

6) `R1⁂`: качественный способ решения вашей задачи №1
6.1) Суть
Архитектура Dual-Write (параллельная запись) в реляционную СУБД (`Sᨀ` / Neon). 
Модификация фронтенда для отправки событий (клики, просмотры) параллельным асинхронным запросом напрямую во внешнюю базу данных `Pᨀ` (`Sᨀ`), полностью минуя бэкенд `Bᨀ`.
Внешняя база данных принимает «сырой» поток событий и агрегирует их в фоновом режиме через материализованные представления или инкрементальные SQL-процедуры.
Основное приложение `Bᨀ` запрашивает уже готовые, посчитанные метрики из внешней базы через API только в момент их отображения пользователю.
6.2) Достоинства
Данный подход физически изолирует поток записи событий от основной транзакционной базы данных, что математически гарантирует отсутствие блокировок ввода-вывода (`P2†`) в системе `S༄`.
Использование стандартного `Pᨀ` во внешней среде снимает проблему отсутствия доступа к журналу предзаписи (`P1†`), так как клиент получает полный административный контроль над новой базой.
Экономическая эффективность решения максимальна, поскольку внешние SQL-сервисы (`Sᨀ`, Neon) предоставляют щедрые бесплатные лимиты и не тарифицируют операции по модели Workload Units.
Механизм `INSERT ON CONFLICT` (Upsert) обеспечивает строгую идемпотентность записи, гарантируя точность данных даже при сбоях сети или повторных отправках.

7) `R2⁂`: качественный способ решения вашей задачи №2
7.1) Суть
Использовать специализированную колоночную базу данных (`Tᨀ`), предназначенной для приема высокочастотных потоков данных через HTTP-эндпоинты.
Клиентское приложение отправляет события в API `Tᨀ`, где они немедленно сохраняются и становятся доступными для аналитических SQL-запросов с субсекундной задержкой.
Интеграция с `Bᨀ` сводится к простому вызову API-эндпоинтов («Pipes») для получения готовой JSON-статистики по каждой сущности.
7.2) Достоинства
Колоночная архитектура обеспечивает феноменальную производительность агрегации на любых объемах данных, полностью устраняя риск замедления системы при росте аудитории.
Сервис автоматически обрабатывает пиковые нагрузки («thundering herd»), защищая инфраструктуру клиента от переполнения.
Отсутствует необходимость в сложном проектировании схемы базы данных и индексов, так как движок оптимизирован для произвольных аналитических запросов.

