https://gemini.google.com/share/dae0955c9f95


## **1. Контекстуальный анализ и идентификация технического ландшафта**

В современной практике разработки программного обеспечения на базе платформ No-Code/Low-Code наблюдается критическая точка бифуркации, когда успешный продукт перерастает возможности своей первоначальной архитектуры данных. Проект P⁎, инициированный клиентом ꆜ, представляет собой хрестоматийный пример такой ситуации. Задача, сформулированная как необходимость создания «слоя ежедневной статистики» (daily stats layer) на основе событий производственной среды, вскрывает фундаментальный конфликт между транзакционной природой платформы, на которой построено приложение, и требованиями к аналитической обработке данных (OLAP).

Анализ предоставленной онтологии проекта (O.md) и сопутствующих исследовательских материалов позволяет с высокой степенью достоверности идентифицировать технологический стек клиента как **Bubble.io**. Данный вывод базируется на совокупности косвенных и прямых признаков: использование терминологии «Entities» (сущности) и «Things» (термин Bubble для записей в базе данных), упоминание проблем с поддержкой репликации, характерных для закрытых экосистем PaaS, и явное указание на риск «наивного планировщика» (naive scheduled job), что является прямой отсылкой к специфическим ограничениям Bubble по Workload Units (WU) и таймаутам серверных процессов.1

### **1.1. Профиль клиента и специфика запроса**

Клиент ꆜ демонстрирует уровень технической осведомленности выше среднего, что подтверждается использованием профессиональной терминологии («idempotent write approach», «backfill plan», «IO load»). Это накладывает повышенные требования к глубине анализа: поверхностные рекомендации будут отвергнуты как некомпетентные. Клиент ищет не просто исполнителя, а архитектора, способного подтвердить или опровергнуть его гипотезы относительно ограничений текущей системы.

Основная цель проекта P⁎ — трансформация сырых данных о поведении пользователей (клики, сохранения, пропуски, просмотры) в агрегированные метрики для каждой сущности. Требования к системе — точность, возможность повторного запуска (rerunnability) и низкие эксплуатационные расходы — вступают в прямое противоречие с нативными возможностями Bubble при работе с большими массивами данных.

### **1.2. Реестр выявленных проблем (T⁎ Пункт 1)**

На основе декомпозиции задачи P⁎ и анализа технических ограничений платформы, мы выделяем следующий спектр проблем, вызывающих беспокойство у клиента. Эти проблемы не являются изолированными; они представляют собой взаимосвязанный узел архитектурных рисков.

1. **Риск «Наивного» планировщика (P2†):** Центральное опасение клиента заключается в том, что прямой пересчет метрик внутри основной базы данных через запланированные задачи (Scheduled Workflows) создаст недопустимую нагрузку на систему ввода-вывода (IO Load). Клиент описывает это как «naive scheduled job could be intensive», подразумевая риск деградации производительности основного приложения для конечных пользователей во время выполнения аналитических расчетов.3  
2. **Архитектурная блокировка репликации (P1†):** Клиент предполагает, что текущая конфигурация (Bubble) не позволяет использовать стандартные промышленные методы репликации данных (например, потоковую репликацию WAL или доступ к Read Replicas), что делает невозможным использование традиционных инструментов Business Intelligence (BI) без разработки сложного промежуточного слоя.4  
3. **Обеспечение идемпотентности в нестабильной среде:** Требование «accurate, rerunnable» указывает на проблему обеспечения целостности данных. В средах, где процессы могут прерываться по таймауту (что характерно для Bubble), повторный запуск процедуры агрегации без специальных механизмов защиты (идемпотентности) неминуемо приведет к дублированию данных и искажению аналитики.6  
4. **Проблема масштабирования N+1:** Задача требует аналитики «per entity» (для каждой сущности). В контексте объектно-ориентированной базы данных Bubble это часто провоцирует архитектурную ошибку N+1, когда для каждой из тысяч сущностей запускается отдельный тяжелый поисковый запрос по таблице событий, что приводит к экспоненциальному росту затрат ресурсов и времени выполнения.1  
5. **Отсутствие изоляции нагрузок (Resource Contention):** Выполнение аналитических запросов (чтение миллионов строк истории событий) конкурирует за ресурсы процессора и памяти с транзакционными запросами реальных пользователей (авторизация, создание заказов), так как в Bubble оба типа нагрузок обрабатываются одними и теми же вычислительными мощностями (Capacity).1

## ---

**2. Глубокий анализ обоснованности проблемы «Наивного» планировщика (P2†)**

Первая и наиболее критическая проблема, обозначенная клиентом, касается рисков реализации аналитики средствами самой платформы через так называемый «наивный» подход. Чтобы оценить обоснованность этого опасения, необходимо детально разобрать механику работы серверных процессов в Bubble и экономическую модель Workload Units (WU).

### **2.1. Анатомия «Наивного» алгоритма в среде Bubble**

Под «наивным планировщиком» (O⌖2) в экосистеме Bubble понимается использование действия *«Schedule API Workflow on a list»* или циклического *Recursive Backend Workflow* для обработки больших массивов данных без предварительной оптимизации или выноса вычислений.

Рассмотрим сценарий: приложению необходимо раз в сутки обновить счетчик просмотров для 10,000 сущностей (Entities), основываясь на таблице событий (Events), содержащей 500,000 записей за прошедшие сутки.  
Алгоритм «наивного» подхода выглядит следующим образом:

1. Запускается Scheduled Workflow.  
2. Выполняется поиск всех сущностей (Do a search for Entities).  
3. Для каждой сущности запускается подпроцесс, который делает поиск по таблице событий (Do a search for Events), фильтруя их по ID сущности и дате, а затем применяет оператор :count.  
4. Результат записывается в поле сущности.

![][image1]

### **2.2. Техническая и экономическая несостоятельность подхода**

Анализ показывает, что опасения клиента по поводу IO Load и интенсивности процесса **абсолютно обоснованы** и даже преуменьшены. Проблема носит тройственный характер:

#### **А. Лимиты выполнения и Таймауты (Timeout Limits)**

Bubble, как платформа, построенная поверх AWS (вероятно, использующая Lambda или аналогичные сервисы для серверных процессов), накладывает жесткие ограничения на время выполнения одного воркфлоу.

* Для тарифных планов Starter/Growth/Team это время исчисляется минутами.  
* Операция агрегации, требующая выполнения 10,001 поискового запроса (1 для списка сущностей + 10,000 для подсчета событий), физически не может уложиться в эти лимиты. В отличие от SQL-запроса GROUP BY, который выполняется оптимизированным движком базы данных за секунды, Bubble выполняет агрегацию на уровне приложения (application layer). Это означает, что данные должны быть извлечены из базы, десериализованы в объекты приложения, подсчитаны, и только затем результат будет записан.  
* **Следствие:** Процесс упадет с ошибкой таймаута на середине списка (например, на 350-й сущности). Поскольку транзакции в Bubble не являются атомарными для всего списка, часть данных обновится, часть — нет. Система придет в несогласованное состояние, требующее ручного вмешательства, что нарушает требование «low maintenance».1

#### **Б. Экспоненциальное потребление Workload Units (WU)**

С переходом Bubble на модель тарификации Workload Units (WU) в 2023 году, «наивный» подход стал финансово неприемлемым.

* Bubble взимает плату за объем данных, возвращенных из базы данных, даже если они не отображаются пользователю.  
* При подсчете :count в поиске Do a search for Events, платформа часто сканирует и «поднимает» метаданные всех соответствующих строк.  
* В нашем примере: 10,000 поисков по таблице с 500,000 записями. Даже если каждый поиск возвращает только число, суммарные затраты на инициализацию поиска и фильтрацию будут колоссальными. По оценкам сообщества, такая операция может потреблять десятки тысяч WU ежедневно, что эквивалентно сотням долларов в месяц только за одну эту фоновую задачу.2

#### **В. Блокировка ввода-вывода (IO Blocking)**

Хотя Bubble использует мощную базу данных (Postgres), абстракция данных не позволяет разработчику управлять уровнями изоляции транзакций. Массовая запись (обновление 10,000 сущностей) в короткий промежуток времени создает очередь на запись.

* Это приводит к тому, что обычные действия пользователей (например, сохранение профиля) начинают выполняться с задержкой, так как база данных занята обслуживанием фонового процесса.  
* Клиент верно идентифицировал этот риск как «heavy IO load on production».3

### **2.3. Вердикт по проблеме P2†**

Статус: КРИТИЧЕСКИЙ РИСК (VALIDATED).  
Реализация аналитики через простой scheduled job внутри Bubble без использования специализированных паттернов (Recursive Workflows с оптимизацией поиска или Satellite Data Types) приведет к нестабильности системы и непрогнозируемым расходам. Гипотеза клиента полностью подтверждается технической документацией и опытом сообщества.

## ---

**3. Глубокий анализ обоснованности проблемы ограничений репликации (P1†)**

Вторая ключевая проблема касается невозможности использования стандартных механизмов репликации данных для выгрузки аналитической нагрузки. Клиент утверждает: «our current setup may limit built in replication support». Это утверждение требует детального разбора того, что означает «репликация» в контексте Bubble и почему она недоступна.

### **3.1. «Огороженный сад» No-Code и стена API**

В традиционной веб-разработке (например, на Django или Node.js с Postgres) проблема разделения нагрузок решается тривиально: создается **Read Replica** — точная копия основной базы данных, работающая в режиме «только чтение». Аналитические запросы (SELECT SUM(...) FROM events GROUP BY...) направляются на реплику, полностью разгружая основную базу (Master), которая продолжает обслуживать пользовательские записи.

В экосистеме Bubble ситуация кардинально отличается из-за архитектуры платформы:

1. **Отсутствие прямого доступа к SQL (No Direct SQL Access):** На всех стандартных тарифных планах (Starter, Growth, Team) Bubble **не предоставляет** клиентам доступ к строке подключения базы данных (Connection String) и порту 5432. База данных полностью абстрагирована. Это означает, что невозможно подключить внешние инструменты ETL (такие как Fivetran, Airbyte) или BI-системы (Tableau, PowerBI) напрямую к базе данных.4  
2. **Доступность только на Enterprise/Dedicated:** Возможность прямого подключения к базе данных и настройки репликации появляется только на выделенных планах (Dedicated Cluster). Стоимость таких планов начинается от нескольких тысяч долларов в месяц, что, судя по бюджету консультации («5 to 10 hours») и профилю клиента (P2⁎ указывает на небольшие бюджеты проектов), является экономически нецелесообразным.11

### **3.2. Data API как «узкое горлышко» (The API Bottleneck)**

Поскольку прямое SQL-соединение недоступно, единственным штатным шлюзом для извлечения данных остается **Bubble Data API** (RESTful API). Клиент справедливо опасается, что этот метод не является полноценной заменой репликации.

* **Проблема пропускной способности:** Data API работает поверх HTTP и прикладного уровня Bubble. Это добавляет огромные накладные расходы (overhead) на сериализацию данных в JSON, проверку прав доступа (Privacy Rules) для каждой записи и передачу по сети. В отличие от бинарного протокола Postgres, JSON-текст занимает в разы больше объема и требует парсинга.12  
* **Лимиты и Пагинация:** Data API имеет жесткие ограничения. Ранее существовал лимит в 50,000 записей, сейчас работа с большими объемами требует сложной логики пагинации (курсоров). Выгрузка 1,000,000 событий через API потребует тысяч последовательных HTTP-запросов. Если один запрос упадет, процесс может потребоваться перезапускать или реализовывать сложную логику повторов (retry logic).14  
* **Rate Limiting:** Data API имеет лимиты на количество запросов в минуту (например, 1,000 request/min). Массированная выгрузка данных может быстро исчерпать этот лимит, блокируя работу других интеграций.4

![][image2]

### **3.3. Вердикт по проблеме P1†**

Статус: ОБОСНОВАНО (VALIDATED).  
Гипотеза клиента верна. Текущая инфраструктура Bubble действительно блокирует использование нативных механизмов репликации баз данных. Любая стратегия построения аналитики (Option 1) должна учитывать, что данные придется «вытягивать» через узкий и дорогой канал Data API, а не через стандартные механизмы репликации Postgres. Это требует построения кастомного ETL-пайплайна, оптимизированного под инкрементальную загрузку, а не простого подключения BI-инструмента.

## ---

**4. Скрытые архитектурные риски (Second-Order Insights)**

Помимо явно выявленных клиентом проблем, наш анализ вскрывает дополнительные риски второго порядка, которые критически важны для успеха проекта. Без их учета даже внешняя архитектура может оказаться несостоятельной.

### **4.1. Проблема «Грязного чтения» и Идемпотентности**

Клиент требует систему, которая будет «accurate» и «rerunnable». В распределенных системах, где ETL-скрипт забирает данные из Bubble по API, возникает риск дублирования данных.

* *Сценарий:* Скрипт запрашивает события за сегодня. Bubble возвращает первую страницу (100 записей). Во время обработки второй страницы происходит сбой сети. При повторном запуске скрипт снова запрашивает первую страницу.  
* Если целевая база данных (Warehouse) просто делает INSERT, мы получим дубликаты метрик. Статистика будет искажена (например, двойной подсчет кликов).  
* **Инсайт:** Простого копирования данных недостаточно. Необходимо внедрение строгой стратегии **Идемпотентности** (Idempotency) на уровне схемы базы данных и логики записи. Это требует генерации детерминированных уникальных ключей для каждого агрегированного события.6

### **4.2. Конфликт схем данных: Документо-ориентированный подход vs Реляционная аналитика**

Bubble поощряет использование списков (List of Things) внутри объектов, что напоминает NoSQL-подход. Однако для аналитики такие структуры губительны.

* Если в Bubble у сущности «Проект» есть список «Просмотры» (List of Views), то при росте списка до >10,000 элементов производительность работы с этой сущностью падает до нуля.11  
* **Инсайт:** При экспорте данных необходимо проводить нормализацию схемы. Нельзя просто копировать структуру Bubble 1-в-1. Аналитическое хранилище должно использовать схему «Звезда» (Star Schema) или широкие таблицы (Wide Tables), оптимизированные для колоночного сжатия и агрегации, а не объектную модель Bubble.18

### **4.3. Бэкфиллинг исторических данных**

Требование клиента включает «backfill plan». Загрузка истории за год через Bubble Data API — это нетривиальная задача.

* При скорости 5 записей в секунду (реалистичная оценка с учетом накладных расходов API), загрузка 1 миллиона событий займет ~55 часов непрерывной работы.  
* В это время лимиты приложения будут исчерпаны, что может повлиять на работу пользователей.  
* **Инсайт:** Бэкфиллинг должен быть стратегически спланирован как фоновый процесс с низким приоритетом, работающий «с конца» (от новых данных к старым), чтобы пользователи сразу получили актуальную аналитику, пока история подгружается.20

## ---

**5. Стратегический анализ архитектурных опций (T⁎ Выполнение)**

На основе проведенного анализа мы переходим к выполнению задачи T⁎: оценке опций и предложению лучшей архитектуры.

### **5.1. Оценка текущих опций**

**Option 1: Copy to Replica/Warehouse.**

* *Плюсы:* Изоляция нагрузки. Возможность использования мощных SQL-инструментов. Масштабируемость.  
* *Минусы:* Сложность реализации ETL (из-за ограничений Bubble API). Задержка данных (не Real-time).  
* *Вердикт:* **Единственно возможный путь** для масштабируемой системы, но требует правильного выбора инструментов.

**Option 2: Scheduled Backend Job (Native).**

* *Плюсы:* Простота (все в одном месте). Отсутствие внешних зависимостей.  
* *Минусы:* Высокие риски таймаутов (P2†). Высокая стоимость WU. Блокировка IO.  
* *Вердикт:* **Неприемлемо** для текущих объемов и требований клиента.

### **5.2. Рекомендуемая архитектура: Гибридная декуплинговая модель (Decoupled Analytics)**

Мы предлагаем гибридную архитектуру, где Bubble остается фронтендом и транзакционной базой для пользовательских данных, а вся аналитическая нагрузка выносится в специализированное внешнее хранилище («Sidecar Database»).

#### **Компоненты решения:**

1. **Источник (Source):** Bubble.io (Таблица Events).  
2. **Слой экстракции (ETL Layer):** Внешний Low-Code оркестратор (например, n8n, Make) или кастомный скрипт на Python/Node.js, размещенный на AWS Lambda / Google Cloud Functions. Этот слой отвечает за инкрементальный опрос Bubble Data API.  
3. **Аналитическое хранилище (Warehouse):** **Supabase** (Managed Postgres) или **Tinybird** (ClickHouse).  
   * *Supabase:* Рекомендуется как основной вариант. Это полноценный Postgres, который имеет отличную интеграцию с Bubble, бесплатен на старте и масштабируется. Он позволяет строить сложные SQL-запросы для аналитики.  
   * *Tinybird:* Рекомендуется как альтернатива, если объем событий превышает миллионы в месяц. Tinybird специализируется на приеме потоков событий (ingestion) через API и мгновенной аналитике в реальном времени.  
4. **Петля обратной связи (Feedback Loop):** Агрегированные данные (например, «Всего просмотров за вчера») вычисляются в хранилище и возвращаются обратно в Bubble через API только в виде готовых чисел, которые записываются в легкие поля сущностей для отображения в интерфейсе.

![][image3]

## ---

**6. Детальный план реализации (Deliverable)**

В ответ на запрос клиента предоставить «A concise written plan my developer can implement», ниже разработан пошаговый план внедрения предложенной архитектуры.

### **6.1. Стратегия инкрементальной обработки (Incremental Strategy)**

Главная задача ETL-скрипта — минимизировать количество запросов к Bubble API, чтобы не платить за сканирование одних и тех же данных.

**Паттерн «Скользящий курсор» (Sliding Cursor Pattern):**

1. Убедитесь, что в таблице Events в Bubble есть системное поле Modified Date (оно создается автоматически и индексируется).  
2. ETL-процесс хранит в своей локальной базе или переменной метку времени последнего успешного запуска: Last_Sync_Timestamp.  
3. При каждом запуске скрипт делает запрос к Bubble Data API с ограничением (Constraint):  
   HTTP  
   GET /obj/Events?constraints=&sort_field=Modified Date&sort_order=ascending

   Это гарантирует, что извлекаются *только* новые или измененные записи. Это решает проблему P2† (Full Scan) и минимизирует IO load.15

### **6.2. Целевая схема данных (Target Schema)**

В аналитической базе данных (Supabase/Postgres) не следует повторять структуру Bubble. Используйте плоскую структуру для агрегатов.

**Таблица агрегации: daily_entity_stats**

| Имя колонки | Тип данных | Описание и назначение |
| :---- | :---- | :---- |
| stat_id | Text (PK) | Уникальный детерминированный хэш (см. 6.3) |
| entity_id | Text | ID сущности из Bubble (Foreign Key logic) |
| date | Date | Дата события (YYYY-MM-DD) |
| metric_type | Text | Тип метрики ('view', 'click', 'save') |
| value | Integer | Значение счетчика |
| last_updated | Timestamp | Техническое поле времени пересчета |

### **6.3. Подход к идемпотентной записи (Idempotent Write Approach)**

Чтобы обеспечить требование «rerunnable» (возможность перезапуска без дублирования данных), необходимо использовать стратегию **Deterministic ID Generation** и **Upsert**.

1. **Генерация ключа:** Для каждой агрегированной строки (например, «Сущность А, дата 01.01.2025, метрика Просмотры») генерируется уникальный ID путем хэширования.  
   * Формула: Hash(EntityID + "_" + Date + "_" + MetricType).  
   * Пример: MD5("12345_2025-01-01_views") -> a1b2c3d4....  
2. Операция UPSERT (Merge):  
   При вставке данных в Supabase используется SQL-команда INSERT... ON CONFLICT:  
   SQL  
   INSERT INTO daily_entity_stats (stat_id, entity_id, date, metric_type, value)  
   VALUES ('a1b2c3d4...', '12345', '2025-01-01', 'view', 150)  
   ON CONFLICT (stat_id)  
   DO UPDATE SET  
       value = EXCLUDED.value,  
       last_updated = NOW();

   Этот подход делает пайплайн неуязвимым к сбоям: если скрипт запустится дважды, данные просто обновятся до актуальных значений, но не задвоятся.6

### **6.4. План бэкфилла (Backfill Plan)**

Для первоначальной загрузки исторических данных нельзя использовать основной инкрементальный процесс.

1. **Обратная хронология:** Начинайте загрузку с *вчерашнего* дня и двигайтесь вглубь истории. Это даст пользователям ценность (аналитику за последнюю неделю) уже в первый день работы скрипта.  
2. **Пакетирование (Batching):** Разбивайте историю на чанки по неделям или месяцам.  
3. **Rate Limiting:** Установите искусственную задержку между запросами к API (например, 500 мс), чтобы бэкфилл не потреблял всю пропускную способность (Capacity) приложения Bubble, оставляя ресурсы для живых пользователей.

### **6.5. Рекомендация по инфраструктуре**

С учетом вводных данных («Short consult», «Individual client»), использование Enterprise-решений типа Snowflake избыточно.

* **Primary Recommendation:** **Supabase**.  
  * Предоставляет полноценный Postgres.  
  * Встроенный API (PostgREST) облегчает интеграцию.  
  * Бесплатный уровень (Free Tier) достаточен для старта (до 500MB данных).  
  * Легкая миграция: если проект вырастет, Postgres — это стандарт индустрии.22

## ---

**7. Стратегическое заключение и матрица решений**

Проведенный анализ подтверждает, что опасения клиента ꆜ являются технически обоснованными и свидетельствуют о глубоком понимании рисков масштабирования No-Code систем. Попытка решить задачу аналитики методами «грубой силы» внутри Bubble (Option 2) приведет к созданию нестабильной системы с высокими эксплуатационными расходами.

Решение задачи лежит не в оптимизации алгоритмов внутри Bubble, а в изменении архитектурной парадигмы: переходе от монолитного No-Code приложения к **композуемой архитектуре**, где Bubble выполняет роль фронтенда и бизнес-логики, а тяжелые операции с данными делегируются специализированным системам (Supabase/Tinybird).

![][image4]

Предложенный план обеспечивает требуемую точность и надежность, минимизируя влияние на производственную среду и создавая фундамент для дальнейшего масштабирования проекта P⁎.

#### **Works cited**

1. Performance | Bubble Docs, accessed December 18, 2025, [https://manual.bubble.io/help-guides/maintaining-an-application/performance-and-scaling](https://manual.bubble.io/help-guides/maintaining-an-application/performance-and-scaling)  
2. How to optimize your app's workload units (biggest WU killers) - Tips - Bubble Forum, accessed December 18, 2025, [https://forum.bubble.io/t/how-to-optimize-your-app-s-workload-units-biggest-wu-killers/338474](https://forum.bubble.io/t/how-to-optimize-your-app-s-workload-units-biggest-wu-killers/338474)  
3. Data Pipeline and DB Architecture Consult - Freelance Job in Data Mining & Management - Less than 30 hrs/week - Upwork, accessed December 18, 2025, [https://www.upwork.com/freelance-jobs/apply/Data-Pipeline-and-Architecture-Consult_~022001694751271577029/](https://www.upwork.com/freelance-jobs/apply/Data-Pipeline-and-Architecture-Consult_~022001694751271577029/)  
4. Hard limits | Bubble Docs, accessed December 18, 2025, [https://manual.bubble.io/help-guides/maintaining-an-application/performance-and-scaling/hard-limits](https://manual.bubble.io/help-guides/maintaining-an-application/performance-and-scaling/hard-limits)  
5. Architecture for Bubble and Big Data 30 million records+ - Database, accessed December 18, 2025, [https://forum.bubble.io/t/architecture-for-bubble-and-big-data-30-million-records/252581](https://forum.bubble.io/t/architecture-for-bubble-and-big-data-30-million-records/252581)  
6. Building idempotent data pipelines interview questions & answers - java-success.com, accessed December 18, 2025, [https://www.java-success.com/building-idempotent-data-pipelines-interview-questions-answers/](https://www.java-success.com/building-idempotent-data-pipelines-interview-questions-answers/)  
7. Idempotent Data Pipelines with Spark and SQLMesh | by Andymadson - Medium, accessed December 18, 2025, [https://medium.com/@andymadson/idempotent-data-pipelines-with-spark-and-sqlmesh-eda8056b07c5](https://medium.com/@andymadson/idempotent-data-pipelines-with-spark-and-sqlmesh-eda8056b07c5)  
8. Best Way to Handle 100k+ Data in Bubble? - Database, accessed December 18, 2025, [https://forum.bubble.io/t/best-way-to-handle-100k-data-in-bubble/376604](https://forum.bubble.io/t/best-way-to-handle-100k-data-in-bubble/376604)  
9. FAQ: Pricing and Workload - Bubble Docs, accessed December 18, 2025, [https://manual.bubble.io/account-and-marketplace/account-and-billing/pricing-plans/pricing-faq](https://manual.bubble.io/account-and-marketplace/account-and-billing/pricing-plans/pricing-faq)  
10. 10 Tips to Maximize Your Web App's Performance on Bubble, accessed December 18, 2025, [https://bubble.io/blog/improve-web-app-performance/](https://bubble.io/blog/improve-web-app-performance/)  
11. What are the limitations of Bubble.is in terms of database capabilities? : r/Bubbleio - Reddit, accessed December 18, 2025, [https://www.reddit.com/r/Bubbleio/comments/vcqkhi/what_are_the_limitations_of_bubbleis_in_terms_of/](https://www.reddit.com/r/Bubbleio/comments/vcqkhi/what_are_the_limitations_of_bubbleis_in_terms_of/)  
12. Exporting large datasets via 1Tcsv plugin(json to csv) server side - Bubble Forum, accessed December 18, 2025, [https://forum.bubble.io/t/exporting-large-datasets-via-1tcsv-plugin-json-to-csv-server-side/249940](https://forum.bubble.io/t/exporting-large-datasets-via-1tcsv-plugin-json-to-csv-server-side/249940)  
13. Exporting large volume of data - Database - Bubble Forum, accessed December 18, 2025, [https://forum.bubble.io/t/exporting-large-volume-of-data/8081](https://forum.bubble.io/t/exporting-large-volume-of-data/8081)  
14. Data API limits, cost, and overages - Questions - Bubble Forum, accessed December 18, 2025, [https://forum.bubble.io/t/data-api-limits-cost-and-overages/365916](https://forum.bubble.io/t/data-api-limits-cost-and-overages/365916)  
15. Impossible to fetch more than 50k records via API? - Bubble Forum, accessed December 18, 2025, [https://forum.bubble.io/t/impossible-to-fetch-more-than-50k-records-via-api/201519](https://forum.bubble.io/t/impossible-to-fetch-more-than-50k-records-via-api/201519)  
16. How to write data to BubbleDB using Data API Bulk Data Loader - Tips - Bubble Forum, accessed December 18, 2025, [https://forum.bubble.io/t/how-to-write-data-to-bubbledb-using-data-api-bulk-data-loader/19087](https://forum.bubble.io/t/how-to-write-data-to-bubbledb-using-data-api-bulk-data-loader/19087)  
17. How much data can we input to my Database - Questions - Bubble Forum, accessed December 18, 2025, [https://forum.bubble.io/t/how-much-data-can-we-input-to-my-database/176588](https://forum.bubble.io/t/how-much-data-can-we-input-to-my-database/176588)  
18. traditional star schema vs wide-table performance comparison in Snowflake, accessed December 18, 2025, [https://stackoverflow.com/questions/59166593/traditional-star-schema-vs-wide-table-performance-comparison-in-snowflake](https://stackoverflow.com/questions/59166593/traditional-star-schema-vs-wide-table-performance-comparison-in-snowflake)  
19. Choosing the Right Data Warehouse Modelling Approach | by Andy Sawyer, accessed December 18, 2025, [https://blog.datatraininglab.com/choosing-the-right-data-warehouse-modelling-approach-45d2b6812512](https://blog.datatraininglab.com/choosing-the-right-data-warehouse-modelling-approach-45d2b6812512)  
20. Backfilling Data: A Foolproof Guide to Managing Historical Data - lakeFS, accessed December 18, 2025, [https://lakefs.io/blog/backfilling-data-foolproof-guide/](https://lakefs.io/blog/backfilling-data-foolproof-guide/)  
21. Mastering Idempotency in Data Analytics: Ensuring Reliable Pipelines | Python-bloggers, accessed December 18, 2025, [https://python-bloggers.com/2024/12/mastering-idempotency-in-data-analytics-ensuring-reliable-pipelines/](https://python-bloggers.com/2024/12/mastering-idempotency-in-data-analytics-ensuring-reliable-pipelines/)  
22. Pricing & Fees - Supabase, accessed December 18, 2025, [https://supabase.com/pricing](https://supabase.com/pricing)  
23. Google Cloud vs Supabase - GetDeploying, accessed December 18, 2025, [https://getdeploying.com/google-cloud-vs-supabase](https://getdeploying.com/google-cloud-vs-supabase)
