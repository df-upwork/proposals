Почти наверняка ваша проблема вызвана изложенной ниже в пункте 1 причиной.
Причина пункта 2 — прямое следствие причины пункта 1.
1) Критический дефект микропрограммы накопителей Samsung NVMe (Bug 3B2QGXA7) и переход в режим «Read-Only»
1.1) Суть
`https://www.google.com/search?q="3B2QGXA7"&pws=0&gl=US`
При определенной наработке или нагрузке эта ошибка переводит устройство в необратимый режим «только для чтения» или вызывает его полное зависание, что интерпретируется гипервизором ESXi как потеря устройства (PDL — Permanent Device Loss).
Видимо, в момент упоминаемой вами миграции виртуальных машин возросшая нагрузка на запись (Write Amplification) спровоцировала проявление этого дефекта. 
Это привело к одновременному отказу нескольких дисков в кэширующем или емкостном слое, так как они, вероятнее всего, были приобретены одной партией и имели идентичную наработку. 
Гипотеза основывается на подтвержденных данных о массовом браке прошивки версии 3B2QGXA7 (и более ранних 3B2QGXA5), который приводит к лавинообразному появлению ошибок носителя (Media Errors) и отказу контроллера SSD. 
1.2) Обоснование
1.2.1)
На вашем снимке экрана виден статус «Unknown» для 4 дисков одновременно на одном хосте. 
Это является классическим признаком системного сбоя однотипного оборудования, характерного для программной ошибки в прошивке («logic bomb»), а не случайного физического износа, который редко происходит синхронно на четырех устройствах.
1.2.2)
Накопители Samsung 980 Pro (и их OEM-аналоги PM9A1) с проблемной прошивкой 3B2QGXA7 переходят в состояние отказа с симптомами, идентичными наблюдаемым: исчезновение из системы, ошибки таймаута и статус «All Paths Down» (APD) в логах ESXi.
1.2.3) Вы в своей работе используете дешманское оборудование потребительского класса (Consumer Grade), о чем свидетельствует название дисков «Local SAMSUNG Disk» на вашем снимке экрана. 
Это полностью совпадает с профилем пострадавших пользователей, описывающих проблемы с Samsung 980 Pro в средах виртуализации.
1.2.4) vCenter отображает статус «Unknown», потому что драйвер ESXi получает от устройства критические предупреждения SMART (Critical Warning), которые интерпретируются стеком хранения как полный и необратимый отказ контроллера.
1.2.5) Описанное вами отсутствие реакции на перезагрузку («problem remains») является характерной чертой сбоя прошивки 3B2QGXA7. 
Диск переходит в защитный режим на уровне своего внутреннего контроллера (ASIC), и сброс питания сервера (Power Cycle) не восстанавливает его способность к записи, так как блокировка записана в энергонезависимую память самого диска. 
1.2.6) Версия ESXi 7.0.3 использует обновленный стек драйверов NVMe, который более чувствителен к нарушениям спецификации протокола. 
Старый драйвер vmklinux мог бы попытаться пересбросить устройство, но новый драйвер nvme-pcie при получении критических ошибок немедленно прекращает обслуживание устройства во избежание коррупции данных.
2) Каскадный отказ дисковой группы из-за сбоя кэширующего устройства (Cache Tier Failure)
2.1) Суть
Данная гипотеза предполагает, что физический или логический отказ всего одного диска — кэширующего SSD (Cache Tier) в дисковой группе хоста №4 — привел к недоступности всех зависимых от него дисков емкости (Capacity Tier). 
Архитектура vSAN OSA (Original Storage Architecture) жестко связывает диски емкости с кэширующим устройством: метаданные о размещении данных на уровне группы, а также буферы записи, хранятся и обрабатываются именно кэширующим диском.   
В случае выхода из строя кэш-диска (например, из-за исчерпания ресурса записи DWPD, что крайне вероятно для ваших потребительских моделей Samsung в задачах кэширования vSAN, где нагрузка на запись колоссальна) вся дисковая группа помечается как неисправная
Множественное число в вашем описании («the disks... are not normal») объясняется тем, что в интерфейсе vCenter все диски группы, лишенные своего «лидера» (кэш-диска), отображаются с ошибками. 
Статус «Metadata Health: Red» на одном из дисков (вероятно, самом кэширующем) подтверждает невозможность чтения критических структур данных (LSOM Log), необходимых для монтирования группы.
2.2) Обоснование
2.2.1) По сути, эта гипотеза — прямое следствие наиболее вероятной гипотезы пункта 1.
2.2.2)  Архитектура vSAN OSA имеет фундаментальную уязвимость: потеря кэш-диска гарантированно выводит из строя всю группу. 
Это полностью соответствует картине массового «отвала» всех дисков на одном хосте, наблюдаемой на вашем снимке экрана.
2.2.3) Потребительские SSD (например, Samsung 980 Pro) имеют низкий показатель выносливости (0.3-0.6 DWPD). 
В роли кэша vSAN они принимают на себя 100% операций записи, что приводит к их износу (Wearout) в десятки раз быстрее расчетного срока. 
2.2.4) «Skyline Health» на вашем снимке экрана показывает 5 проблемных дисков: 1 с ошибкой метаданных и 4 со статусом «Unknown».
Это идеально коррелирует со стандартной конфигурацией vSAN ReadyNode (1 Cache + 4 Capacity) или типовой сборкой сервера (все слоты заполнены). 
Диск с ошибкой метаданных, вероятнее всего, является кэш-диском, чья файловая система разрушена. 
2.2.5) В случае отказа кэш-диска, диски емкости остаются физически исправными, но логически «осиротевшими». 
Система не может сопоставить их UUID с конфигурацией группы, так как таблица маппинга находилась на умершем кэш-диске. 
Это приводит к невозможности их идентификации и статусу «Unknown». 


