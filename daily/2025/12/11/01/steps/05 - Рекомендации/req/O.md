# 0.
Сегодня 2025-12-11.

# 1.
## 1.1.
`UW` ≔ (Upwork: https://en.wikipedia.org/wiki/Upwork)

## 1.2.
`ꆜ` ≔ (Некий конкретный потенциальный клиент на `UW`)

## 1.3.
`P⁎` ≔ (Некий конкретный потенциальный проект, опубликованный `ꆜ` на `UW`)

# 2. Информация о `P⁎`
## 2.1. URL
https://www.upwork.com/jobs/~021999029723057542100

## 2.2. Title
Varnish Cache Expert (consultancy) - Memory Management

## 2.3. Description
`PD` ≔ 
```text
#
Me an my developer are looking for a Varnish Cache specialist to help us diagnose and resolve persistent memory issues in our caching layer on our website RunRepeat.com

#
Our frontend is on a Gravitron CPU 8 Cores, 32Gb RAM. 

#
Basically, Varnish repeatedly grows the memory, which leads to performance degradation - regardless of what config we've tried. 

#
We need help with VCL configuration, cache policies, proper memory allocation, TTLs, eviction strategies and guidance on monitoring and alerting best practices.

#
Our site receives about 4M monthly sessions and the complexity is that our pages are not fully static, as users can filter by gender, size, color, which is then used throughout the site. We also have ads on the site. 

#
This is a one-time-consultantion for now, but we might need more help on server-setup things in the future, and it would be amazing to have you as a point of contact.
```

## 2.4. Tags
STUB

## 2.5. Questions
### 2.5.1.
STUB

### 2.5.2.
STUB

### 2.5.3.
STUB

### 2.5.4.
STUB

### 2.5.5.
STUB

# 5. Информация о `ꆜ`
## 5.1. Местоположение
Denmark
Frederiksberg

## 5.2. Характеристики компании
### 5.2.1. Сектор экономики
Sports & Recreation

### 5.2.2. Количество сотрудников
10-99

## 5.3. Характеристики учётной записи на `UW`
### 5.3.1. Member since
Jun 8, 2013
### 5.3.2. Hire rate (%)
93
### 5.3.3. Количество опубликованных проектов (jobs posted)
113
### 5.3.4. Total spent (USD)
540K
### 5.3.5. Количество оплаченных часов в почасовых проектах
42423
### 5.3.6. Средняя почасовая ставка (USD)
12.46 

# 6. Другие проекты `ꆜ` на `UW`
## 6.1. `P1⁎`

### 6.1.1. URL
https://www.upwork.com/jobs/~013caa0ae3e610c8bb

### 6.1.2. Title
Large-scale NLP and AI copy for book reviews

### 6.1.3. Description
`P1D` ≔ 
```text
I’m Jens, founder of RunRepeat.com. We’re a 25 people team and I have worked on this for 7 years. 

I’m now starting a new project aggregating and summarizing reviews of books. It’s a huge project that depends on two main skills: (1) heavy scraping and (2) NLP and AI copy. This post is about NLP and AI copy. I have created a separate one for the scraping part as I figured we might need a separate person for that part.

Why this job is cool:
(1) it's a huge project = stable income, and you can combine with other freelance jobs as you like
(2) I have a profitable business (RunRepeat), which means that we would not run out of money. 
(3) A lot of decision-making on your end, and zero bureaucracy. 

It’s a big project, and you will be part of defining the direction of where we’ll go. Below are the bare fundamentals on where we want to get at. I understand that some of these require different skill sets, and you might not have them all. But, if you have fundamental skills in these areas and hands-on experience with something similar, I’d love to chat with you about this and see how we could work together. The tasks below are for both scrapings, NLP and AI copy - just to give you the overview of the entire project. 

(a) Scrape Amazon and Goodreads for all book titles and store basic information about the book, author, categories etc. (Millions of books). Millions of books. Example page: https://www.amazon.com/Zero-to-One-audiobook/dp/B00M284NY2/ref=sr_1_1

(b) Find all critic reviews of that book title and consider how to match variations, e.g. some only mentioning the first part of the title, or another word for it.

(c) Do text analysis of each critic review to rate them 1-100 in how positive the critic is about the review itself. I understand that it will be hard/impossible to reach such a granular score, but maybe we’ll end up with a 1 to 4 rating scale like what this site has or similar: https://bookmarks.reviews/reviews/something-new-under-the-sun/

(d) Find the best way to make AI writeups summarizing critic opinions as well as book summary/introduction to have unique copy on our pages. 

(e) Look for all “lists” where books are mentioned. For example “best business books” or “most recommended books to read in 2021” and suggest an algorithm how we incorporate these “buying guides” into our overall scoring system. How to weigh the first book listed, the 10th etc?  

(f) Get an overview of all cases of where the book has been recommended by some person or entity. The end goal is that product pages would have sections like “Recommneded by: Elon Musk, Bill Gates” and then users can click on these tags to land on a page with all books recommended by Elon Musk. Store quotes. 

(g) Scrape all user reviews and make text analysis to extract characteristics of the books.

(h) Get all awards for each book. 

(i) Overview of all forum discussions, e.g. scraping of reddit and other sites that users can click on to read more. Provide short snippets. 

(j) Based on user and critic reviews, get to an overall score, and create our own lists for all possible categories, like “best python programming books” or “most recommended” that can then be narrowed down with filters. 

I know, it’s not something that you’ll have done by tomorrow. As a first step, let’s see if there’s a match between you, I and the project. 
```

### 6.1.4. Publication Date
4 years ago

# 7.
## 7.1.
`POs` ≔⠿ {`P1⁎`}

## 7.2.
`Ps` ≔ (⠿{`P⁎`} ⋃ `POs`)

## 7.3.
`Pi` : `Ps`

# 8.
## 8.1.
`С⁎` ≔ 
```
Компания `ꆜ`:
~~~
RunRepeat.com
~~~
```

## 8.2.
⊤ (Все `Pi` касаются `С⁎`)

## 8.3.
Сайт `С⁎`: https://runrepeat.com

# 9.
`P†` ≔†
```
Проблема, о которой `ꆜ` пишет в `PD`:
~~~
Varnish repeatedly grows the memory, which leads to performance degradation - regardless of what config we've tried
~~~
```

# 10. Что беспокоит `ꆜ` (анализ выполнен Gemini Deep Think)
https://gemini.google.com/share/91e87ec1062c

## 1. Выявление проблем в проекте `P⁎`

На основе анализа описания задачи `PD` и онтологии `O.md`, можно выделить следующие ключевые проблемы, которые беспокоят клиента `ꆜ`:

1.  **Неконтролируемый рост потребления оперативной памяти (Memory Leak / Unbounded Growth).** Varnish постоянно увеличивает потребление RAM вплоть до исчерпания ресурсов сервера (32 ГБ), несмотря на установленные лимиты.
2.  **Деградация производительности (Performance Degradation).** Исчерпание памяти приводит к замедлению работы сайта. Вероятно, это связано с уходом системы в swap, повышением нагрузки на CPU из-за агрессивной работы сборщика мусора (LRU nuking) или фрагментацией памяти.
3.  **Неэффективность конфигурации («Config changes haven't helped»).** Клиент утверждает, что стандартные методы тюнинга не решают проблему. Это указывает на то, что корень проблемы лежит вне стандартных настроек размера кэша (`-s malloc,SIZE`).
4.  **Сложность кэширования динамического контента (High Cardinality).** Наличие фасетного поиска (фильтры по полу, размеру, цвету) и рекламных меток создает высокую вариативность запросов.
5.  **Влияние аппаратной архитектуры (Graviton CPU).** Использование процессоров ARM64 (AWS Graviton) может вносить специфику в управление памятью, если используемое ПО не оптимизировано под эту архитектуру.

## 2. Анализ обоснованности выявленных проблем

Выявленные проблемы технически обоснованы. Ситуация `RunRepeat.com` представляет собой классический анти-паттерн конфигурации Varnish для E-commerce проектов с высокой вариативностью.

### 2.1. Проблема «Взрыва кэша» (Cache Bloat / High Cardinality)
Эта проблема является **наиболее вероятной первопричиной** и полностью обоснована техническим устройством Varnish.
*   **Механизм:** Varnish по умолчанию использует полный URL (включая строку запроса `query string`) для формирования ключа объекта.
*   **Анализ:**
    *   Фильтры (`gender`, `size`, `color`) создают множество перестановок. Запросы `/shoe?size=42&color=red` и `/shoe?color=red&size=42` считаются разными объектами.
    *   Реклама на сайте («We also have ads») подразумевает наличие меток (gclid, fbclid, utm), уникальных для каждого пользователя. Это заставляет Varnish кэшировать копию страницы для каждого клика.
*   **Влияние на память:** Даже если размер *данных* ограничен параметром `-s malloc`, каждый объект потребляет около **1 КБ** оперативной памяти на **метаданные** (структуры `struct obj`, `struct objcore`), которые хранятся вне основного хранилища. При миллионах мелких объектов (из-за фильтров и рекламы) одни только метаданные могут занять десятки гигабайт RAM, вызывая переполнение памяти.

### 2.2. Проблема Transient Storage (Временное хранилище)
Эта проблема обосновывает жалобу клиента на то, что «изменения конфигов не помогают».
*   **Обоснование:** В Varnish существует отдельное хранилище `Transient` для объектов с коротким TTL и технических записей `hit-for-pass` / `hit-for-miss` (меток о том, что объект нельзя кэшировать).
*   **Анализ:**
    *   По умолчанию размер `Transient` хранилища **не ограничен** (unbounded).
    *   Если бэкенд сайта выставляет заголовок `Set-Cookie` или `Cache-Control: private` в ответ на запросы с рекламными метками, Varnish создает запись `hit-for-miss` для каждого такого запроса.
    *   Эти записи накапливаются в Transient-хранилище, потребляя память бесконтрольно, игнорируя основной лимит кэша. Это выглядит как утечка памяти, которую невозможно устранить стандартными настройками `-s`.

### 2.3. Фрагментация памяти (Memory Fragmentation)
Обоснована, учитывая архитектуру `P⁎`.
*   **Обоснование:** Varnish часто использует системный аллокатор памяти (`glibc malloc`). В сценариях с активным созданием и удалением миллионов мелких объектов (фильтры, сессии) возникает сильная фрагментация кучи.
*   **Анализ:** Операционная система может сообщать, что процесс занимает всю память (RSS), хотя полезных данных в кэше гораздо меньше. Стандартным решением является использование аллокатора **jemalloc**, который лучше справляется с фрагментацией, но он может требовать явной настройки.

### 2.4. Специфика Graviton (ARM64)
Является важным фактором обоснованности проблем с производительностью.
*   **Анализ:** Для архитектуры ARM64 критически важен размер страниц памяти. Стандартные настройки Linux (4K pages) могут создавать высокую нагрузку на TLB (Translation Lookaside Buffer) при работе с большими объемами памяти (32 ГБ) и огромным количеством объектов. Переход на 64K pages часто дает прирост производительности и стабильности, но требует поддержки со стороны ОС и сборки Varnish.

# 11. Что беспокоит `ꆜ` (анализ выполнен Gemini Deep Research) 
https://gemini.google.com/share/abbaebeb2f0d

## **1. Стратегический обзор архитектурных вызовов в условиях высокой кардинальности**

Проект RunRepeat.com (в дальнейшем именуемый "Проект P⁎"), представляющий собой масштабную платформу агрегации обзоров и электронной коммерции, столкнулся с рядом критических проблем производительности и стабильности инфраструктуры кэширования. Анализ симптоматики, предоставленной технической командой клиента, указывает на классическую, но сложную в диагностике дихотомию между "утечкой памяти" (memory leak) и "раздуванием кэша" (cache bloat). В контексте высоконагруженных систем, использующих Varnish Cache в качестве HTTP-акселератора, эти понятия часто смешиваются, приводя к ошибочным стратегиям оптимизации.

Современные архитектуры e-commerce, подобные RunRepeat, характеризуются использованием фасетной навигации — системы глубокой фильтрации контента по множеству атрибутов (размер, цвет, бренд, технические характеристики обуви).1 Это создает среду с экстремально высокой кардинальностью URL-адресов. В отсутствие строгих механизмов нормализации запросов, Varnish Cache вынужден обрабатывать комбинаторный взрыв уникальных объектов, что неизбежно приводит к исчерпанию ресурсов оперативной памяти. Однако, как показывает детальное изучение технических данных, проблема RunRepeat выходит за рамки простого управления объектами и затрагивает фундаментальные механизмы взаимодействия демона varnishd с подсистемой управления памятью операционной системы Linux.

Центральной гипотезой данного исследования является утверждение, что наблюдаемая нестабильность вызвана тремя взаимосвязанными факторами:

1. **Фрагментация кучи (Heap Fragmentation):** Неэффективность стандартного аллокатора glibc при работе с паттернами аллокации Varnish, приводящая к росту RSS (Resident Set Size) процесса без реального увеличения полезной нагрузки.3  
2. **Аномалии временного хранилища (Transient Storage):** Неконтролируемый рост "Transient" хранилища, которое по умолчанию не имеет верхнего лимита памяти и используется для короткоживущих объектов и буферизации потоковой передачи данных.5  
3. **Кэш-блоттинг (Cache Bloat):** Заполнение хранилища дубликатами контента из-за отсутствия нормализации Query String и заголовков User-Agent, что превращает полезный кэш в хранилище мусорных данных.7

В данном отчете представлен исчерпывающий анализ каждого из этих слоев, подкрепленный техническими данными и рекомендациями по переходу к устойчивой архитектуре.

## ---

**2. Глубинный анализ подсистемы управления памятью: Аллокаторы и Фрагментация**

Для понимания природы "утечек памяти", о которых сообщает клиент, необходимо рассмотреть механизм взаимодействия Varnish с системной памятью. Varnish не управляет физической памятью напрямую; вместо этого, при использовании бэкенда хранения malloc, он делегирует эту задачу стандартному системному аллокатору через вызовы malloc() и free().8

### **2.1. Механика взаимодействия Varnish и системного аллокатора**

Когда Varnish настроен с параметром -s malloc,256G, это создает иллюзию, что потребление памяти жестко ограничено 256 гигабайтами. В реальности этот лимит применяется только к *полезной нагрузке* кэшированных объектов. Он не учитывает накладные расходы на структуры данных ядра Varnish (overhead), такие как struct object, struct objcore и struct objhead, которые необходимы для отслеживания заголовков, сроков действия (TTL) и состояния объектов. Оценки показывают, что накладные расходы составляют примерно 1 КБ на каждый объект.8

Для сайта масштаба RunRepeat, где количество объектов может исчисляться десятками миллионов (из-за вариативности фильтров), накладные расходы могут составлять десятки гигабайт сверх установленного лимита -s.

| Тип памяти | Описание | Управляемость лимитом -s |
| :---- | :---- | :---- |
| **Object Storage** | Тело кэшированного объекта (HTML, JSON, изображения) | **Да** (Жесткий лимит) |
| **Object Overhead** | Метаданные (заголовки, баны, указатели) ~1KB/объект | **Нет** (Линейный рост от кол-ва объектов) |
| **Transient Storage** | Временные объекты, streaming buffers, hit-for-miss | **Нет** (По умолчанию unbounded) |
| **Workspace Memory** | Память потоков (workspace_client, thread_pool_stack) | **Нет** (Зависит от кол-ва потоков) |
| **Fragmentation** | Потерянная память внутри аллокатора ("дыры") | **Нет** (Зависит от эффективности аллокатора) |

### **2.2. Проблема фрагментации в glibc malloc**

Стандартным аллокатором в большинстве дистрибутивов Linux (RHEL, Debian, Ubuntu) является реализация malloc из библиотеки glibc (основанная на ptmalloc). Анализ источников указывает на то, что glibc крайне неэффективен для паттернов нагрузки, характерных для Varnish: высокая конкурентность, частые аллокации и деаллокации объектов различного размера.3

Проблема заключается в механизме работы с "аренами" (arenas). Для уменьшения блокировок (lock contention) в многопоточной среде, glibc создает несколько арен памяти. Когда память освобождается (free()), она возвращается в арену, но не всегда возвращается операционной системе. Если Varnish запрашивает блок памяти, который не помещается в существующие "дыры" фрагментированной кучи, аллокатор запрашивает новые страницы у ОС. Это приводит к росту виртуальной памяти (VSZ) и резидентной памяти (RSS), даже если внутренние счетчики Varnish показывают наличие свободного места в хранилище.4

Клиент интерпретирует это как утечку памяти, так как процесс varnishd потребляет все больше RAM, в то время как объем полезных данных в кэше может оставаться стабильным. Это классический пример внешней фрагментации. В особо тяжелых случаях, описанных в технических отчетах, переключение с glibc на альтернативные аллокаторы позволяло сократить потребление памяти с 192 ГБ до 18 ГБ.10

### **2.3. Превосходство jemalloc в высоконагруженных средах**

Техническим стандартом де-факто для высокопроизводительных приложений управления памятью (таких как Redis, Varnish, Firefox) является использование аллокатора jemalloc, разработанного Джейсоном Эвансом.

jemalloc использует принципиально иную стратегию управления памятью, разделяя объекты на классы по размеру (size classes) и используя структуру "chunks" и "runs". Это позволяет минимизировать фрагментацию, так как объекты одного размера группируются вместе. Освобождение блока памяти в jemalloc с гораздо большей вероятностью приводит к освобождению целого чанка, который может быть немедленно возвращен операционной системе.3

Кроме того, jemalloc предоставляет расширенные возможности интроспекции и настройки, такие как параметры "decay", управляющие скоростью возврата "грязных" страниц (dirty pages) ядру ОС. Установка агрессивных параметров decay может существенно снизить RSS процесса ценой незначительного увеличения нагрузки на CPU.12

Для RunRepeat.com критически важно верифицировать, с какой библиотекой слинкован исполняемый файл varnishd. В системах на базе RHEL/CentOS jemalloc часто не является дефолтным и требует явной установки пакета jemalloc и настройки systemd unit-файла для предзагрузки библиотеки или использования специально скомпилированной версии Varnish.14 Игнорирование этого фактора делает любые настройки VCL косметическими мерами на фоне фундаментальной утечки ресурсов.

## ---

**3. Парадокс временного хранилища (Transient Storage)**

Одной из наиболее коварных и наименее очевидных причин нестабильности Varnish является механизм Transient Storage. Анализ конфигурации и симптомов указывает на высокую вероятность того, что именно этот компонент ответственен за неконтролируемые всплески потребления памяти, приводящие к срабатыванию OOM Killer.15

### **3.1. Архитектура Transient Storage**

В архитектуре Varnish предусмотрено специальное хранилище для объектов, которые считаются "короткоживущими". По умолчанию, любой объект, чей TTL (Time To Live) меньше значения параметра shortlived (по умолчанию 10.0 секунд), автоматически помещается в Transient Storage, а не в основное хранилище (например, malloc или file).17

Критическая уязвимость конфигурации по умолчанию заключается в том, что Transient Storage использует **неограниченный** (unbounded) бэкенд malloc. Это означает, что если сайт подвергается атаке, или бэкенд начинает отдавать массовые ошибки с коротким TTL, или происходит всплеск посещаемости на страницах с отключенным кэшированием (hit-for-miss), Varnish будет аллоцировать память под эти объекты до полного исчерпания физической RAM сервера, игнорируя любые лимиты, установленные для основного хранилища.5

### **3.2. Векторы атаки через короткоживущие объекты**

Для RunRepeat.com существует несколько сценариев, при которых Transient Storage становится вектором отказа в обслуживании:

1. **Массовое создание объектов Hit-For-Miss:** Если Varnish настроен на создание hit-for-miss объектов (запоминание того, что страница не кэшируется) для запросов с уникальными параметрами, и TTL этих записей мал (например, 2 минуты, что является дефолтом для uncacheable_ttl 20), они могут попадать в Transient Storage, если параметр shortlived настроен некорректно или если логика VCL явно не переопределяет хранилище.  
2. **Буферизация потоков (Streaming Buffering):** Когда Varnish получает ответ от бэкенда, который нельзя кэшировать (например, из-за заголовка Set-Cookie), но который нужно передать медленному клиенту, данные буферизируются. Эти байты учитываются в счетчиках Transient Storage (SMA.Transient.c_bytes). При большом количестве одновременных подключений (high concurrency) объем этих буферов может достигать гигабайт.6  
3. **Синтетические ответы:** Ошибки, генерируемые внутри Varnish (vcl_backend_error), также часто попадают в Transient Storage. При сбое бэкенда лавина ошибок 503 может заполнить память.22

### **3.3. Стратегия ограничения (Bounding)**

Решение проблемы Transient Storage является императивным требованием для стабильности. Необходимо явно определить лимит для этого хранилища в параметрах запуска демона varnishd.

Синтаксис для ограничения Transient Storage:

Bash

-s malloc,20G   
-s Transient=malloc,2G

В данной конфигурации основное хранилище получает 20 ГБ, а временное жестко ограничено 2 ГБ. При достижении лимита в 2 ГБ Varnish начнет применять политику вытеснения (LRU) к временным объектам, вместо того чтобы аварийно завершать работу всего процесса.23

Также рекомендуется пересмотреть значение параметра shortlived. Установка его в 0s заставит Varnish помещать все объекты, независимо от их TTL, в основное хранилище, которое имеет строгие лимиты. Это предотвратит "скрытое" потребление памяти, хотя может усилить фрагментацию основного хранилища из-за частого удаления короткоживущих объектов.

## ---

**4. Феномен Cache Bloat в условиях фасетной навигации**

Проект RunRepeat.com обладает архитектурной особенностью, которая делает его экстремально уязвимым к раздуванию кэша (Cache Bloat) — это сложная система фильтрации товаров. Исследование структуры URL показывает наличие множественных параметров фильтрации: size, width, brand, color, drop, terrain и других.2

### **4.1. Комбинаторный взрыв URL-адресов**

Varnish кэширует объекты, используя хэш, вычисляемый (по умолчанию) на основе URL и заголовка Host. Это означает, что порядок параметров в строке запроса имеет значение.

Рассмотрим два запроса:

1. /running-shoes?brand=Nike&size=10&color=Black  
2. /running-shoes?size=10&brand=Nike&color=Black

С точки зрения логики приложения (бэкенда), эти запросы идентичны и возвращают одинаковый HTML. С точки зрения Varnish, это **два разных объекта**.

Количество возможных перестановок параметров растет факториально. Если пользователь может выбрать 5 фильтров из доступных 20, количество уникальных URL-адресов превышает количество атомов во вселенной. Поисковые боты и сканеры, перебирающие фильтры в произвольном порядке, могут генерировать миллионы уникальных запросов в сутки. Это явление называется "Cache Bloat" — заполнение кэша низкополезными дубликатами, что приводит к вытеснению (eviction) действительно востребованного контента (например, главной страницы или популярных категорий).7

Счетчик n_lru_nuked в varnishstat является главным индикатором этой проблемы. Высокие значения этого счетчика свидетельствуют о том, что Varnish вынужден агрессивно удалять объекты, чтобы освободить место для новых, зачастую бесполезных вариаций.27

### **4.2. Маркетинговые метки и "мусорные" параметры**

Помимо функциональных фильтров, e-commerce трафик насыщен маркетинговыми параметрами: utm_source, utm_medium, gclid, fbclid и уникальными идентификаторами сессий. Если эти параметры попадают в хэш кэша, каждый переход пользователя из рекламной рассылки создает уникальную копию страницы в памяти.

Для сайта с посещаемостью RunRepeat один популярный newsletter может мгновенно инвалидировать эффективность кэширования для целевых страниц, заполнив память тысячами копий одной и той же страницы, отличающихся лишь меткой utm_id.

## ---

**5. Стратегии нормализации VCL: От хаоса к порядку**

Решение проблемы Cache Bloat лежит исключительно в плоскости конфигурации VCL (Varnish Configuration Language). Необходима жесткая нормализация входящих запросов в процедуре vcl_recv **до** того, как будет вычислен хэш объекта.

### **5.1. Алгоритмическая сортировка параметров (Query String Sorting)**

Единственным надежным способом борьбы с комбинаторным взрывом перестановок является алфавитная сортировка параметров запроса. Это гарантирует, что запросы ?a=1&b=2 и ?b=2&a=1 будут преобразованы в единую каноническую форму перед поиском в кэше.

Использование модуля vmod_querystring (или функционала std в современных версиях Varnish) позволяет реализовать это одной строкой кода.

**Пример реализации (VCL):**

Code snippet

import std;  
import querystring;

sub vcl_recv {  
    # Сортировка параметров для канонизации URL  
    set req.url = std.querysort(req.url);  
      
    # Альтернативно с использованием vmod_querystring для очистки  
    set req.url = querystring.sort(req.url);  
}

Внедрение сортировки немедленно устраняет дублирование, вызванное произвольным порядком кликов пользователя или поведением ботов.29

### **5.2. Санитизация маркетинговых параметров**

Необходимо внедрить белый (whitelist) или черный (blacklist) список параметров. Для RunRepeat, учитывая сложность фильтров, черный список (удаление известного мусора) может быть более безопасным стартом, но белый список (разрешение только известных фильтров) является идеалом архитектурной чистоты.

**Рекомендуемый VCL для очистки:**

Code snippet

sub vcl_recv {  
    # Удаление стандартных меток Google Analytics и Facebook  
    if (req.url ~ "(?|&)(utm_source|utm_medium|utm_campaign|gclid|fbclid|cx|ie|cof|siteurl)=") {  
        set req.url = regsuball(req.url, "&(utm_source|utm_medium|utm_campaign|gclid|fbclid|cx|ie|cof|siteurl)=([A-z0-9_-.%25]+)", "");  
        set req.url = regsub(req.url, "(?&)", "?");  
        set req.url = regsub(req.url, "?$", "");  
    }  
}

Этот код удаляет параметры, которые нужны только клиентскому JavaScript (Google Analytics), но не влияют на генерацию HTML на бэкенде. Это позволяет отдавать один и тот же кэшированный объект пользователям, пришедшим из разных рекламных каналов.7

### **5.3. Нормализация заголовка User-Agent**

Еще одним вектором раздувания кэша является заголовок Vary: User-Agent. Если бэкенд RunRepeat выдает этот заголовок (что часто случается в PHP-фреймворках для разделения мобильной и десктопной версий), Varnish будет хранить копию страницы для *каждой* версии браузера Chrome, Safari, Firefox и т.д.

Учитывая тысячи вариаций User-Agent, это катастрофически снижает Hit Rate. Решением является нормализация User-Agent в vcl_recv до ограниченного набора бакетов: "mobile", "tablet", "desktop".

Code snippet

sub vcl_recv {  
    if (req.http.User-Agent ~ "(?i)(mobile|android|iphone)") {  
        set req.http.X-UA-Device = "mobile";  
    } else {  
        set req.http.X-UA-Device = "desktop";  
    }  
    # Опционально: перезаписать User-Agent для бэкенда или использовать X-UA-Device в vcl_hash  
}

Если сайт использует адаптивный дизайн (Responsive Design) и HTML не меняется в зависимости от устройства, заголовок Vary: User-Agent следует принудительно удалять в vcl_backend_response.30

## ---

**6. Тонкая настройка инфраструктуры и многопоточности**

Помимо управления памятью и нормализации запросов, стабильность Varnish под нагрузкой зависит от конфигурации пулов потоков (thread pools) и рабочих областей памяти (workspaces).

### **6.1. Динамика Thread Pools**

Клиент может наблюдать большое количество потоков или "дубликатов процессов". Varnish использует модель пула потоков для обработки соединений. Параметры thread_pool_min и thread_pool_max определяют границы масштабирования.

Распространенной ошибкой является установка слишком низкого значения thread_pool_min (по умолчанию 100). В условиях трафика RunRepeat резкие всплески нагрузки (micro-bursts) могут приводить к задержкам, пока Varnish спавнит новые потоки. Это явление, известное как "Thundering Herd" на уровне планировщика потоков.

**Рекомендация:** Увеличить thread_pool_min до 500-1000, чтобы держать "горячий" резерв потоков. При этом thread_pool_max не должен превышать лимиты файловых дескрипторов системы. Важно мониторить счетчик sess_dropped, который показывает количество соединений, сброшенных из-за переполнения очереди ожидания потоков.6

### **6.2. Расчет Workspace Memory**

Каждый поток Varnish имеет выделенную область памяти (workspace_client и workspace_backend) для обработки заголовков и выполнения логики VCL. Для e-commerce сайтов с большим количеством Cookie и длинными URL (из-за фильтров), дефолтный размер (обычно 64k) может быть недостаточен.

Переполнение workspace приводит к ошибкам 500/503. Увеличение workspace_client до 128k или 256k является безопасной мерой оптимизации, незначительно влияющей на общее потребление памяти, но критически важной для стабильности обработки сложных запросов.32

## ---

**7. Мониторинг, Наблюдаемость и Форензика**

Переход от реактивного устранения сбоев к проактивному управлению требует внедрения правильных метрик. Утилита varnishstat предоставляет сырые данные, которые необходимо интерпретировать в контексте бизнес-логики.

### **7.1. Матрица критических метрик**

В таблице ниже представлены ключевые счетчики, мониторинг которых обязателен для диагностики описанных проблем.

| Метрика (Counter) | Описание | Интерпретация для RunRepeat | Порог тревоги |
| :---- | :---- | :---- | :---- |
| **SMA.s0.g_bytes** | Байты в основном хранилище | Должна выходить на плато у лимита -s. Если падает резко — возможен перезапуск. | > 95% от лимита |
| **SMA.Transient.g_bytes** | Байты во временном хранилище | **Главный индикатор утечки.** Неконтролируемый рост указывает на проблему unbounded storage. | > 1-2 ГБ |
| **n_lru_nuked** | Принудительно удаленные объекты | Индикатор Cache Bloat. Высокая скорость роста означает, что полезный кэш вымывается мусорными вариациями. | Рост > 100/сек |
| **n_object** | Количество объектов | Сравнить с каталогом товаров. Если n_object >> кол-ва товаров * вариации, значит нормализация не работает. | Аномальный рост |
| **cache_hit** / **cache_miss** | Попадания/Промахи | Hit Rate = hits / (hits + misses). Низкий Hit Rate при высоком n_object подтверждает проблему дубликатов. | < 60-70% |
| **sess_dropped** | Сброшенные сессии | Нехватка потоков или перегрузка CPU. | > 0 |

21

### **7.2. Интерпретация сценариев сбоя**

* **Сценарий А: OOM Killer убивает Varnish.**  
  * Проверка: Если SMA.s0.g_bytes стабилен, а системный RAM исчерпан, виноват либо glibc (фрагментация), либо SMA.Transient (скрытый рост).  
  * Действие: Сверить графики RSS процесса и SMA.Transient.g_bytes.  
* **Сценарий Б: Низкая производительность, высокий Backend Load.**  
  * Проверка: Высокий n_lru_nuked. Varnish "молотит" память, постоянно записывая и удаляя объекты.  
  * Действие: Внедрить нормализацию Query String.

## ---

**8. Перспективы Enterprise-решений: MSE и Memory Governor**

В контексте долгосрочной стратегии развития RunRepeat.com стоит рассмотреть возможности коммерческой версии Varnish Enterprise, которая предлагает архитектурные решения описанных проблем "из коробки".

### **8.1. Massive Storage Engine (MSE)**

В отличие от malloc (память) и file (файл с mmap), движок MSE разработан для работы с большими наборами данных (dataset), превышающими объем RAM. Он использует собственную систему аллокации, которая полностью устраняет проблему фрагментации, присущую glibc. Кроме того, MSE поддерживает персистентность (сохранение кэша при перезагрузке), что критично для минимизации нагрузки на бэкенд при обслуживании ("Cache Warming").8

### **8.2. Memory Governor**

Функция Memory Governor в Varnish Enterprise динамически управляет размером кэша. Вместо жесткого лимита на *объекты*, администратор задает целевой объем памяти для *всего процесса*. Memory Governor автоматически уменьшает размер хранилища объектов, если растут накладные расходы или потребление Transient Storage, гарантируя, что процесс никогда не выйдет за пределы выделенного бюджета памяти и не будет убит OOM Killer.16

## ---

**9. Стратегический план ремедиации (Remediation Roadmap)**

На основании проведенного аудита предлагается следующий пошаговый план действий для стабилизации инфраструктуры RunRepeat.com.

### **Фаза 1: Немедленная стабилизация (Infrastructure & Config)**

1. **Замена Аллокатора:**  
   * Проверить текущий линковщик: ldd /usr/sbin/varnishd.  
   * Внедрить jemalloc. Если используется systemd, добавить в override.conf:  
     Environment="LD_PRELOAD=/usr/lib64/libjemalloc.so.2" (путь может отличаться).  
   * Это решит проблему фрагментации и снизит RSS на 15-30%.9  
2. **Ограничение Transient Storage:**  
   * Изменить параметры запуска varnishd.  
   * Было: -s malloc,24G (пример).  
   * Стало: -s malloc,20G -s Transient=malloc,2G.  
   * Это предотвратит OOM при атаках на некэшируемый контент.  
3. **Корректировка параметров потоков:**  
   * Установить thread_pool_min=500.

### **Фаза 2: Логическая оптимизация (VCL)**

1. **Нормализация запросов (Query Sort):**  
   * Внедрить модуль std или vmod_querystring.  
   * Добавить в vcl_recv: set req.url = std.querysort(req.url);.  
   * Реализовать удаление utm_* меток.  
2. **Управление Vary:**  
   * Проанализировать заголовки бэкенда.  
   * Удалить или нормализовать Vary: User-Agent.  
   * Заменить на Vary: X-UA-Device с предварительным детектированием устройства в VCL.

### **Фаза 3: Мониторинг и валидация**

1. **Настройка Dashboard:**  
   * Вывести графики SMA.Transient.g_bytes и n_lru_nuked в систему мониторинга (Grafana/Datadog).  
   * Настроить алертинг на превышение 80% заполнения Transient Storage.  
2. **Стресс-тестирование:**  
   * Провести нагрузочное тестирование с использованием рандомизированных URL (имитация ботов) для проверки эффективности нормализации и стабильности памяти при новом аллокаторе.

Реализация данного плана трансформирует Varnish Cache из источника нестабильности в надежный и предсказуемый слой акселерации, способный эффективно справляться с высокой кардинальностью данных проекта RunRepeat.

#### **Works cited**

1. RunRepeat: 1000+ shoes reviewed and cut in half, accessed December 11, 2025, [https://runrepeat.com/](https://runrepeat.com/)  
2. 100+ Running Shoe Reviews - RunRepeat, accessed December 11, 2025, [https://runrepeat.com/catalog/running-shoes](https://runrepeat.com/catalog/running-shoes)  
3. libmalloc, jemalloc, tcmalloc, mimalloc - Exploring Different Memory Allocators, accessed December 11, 2025, [https://dev.to/frosnerd/libmalloc-jemalloc-tcmalloc-mimalloc-exploring-different-memory-allocators-4lp3](https://dev.to/frosnerd/libmalloc-jemalloc-tcmalloc-mimalloc-exploring-different-memory-allocators-4lp3)  
4. Solving unbounded Java Process memory growth using JEMalloc - Medium, accessed December 11, 2025, [https://medium.com/@sohelcts/solving-unbounded-java-process-memory-growth-using-jemalloc-a43de47e5d0b](https://medium.com/@sohelcts/solving-unbounded-java-process-memory-growth-using-jemalloc-a43de47e5d0b)  
5. Storage backends - Varnish Cache - Read the Docs, accessed December 11, 2025, [https://varnish-cache.readthedocs.io/users-guide/storage-backends.html](https://varnish-cache.readthedocs.io/users-guide/storage-backends.html)  
6. Varnish memory usage keeps increasing - Stack Overflow, accessed December 11, 2025, [https://stackoverflow.com/questions/76209998/varnish-memory-usage-keeps-increasing](https://stackoverflow.com/questions/76209998/varnish-memory-usage-keeps-increasing)  
7. Example VCL template - Varnish Developer Portal, accessed December 11, 2025, [https://www.varnish-software.com/developers/tutorials/example-vcl-template/](https://www.varnish-software.com/developers/tutorials/example-vcl-template/)  
8. Understanding Varnish Cache Memory Usage - Resources, accessed December 11, 2025, [https://info.varnish-software.com/blog/understanding-varnish-cache-memory-usage](https://info.varnish-software.com/blog/understanding-varnish-cache-memory-usage)  
9. jemalloc vs glibc malloc: Memory Allocation Performance Comparison | by Binita Bharati, accessed December 11, 2025, [https://medium.com/@binitabharati/jemalloc-vs-glibc-malloc-memory-allocation-performance-comparison-fbaeda1740de](https://medium.com/@binitabharati/jemalloc-vs-glibc-malloc-memory-allocation-performance-comparison-fbaeda1740de)  
10. Picking a global allocator : r/rust - Reddit, accessed December 11, 2025, [https://www.reddit.com/r/rust/comments/1ifjzvv/picking_a_global_allocator/](https://www.reddit.com/r/rust/comments/1ifjzvv/picking_a_global_allocator/)  
11. Background · jemalloc/jemalloc Wiki - GitHub, accessed December 11, 2025, [https://github.com/jemalloc/jemalloc/wiki/Background](https://github.com/jemalloc/jemalloc/wiki/Background)  
12. How to trace the fragmentation? · Issue #2850 · jemalloc/jemalloc - GitHub, accessed December 11, 2025, [https://github.com/jemalloc/jemalloc/issues/2850](https://github.com/jemalloc/jemalloc/issues/2850)  
13. Jemalloc Memory Analysis - Apache Doris, accessed December 11, 2025, [https://doris.apache.org/docs/3.x/admin-manual/trouble-shooting/memory-management/memory-analysis/jemalloc-memory-analysis/](https://doris.apache.org/docs/3.x/admin-manual/trouble-shooting/memory-management/memory-analysis/jemalloc-memory-analysis/)  
14. 1656034 – Varnish is compiled without jemalloc. jemalloc is missing. - Red Hat Bugzilla, accessed December 11, 2025, [https://bugzilla.redhat.com/show_bug.cgi?id=1656034](https://bugzilla.redhat.com/show_bug.cgi?id=1656034)  
15. Varnish duplicate process 170 once - Unix & Linux Stack Exchange, accessed December 11, 2025, [https://unix.stackexchange.com/questions/632427/varnish-duplicate-process-170-once](https://unix.stackexchange.com/questions/632427/varnish-duplicate-process-170-once)  
16. Two-Minute Tech Tuesdays - Memory Governor - Resources - Varnish Software, accessed December 11, 2025, [https://info.varnish-software.com/blog/two-minute-tech-tuesdays-memory-governor](https://info.varnish-software.com/blog/two-minute-tech-tuesdays-memory-governor)  
17. Parameters — Varnish version 4.0.5 documentation, accessed December 11, 2025, [https://varnish-cache.org/docs/4.0/users-guide/params.html](https://varnish-cache.org/docs/4.0/users-guide/params.html)  
18. Storage backends — Varnish version trunk documentation, accessed December 11, 2025, [https://varnish-cache.org/docs/trunk/users-guide/storage-backends.html](https://varnish-cache.org/docs/trunk/users-guide/storage-backends.html)  
19. Storage backends - malloc - Varnish Cache, accessed December 11, 2025, [https://varnish-cache.org/docs/4.1/users-guide/storage-backends.html](https://varnish-cache.org/docs/4.1/users-guide/storage-backends.html)  
20. varnishd — Varnish version trunk documentation, accessed December 11, 2025, [https://varnish-cache.org/docs/trunk/reference/varnishd.html](https://varnish-cache.org/docs/trunk/reference/varnishd.html)  
21. varnish-counters — Varnish version trunk documentation, accessed December 11, 2025, [https://varnish-cache.org/docs/trunk/reference/varnish-counters.html](https://varnish-cache.org/docs/trunk/reference/varnish-counters.html)  
22. VSV00002 Data leak - '-sfile' Stevedore transient objects — Varnish HTTP Cache, accessed December 11, 2025, [https://varnish-cache.org/security/VSV00002.html](https://varnish-cache.org/security/VSV00002.html)  
23. Varnish crashes on bigger files - cache - Server Fault, accessed December 11, 2025, [https://serverfault.com/questions/1031656/varnish-crashes-on-bigger-files](https://serverfault.com/questions/1031656/varnish-crashes-on-bigger-files)  
24. Limiting memory for varnish process - caching - Stack Overflow, accessed December 11, 2025, [https://stackoverflow.com/questions/58909821/limiting-memory-for-varnish-process](https://stackoverflow.com/questions/58909821/limiting-memory-for-varnish-process)  
25. 90+ Knit Running Shoe Reviews - RunRepeat, accessed December 11, 2025, [https://runrepeat.com/catalog/knit-running-shoes](https://runrepeat.com/catalog/knit-running-shoes)  
26. Performance Boosting with Varnish Cache - maxcluster, accessed December 11, 2025, [https://maxcluster.de/en/knowledge/blog/article/performance-page-speed-boosting-varnish-cache](https://maxcluster.de/en/knowledge/blog/article/performance-page-speed-boosting-varnish-cache)  
27. Varnish monitoring - Varnish Developer Portal, accessed December 11, 2025, [https://www.varnish-software.com/developers/tutorials/varnish-monitoring/](https://www.varnish-software.com/developers/tutorials/varnish-monitoring/)  
28. Top Varnish performance metrics | Datadog, accessed December 11, 2025, [https://www.datadoghq.com/blog/top-varnish-performance-metrics/](https://www.datadoghq.com/blog/top-varnish-performance-metrics/)  
29. querystring.sort | Fastly Documentation, accessed December 11, 2025, [https://www.fastly.com/documentation/reference/vcl/functions/query-string/querystring-sort/](https://www.fastly.com/documentation/reference/vcl/functions/query-string/querystring-sort/)  
30. Vary — Varnish version 3.0.7 documentation, accessed December 11, 2025, [https://varnish-cache.org/docs/3.0/tutorial/vary.html](https://varnish-cache.org/docs/3.0/tutorial/vary.html)  
31. 5 Don'ts When Caching with Varnish - Resources, accessed December 11, 2025, [https://info.varnish-software.com/blog/5-varnish-donts](https://info.varnish-software.com/blog/5-varnish-donts)  
32. Varnish Using Significantly More Memory than Cache? - Stack Overflow, accessed December 11, 2025, [https://stackoverflow.com/questions/78379910/varnish-using-significantly-more-memory-than-cache](https://stackoverflow.com/questions/78379910/varnish-using-significantly-more-memory-than-cache)  
33. Varnish Cache extension — Dynatrace Docs, accessed December 11, 2025, [https://docs.dynatrace.com/docs/observe/infrastructure-observability/databases/extensions/varnish-cache-1](https://docs.dynatrace.com/docs/observe/infrastructure-observability/databases/extensions/varnish-cache-1)

# 12.
## 12.1.
`D𐊑⠿` ≔ ⠿~ (Заблуждения `ꆜ` относительно `P⁎`)

## 12.2.
`D𐊑ᵢ` : `D𐊑⠿`

## 12.3.
`Pⰳ(D𐊑ᵢ)` ≔
```
Правдоподобность `D𐊑ᵢ`.
Правдоподобность заблуждения `D𐊑ᵢ` означает оценку того, насколько утверждение `D𐊑ᵢ` действительно является заблуждением `ꆜ`. 
```

# 13. Анализ `D𐊑⠿` (выполнен Gemini Deep Think)
https://gemini.google.com/share/8d6a27ba5b92

## 2.1. Идентификация `D𐊑⠿`
Основываясь на глубоком анализе описания проблемы `PD` и онтологии `O.md` (в частности, разделов §10 и §11), я выделяю следующее множество заблуждений `ꆜ` (`D𐊑⠿`), которые блокируют решение задачи `P⁎`:

*   **`D𐊑₁`**: «Наблюдаемый рост потребления памяти является программным сбоем («утечкой»), а не следствием архитектурного устройства Varnish (Overhead + Transient)».
*   **`D𐊑₂`**: «Параметр запуска `-s malloc,SIZE` устанавливает жесткий физический лимит («стену») для процесса Varnish, который тот не может превысить при штатной работе».
*   **`D𐊑₃`**: «Проблема высокой вариативности запросов (фильтры, реклама) решается настройкой политик вытеснения (cache policies/eviction strategies), а не предварительной нормализацией входящих данных».
*   **`D𐊑₄`**: «Выбор системного аллокатора памяти (стандартный `glibc` vs `jemalloc`) не является критическим фактором на архитектуре AWS Graviton (ARM64)».

## 2.2. Анализ `D𐊑⠿`

### Анализ `D𐊑₁` (Миф об утечке)
**Суть:** `ꆜ` трактует постоянный рост потребления RAM («repeatedly grows the memory») как аномалию или баг, который нужно «диагностировать», тогда как это ожидаемое поведение при текущей конфигурации.

#### 2.2.1. Доводы за `Pⰳ(D𐊑₁)`
*   **Свидетельства веры клиента:** В `PD` клиент пишет о «persistent memory issues» и «performance degradation», явно ожидая, что память должна быть стабильной.
*   **Техническое опровержение веры:** В реальности память потребляется легитимно двумя механизмами, о которых клиент не подозревает:
    1.  **Transient Storage:** Временное хранилище для объектов `hit-for-miss` (создаются при наличии cookies/рекламных меток) по умолчанию **не ограничено** (unbounded). Оно может занимать всю свободную память сервера.
    2.  **Overhead:** Метаданные (структуры `struct obj`) занимают ~1 КБ на объект. При миллионах объектов (High Cardinality) это гигабайты неучтенной памяти.

#### 2.2.2. Доводы против `Pⰳ(D𐊑₁)`
*   Теоретически возможна реальная утечка памяти в конкретной версии Varnish или VMOD, но вероятность этого исчезающе мала по сравнению с архитектурными причинами.

#### 2.3. Оценка `Pⰳ(D𐊑₁)`
**95**

---

### Анализ `D𐊑₂` (Миф о жестком лимите)
**Суть:** `ꆜ` убежден, что настройка `-s` (Storage) должна гарантировать потребление памяти в заданных пределах.

#### 2.2.1. Доводы за `Pⰳ(D𐊑₂)`
*   **Свидетельства веры клиента:** Фраза «regardless of what config we've tried» подразумевает, что они пытались менять размеры хранилища, но RSS процесса все равно уходил за пределы.
*   **Техническое опровержение веры:** Параметр `-s malloc` ограничивает только **Payload** (тело объектов). Он игнорирует фрагментацию памяти (Heap Fragmentation), память потоков (Thread Stacks) и, самое главное, накладные расходы на огромное количество мелких объектов, генерируемых фильтрами сайта.

#### 2.2.2. Доводы против `Pⰳ(D𐊑₂)`
*   Отсутствуют. Это классическое заблуждение администраторов, не знакомых с внутренним устройством аллокации памяти в Varnish.

#### 2.3. Оценка `Pⰳ(D𐊑₂)`
**98**

---

### Анализ `D𐊑₃` (Миф об Eviction vs Normalization)
**Суть:** Клиент ищет спасение в настройке правил удаления старых объектов («eviction strategies»), вместо того чтобы предотвращать создание дубликатов.

#### 2.2.1. Доводы за `Pⰳ(D𐊑₃)`
*   **Свидетельства веры клиента:** Прямой запрос в описании задачи: «We need help with... eviction strategies».
*   **Техническое опровержение веры:** Сайт `RunRepeat.com` использует фасетный поиск (цвет, размер) и рекламные метки (`gclid`, `utm`). Это создает комбинаторный взрыв URL (Cache Bloat). Varnish по умолчанию считает `/shoe?color=red` и `/shoe?gclid=123` разными объектами. Если не делать агрессивную **нормализацию** (очистку и сортировку параметров) *до* кэширования, память будет забиваться "мусором" быстрее, чем любые политики eviction смогут её освободить.

#### 2.2.2. Доводы против `Pⰳ(D𐊑₃)`
*   Возможно, клиент понимает необходимость нормализации, но включает её в широкое понятие «VCL configuration». Однако акцент на eviction выдает неверный вектор мышления.

#### 2.3. Оценка `Pⰳ(D𐊑₃)`
**90**

---

### Анализ `D𐊑₄` (Игнорирование системного уровня)
**Суть:** Клиент не осознает связь между архитектурой CPU (Graviton) и выбором аллокатора памяти.

#### 2.2.1. Доводы за `Pⰳ(D𐊑₄)`
*   **Свидетельства веры клиента:** Упоминание «Gravitron CPU» идет просто как факт конфигурации. Нет запроса на системный тюнинг (Linux tuning).
*   **Техническое опровержение веры:** Стандартный аллокатор `glibc` на Linux склонен к сильной фрагментации памяти при работе с Varnish, особенно на ARM64 (Graviton), где размер страниц памяти может отличаться (64k vs 4k). Без перехода на **jemalloc** (который эффективно борется с фрагментацией) процесс Varnish будет занимать гораздо больше памяти, чем реально использует, из-за «дыр» в куче.

#### 2.2.2. Доводы против `Pⰳ(D𐊑₄)`
*   Возможно, в их сборке OS `jemalloc` уже является дефолтным, хотя это редкость для стандартных дистрибутивов.

#### 2.3. Оценка `Pⰳ(D𐊑₄)`
**85**

## 2.4. Вердикт
Клиент `ꆜ` находится в плену **«Конфигурационной иллюзии»**. Он пытается решить проблему **архитектурного несоответствия** (High Cardinality Data vs Standard Memory Allocator) методами **прикладной настройки** (VCL Eviction Policies).

`ꆜ` ошибочно полагает, что Varnish «течет» или сломан (`D𐊑₁`), в то время как система работает технически корректно в условиях **Cache Bloat** (взрывного роста дубликатов кэша), усугубленного отсутствием лимитов на временное хранилище (`Transient`) и использованием неэффективного аллокатора (`glibc`) на архитектуре Graviton. Решение лежит не в подборе параметров кэша, а в **санитизации трафика** (нормализация URL) и **системном тюнинге** (переход на jemalloc).

# 14. Анализ `D𐊑⠿` (выполнен Gemini Deep Research)
https://gemini.google.com/share/614be88df46e

**1. Анализ заблуждения D𐊑₁: Иллюзия детерминированного лимитирования памяти параметром -s malloc**

Центральным элементом в понимании проблем проекта P⁎ является интерпретация того, как Varnish управляет выделением памяти. Клиент ꆜ в описании проблемы (PD) указывает на то, что потребление памяти растет «regardless of what config we've tried». Это свидетельствует о наличии устойчивого заблуждения D𐊑₁, согласно которому параметр конфигурации -s malloc,SIZE воспринимается как жесткий, физический ограничитель (hard limit) для всего процесса демона.

### **1.1. Доводы в пользу правдоподобности заблуждения (Pⰳ(D𐊑₁))**

Анализ технической документации и архитектурных принципов Varnish Cache позволяет с высокой точностью реконструировать логику возникновения этого заблуждения и подтвердить его критическое влияние на эксплуатацию системы.

**Архитектурная дихотомия: Хранилище данных против Метаданных**

Фундаментальная ошибка заключается в непонимании того, что параметр -s в Varnish ограничивает исключительно пространство, выделяемое под *тела* кэшируемых объектов (Object Payload).1 В экосистеме Varnish память расходуется по двум основным векторам, из которых -s контролирует только первый:

1. **Storage Memory (Управляемая):** Это байты, составляющие контент (HTML, изображения, JSON), которые сервер отдает клиенту. Именно этот объем регулируется параметром -s malloc,25G.  
2. **Overhead Memory (Неуправляемая):** Это память, необходимая для поддержания структур данных, обеспечивающих функционирование кэша. Сюда входят хеш-таблицы, списки LRU (Least Recently Used), структуры объектов (struct obj), заголовки (struct objhead) и ссылки (struct objcore).2

В контексте проекта RunRepeat с его фасетной навигацией и высокой посещаемостью (4 млн сессий), количество объектов в кэше может достигать экстремальных значений. Исследования показывают, что накладные расходы (overhead) на один объект в Varnish составляют приблизительно 1 КБ.1 Это значение кажется незначительным для единичного объекта, но масштабируется линейно.

Рассмотрим математическую модель потребления памяти для P⁎:  
Предположим, что из-за вариативности URL (см. анализ D𐊑₅) в кэше находится 15 миллионов объектов.

$$text{Memory}_{text{overhead}} approx N_{text{objects}} times 1 text{ KB}$$

$$text{Memory}_{text{overhead}} approx 15,000,000 times 1024 text{ bytes} approx 14.3 text{ GB}$$  
Если клиент выделил под хранилище данных 25 ГБ (-s malloc,25G) на сервере с 32 ГБ RAM, то реальное потребление памяти процессом составит:

$$text{Total RAM} = text{Storage} (25 text{ GB}) + text{Overhead} (14.3 text{ GB}) + text{System} approx 39.3 text{ GB}$$  
Это значение превышает физически доступную память (32 ГБ), что неизбежно приводит к вмешательству механизма OOM Killer (Out-Of-Memory Killer) операционной системы, который принудительно завершает процесс varnishd.1 Клиент, наблюдая это, интерпретирует ситуацию как «утечку», не осознавая, что система ведет себя абсолютно корректно в рамках заданных (ошибочных) ограничений.

**Скрытое потребление: Рабочие области и Потоки**

Помимо метаданных объектов, значительный объем памяти расходуется на инфраструктуру обработки запросов. Varnish использует многопоточную архитектуру, где каждый запрос обрабатывается отдельным потоком (worker thread).

* **Thread Stack:** Каждый поток требует собственного стека. Параметр thread_pool_stack (по умолчанию часто 48-52 КБ) определяет этот размер.5  
* **Workspace Memory:** Для обработки HTTP-заголовков, выполнения VCL-логики и манипуляций с данными каждому потоку выделяются рабочие области: workspace_client (память для запроса клиента), workspace_backend (память для ответа бэкенда) и workspace_session.5

В конфигурации по умолчанию или при агрессивном тюнинге под высокую нагрузку (например, thread_pool_max=5000), суммарное потребление памяти потоками может быть значительным:

$$text{Memory}_{text{threads}} = N_{text{threads}} times (text{stack} + text{workspace}_{text{client}} + text{workspace}_{text{backend}})$$

$$text{Memory}_{text{threads}} approx 5000 times (48text{K} + 64text{K} + 64text{K}) approx 880 text{ MB}$$  
Хотя 1 ГБ кажется небольшим объемом по сравнению с 32 ГБ, в условиях, когда память уже исчерпана данными и метаданными, этот гигабайт становится критическим фактором нестабильности.7 Клиент ꆜ, вероятно, не учитывает эти расходы в своей калькуляции ресурсов, полагая, что -s malloc охватывает все потребности процесса.

### **1.2. Доводы против правдоподобности заблуждения (Pⰳ(D𐊑₁))**

Единственным сценарием, при котором данное утверждение не являлось бы заблуждением, было бы использование клиентом специализированных версий Varnish Enterprise с включенным механизмом **Memory Governor**.

Технология Memory Governor, являющаяся частью движка Massive Storage Engine (MSE), фундаментально меняет парадигму управления памятью. В этом режиме администратор задает не размер кэша, а целевой лимит потребления памяти для всего процесса (Memory Target). Движок автоматически масштабирует размер хранилища объектов, уменьшая его при росте накладных расходов или потребления временного хранилища, гарантируя, что процесс никогда не выйдет за пределы установленного лимита.8

Однако в описании задачи (PD) и онтологии (O.md) отсутствуют какие-либо указания на использование коммерческой лицензии Varnish Enterprise. Напротив, описание проблем («Varnish repeatedly grows...») прямо противоречит логике работы Memory Governor, который призван предотвращать именно такое поведение. Следовательно, использование стандартной Community-версии (Varnish Cache) является практически достоверным фактом, что делает заблуждение D𐊑₁ высоковероятным.

### **1.3. Вердикт и оценка правдоподобности**

**Оценка Pⰳ(D𐊑₁): 95/100.**

Анализ подтверждает, что клиент ꆜ находится в плену иллюзии полного контроля над памятью через параметр -s malloc. Это заблуждение является корневой причиной неправильной оценки необходимых ресурсов. Вместо того чтобы оставить запас памяти (Headroom) в размере 25-30% для метаданных и операционных расходов, клиент, вероятно, устанавливает лимит хранилища близко к физическому объему RAM, провоцируя нестабильность.

Рекомендация по устранению данного заблуждения заключается в пересмотре формулы расчета памяти:

$$text{Malloc Limit} = (text{Total RAM} - text{System Reserved} - text{Transient Max}) times 0.75$$

Для сервера с 32 ГБ RAM безопасным значением параметра -s malloc будет не 25G, а диапазон 16G - 18G.

## ---

**2. Анализ заблуждения D𐊑₂: Ложная идентификация утечки памяти (Memory Leak) вместо Фрагментации (Fragmentation)**

Вторым критическим заблуждением является классификация проблемы. Клиент описывает ситуацию терминами «persistent memory issues» и «grows memory», подразумевая утечку памяти (Memory Leak) — ошибку программирования, при которой выделенная память не освобождается. Однако глубокий анализ среды исполнения (AWS Graviton, Linux) указывает на совершенно иную природу феномена: **фрагментацию кучи** (Heap Fragmentation).

### **2.1. Доводы в пользу правдоподобности заблуждения (Pⰳ(D𐊑₂))**

Фрагментация памяти в контексте Varnish — это сложный процесс взаимодействия прикладного ПО и системного аллокатора, который внешне (для утилит мониторинга типа top или htop) неотличим от утечки.

**Аллокатор glibc vs jemalloc: Битва за эффективность**

Стандартным аллокатором памяти в большинстве дистрибутивов Linux (включая Amazon Linux 2023 и RHEL 9, используемых на AWS) является реализация malloc из библиотеки glibc (основанная на ptmalloc). Этот аллокатор оптимизирован для универсальных задач, но демонстрирует низкую эффективность в сценариях, характерных для Varnish:

* Высокая конкурентность (тысячи потоков).  
* Интенсивная аллокация и деаллокация мелких объектов разного размера.  
* Долгоживущий процесс.10

В многопоточной среде glibc создает множество арен (memory arenas) для снижения блокировок (lock contention). Когда память освобождается (free()) внутри Varnish, она возвращается в конкретную арену аллокатора, но далеко не всегда возвращается операционной системе. Образуются «дыры» — фрагментированные участки свободной памяти внутри процесса, которые слишком малы для размещения новых объектов, но удерживают целые страницы памяти от возврата ОС.

В результате метрика RSS (Resident Set Size) процесса растет, хотя внутренние счетчики Varnish (varnishstat) показывают наличие свободного места в хранилище (SMA.s0.g_space). Клиент видит рост потребления RAM и делает вывод об утечке, хотя технически вся память учтена, но не может быть эффективно использована.11

**Критический фактор среды AWS Graviton**

Ситуация усугубляется спецификой современных дистрибутивов Linux на архитектуре ARM64. В старых версиях Varnish или в других дистрибутивах аллокатор jemalloc часто поставлялся как зависимость или был слинкован статически. jemalloc (разработанный Джейсоном Эвансом) де-факто является стандартом для приложений типа Varnish, Redis и браузеров, так как он использует изощренные стратегии (size classes, runs, chunks) для минимизации фрагментации.5

Однако, как показывают отчеты сообщества 5, на новых платформах (RHEL 9, Amazon Linux 2023) бинарный файл varnishd часто слинкован с glibc по умолчанию. Пользователи, не знающие об этом нюансе, запускают Varnish «из коробки» и сталкиваются с двукратным (и более) ростом потребления памяти по сравнению с ожидаемым.

Источник 5 приводит прямой эмпирический опыт: «I've installed version 6.0.13... it looks like varnish is using glibc's malloc... Memory usage for a 1GB cache has gone down from ~3.7GB to ~2GB [after installing jemalloc]». Это подтверждает, что разница в потреблении памяти между glibc и jemalloc может достигать **100% от полезной нагрузки**.

### **2.2. Доводы против правдоподобности заблуждения (Pⰳ(D𐊑₂))**

Теоретически возможно, что клиент столкнулся с реальным багом в коде Varnish (software defect). Например, известная уязвимость CVE-2017-8807 14 приводила к утечке данных и памяти при некорректной обработке синтетических объектов в Transient Storage. Также существуют редкие баги, связанные с JIT-компиляцией PCRE (регулярных выражений) на специфических платформах.13

Однако вероятность столкнуться с неизвестным багом ядра Varnish (проект с более чем 15-летней историей стабильности) на порядки ниже, чем вероятность эксплуатации неоптимизированного аллокатора. Фраза клиента «regardless of what config we've tried» указывает на перебор параметров конфигурации (.vcl, -p), но не на системные изменения уровня линковки библиотек (LD_PRELOAD), что усиливает гипотезу о заблуждении.

### **2.3. Вердикт и оценка правдоподобности**

**Оценка Pⰳ(D𐊑₂): 90/100.**

Клиент ꆜ, с высокой долей вероятности, не различает истинную утечку памяти (потерю указателей на выделенные блоки) и внешнюю фрагментацию аллокатора. Отсутствие явного упоминания jemalloc в описании проблемы является сильным индикатором того, что Varnish работает на дефолтном glibc.

Рекомендация:  
Для устранения этой проблемы необходимо не «искать утечку» в VCL, а изменить среду исполнения:

1. Установить пакет jemalloc (например, dnf install jemalloc на Amazon Linux).  
2. Настроить systemd юнит для предзагрузки библиотеки:  
   Environment="LD_PRELOAD=/usr/lib64/libjemalloc.so.2"  
3. Перезапустить сервис и мониторить метрику RSS. Ожидается снижение потребления памяти на 30-50%.5

## ---

**3. Анализ заблуждения D𐊑₃: Игнорирование опасности и природы Transient Storage**

Третье заблуждение касается компонента Varnish, который часто остается «в слепой зоне» администраторов — Временного Хранилища (Transient Storage). Клиент, фокусируясь на настройках основного кэша (-s malloc), упускает из виду механизм, способный потребить всю память сервера за считанные минуты.

### **3.1. Доводы в пользу правдоподобности заблуждения (Pⰳ(D𐊑₃))**

Transient Storage предназначено для хранения короткоживущих объектов (чей TTL меньше параметра shortlived, по умолчанию 10 секунд) и объектов, созданных в результате решений о некэшируемости (hit-for-miss, hit-for-pass).16

**Архитектурная ловушка: Unbounded by Default**

Критическая особенность Transient Storage заключается в его конфигурации по умолчанию. Если администратор явно не задает параметры для Transient Storage (через -s Transient=...), Varnish автоматически создает для него хранилище на базе malloc, которое **не имеет лимита по размеру** (unbounded).5

В документации это описано так: «If no Transient storage is defined, the default is an unbound malloc storage». Это означает, что Varnish будет запрашивать у ОС память под временные объекты бесконечно, пока не исчерпает физические ресурсы, игнорируя любые ограничения, установленные для основного кэша.

**Механизм катастрофы: Hit-For-Miss шторм**

Проект RunRepeat имеет характеристики, делающие его чрезвычайно уязвимым для этой архитектурной особенности:

1. **Высокая посещаемость (4M сессий):** Огромный поток запросов.  
2. **Наличие рекламы и трекинга:** Ссылки с метками gclid, fbclid, utm_* часто обрабатываются бэкендом с установкой cookies или заголовков Cache-Control: private.  
3. **Логика Varnish:** Когда Varnish получает ответ с Set-Cookie или запретом кэширования, он создает специальный объект hit-for-miss (или hit-for-pass в старых версиях).18 Этот объект служит маркером: «не отправляй запросы на этот URL в очередь (request coalescing), а пропускай сразу на бэкенд».  
4. **Лавинообразный эффект:** Поскольку каждый запрос с уникальным gclid является уникальным URL, Varnish создает уникальную запись hit-for-miss для каждого клика по рекламе. Если TTL этих записей (по умолчанию 120 секунд) попадает под критерий shortlived или если они явно помещаются в Transient, память начинает заполняться миллионами мелких служебных объектов.

В ситуации RunRepeat, где трафик интенсивен, а нормализация URL (вероятно) отсутствует, Transient Storage может разрастись до нескольких гигабайт за минуты. Клиент видит, что основной кэш заполнен лишь частично, но память сервера исчерпана. Жалоба «config changes haven't helped» идеально укладывается в этот сценарий: клиент меняет параметры *основного* хранилища, которые никак не влияют на *временное*.

### **3.2. Доводы против правдоподобности заблуждения (Pⰳ(D𐊑₃))**

Единственным аргументом против может быть наличие в конфигурации явного ограничения (например, -s Transient=malloc,1G). Однако, если бы такое ограничение было установлено, Varnish начал бы применять LRU-вытеснение к временным объектам при достижении лимита, а не падал бы с OOM. Симптоматика «неконтролируемого роста» однозначно указывает на отсутствие лимита (unbounded nature).

### **3.3. Вердикт и оценка правдоподобности**

**Оценка Pⰳ(D𐊑₃): 95/100.**

Клиент с вероятностью, близкой к 100%, не осведомлен о существовании или принципах работы Transient Storage. Это «тихий убийца» производительности Varnish в e-commerce проектах.

Рекомендация:  
Необходимо изменить строку запуска демона varnishd, явно ограничив временное хранилище:  
-s malloc,18G -s Transient=malloc,2G  
Это создаст жесткий барьер для роста временных объектов. При достижении 2 ГБ старые временные объекты будут удаляться, освобождая место новым, но процесс Varnish останется в рамках выделенного бюджета памяти.

## ---

**4. Анализ заблуждения D𐊑₄: Игнорирование специфики управления памятью на архитектуре ARM64 (Graviton)**

Четвертое заблуждение связано с аппаратной платформой. Клиент упоминает использование «Gravitron CPU» (правильно: Graviton) как данность, но, по всей видимости, не связывает выбор архитектуры процессора с необходимостью низкоуровневого тюнинга операционной системы.

### **4.1. Доводы в пользу правдоподобности заблуждения (Pⰳ(D𐊑₄))**

Архитектура ARM64 (aarch64), на которой построены процессоры AWS Graviton, имеет существенные отличия от традиционной x86_64 в работе подсистемы управления памятью (MMU - Memory Management Unit).

**Проблема размера страниц (Page Size): 4k vs 64k**

В операционных системах Linux память управляется страницами. Стандартный размер страницы для x86_64 и большинства дефолтных ядер ARM64 составляет 4 КБ (4k pages). Для трансляции виртуальных адресов в физические процессор использует таблицу страниц (Page Table) и кэш трансляций (TLB - Translation Lookaside Buffer).20

При использовании 32 ГБ RAM и приложения типа Varnish, которое активно обращается к огромным массивам памяти в случайном порядке (random access pattern к объектам в куче), использование 4k страниц создает колоссальную нагрузку на TLB.

* Количество записей в TLB ограничено.  
* При 4k страницах 32 ГБ памяти требуют $32 times 1024^3 / 4096 approx 8,388,608$ записей в таблице страниц.  
* Это приводит к высокому уровню промахов TLB (TLB misses). При каждом промахе процессор вынужден выполнять дорогостоящую операцию «прогулки по таблице страниц» (page table walk), что увеличивает латентность доступа к памяти и нагрузку на CPU.20

**Решение: 64k Pages**

Архитектура ARM64 оптимизирована для работы со страницами размером 64 КБ. Использование ядра с поддержкой 64k pages:

1. Увеличивает охват памяти одной записью TLB в 16 раз.  
2. Радикально снижает количество промахов TLB.  
3. Уменьшает размер самой таблицы страниц, освобождая системную память.  
4. Улучшает производительность дискового ввода-вывода и DMA операций, так как снижается количество пересечений границ страниц.5

Большинство пользователей, мигрирующих с x86, просто не знают об этом нюансе. Стандартные AMI (Amazon Machine Images) часто поставляются с ядром 4k для максимальной совместимости.

### **4.2. Доводы против правдоподобности заблуждения (Pⰳ(D𐊑₄))**

Можно возразить, что Varnish способен работать и на 4k страницах. Это так, но в условиях «борьбы за каждый байт» и высокой нагрузки (4M сессий) игнорирование этой оптимизации является технической халатностью. Влияние 64k страниц на фрагментацию также может быть положительным, так как аллокации становятся более крупнулярными.

### **4.3. Вердикт и оценка правдоподобности**

**Оценка Pⰳ(D𐊑₄): 75/100.**

Клиент, вероятно, использует стандартное ядро Linux (4k pages), упуская возможность бесплатной оптимизации производительности и снижения накладных расходов системы. Хотя это не является единственной причиной «утечки», это важный фактор общей неэффективности системы.

Рекомендация:  
Проверить текущий размер страниц командой getconf PAGESIZE. Если результат 4096, рассмотреть переход на ядро с поддержкой 64k (например, установка пакета kernel-64k в Amazon Linux 2023 или использование соответствующего AMI Ubuntu arm64+largemem).22

## ---

**5. Анализ заблуждения D𐊑₅: Приоритет инфраструктурного тюнинга над нормализацией данных (Cache Bloat)**

Пятое и, возможно, самое разрушительное заблуждение касается уровня приложения. Клиент ищет решение проблемы в «memory allocation» и «server-setup», в то время как первопричиной является бизнес-логика сайта, генерирующая «мусорный» трафик.

### **5.1. Доводы в пользу правдоподобности заблуждения (Pⰳ(D𐊑₅))**

Проблема проекта RunRepeat классифицируется как **Cache Bloat** (Раздувание кэша) вследствие **High Cardinality** (Высокой кардинальности) запросов.

**Комбинаторный взрыв URL**

Сайт использует фасетную навигацию с фильтрами по полу, размеру, цвету и другим параметрам.

$$text{URL} = text{/shoes?color=red&size=42&gender=men}$$

$$text{URL} = text{/shoes?size=42&gender=men&color=red}$$  
Для Varnish эти два URL — это **два разных объекта**, требующих раздельного кэширования, хранения метаданных и памяти. Количество возможных перестановок параметров растет факториально. При наличии 10 активных фильтров количество уникальных URL может исчисляться миллиардами. Поисковые боты и сканеры часто перебирают эти фильтры в хаотичном порядке, заполняя кэш дубликатами одного и того же контента.23

**Маркетинговый шум**

Клиент упоминает наличие рекламы («We also have ads»). Это означает приход пользователей по ссылкам с метками:  
?utm_source=google&utm_campaign=summer&gclid=ABC...  
Поскольку gclid (Google Click ID) уникален для каждого клика, каждый визит пользователя создает новую копию страницы в кэше.  
Если на сайте 4 миллиона сессий в месяц, и значительная часть трафика приходит с рекламы или использует фильтры, Varnish вынужден создавать миллионы объектов. Это приводит к:

1. Исчерпанию памяти под метаданные (см. D𐊑₁).  
2. Высокой фрагментации памяти из-за постоянной записи и удаления (Eviction) объектов (см. D𐊑₂).  
3. Заполнению Transient Storage объектами hit-for-miss (см. D𐊑₃).

Клиент фокусируется на том, как *вместить* эти объекты в память (увеличивая -s malloc), вместо того чтобы *предотвратить* их создание.

### **5.2. Доводы против правдоподобности заблуждения (Pⰳ(D𐊑₅))**

В описании задачи (PD) клиент пишет: «We need help with VCL configuration». Это указывает на понимание того, что VCL играет роль. Однако контекст перечисления («cache policies, proper memory allocation...») говорит о том, что они видят VCL как инструмент настройки *кэширования*, а не *нормализации*. Если бы они понимали масштаб проблемы Cache Bloat, они бы упомянули «URL normalization» или «parameter stripping» как приоритетные задачи.

### **5.3. Вердикт и оценка правдоподобности**

**Оценка Pⰳ(D𐊑₅): 85/100.**

Клиент недооценивает тот факт, что никакое количество RAM (даже 128 ГБ) не спасет от комбинаторного взрыва URL без строгой нормализации на уровне VCL.

Рекомендация:  
Внедрить агрессивную нормализацию в процедуре vcl_recv:

1. **Сортировка параметров:** Использовать std.querysort(req.url) для приведения параметров к каноническому порядку.14  
2. **Санитизация:** Удалять все маркетинговые метки (utm_*, gclid, fbclid) из req.url перед хэшированием. Эти параметры нужны только клиентскому JavaScript (Google Analytics), бэкенду для генерации страницы они не требуются.  
3. **Нормализация User-Agent:** Приводить заголовок User-Agent к ограниченному набору значений (mobile/desktop) перед добавлением в Vary, чтобы избежать кэширования версий для каждого минорного релиза браузера.19

## ---

**6. Синтез и итоговая стратегия ремедиации**

Проведенный анализ (᛭T) показал, что критическая ситуация в проекте RunRepeat обусловлена не единичной ошибкой, а системным эффектом наложения пяти фундаментальных заблуждений. Клиент пытается решить проблему переполнения памяти («Memory Leak»), не понимая, что его конфигурация сама провоцирует это переполнение через множественные векторы (Overhead, Fragmentation, Transient, Cache Bloat).

### **Сводная таблица диагноза**

| Заблуждение (D𐊑ᵢ) | Реальная проблема | Вклад в сбой | Оценка Pⰳ |
| :---- | :---- | :---- | :---- |
| **D𐊑₁ (Hard Limit)** | Игнорирование Overhead (1KB/obj) | Критический | 95/100 |
| **D𐊑₂ (Leak vs Frag)** | Фрагментация glibc vs jemalloc | Высокий | 90/100 |
| **D𐊑₃ (Safe Transient)** | Unbounded Transient Storage | Критический | 95/100 |
| **D𐊑₄ (Arch Neutral)** | 4k pages on ARM64 | Средний | 75/100 |
| **D𐊑₅ (Infra Priority)** | Cache Bloat / High Cardinality | Высокий | 85/100 |

### **План действий для эксперта (Action Plan)**

Для успешного выполнения консалтингового проекта P⁎ необходимо реализовать следующую стратегию:

1. **Инфраструктурный слой:**  
   * Проверить текущий аллокатор: ldd /usr/sbin/varnishd.  
   * Установить и активировать **jemalloc** через systemd override (LD_PRELOAD).  
   * (Опционально) Мигрировать на ядро с поддержкой **64k pages** для AWS Graviton.  
2. **Конфигурационный слой:**  
   * Пересчитать лимиты памяти. Установить -s malloc с запасом на overhead (например, 18GB).  
   * **Жестко ограничить Transient Storage:** Добавить флаг -s Transient=malloc,2G. Это предотвратит падение сервера при атаках и всплесках некэшируемого трафика.  
   * Оптимизировать параметры потоков (thread_pool_min/max) и workspaces под реальную нагрузку.  
3. **Прикладной слой (VCL):**  
   * Написать логику нормализации Query String (сортировка + очистка мусорных параметров).  
   * Настроить нормализацию заголовка Vary: User-Agent.  
   * Реализовать защиту от создания hit-for-miss объектов для уникальных, но бесполезных запросов.

Только комплексное устранение всех пяти заблуждений позволит стабилизировать работу Varnish на проекте RunRepeat и вернуть производительность к приемлемым показателям.

#### **Works cited**

1. Why isn't varnish taking into account the malloc limit? - Stack Overflow, accessed December 11, 2025, [https://stackoverflow.com/questions/16693677/why-isnt-varnish-taking-into-account-the-malloc-limit](https://stackoverflow.com/questions/16693677/why-isnt-varnish-taking-into-account-the-malloc-limit)  
2. Understanding Varnish Cache Memory Usage - Resources, accessed December 11, 2025, [https://info.varnish-software.com/blog/understanding-varnish-cache-memory-usage](https://info.varnish-software.com/blog/understanding-varnish-cache-memory-usage)  
3. Understanding Varnish Cache Memory Usage, accessed December 11, 2025, [https://varnish-software.medium.com/understanding-varnish-cache-memory-usage-6f1cab5e20ff](https://varnish-software.medium.com/understanding-varnish-cache-memory-usage-6f1cab5e20ff)  
4. Varnish crashes on bigger files - cache - Server Fault, accessed December 11, 2025, [https://serverfault.com/questions/1031656/varnish-crashes-on-bigger-files](https://serverfault.com/questions/1031656/varnish-crashes-on-bigger-files)  
5. Varnish Using Significantly More Memory than Cache? - Stack Overflow, accessed December 11, 2025, [https://stackoverflow.com/questions/78379910/varnish-using-significantly-more-memory-than-cache](https://stackoverflow.com/questions/78379910/varnish-using-significantly-more-memory-than-cache)  
6. varnishd — Varnish version 6.5.2 documentation, accessed December 11, 2025, [https://varnish-cache.org/docs/6.5/reference/varnishd.html](https://varnish-cache.org/docs/6.5/reference/varnishd.html)  
7. Varnish duplicate process 170 once - Unix & Linux Stack Exchange, accessed December 11, 2025, [https://unix.stackexchange.com/questions/632427/varnish-duplicate-process-170-once](https://unix.stackexchange.com/questions/632427/varnish-duplicate-process-170-once)  
8. Two-Minute Tech Tuesdays - Memory Governor - Resources - Varnish Software, accessed December 11, 2025, [https://info.varnish-software.com/blog/two-minute-tech-tuesdays-memory-governor](https://info.varnish-software.com/blog/two-minute-tech-tuesdays-memory-governor)  
9. Auto-scaling memory usage to increase cache size in Varnish - Resources, accessed December 11, 2025, [https://info.varnish-software.com/blog/auto-scaling-memory-usage-to-increase-cache-size-in-varnish](https://info.varnish-software.com/blog/auto-scaling-memory-usage-to-increase-cache-size-in-varnish)  
10. Improve MySQL and MariaDB performance with memory allocators like Jemalloc and TCMalloc - Managed Server, accessed December 11, 2025, [https://www.managedserver.eu/Improve-mysql-and-mariadb-performance-with-memory-allocators-like-jemalloc-and-tcmalloc/](https://www.managedserver.eu/Improve-mysql-and-mariadb-performance-with-memory-allocators-like-jemalloc-and-tcmalloc/)  
11. jemalloc vs glibc malloc: Memory Allocation Performance Comparison | by Binita Bharati, accessed December 11, 2025, [https://medium.com/@binitabharati/jemalloc-vs-glibc-malloc-memory-allocation-performance-comparison-fbaeda1740de](https://medium.com/@binitabharati/jemalloc-vs-glibc-malloc-memory-allocation-performance-comparison-fbaeda1740de)  
12. How glibc Memory Handling Affects Java Applications: The Hidden Cost of Fragmentation | by Daniyal Hassan | Medium, accessed December 11, 2025, [https://medium.com/@daniyal.hass/how-glibc-memory-handling-affects-java-applications-the-hidden-cost-of-fragmentation-8e666ee6e000](https://medium.com/@daniyal.hass/how-glibc-memory-handling-affects-java-applications-the-hidden-cost-of-fragmentation-8e666ee6e000)  
13. 1656034 – Varnish is compiled without jemalloc. jemalloc is missing. - Red Hat Bugzilla, accessed December 11, 2025, [https://bugzilla.redhat.com/show_bug.cgi?id=1656034](https://bugzilla.redhat.com/show_bug.cgi?id=1656034)  
14. VSV00002 Data leak - '-sfile' Stevedore transient objects — Varnish HTTP Cache, accessed December 11, 2025, [https://varnish-cache.org/security/VSV00002.html](https://varnish-cache.org/security/VSV00002.html)  
15. Reducing Rails Memory Use on Amazon Linux with Jemalloc - HackerNoon, accessed December 11, 2025, [https://hackernoon.com/reducing-rails-memory-use-on-amazon-linux-with-jemalloc](https://hackernoon.com/reducing-rails-memory-use-on-amazon-linux-with-jemalloc)  
16. Storage backends — Varnish version @VERSION@ documentation, accessed December 11, 2025, [https://varnish-cache.readthedocs.io/users-guide/storage-backends.html](https://varnish-cache.readthedocs.io/users-guide/storage-backends.html)  
17. Storage backends — Varnish version 7.3.2 documentation, accessed December 11, 2025, [https://varnish-cache.org/docs/7.3/users-guide/storage-backends.html](https://varnish-cache.org/docs/7.3/users-guide/storage-backends.html)  
18. Achieving a high hitrate — Varnish version 6.1.1 documentation, accessed December 11, 2025, [https://varnish-cache.org/docs/6.1/users-guide/increasing-your-hitrate.html](https://varnish-cache.org/docs/6.1/users-guide/increasing-your-hitrate.html)  
19. 10 Varnish Cache mistakes and how to avoid them, accessed December 11, 2025, [https://varnish-software.medium.com/10-varnish-cache-mistakes-and-how-to-avoid-them-d240f452ab35](https://varnish-software.medium.com/10-varnish-cache-mistakes-and-how-to-avoid-them-d240f452ab35)  
20. Improve Performance with 64K Memory Pages on AWS Graviton ..., accessed December 11, 2025, [https://dev.to/aws-builders/improve-performance-with-64k-memory-pages-on-aws-graviton-processors-ifa](https://dev.to/aws-builders/improve-performance-with-64k-memory-pages-on-aws-graviton-processors-ifa)  
21. AWS Graviton4 demonstrates leading performance for HPC - Arm Developer, accessed December 11, 2025, [https://developer.arm.com/community/arm-community-blogs/b/servers-and-cloud-computing-blog/posts/leading-hpc-performance-with-graviton4](https://developer.arm.com/community/arm-community-blogs/b/servers-and-cloud-computing-blog/posts/leading-hpc-performance-with-graviton4)  
22. Choose between the arm64 and arm64+largemem installer options - Ubuntu documentation, accessed December 11, 2025, [https://documentation.ubuntu.com/server/how-to/installation/choosing-between-the-arm64-and-arm64-largemem-installer-options/](https://documentation.ubuntu.com/server/how-to/installation/choosing-between-the-arm64-and-arm64-largemem-installer-options/)  
23. Achieving a high hitrate — Varnish version 6.0.16 documentation, accessed December 11, 2025, [https://varnish-cache.org/docs/6.0/users-guide/increasing-your-hitrate.html](https://varnish-cache.org/docs/6.0/users-guide/increasing-your-hitrate.html)  
24. Example VCL template - Varnish Developer Portal, accessed December 11, 2025, [https://www.varnish-software.com/developers/tutorials/example-vcl-template/](https://www.varnish-software.com/developers/tutorials/example-vcl-template/)  
25. 10 Varnish Cache mistakes and how to avoid them - Resources, accessed December 11, 2025, [https://info.varnish-software.com/blog/10-varnish-cache-mistakes-and-how-avoid-them](https://info.varnish-software.com/blog/10-varnish-cache-mistakes-and-how-avoid-them)

# 15.
## 15.1.
`Cᛘ⠿` ≔ ⠿~ (Возможные причины `P†`)

## 15.2.
`Cᛘᵢ` : `Cᛘ⠿`

## 15.3.
? `Cᛘᵢ`

## 15.4.
`Pⰳ(Cᛘᵢ)` ≔ (Правдоподобность гипотезы `Cᛘᵢ`)

# 16. Анализ `Cᛘ⠿` (выполнен Gemini Deep Think)
https://gemini.google.com/share/c5d510ff758a

## Cᛘ₁: Комбинаторный взрыв кэша (Cache Bloat)

### Суть
Фундаментальной причиной сбоев является отсутствие нормализации URL-адресов в конфигурации VCL, что приводит к созданию миллионов дубликатов объектов в памяти.
В условиях фасетной навигации (фильтры по размеру, цвету) и наличия рекламных меток (`gclid`, `utm`) каждый уникальный запрос сохраняется Varnish как отдельный объект.
Это вызывает экспоненциальный рост количества записей в кэше, вытесняя полезные данные и потребляя ресурсы на хранение ключей.

### Оценка
100

### Доводы за
В описании проекта прямо указано наличие множественных фильтров («users can filter by gender, size, color») и рекламного трафика.
Без явной сортировки параметров строки запроса Varnish по умолчанию считает ссылки `?a=1&b=2` и `?b=2&a=1` разными объектами.
Высокая посещаемость сайта (4 млн сессий) гарантирует постоянный приток уникальных комбинаций URL, которые невозможно эффективно кэшировать без очистки.
Жалоба клиента на деградацию производительности коррелирует с перегрузкой структур данных, отвечающих за поиск и вытеснение объектов (LRU).

### Доводы против
Отсутствуют, так как это стандартное поведение Varnish Cache, которое гарантированно приводит к исчерпанию ресурсов без специальной настройки VCL.

## Cᛘ₂: Неограниченное временное хранилище (Unbounded Transient Storage)

### Суть
Varnish использует специальное хранилище `Transient` для короткоживущих объектов и технических записей `hit-for-miss`, создаваемых при невозможности кэширования.
По умолчанию это хранилище использует системный аллокатор `malloc` и не имеет ограничения по максимальному объему потребляемой памяти.
При наплыве трафика с уникальными метками или Cookies, которые бэкенд помечает как `private`, Varnish бесконтрольно заполняет RAM этими временными записями до полного падения сервера (OOM).

### Оценка
98

### Доводы за
Официальная документация подтверждает, что если параметр `-s Transient` не задан явно, используется «unbound malloc storage».
Симптомы, описанные клиентом («changes haven't helped»), указывают на то, что лимитирование основного хранилища не влияет на источник утечки.
Рекламный трафик генерирует массовое создание объектов `hit-for-miss` для предотвращения блокировок очередей запросов.
Этот механизм является «тихим убийцей» памяти, так как он работает параллельно с основным кэшем и часто игнорируется при настройке.

### Доводы против
Существует незначительная вероятность, что в используемом клиентом дистрибутиве (пакете) настройки по умолчанию изменены на безопасные.

## Cᛘ₃: Скрытые накладные расходы на метаданные (Metadata Overhead)

### Суть
Параметр конфигурации `-s malloc,SIZE` ограничивает только объем памяти для тела объектов, но игнорирует затраты на их метаданные.
Каждый объект в кэше требует около 1 КБ оперативной памяти для служебных структур (`struct obj`, `objcore`), хранящихся вне лимитируемой области.
Из-за проблемы `Cᛘ₁` количество объектов может достигать десятков миллионов, что приводит к потреблению десятков гигабайт памяти исключительно на метаданные.

### Оценка
95

### Доводы за
Математическая модель показывает, что 15 миллионов мелких объектов займут около 15 ГБ RAM сверх выделенного лимита хранилища.
Для сервера с 32 ГБ RAM такой неучтенный расход является критическим и неизбежно ведет к исчерпанию физической памяти.
Клиент демонстрирует непонимание этого механизма, полагая, что Varnish должен укладываться в заданные конфигом рамки.
Это объясняет «постоянный рост памяти» по мере наполнения кэша новыми уникальными ссылками.

### Доводы против
Данная проблема является вторичной и проявляется только при аномально большом количестве объектов в кэше.

## Cᛘ₄: Фрагментация памяти (Heap Fragmentation)

### Суть
Стандартный системный аллокатор `glibc`, используемый в Linux по умолчанию, неэффективен для многопоточной работы Varnish с частым выделением памяти.
Это приводит к внешней фрагментации кучи, когда операционная система считает память занятой процессом, хотя внутри она свободна, но разбита на мелкие участки.
На архитектуре AWS Graviton (ARM64) проблема фрагментации `glibc` проявляется особенно остро, вызывая рост RSS процесса.

### Оценка
90

### Доводы за
Инфраструктура клиента работает на процессорах Graviton, где выбор аллокатора критичен для производительности.
Многие стандартные образы OS не включают оптимизированный аллокатор `jemalloc` по умолчанию.
Сообщество пользователей Varnish подтверждает, что переход на `jemalloc` снижает потребление памяти на 30-50% за счет дефрагментации.
Симптомы «утечки», которую невозможно устранить настройками VCL, полностью соответствуют картине фрагментации памяти.

### Доводы против
Некоторые современные облачные образы (AMI) могут иметь предустановленный и настроенный `jemalloc`.

## Cᛘ₅: Неоптимальный размер страниц памяти (Page Size Mismatch)

### Суть
Процессоры AWS Graviton показывают значительно лучшую производительность при использовании страниц памяти размером 64 КБ (64k pages).
Стандартные ядра Linux используют страницы 4 КБ, что при больших объемах RAM увеличивает нагрузку на буфер трансляции адресов (TLB).
Это приводит к дополнительным накладным расходам и деградации производительности при произвольном доступе к памяти.

### Оценка
75

### Доводы за
Официальные рекомендации AWS для Graviton настоятельно советуют использовать 64k pages для нагрузок типа кэширования.
Использование 4k pages увеличивает размер таблиц страниц в памяти и количество промахов TLB.
Это объясняет часть проблем с производительностью, на которые жалуется клиент.

### Доводы против
Данный фактор влияет на производительность и латентность, но редко является прямой причиной аварийного завершения процесса из-за нехватки памяти.

## Вердикт

Проблема `P†` вызвана системным сочетанием критических архитектурных упущений.
Первопричиной является **Cache Bloat (`Cᛘ₁`)**, генерирующий миллионы паразитных объектов из-за отсутствия нормализации URL.
Это запускает механизмы **Metadata Overhead (`Cᛘ₃`)** и **Unbounded Transient Storage (`Cᛘ₂`)**, которые бесконтрольно потребляют оперативную память сверх установленных лимитов.
Ситуация усугубляется использованием неэффективного аллокатора **glibc (`Cᛘ₄`)**, который фрагментирует оставшиеся ресурсы.
Для решения задачи необходимо внедрить нормализацию запросов, жестко ограничить временное хранилище и переключиться на аллокатор `jemalloc`.

# 17. Анализ `Cᛘ⠿` (выполнен экземпляром №1 Gemini Deep Research)
https://gemini.google.com/share/0bd6830b26e3


## **Cᛘ1: Критический рост потребления памяти Transient-хранилища вследствие архитектурных особенностей механизма Hit-for-Miss**

### **Суть**

Архитектура Varnish Cache в своей основе опирается на модульную систему управления памятью, где различные стратегии хранения данных реализуются через интерфейсы, называемые «stevedores».  
Одним из фундаментальных, но часто недооцененных компонентов этой системы является хранилище типа Transient, которое играет роль буфера для объектов с коротким жизненным циклом.  
В контексте операционной системы Amazon Linux 2023, функционирующей на вычислительных мощностях AWS Graviton, поведение этого хранилища приобретает критическое значение для стабильности процесса varnishd.  
Согласно спецификациям 1, хранилище Transient используется по умолчанию для размещения объектов, которые движок Varnish классифицирует как не подлежащие длительному кэшированию.  
К этой категории относятся объекты, имеющие время жизни (Time To Live, TTL), меньшее, чем значение глобального параметра shortlived, который по умолчанию установлен на отметку в 10 секунд.2  
Однако наиболее коварным сценарием использования Transient является обслуживание механизма синхронизации запросов, известного как Hit-for-Miss.3  
Механизм Hit-for-Miss был внедрен в архитектуру Varnish начиная с ветки 4.0 как эволюционное развитие предыдущей концепции Hit-for-Pass, призванное устранить недостатки в обработке конкурентных запросов к одному и тому же ресурсу.3  
Основная задача этого механизма заключается в предотвращении эффекта «thundering herd» (проблемы грочущего стада), когда множество клиентов одновременно запрашивают контент, который бэкенд-сервер не может или не хочет кэшировать.  
В штатном режиме работы Varnish пытается объединить идентичные запросы (request coalescing), отправляя на бэкенд только один запрос и раздавая полученный ответ всем ожидающим клиентам.  
Если бэкенд возвращает ответ, который технически невозможно сохранить в кэше (например, ответ содержит заголовок Set-Cookie или директиву Cache-Control: private), Varnish должен принять решение о том, как обрабатывать последующие запросы к этому URL.  
В старой модели Hit-for-Pass Varnish создавал запись, которая безусловно отправляла все будущие запросы в обход кэша (pass) на определенное время, что снижало эффективность при изменении состояния бэкенда.  
Новая модель Hit-for-Miss создает в кэше специальный маркерный объект, который инструктирует Varnish обрабатывать последующие запросы как «промахи» (miss), позволяя тем самым предпринимать попытки кэширования в будущем, но отключая ожидание (coalescing) для текущего момента.3  
Критическая уязвимость данной схемы заключается в том, что этот маркерный объект Hit-for-Miss физически сохраняется в хранилище Transient.4  
Стандартная конфигурация VCL (Varnish Configuration Language), поставляемая вместе с дистрибутивом, содержит логику, которая автоматически переводит транзакцию в режим Hit-for-Miss при обнаружении заголовка Set-Cookie в ответе бэкенда.5  
Это поведение зафиксировано в процедуре vcl_backend_response и является предопределенным стандартом безопасности, предотвращающим случайное кэширование персональных сессионных данных пользователей.  
Проблема масштабируется из-за того, что время жизни (TTL) для таких объектов Hit-for-Miss по умолчанию жестко задано на уровне 120 секунд.6  
В условиях современного веб-трафика, насыщенного динамическими параметрами и трекинговыми метками, количество уникальных URL, генерирующих ответы с Set-Cookie, может исчисляться десятками тысяч в секунду.  
Каждый такой запрос инициирует создание отдельного объекта в памяти Varnish, который, несмотря на малый размер полезной нагрузки (метаданные), потребляет ресурсы оперативной памяти.  
Ситуация усугубляется тем, что хранилище Transient в Varnish реализовано через системный аллокатор памяти (обычно malloc) и, в отличие от явно конфигурируемых хранилищ (например, -s file или -s malloc,SIZE), не имеет встроенного верхнего предела потребления памяти по умолчанию.7  
Документация явно указывает, что если администратор не определил параметры Transient хранилища вручную, Varnish считает его безграничным («unbounded»).2  
Это создает опасную иллюзию контроля: администратор может ограничить основное хранилище кэша значением, например, 8 ГБ, полагая, что потребление памяти процессом не превысит 10-12 ГБ с учетом накладных расходов.  
Однако при активном создании объектов Hit-for-Miss реальное потребление памяти может линейно расти вплоть до физического предела RAM сервера, игнорируя настройки основного хранилища.8  
На архитектуре ARM64, используемой в инстансах AWS Graviton, эффективность управления памятью через стандартные аллокаторы может отличаться от x86_64, но логическая ошибка отсутствия лимита остается первичной причиной.  
Объекты Hit-for-Miss, накапливаясь в Transient хранилище, не вытесняются по алгоритму LRU (Least Recently Used) так же агрессивно, как объекты в основном хранилище, поскольку они считаются служебными и короткоживущими.  
Каждый объект в Varnish требует создания структур данных objecthead (заголовок объекта) и objectcore (ядро объекта), которые занимают около 1 КБ памяти, независимо от размера самого объекта.9  
При атаке или всплеске трафика, генерирующего 50 000 некэшируемых запросов в секунду, за двухминутное окно TTL в памяти будет создано 6 миллионов объектов.  
Простая арифметика показывает, что 6 миллионов объектов умноженные на 1 КБ накладных расходов дают 6 ГБ занятой памяти только под метаданные, не считая возможного сохранения тел ответов.  
Если бэкенд при этом отдает небольшие тела ошибок или заглушек, которые также попадают в Transient, объем потребления возрастает многократно.  
В логах varnishlog данное явление можно идентифицировать по массовому появлению тегов HitMiss и записей Storage: Transient.10  
Метрика SMA.Transient.g_bytes в утилите мониторинга varnishstat будет демонстрировать неуклонный рост, коррелирующий с количеством входящих запросов, даже если основное хранилище s0 остается полупустым.11  
Особую опасность представляет сочетание этой особенности с использованием фреймворков, которые устанавливают cookies на каждый ответ (например, PHP session start, CSRF токены), если VCL не настроен на их удаление для статики.  
Отсутствие явного лимита на Transient в строке запуска демона является распространенной ошибкой конфигурации, которая на платформе Amazon Linux 2023 проявляется особенно остро из-за высокой производительности сетевого стека, позволяющего пропускать огромный объем трафика.12  
Механизм Hit-for-Miss, задуманный как средство защиты, в данной конфигурации превращается в вектор отказа в обслуживании (DoS) через исчерпание ресурсов (Resource Exhaustion).  
Внутренние счетчики Varnish могут показывать, что система работает штатно, так как аллокации проходят успешно, пока не вмешивается OOM-killer ядра Linux.8  
Таким образом, гипотеза Cᛘ1 постулирует, что корневой причиной проблемы является архитектурное решение Varnish по использованию безлимитного хранилища для временных объектов в сочетании с агрессивной политикой создания HfM-маркеров.

### **Оценка**

95

### **Доводы за**

Документация проекта Varnish Cache недвусмысленно подтверждает, что хранилище Transient не имеет ограничений по размеру в дефолтной конфигурации, что является фундаментальным риском для любой инсталляции.2  
Многочисленные отчеты инженеров эксплуатации на платформах StackOverflow и ServerFault описывают сценарии, идентичные наблюдаемым симптомам: неконтролируемый рост потребления памяти процессом varnishd при фиксированном размере основного кэша.8  
Стандартный файл конфигурации VCL (builtin.vcl), поставляемый с пакетами Varnish, содержит логику, которая форсирует создание объектов Hit-for-Miss при наличии заголовка Set-Cookie, что делает эту проблему актуальной для большинства "коробочных" установок.5  
Значение TTL по умолчанию в 120 секунд для объектов Hit-for-Miss, зашитое в исходный код и документацию, создает достаточно широкое временное окно для накопления критической массы объектов при высокой интенсивности запросов.6  
Технический анализ накладных расходов памяти показывает, что структуры objecthead и objectcore потребляют значительный объем RAM (до 1 КБ на объект), который часто не учитывается при планировании мощностей (capacity planning).9  
В условиях облачной инфраструктуры AWS, где трафик может масштабироваться мгновенно, отсутствие жестких лимитов на служебные буферы памяти является критической уязвимостью архитектуры.12  
Появление тегов HitMiss в логах транзакций VSL является прямым доказательством работы данного механизма и позволяет однозначно связать рост памяти с конкретными типами запросов.10  
Коммерческая версия Varnish Enterprise внедрила функцию "Memory Governor" именно для решения проблемы непредсказуемого потребления памяти процессом, что косвенно подтверждает наличие этой проблемы в Open Source версии.16  
Ошибки, связанные с утечками памяти в Transient хранилище, регулярно фиксировались в баг-трекере проекта (например, issue #2654), что указывает на сложность корректного управления этим ресурсом.17  
Специфика работы с cookies в современных веб-приложениях делает сценарий Hit-for-Miss не исключением, а правилом для значительной части трафика, если не применяется агрессивная нормализация VCL.18

### **Доводы против**

Опытные системные администраторы могут предотвратить эту проблему путем явного задания параметров размера Transient хранилища в аргументах запуска демона (-s Transient=malloc,2G), что переводит проблему из разряда "утечка" в разряд "вытеснение кэша".7  
Если VCL настроен корректно и удаляет заголовок Set-Cookie для статических ресурсов и изображений, то создание объектов Hit-for-Miss для основного объема трафика будет предотвращено.19  
Современные версии Varnish включают улучшения в управлении памятью и могут использовать более агрессивные стратегии очистки короткоживущих объектов, если система находится под давлением памяти, хотя это и зависит от используемого аллокатора.20  
При использовании аллокатора jemalloc фрагментация памяти в Transient хранилище должна быть минимальной (около 20%), что позволяет эффективно переиспользовать освобожденные блоки памяти.20  
В некоторых сценариях проблема может быть вызвана не логикой Hit-for-Miss, а ошибками в модулях VMOD или утечками памяти в пользовательском C-коде, подключенном через inline C.21  
Если трафик на сайт имеет низкую кардинальность (мало уникальных URL) и высокий Hit Rate, то количество объектов Hit-for-Miss будет незначительным, и они не смогут исчерпать память современного сервера.22  
Проблема может быть ложно диагностирована как HfM, в то время как реальной причиной является буферизация больших тел ответов при медленных клиентах, что также использует Transient, но по другому механизму.11

## **Cᛘ2: Фрагментация кучи процесса вследствие неоптимальной работы аллокатора glibc на многоядерной архитектуре ARM64**

### **Суть**

Вторая критическая гипотеза переносит фокус анализа с логического уровня Varnish на системный уровень управления памятью в среде Linux, специфичный для архитектуры ARM64.  
Varnish Cache является высокопроизводительным многопоточным приложением, которое осуществляет миллионы операций выделения и освобождения памяти (malloc/free) в секунду для обработки HTTP-запросов и хранения объектов.  
Эффективность этих операций напрямую зависит от используемого системного аллокатора памяти (memory allocator).  
Стандартным аллокатором в большинстве дистрибутивов Linux, включая Amazon Linux 2023, является ptmalloc, входящий в состав стандартной библиотеки C (glibc).23  
Аллокатор glibc исторически оптимизирован для универсальных задач, но имеет известные архитектурные недостатки при работе в высоконагруженных многопоточных средах.  
Для уменьшения конкуренции потоков за блокировки (lock contention) glibc создает отдельные области памяти, называемые аренами (arenas), для каждого потока или группы потоков.24  
Инстансы AWS Graviton, построенные на архитектуре ARM64, характеризуются большим количеством физических ядер (до 64 ядер на Graviton2 и больше на последующих поколениях).12  
Поскольку Varnish масштабирует количество своих рабочих потоков (thread_pools и thread_pool_max) в зависимости от доступных ядер CPU, на мощных инстансах создаются сотни и тысячи потоков.15  
Это приводит к созданию огромного количества арен памяти в glibc, каждая из которых резервирует адресное пространство и физическую память.  
Основная проблема glibc в данном контексте — это фрагментация памяти (heap fragmentation).  
Когда Varnish освобождает память (удаляет объект из кэша), glibc помечает этот блок как свободный внутри конкретной арены, но не обязательно возвращает его операционной системе немедленно.23  
Если другой поток, привязанный к другой арене, запрашивает память, он не может использовать свободное место из первой арены и вынужден запрашивать новые страницы у ядра ОС.  
В результате процесс varnishd может удерживать значительный объем памяти (высокий RSS), которая внутри аллокатора считается свободной, но недоступна для системы.  
На архитектуре ARM64 в облаке AWS ситуация усугубляется особенностями управления страницами виртуальной памяти.  
Для повышения производительности и снижения нагрузки на TLB (Translation Lookaside Buffer), ядра Linux на Graviton часто настраиваются на использование страниц размером 64 КБ вместо стандартных для x86 4 КБ.25  
Увеличенный размер страницы означает, что минимальный квант выделения памяти, который аллокатор запрашивает у ядра (через mmap), составляет 64 КБ.  
Если Varnish необходимо сохранить объект размером 2 КБ, и аллокатор не находит места в текущих страницах, он запрашивает новую страницу на 64 КБ, используя лишь 3% её объема.  
Это явление называется внутренней фрагментацией, и оно значительно усиливает накладные расходы на память при работе с большим количеством мелких объектов, характерных для веб-кэша.  
В дистрибутиве Amazon Linux 2023, который отличается от Amazon Linux 2 обновленной пакетной базой и разрывом совместимости, пакет varnish может поставляться без жесткой привязки к альтернативному аллокатору jemalloc.26  
Аллокатор jemalloc (Jason Evans' malloc) является де-факто стандартом для Varnish, так как он специально спроектирован для минимизации фрагментации и эффективной работы на многоядерных системах.20  
Согласно тестам, jemalloc удерживает фрагментацию на уровне не более 20%, тогда как glibc в худших сценариях может потреблять в 2-3 раза больше памяти, чем реально необходимо приложению.20  
Отсутствие jemalloc в цепочке зависимостей пакета Varnish на AL2023 приводит к тому, что демон запускается с дефолтным glibc, что является «тихой» проблемой конфигурации.  
Пользователи, столкнувшиеся с этой проблемой, отмечают, что мониторинг Varnish (varnishstat) показывает корректное использование памяти кэшем (SMA.g_bytes), но системный мониторинг (top, ps) фиксирует постоянный рост RSS процесса вплоть до срабатывания OOM-killer.8  
В логах системы ldd для бинарного файла varnishd можно обнаружить отсутствие линковки с libjemalloc.so, что подтверждает использование системного аллокатора.2  
Настройка параметров glibc, таких как MALLOC_ARENA_MAX, может лишь частично смягчить проблему ценой падения производительности из-за блокировок, но не решает её корневую причину.28  
Таким образом, гипотеза Cᛘ2 утверждает, что исчерпание памяти вызвано не логической утечкой данных, а неэффективностью системного программного обеспечения (glibc) на специфической аппаратной платформе (ARM64/Graviton) при работе с паттерном нагрузки Varnish.

### **Оценка**

85

### **Доводы за**

Сравнительные тесты производительности и потребления памяти однозначно показывают преимущество jemalloc над glibc для приложений класса Varnish, особенно в долгоживущих процессах.20  
Существуют документированные подтверждения от пользователей RHEL 9 (близкого родственника AL2023), которые фиксировали трехкратное снижение потребления памяти после принудительного переключения Varnish на jemalloc.2  
Архитектура процессоров AWS Graviton с их большим количеством ядер создает экстремальную нагрузку на механизм арен памяти в glibc, провоцируя максимальную фрагментацию.12  
Использование страниц памяти размером 64 КБ на ARM64 является документированной оптимизацией в AWS, которая технически неизбежно увеличивает гранулярность выделения памяти и способствует росту потребления RAM для мелких объектов.25  
Изменения в репозиториях и политиках поддержки пакетов Amazon Linux 2023 создают реальную вероятность того, что зависимости пакета Varnish были изменены или упрощены, исключив jemalloc из установки по умолчанию.26  
Симптоматика проблемы (расхождение между метриками Varnish и системными метриками памяти) полностью соответствует картине фрагментации кучи, когда приложение "думает", что память свободна, а ОС видит её занятой.29  
Официальные рекомендации Varnish Software настоятельно советуют использовать jemalloc для предотвращения проблем с памятью, признавая glibc субоптимальным выбором.20  
Проблема "retained memory" в glibc является известным багом/особенностью, которая особенно ярко проявляется в контейнеризированных средах и на виртуальных машинах с ограниченными ресурсами.23  
В баг-трекерах RedHat и Fedora присутствуют тикеты, обсуждающие проблемы сборки jemalloc и Varnish для aarch64 (ARM64), что указывает на наличие специфических платформенных сложностей.30  
Практика использования переменных окружения типа MALLOC_CONF для тюнинга памяти в Varnish показывает, что проблема лежит именно в плоскости аллокатора.28

### **Доводы против**

Если установка Varnish производилась из официальных репозиториев varnish-cache.org или с использованием официального Docker-образа, то jemalloc обычно включен в сборку статически или настроен корректно, независимо от дистрибутива.31  
Современные версии glibc (начиная с 2.26 и выше) включают механизм tcache (thread local cache), который улучшает производительность, хотя и может способствовать дополнительному потреблению памяти, но разработчики библиотеки активно работают над уменьшением фрагментации.29  
Многие крупные инсталляции успешно работают на ARM64 без ручного вмешательства в аллокатор, что говорит о том, что проблема может проявляться только при специфических паттернах нагрузки (например, очень высокая частота аллокации/освобождения).27  
Настройка ядра Linux (например, отключение Transparent Huge Pages) может оказывать более значительное влияние на память, чем выбор между glibc и jemalloc.28  
Если проблема вызвана бесконечным ростом Transient хранилища (Cᛘ1), то смена аллокатора не решит проблему, а лишь немного отсрочит наступление OOM, так как утечка носит логический характер.8  
Диагностика через varnishstat может быть неправильно интерпретирована пользователем; высокий g_bytes в Transient — это не фрагментация, а занятая память, и аллокатор здесь ни при чем.11

## **Cᛘ3: Масштабное раздувание метаданных кэша вследствие высокой кардинальности входящих запросов**

### **Суть**

Третья гипотеза рассматривает проблему исчерпания памяти как следствие феномена "Cache Bloat" (раздувание кэша), вызванного отсутствием надлежащей нормализации запросов на уровне VCL.  
Varnish Cache идентифицирует объекты в памяти по хэш-ключу, который вычисляется в процедуре vcl_hash на основе URL запроса, заголовка Host и, опционально, других факторов.7  
В современном интернет-ландшафте URL-адреса часто содержат параметры, которые уникальны для каждого пользователя или перехода, но не влияют на содержание отдаваемого контента.  
Типичными примерами являются маркетинговые метки (Google Analytics utm_*, Facebook fbclid), идентификаторы сессий, передаваемые в строке запроса (jsessionid), или случайные параметры, добавляемые клиентами для обхода браузерного кэширования (?nocache=RANDOM).32  
Если конфигурация VCL не содержит правил для очистки этих параметров перед хэшированием, Varnish будет воспринимать каждый такой запрос как уникальный объект, подлежащий кэшированию.  
При высокой посещаемости ресурса или при активности поисковых ботов и сканеров, генерирующих миллионы уникальных ссылок, количество объектов в кэше начинает расти экспоненциально.22  
Даже если сами закэшированные страницы имеют небольшой размер, или если Varnish сохраняет только факт отсутствия контента (Hit-for-Miss), каждый объект требует выделения служебных структур данных.  
Внутренняя архитектура Varnish оперирует структурами objecthead (запись в глобальной хэш-таблице) и objectcore (описание состояния объекта, ссылки на хранилище), а также другими метаданными.33  
Совокупный размер этих накладных расходов (overhead) составляет приблизительно 1 КБ на каждый объект.9  
Это означает, что один миллион уникальных "мусорных" объектов займет в оперативной памяти около 1 ГБ, даже если полезная нагрузка равна нулю.  
В сценариях массированной атаки или неконтролируемого сканирования количество объектов может достигать десятков миллионов, что приводит к потреблению десятков гигабайт RAM исключительно на метаданные.15  
Этот оверхед обычно аллоцируется через системный malloc и не всегда учитывается в лимитах, заданных параметром -s malloc,SIZE, который ограничивает только объем данных объектов.9  
Еще одним мощным вектором раздувания кэша является некорректное использование заголовка Vary.  
Если бэкенд-сервер возвращает заголовок Vary: User-Agent (что часто встречается в дефолтных настройках веб-серверов Apache и Nginx), Varnish обязан хранить отдельную копию страницы для каждой уникальной строки User-Agent.34  
Учитывая огромное разнообразие версий браузеров, операционных систем и мобильных устройств, это приводит к фрагментации кэша на тысячи вариаций одного и того же контента.  
На платформе Amazon Linux 2023 с мощными процессорами Graviton Varnish способен обрабатывать гигантские потоки запросов, что позволяет процессу "накачивания" кэша происходить очень быстро, опережая механизмы вытеснения устаревших данных (LRU Expiry).  
Ситуация усложняется тем, что эти объекты могут попадать как в основное хранилище, так и в Transient (если они классифицированы как HfM из-за cookies), создавая комплексную нагрузку на подсистему памяти.18  
Диагностика данной проблемы требует анализа метрики MAIN.n_object в varnishstat, которая будет показывать аномально высокие значения, и использования утилиты varnishtop -i BereqURL для выявления паттернов запросов с высокой кардинальностью.22  
Решением проблемы является строгая нормализация входящих запросов в vcl_recv: удаление известных трекинговых параметров из req.url, сортировка query arguments и нормализация заголовка User-Agent перед хэшированием.32  
Без этих мер Varnish на мощном оборудовании превращается в эффективный инструмент для потребления собственной памяти.

### **Оценка**

70

### **Доводы за**

Проблема "Cache Bloat" из-за query parameters является одной из самых распространенных причин деградации производительности Varnish, подробно описанной в руководствах по эксплуатации.35  
Техническая документация подтверждает наличие фиксированного оверхеда в 1 КБ на объект, что делает хранение миллионов мелких объектов экономически неэффективным и опасным для стабильности памяти.9  
Логи веб-серверов повсеместно демонстрируют наличие "паразитного" трафика с уникальными параметрами (utm marks, click IDs), который без фильтрации гарантированно попадает в кэш как уникальный контент.32  
Механизм Vary: User-Agent является известной ловушкой для администраторов, способной увеличить потребление памяти в сотни раз без видимых причин в логике приложения.34  
Инструменты мониторинга Varnish предоставляют четкие индикаторы этой проблемы: высокий n_object, низкий cache_hit rate и большое разнообразие URL в логах.22  
В контексте AWS Graviton высокая производительность CPU позволяет Varnish обрабатывать и аллоцировать эти объекты с огромной скоростью, быстрее приводя к OOM по сравнению с более медленными системами.12  
Существуют специализированные VMOD и стандартные VCL-сниппеты, направленные именно на решение этой проблемы, что говорит о её индустриальной значимости.32  
Если "мусорные" запросы также содержат cookies, они создают объекты Hit-for-Miss, которые попадают в безлимитный Transient, объединяя риски Cᛘ1 и Cᛘ3.19

### **Доводы против**

Varnish имеет встроенный механизм LRU (Least Recently Used), который должен автоматически удалять старые и редко используемые объекты, когда выделенная под хранилище память заканчивается.18  
Если администратор корректно настроил лимит -s malloc, Varnish должен удерживать потребление памяти в заданных рамках, жертвуя Hit Rate, но не падая с OOM (за исключением оверхеда, который должен быть учтен в "запасе" памяти).37  
Для того чтобы оверхед в 1 КБ съел всю память сервера (например, 32 ГБ), нужно создать около 30 миллионов объектов, что является экстремальным значением и будет заметно в любой системе мониторинга.15  
Проблема раздувания кэша чаще приводит к снижению эффективности кэширования (thrashing), чем к полной остановке сервиса, так как Varnish агрессивно "nukes" (удаляет) объекты при нехватке места.31  
Эта гипотеза не объясняет специфику проблем именно на Amazon Linux 2023 по сравнению с другими дистрибутивами, так как логика хэширования универсальна для всех версий Varnish.

## **Cᛘ4: Исчерпание памяти транзитными буферами при обработке больших объектов или медленных клиентов**

### **Суть**

Четвертая гипотеза связывает утечку памяти с механизмами буферизации данных, передаваемых через Varnish.  
Varnish Cache выполняет роль посредника между клиентом и бэкендом, и его задача — передать контент максимально эффективно.  
Существует два основных режима передачи: буферизация (store-and-forward) и потоковая передача (streaming).3  
В режиме буферизации Varnish полностью загружает объект от бэкенда в свое хранилище, и только после завершения загрузки начинает отдавать его клиенту.  
В режиме стриминга (beresp.do_stream = true) передача клиенту начинается сразу же по мере поступления первых байтов от бэкенда.11  
Однако, если объект классифицирован как некэшируемый (uncacheable), или если Varnish решил не кэшировать его (Hit-for-Pass/Hit-for-Miss), данные все равно должны где-то храниться в процессе передачи.  
Для этих целей используется все то же хранилище Transient.1  
Проблема возникает, когда размер передаваемого объекта велик (сотни мегабайт или гигабайты), а скорость клиента значительно ниже скорости получения данных от бэкенда.  
В облачной среде AWS внутренняя сеть между инстансами (например, между EC2 с Varnish и S3 или другим EC2) имеет огромную пропускную способность (до 25-100 Гбит/с).12  
Varnish вычитывает данные от бэкенда с максимальной скоростью и заполняет ими буферы в памяти Transient.  
Если клиент подключен через мобильную сеть 3G/4G, он не может принять эти данные с такой скоростью.  
В результате Varnish вынужден хранить разницу ("backpressure") в своей оперативной памяти.  
Параметр beresp.transit_buffer предназначен для ограничения объема этой буферизации, но по умолчанию он может быть не настроен или настроен на большие значения.38  
Документация указывает "правило большого пальца" для расчета памяти под некэшируемые объекты: n * transit_buffer, где n — количество конкурентных запросов.1  
При одновременной загрузке нескольких больших файлов (например, обновлений ПО, видеофайлов) потребление памяти может мгновенно вырасти на несколько гигабайт.  
Поскольку Transient хранилище не ограничено (как выяснено в Cᛘ1), Varnish будет аллоцировать память до тех пор, пока она есть физически.  
Особый случай — когда администратор пытается ограничить кэширование больших файлов через VCL (например, if (beresp.http.Content-Length > 20MB) { set beresp.uncacheable = true; }), но не включает return(pipe) в vcl_recv.13  
В этом случае Varnish все равно пропускает трафик через свой процесс ("fetch processor"), аллоцируя память под транзитные буферы.  
На системах с ARM64 процессорами Graviton, которые часто используются для задач с высокой пропускной способностью (High Throughput), риск возникновения таких ситуаций повышается из-за способности оборудования обрабатывать огромные потоки данных.39  
Симптомы данной проблемы включают резкие скачки потребления памяти (spikes), совпадающие по времени с запросами к большим файлам, и последующее падение по OOM.2  
В статистике varnishstat это отражается в метриках SMA.Transient.c_bytes (общий объем аллоцированных байт) и SMA.Transient.g_bytes (текущий занятый объем).15  
Решением является использование механизма pipe для больших объектов, который замыкает сокет клиента напрямую на сокет бэкенда, минуя память Varnish, или тщательная настройка параметров стриминга.31

### **Оценка**

60

### **Доводы за**

Пользователи часто сообщают о падении Varnish (OOM) при попытке скачать файлы размером несколько гигабайт, если конфигурация не предусматривает использование pipe.13  
Метрика SMA.Transient.c_bytes позволяет точно отследить объем данных, проходящих через транзитное хранилище, и корреляция этой метрики с OOM является сильным индикатором проблемы.11  
Архитектура Varnish официально использует Transient для буферизации некэшируемого контента, и документация предупреждает о необходимости учета этого фактора при сайзинге памяти.1  
Высокоскоростная сетевая инфраструктура AWS способствует быстрому заполнению буферов, делая проблему более явной, чем в медленных сетях.12  
Механизм буферизации для медленных клиентов является классической проблемой прокси-серверов, и Varnish здесь не исключение.38  
В баг-трекере Varnish присутствуют обсуждения, касающиеся "висящих" транзакций Hit-for-Miss, которые удерживают буферы памяти дольше необходимого при обрыве связи клиентом.40

### **Доводы против**

В современных версиях Varnish (6.0+) механизм потоковой передачи (do_stream) включен по умолчанию для некэшируемых объектов, что должно предотвращать полную буферизацию тела ответа в память.11  
Для возникновения OOM требуется совпадение нескольких факторов: наличие очень больших файлов, медленных клиентов и высокой конкурентности запросов; для типичных веб-сайтов (e-commerce, новости) это нехарактерный профиль нагрузки.8  
Стандартной практикой администрирования Varnish является использование return(pipe) для любого контента, превышающего определенный размер, что полностью исключает этот вектор утечки.31  
Проблема носит эпизодический характер (во время загрузки), тогда как утечка памяти (memory leak) обычно характеризуется монотонным, постоянным ростом потребления ресурсов в течение длительного времени.11  
Гипотеза не объясняет, почему проблема стала острой именно на Amazon Linux 2023, если только не изменились дефолтные параметры сети или ядра, влияющие на буферизацию сокетов.

#### **Works cited**

1. Storage backends — Varnish version trunk documentation, accessed December 11, 2025, [https://varnish-cache.org/docs/trunk/users-guide/storage-backends.html](https://varnish-cache.org/docs/trunk/users-guide/storage-backends.html)  
2. Varnish Using Significantly More Memory than Cache? - Stack Overflow, accessed December 11, 2025, [https://stackoverflow.com/questions/78379910/varnish-using-significantly-more-memory-than-cache](https://stackoverflow.com/questions/78379910/varnish-using-significantly-more-memory-than-cache)  
3. The difference between Hit-for-Miss and Hit-for-Pass - Resources - Varnish Software, accessed December 11, 2025, [https://info.varnish-software.com/blog/the-difference-between-hit-for-miss-and-hit-for-pass](https://info.varnish-software.com/blog/the-difference-between-hit-for-miss-and-hit-for-pass)  
4. varnishd — Varnish version trunk documentation, accessed December 11, 2025, [https://varnish-cache.org/docs/trunk/reference/varnishd.html](https://varnish-cache.org/docs/trunk/reference/varnishd.html)  
5. varnish-cache/doc/sphinx/users-guide/increasing-your-hitrate.rst at master - GitHub, accessed December 11, 2025, [https://github.com/varnishcache/varnish-cache/blob/master/doc/sphinx/users-guide/increasing-your-hitrate.rst](https://github.com/varnishcache/varnish-cache/blob/master/doc/sphinx/users-guide/increasing-your-hitrate.rst)  
6. Under the hood - Varnish Software Documentation, accessed December 11, 2025, [https://docs.varnish-software.com/book/what-is-varnish/under-the-hood/](https://docs.varnish-software.com/book/what-is-varnish/under-the-hood/)  
7. varnishd — Varnish version 7.7.3 documentation, accessed December 11, 2025, [https://varnish-cache.org/docs/7.7/reference/varnishd.html](https://varnish-cache.org/docs/7.7/reference/varnishd.html)  
8. Why does Varnish eat up all memory despite having both transient and malloc limits?, accessed December 11, 2025, [https://serverfault.com/questions/1035846/why-does-varnish-eat-up-all-memory-despite-having-both-transient-and-malloc-limi](https://serverfault.com/questions/1035846/why-does-varnish-eat-up-all-memory-despite-having-both-transient-and-malloc-limi)  
9. Sizing your cache — Varnish version 7.4.3 documentation, accessed December 11, 2025, [https://varnish-cache.org/docs/7.4/users-guide/sizing-your-cache.html](https://varnish-cache.org/docs/7.4/users-guide/sizing-your-cache.html)  
10. Logging cache hits and misses - Varnish Developer Portal, accessed December 11, 2025, [https://www.varnish-software.com/developers/tutorials/logging-cache-hits-misses-varnish/](https://www.varnish-software.com/developers/tutorials/logging-cache-hits-misses-varnish/)  
11. Varnish memory usage keeps increasing - Stack Overflow, accessed December 11, 2025, [https://stackoverflow.com/questions/76209998/varnish-memory-usage-keeps-increasing](https://stackoverflow.com/questions/76209998/varnish-memory-usage-keeps-increasing)  
12. AWS Graviton4-based Amazon EC2 R8g instances: best price performance in Amazon EC2, accessed December 11, 2025, [https://aws.amazon.com/blogs/aws/aws-graviton4-based-amazon-ec2-r8g-instances-best-price-performance-in-amazon-ec2/](https://aws.amazon.com/blogs/aws/aws-graviton4-based-amazon-ec2-r8g-instances-best-price-performance-in-amazon-ec2/)  
13. limit readahead for private objects · Issue #2964 · varnishcache/varnish-cache - GitHub, accessed December 11, 2025, [https://github.com/varnishcache/varnish-cache/issues/2964](https://github.com/varnishcache/varnish-cache/issues/2964)  
14. Achieving a high hitrate — Varnish version 7.5.0 documentation, accessed December 11, 2025, [https://varnish-cache.org/docs/7.5/users-guide/increasing-your-hitrate.html](https://varnish-cache.org/docs/7.5/users-guide/increasing-your-hitrate.html)  
15. Varnish duplicate process 170 once - Unix & Linux Stack Exchange, accessed December 11, 2025, [https://unix.stackexchange.com/questions/632427/varnish-duplicate-process-170-once](https://unix.stackexchange.com/questions/632427/varnish-duplicate-process-170-once)  
16. Two-Minute Tech Tuesdays - Memory Governor - Resources - Varnish Software, accessed December 11, 2025, [https://info.varnish-software.com/blog/two-minute-tech-tuesdays-memory-governor](https://info.varnish-software.com/blog/two-minute-tech-tuesdays-memory-governor)  
17. Overuse of Transient storage with hit-for-miss objects · Issue #2654 · varnishcache/varnish-cache - GitHub, accessed December 11, 2025, [https://github.com/varnishcache/varnish-cache/issues/2654](https://github.com/varnishcache/varnish-cache/issues/2654)  
18. Troubleshooting Varnish - Varnish Developer Portal, accessed December 11, 2025, [https://www.varnish-software.com/developers/tutorials/troubleshooting-varnish/](https://www.varnish-software.com/developers/tutorials/troubleshooting-varnish/)  
19. how to use varnish cache with set-cookie named mp3list and phpsessionid - Server Fault, accessed December 11, 2025, [https://serverfault.com/questions/649629/how-to-use-varnish-cache-with-set-cookie-named-mp3list-and-phpsessionid](https://serverfault.com/questions/649629/how-to-use-varnish-cache-with-set-cookie-named-mp3list-and-phpsessionid)  
20. Understanding Varnish Cache Memory Usage - Resources, accessed December 11, 2025, [https://info.varnish-software.com/blog/understanding-varnish-cache-memory-usage](https://info.varnish-software.com/blog/understanding-varnish-cache-memory-usage)  
21. Reduce concurrency when using glibc-based Linux without jemalloc to help prevent memory fragmentation · Issue #2607 · lovell/sharp - GitHub, accessed December 11, 2025, [https://github.com/lovell/sharp/issues/2607](https://github.com/lovell/sharp/issues/2607)  
22. Achieving a high cache hit rate with Varnish - Resources, accessed December 11, 2025, [https://info.varnish-software.com/blog/high-hit-rate-with-varnish](https://info.varnish-software.com/blog/high-hit-rate-with-varnish)  
23. How glibc Memory Handling Affects Java Applications: The Hidden Cost of Fragmentation | by Daniyal Hassan | Medium, accessed December 11, 2025, [https://medium.com/@daniyal.hass/how-glibc-memory-handling-affects-java-applications-the-hidden-cost-of-fragmentation-8e666ee6e000](https://medium.com/@daniyal.hass/how-glibc-memory-handling-affects-java-applications-the-hidden-cost-of-fragmentation-8e666ee6e000)  
24. Why does the default glibc allocator have relatively poor performance? (What mak... | Hacker News, accessed December 11, 2025, [https://news.ycombinator.com/item?id=8612645](https://news.ycombinator.com/item?id=8612645)  
25. Improve Performance with 64K Memory Pages on AWS Graviton Processors, accessed December 11, 2025, [https://dev.to/aws-builders/improve-performance-with-64k-memory-pages-on-aws-graviton-processors-ifa](https://dev.to/aws-builders/improve-performance-with-64k-memory-pages-on-aws-graviton-processors-ifa)  
26. Package support statements - Amazon Linux 2023, accessed December 11, 2025, [https://docs.aws.amazon.com/linux/al2023/release-notes/support-info-by-support-statement.html](https://docs.aws.amazon.com/linux/al2023/release-notes/support-info-by-support-statement.html)  
27. CPU and memory usage of jemalloc as compared to glibc malloc - Stack Overflow, accessed December 11, 2025, [https://stackoverflow.com/questions/13027475/cpu-and-memory-usage-of-jemalloc-as-compared-to-glibc-malloc](https://stackoverflow.com/questions/13027475/cpu-and-memory-usage-of-jemalloc-as-compared-to-glibc-malloc)  
28. Varnish 6 LTS /w CentOS 8 not respecting memory limits? - Stack Overflow, accessed December 11, 2025, [https://stackoverflow.com/questions/65450044/varnish-6-lts-w-centos-8-not-respecting-memory-limits](https://stackoverflow.com/questions/65450044/varnish-6-lts-w-centos-8-not-respecting-memory-limits)  
29. Handling native memory fragmentation of glibc - Brice Dutheil, accessed December 11, 2025, [https://blog.arkey.fr/drafts/2021/01/22/native-memory-fragmentation-with-glibc/](https://blog.arkey.fr/drafts/2021/01/22/native-memory-fragmentation-with-glibc/)  
30. 1545539 – jemalloc(aarch64): munmap - Invalid Argument - build-time pagesize 4k != Fedora kernel (64k) - Red Hat Bugzilla, accessed December 11, 2025, [https://bugzilla.redhat.com/show_bug.cgi?id=1545539](https://bugzilla.redhat.com/show_bug.cgi?id=1545539)  
31. Varnish crashes on bigger files - cache - Server Fault, accessed December 11, 2025, [https://serverfault.com/questions/1031656/varnish-crashes-on-bigger-files](https://serverfault.com/questions/1031656/varnish-crashes-on-bigger-files)  
32. Stripping out select querystring attribute/value pairs so varnish will not vary cache by them, accessed December 11, 2025, [https://stackoverflow.com/questions/13144172/stripping-out-select-querystring-attribute-value-pairs-so-varnish-will-not-vary](https://stackoverflow.com/questions/13144172/stripping-out-select-querystring-attribute-value-pairs-so-varnish-will-not-vary)  
33. varnish-counters — Varnish version trunk documentation, accessed December 11, 2025, [https://varnish-cache.org/docs/trunk/reference/varnish-counters.html](https://varnish-cache.org/docs/trunk/reference/varnish-counters.html)  
34. Achieving a high hitrate — Varnish version 7.4.3 documentation, accessed December 11, 2025, [https://varnish-cache.org/docs/7.4/users-guide/increasing-your-hitrate.html](https://varnish-cache.org/docs/7.4/users-guide/increasing-your-hitrate.html)  
35. Stripping query strings in Varnish | Acquia Product Documentation, accessed December 11, 2025, [https://docs.acquia.com/acquia-cloud-platform/stripping-query-strings-varnish](https://docs.acquia.com/acquia-cloud-platform/stripping-query-strings-varnish)  
36. What are the commands to get top MISSES and HITS from Varnish 4? - Server Fault, accessed December 11, 2025, [https://serverfault.com/questions/649268/what-are-the-commands-to-get-top-misses-and-hits-from-varnish-4](https://serverfault.com/questions/649268/what-are-the-commands-to-get-top-misses-and-hits-from-varnish-4)  
37. 10 Varnish Cache mistakes and how to avoid them, accessed December 11, 2025, [https://varnish-software.medium.com/10-varnish-cache-mistakes-and-how-to-avoid-them-d240f452ab35](https://varnish-software.medium.com/10-varnish-cache-mistakes-and-how-to-avoid-them-d240f452ab35)  
38. Two-Minute Tech Tuesdays - Transit Buffer - Resources - Varnish Software, accessed December 11, 2025, [https://info.varnish-software.com/blog/two-minute-tech-tuesdays-transit-buffer](https://info.varnish-software.com/blog/two-minute-tech-tuesdays-transit-buffer)  
39. AWS Graviton Performance Testing: Tips for Independent Software Vendors - AWS Whitepaper - AWS Documentation, accessed December 11, 2025, [https://docs.aws.amazon.com/pdfs/whitepapers/latest/aws-graviton-performance-testing/aws-graviton-performance-testing.pdf](https://docs.aws.amazon.com/pdfs/whitepapers/latest/aws-graviton-performance-testing/aws-graviton-performance-testing.pdf)  
40. Changelog - Varnish Enterprise, accessed December 11, 2025, [https://docs.varnish-software.com/varnish-enterprise/changelog/](https://docs.varnish-software.com/varnish-enterprise/changelog/)

# 18. Анализ `Cᛘ⠿` (выполнен экземпляром №5 Gemini Deep Research)
https://gemini.google.com/share/d5ef05331eb4

## **Cᛘ₁: Взрыв кэша из-за высокой кардинальности запросов**

### **Суть**

Данная гипотеза постулирует, что исчерпание оперативной памяти сервера вызвано комбинаторным взрывом количества уникальных объектов кэша, возникающим вследствие отсутствия агрессивной нормализации URL-адресов в условиях фасетной навигации и активного рекламного трафика.  
Ключевым механизмом, лежащим в основе этой проблемы, является дефолтное поведение Varnish Cache, который использует полную строку URL, включая все параметры запроса (query string), в качестве ключа для вычисления хэша объекта, что при малейшем изменении порядка параметров или их состава приводит к созданию новой записи в памяти.1  
В контексте проекта RunRepeat.com, архитектура которого включает фильтрацию товаров по полу, размеру и цвету, количество возможных перестановок параметров (например, /shoe?size=42&color=red против /shoe?color=red&size=42) растет факториально, создавая множественные копии одного и того же контента.1  
Ситуация критически усугубляется наличием рекламного трафика, о чем свидетельствует упоминание клиента «We also have ads», что неизбежно привносит в URL уникальные идентификаторы кликов, такие как gclid (Google Click ID), fbclid (Facebook Click ID) и различные utm_* метки.3  
Эти метки, предназначенные исключительно для клиентской аналитики или трекинга на стороне сервера, делают каждый входящий запрос технически уникальным с точки зрения Varnish, заставляя его сохранять копию страницы для каждого отдельного перехода пользователя по рекламе.3  
Даже если сам размер кэшируемых данных (HTML-тела страницы) ограничен параметром запуска -s malloc,SIZE, каждый создаваемый объект требует выделения структур метаданных, таких как struct obj и struct objcore, которые хранятся в оперативной памяти вне области, отведенной под хранилище данных (storage payload).6  
Согласно технической документации, накладные расходы (overhead) на один объект составляют приблизительно 1 КБ памяти, которая аллоцируется системным malloc и не учитывается в лимитах -s, задаваемых администратором при старте демона.6  
При сценарии, когда сайт получает около 4 миллионов сессий в месяц, и значительная часть этого трафика является рекламной или создается ботами, перебирающими фильтры, количество мелких объектов в памяти может достигать десятков миллионов.6  
Это приводит к тому, что метаданные начинают занимать гигабайты оперативной памяти (например, 10 миллионов объектов потребуют около 10 ГБ RAM только под структуры управления), что в условиях 32 ГБ общей памяти сервера создает критическое давление на ресурсы.6  
Более того, огромное количество объектов в хэш-таблице замедляет операции поиска (HSH_Lookup), увеличивает длину цепочек коллизий и создает дополнительную нагрузку на процессор, что клиент описывает как «performance degradation».7  
Отсутствие в описании проблемы упоминаний о применении модуля vmod_std и функции std.querysort для сортировки параметров или регулярных выражений для очистки трекинговых меток делает эту гипотезу наиболее вероятной технической причиной наблюдаемого поведения.10  
Если VCL (Varnish Configuration Language) не содержит явных инструкций по нормализации req.url до этапа vcl_hash, Varnish будет послушно кэшировать бесконечное множество вариаций одного URL, быстро исчерпывая физическую память сервера, независимо от того, какой лимит установлен для полезной нагрузки.12

### **Оценка**

95

### **Доводы за**

Фундаментальная архитектура E-commerce проектов с фасетным поиском («users can filter by gender, size, color») является хрестоматийным примером уязвимости к проблеме Cache Bloat, так как количество возможных комбинаций фильтров стремится к бесконечности.8  
Прямое указание клиента на наличие рекламы («We also have ads») служит практически гарантией присутствия в запросах высокоэнтропийных параметров отслеживания (gclid, utm), которые без специальной обработки приводят к коэффициенту кэширования (Hit Rate) близкому к нулю и переполнению памяти уникальными объектами.3  
Техническая спецификация Varnish Cache подтверждает наличие неустранимых накладных расходов в размере ~1 КБ на объект, которые находятся вне контроля параметра -s malloc, что полностью объясняет симптом «Varnish repeatedly grows the memory... regardless of what config we've tried».6  
Клиент отмечает, что «pages are not fully static», что подразумевает высокую динамику генерации контента и, вероятно, использование различных параметров запроса для управления отображением, что усиливает риск дублирования кэша [O.md §2.3].  
Отсутствие сортировки параметров запроса (std.querysort) приводит к тому, что идентичные по семантике запросы /A?x=1&y=2 и /A?y=2&x=1 обрабатываются как разные сущности, что эффективно удваивает потребление памяти для популярных страниц категорий.10  
Масштаб трафика в 4 миллиона сессий в месяц является достаточным для того, чтобы даже небольшой процент "мусорных" запросов (например, от поисковых ботов, сканирующих все комбинации фильтров) привел к созданию миллионов объектов за короткий промежуток времени.15  
Указание на то, что «config changes haven't helped», свидетельствует о том, что администраторы пытаются тюнить параметры размера хранилища, не понимая, что утечка происходит через метаданные объектов, количество которых не ограничено стандартными настройками.6  
В документации Varnish Enterprise проблема управления памятью через Massive Storage Engine (MSE) и Memory Governor выделяется как ключевое преимущество перед Open Source версией именно в сценариях с большим количеством объектов, что косвенно подтверждает уязвимость бесплатной версии к таким проблемам.14  
Использование Graviton CPU с большим количеством ядер (8 Cores) позволяет обрабатывать запросы параллельно с высокой скоростью, что может ускорить процесс заполнения памяти «мусорными» объектами при DDoS-подобной активности ботов [O.md §2.3].  
Существующие в открытом доступе рекомендации по настройке Varnish для Magento и других E-commerce платформ часто упускают нюансы глубокой очистки URL, ограничиваясь лишь базовыми правилами, что оставляет систему уязвимой для специфических трекеров.13

### **Доводы против**

Если команда разработчика клиента использует профессионально подготовленные шаблоны VCL для E-commerce (например, официальный VCL для Magento 2), то базовые правила нормализации URL и удаления технических параметров (utm_source и т.д.) могут быть уже включены в конфигурацию по умолчанию.13  
Механизм LRU (Least Recently Used), встроенный в Varnish, предназначен для автоматического удаления старых объектов при исчерпании выделенного лимита хранилища, что теоретически должно стабилизировать потребление памяти на заданном уровне, если только рост метаданных не происходит быстрее, чем процесс очистки.6  
В некоторых случаях, если сайт использует Vary заголовки корректно, Varnish может эффективно управлять вариациями контента без создания полностью независимых объектов, хотя это требует сложной настройки бэкенда.18  
Если бы проблема заключалась исключительно в дублировании URL, логи доступа (varnishlog) показали бы очевидную картину с огромным количеством уникальных ключей, что квалифицированный специалист должен был заметить на ранних этапах диагностики.19  
Утверждение клиента о «persistent memory issues» может указывать на то, что память не освобождается даже при снижении трафика, что более характерно для утечек памяти (memory leaks) в коде или фрагментации, чем для простого заполнения кэша, который должен реагировать на команды очистки или перезагрузки.14

## **Cᛘ₂: Неограниченное потребление памяти во временном хранилище**

### **Суть**

Гипотеза Cᛘ₂ утверждает, что наблюдаемая «утечка» памяти на самом деле является штатным, но неконтролируемым накоплением данных во временном хранилище (Transient Storage), которое в архитектуре Varnish Cache спроектировано как неограниченное по размеру пространство.  
Временное хранилище используется Varnish для размещения объектов с очень коротким временем жизни (определяется параметром shortlived, по умолчанию 10 секунд), а также для транзитных объектов, которые не подлежат длительному кэшированию.14  
Критически важным аспектом является механизм обработки ответов, которые нельзя кэшировать (uncacheable): когда Varnish решает не помещать объект в основной кэш (например, из-за наличия заголовка Set-Cookie или Cache-Control: private), он создает специальную запись hit-for-miss или hit-for-pass.21  
Эти технические записи, предназначенные для предотвращения "thundering herd" проблемы (когда множество запросов одновременно идут на бэкенд), сохраняются именно в Transient хранилище.22  
В сценарии E-commerce с активной рекламой, каждый переход пользователя по ссылке с gclid часто инициирует создание новой сессии на бэкенде, который отвечает установкой Set-Cookie.17  
В результате, Varnish вынужден создавать уникальный hit-for-miss объект для каждого такого запроса, сохраняя его в Transient хранилище на время действия TTL (по умолчанию 120 секунд для hit-for-miss).22  
Поскольку Transient хранилище по умолчанию использует системный аллокатор malloc без ограничения максимального размера (unbounded), при высокой интенсивности трафика (4 млн сессий) объем накопленных транзитных объектов может расти лавинообразно.14  
Этот рост происходит параллельно с использованием основного хранилища (определенного через -s malloc,SIZE), и суммарное потребление памяти процессом varnishd становится равным Storage Size + Transient Size + Overhead.7  
Клиент, наблюдая рост памяти, может пытаться уменьшить основной кэш, но это не влияет на Transient, что объясняет фразу «regardless of what config we've tried».14  
Особенно опасна ситуация с медленными клиентами или большими объемами передаваемых данных, так как Varnish буферизирует тело ответа в Transient хранилище во время его передачи от бэкенда к клиенту (streaming/buffering), и память освобождается только после полного завершения передачи.14  
Если на сайте присутствуют большие страницы или файлы, и множество пользователей с медленным интернетом (например, мобильных) одновременно загружают их, объем занятой в Transient памяти может достигать гигантских значений.14  
Данная проблема является архитектурной особенностью Open Source версии Varnish, где отсутствуют продвинутые механизмы управления памятью, доступные в Enterprise версии (Memory Governor), которые могли бы лимитировать Transient.14  
Таким образом, «утечка» памяти является фактически накоплением легитимных, но короткоживущих данных, которые система не успевает освобождать или накапливает в объемах, превышающих физические возможности сервера.22

### **Оценка**

90

### **Доводы за**

Документация Varnish Cache и многочисленные обсуждения в сообществе (StackOverflow, mailing lists) однозначно определяют Transient Storage как «unbounded memory space», что является известным источником проблем стабильности (OOM).14  
Анализ реальных инцидентов показывает, что метрика SMA.Transient.c_bytes может многократно превышать размер основного хранилища SMA.s0.c_bytes в ситуациях с высоким трафиком и некорректной политикой кэширования.22  
Клиентская жалоба на неэффективность изменений конфигурации («config changes haven't helped») прямо указывает на то, что проблема находится вне зоны действия стандартного параметра -s, который ограничивает только основной кэш.14  
Наличие на сайте рекламы и динамического контента («users can filter... ads on the site») генерирует паттерн трафика, богатый запросами, которые нельзя кэшировать (из-за кук или уникальности), что массово порождает объекты hit-for-miss в Transient.3  
Механизм hit-for-pass (в старых версиях) и hit-for-miss (в новых) специально разработан для защиты бэкенда, но ценой потребления памяти Varnish, что при атаке или всплеске трафика перекладывает нагрузку с CPU бэкенда на RAM прокси.21  
При 4 миллионах сессий в месяц, даже небольшой процент запросов, попадающих в Transient (например, корзина, чекаут, личный кабинет), создает постоянный базовый уровень потребления памяти, который может иметь пики, превышающие доступные 32 ГБ.7  
Отсутствие явного указания параметра -s Transient=malloc,SIZE в стандартных конфигурациях означает, что в 99% случаев эта настройка остается дефолтной (неограниченной), оставляя систему уязвимой.23  
Проблема усугубляется, если используются медленные бэкенды, так как объекты задерживаются в Transient на время ожидания и передачи, увеличивая время жизни аллокаций.14

### **Доводы против**

Теоретически, объекты в Transient хранилище имеют короткий жизненный цикл и должны освобождаться автоматически и быстро, что должно приводить к пилообразному графику потребления памяти, а не к постоянному линейному росту, описываемому клиентом.14  
В современных версиях Varnish (6.0+) механизм обработки hit-for-miss был оптимизирован по сравнению со старым hit-for-pass, чтобы уменьшить накладные расходы и время жизни записей, что должно снижать остроту проблемы.24  
Если сайт обслуживает преимущественно мелкие страницы (HTML), то буферизация ответов не должна занимать гигабайты памяти, если только не происходит массовая загрузка больших медиа-файлов через Varnish (что обычно выносится на CDN).14  
Клиент может использовать параметр shortlived с очень маленьким значением, что заставляет Varnish агрессивнее считать объекты транзитными, но это обычно требует осознанной настройки, а не происходит само собой.20

## **Cᛘ₃: Фрагментация памяти из-за системного аллокатора**

### **Суть**

Гипотеза Cᛘ₃ фокусируется на проблеме внутренней и внешней фрагментации оперативной памяти, возникающей из-за взаимодействия Varnish Cache с системным аллокатором памяти (glibc malloc) на операционной системе Linux.  
Varnish Cache работает по модели интенсивного выделения и освобождения памяти: миллионы объектов создаются, живут разное время и удаляются, что создает колоссальную нагрузку на аллокатор памяти.7  
Стандартный аллокатор glibc (ptmalloc), используемый по умолчанию в большинстве дистрибутивов Linux (RHEL, CentOS, Amazon Linux), исторически плохо справляется с паттерном нагрузки, характеризующимся высокой конкурентностью потоков и множеством мелких разнородных аллокаций.25  
В результате работы glibc образуется фрагментация кучи (heap fragmentation): память, освобожденная процессом (free()), остается закрепленной за процессом и не возвращается операционной системе, при этом она может быть разбита на мелкие блоки, непригодные для повторного использования под крупные объекты.7  
Это приводит к ситуации, когда метрика RSS (Resident Set Size) процесса Varnish постоянно растет, создавая видимость утечки памяти, хотя внутри самого Varnish (по метрикам счетчиков) объем используемых данных может быть стабильным.7  
Документация Varnish Software настоятельно рекомендует использовать альтернативный аллокатор jemalloc, который специально оптимизирован для предотвращения фрагментации и лучшей работы в многопоточных средах.7  
jemalloc использует механизм арен (arenas) и экстентов (extents), что позволяет удерживать уровень фрагментации на уровне не более 20% в худшем случае, тогда как для glibc этот показатель может быть значительно выше и непредсказуем.7  
Однако, в дистрибутивах семейства Red Hat (к которым относится Amazon Linux), jemalloc часто не является аллокатором по умолчанию и даже может отсутствовать в зависимостях пакета, требуя ручной установки и настройки через переменную окружения LD_PRELOAD или конфигурацию systemd.27  
На архитектуре ARM64 (Graviton), которая имеет отличную от x86 модель памяти и примитивы синхронизации, проблемы с блокировками (lock contention) и управлением памятью в glibc могут проявляться более остро, влияя не только на потребление памяти, но и на производительность CPU.25  
Клиент упоминает использование «Gravitron CPU» и «persistent memory issues», что делает версию с неэффективным аллокатором крайне правдоподобной, особенно если используется стандартный образ ОС без тюнинга [O.md §2.3].  
Важно отметить, что Varnish выделяет память не только под объекты, но и под рабочие пространства потоков (workspace_client, workspace_backend), размер которых также влияет на общую картину потребления и фрагментации.30  
Если фрагментация достигает 50% и более (что возможно с glibc в долгосрочной перспективе), сервер с 32 ГБ RAM может исчерпать память при реальном объеме полезных данных всего в 15-20 ГБ.7

### **Оценка**

85

### **Доводы за**

Официальный блог Varnish Software и документация прямо указывают на то, что jemalloc является рекомендованным стандартом, и использование других аллокаторов чревато высокой фрагментацией.7  
В release notes для Red Hat Enterprise Linux 10 интеграция jemalloc 5.3.0 в пакет Varnish подается как исправление критической проблемы «excessive memory usage... despite setting explicit memory limits», что подтверждает массовый характер проблемы на системах RHEL/Amazon Linux с glibc.27  
Бенчмарки баз данных (MySQL) и других кэширующих систем показывают, что переход с glibc на jemalloc может снизить потребление RSS в 2 раза при той же полезной нагрузке, что доказывает масштаб влияния аллокатора.25  
Проблема фрагментации объясняет «бесконечный» рост памяти: по мере работы процесса куча становится все более фрагментированной, и аллокатор вынужден запрашивать новые страницы у ОС, увеличивая RSS, даже если старые страницы формально свободны (но фрагментированы).7  
На Amazon Linux (основанном на RHEL/Fedora) пакет jemalloc может не быть установлен или активирован по умолчанию для Varnish, что является частой ловушкой для инженеров, мигрирующих с Debian/Ubuntu, где это часто сделано из коробки.27  
Специфика архитектуры Graviton (ARM64) может усугублять накладные расходы glibc из-за особенностей реализации спинлоков и атомарных операций, что коррелирует с жалобой на деградацию производительности.29

### **Доводы против**

Если клиент использует Varnish Enterprise или грамотно собранный Docker-контейнер, вероятность того, что jemalloc уже настроен, высока, так как это best practice.14  
В последних версиях glibc (начиная с 2.26) был внедрен per-thread cache (tcache), который значительно улучшил производительность и уменьшил фрагментацию, приблизив показатели к jemalloc в некоторых сценариях.25  
Проблема фрагментации обычно приводит к выходу на "плато" потребления памяти (saturation point), а не к бесконечному линейному росту до OOM, если только нагрузка не растет постоянно.26  
Диагностировать эту проблему достаточно легко с помощью утилит типа pmap или встроенных счетчиков jemalloc (если он подключен), и квалифицированный разработчик мог бы заметить разницу между g_bytes и RSS.7

## **Cᛘ₄: Неэффективность размера страниц памяти на архитектуре ARM64**

### **Суть**

Гипотеза Cᛘ₄ связывает проблемы производительности и, косвенно, управления памятью с использованием субоптимального размера страниц памяти (page size) на архитектуре процессоров AWS Graviton (ARM64).  
В отличие от архитектуры x86_64, где размер страницы памяти жестко зафиксирован на уровне 4 КБ (с опциональными Huge Pages), архитектура ARM64 поддерживает выбор размера страницы на уровне ядра ОС: 4 КБ, 16 КБ или 64 КБ.32  
Стандартные образы операционных систем (Amazon Linux 2, RHEL 8, Ubuntu) для ARM64 часто поставляются с ядром, настроенным на использование страниц 4 КБ для обеспечения максимальной совместимости с программным обеспечением.33  
Однако для приложений с интенсивным использованием памяти, таких как Varnish Cache (выделенный объем 32 ГБ), использование мелких страниц 4 КБ создает колоссальную нагрузку на подсистему управления памятью процессора (MMU) и буфер ассоциативной трансляции (TLB - Translation Lookaside Buffer).32  
При объеме памяти 32 ГБ и размере страницы 4 КБ таблица страниц (page table) может содержать миллионы записей, которые не помещаются в TLB, вызывая частые промахи (TLB misses).35  
Каждый промах TLB заставляет процессор выполнять дорогостоящую процедуру "прогулки по таблице страниц" (page walk), затрачивая циклы CPU и увеличивая латентность доступа к памяти.35  
Это явление напрямую коррелирует с жалобой клиента на «performance degradation», так как процессор тратит значительное время на обслуживание памяти, а не на обработку запросов.34  
Переход на ядро с поддержкой страниц 64 КБ (kernel-64k) позволяет уменьшить размер таблицы страниц в 16 раз и значительно повысить эффективность TLB, покрывая больший объем памяти меньшим количеством записей.33  
Хотя использование страниц 64 КБ может привести к некоторому увеличению потребления памяти для очень мелких файлов (внутренняя фрагментация, так как минимальный аллоцируемый блок равен 64 КБ), для Varnish, который управляет памятью большими чанками внутри malloc, это влияние нивелируется общим выигрышем в производительности.32  
Amazon Linux 2023 и RHEL 9 предоставляют пакет kernel-64k как опцию для высоконагруженных систем, баз данных и кэшей, работающих на Graviton.33  
Если клиент использует стандартное ядро 4 КБ на мощном инстансе Graviton с 32 ГБ памяти, он искусственно ограничивает пропускную способность системы и создает предпосылки для нестабильной работы под нагрузкой.34

### **Оценка**

60

### **Доводы за**

Документация Red Hat и Amazon AWS явно рекомендует использование kernel-64k для «memory-intensive workloads» и «large datasets» на платформе ARM64, к которым безусловно относится кэширующий сервер.33  
Независимые тесты производительности (Phoronix) демонстрируют значительный прирост производительности и снижение системных накладных расходов при переходе с 4 КБ на 64 КБ страницы на процессорах ARM64 серверного класса.34  
Проблема TLB Misses является классическим «бутылочным горлышком» для приложений с произвольным доступом к большим массивам памяти, что характерно для алгоритмов работы хэш-таблиц Varnish.35  
Упоминание клиентом конкретной аппаратной платформы «Gravitron CPU» (вероятно, опечатка от Graviton) намекает на то, что проблема может иметь аппаратно-зависимый характер, который не проявлялся бы на x86 [O.md §2.3].  
Снижение нагрузки на CPU за счет уменьшения page walks освобождает ресурсы для обработки большего количества запросов и сборки мусора, что может косвенно помочь в стабилизации памяти.35

### **Доводы против**

Данная проблема объясняет в первую очередь деградацию производительности (CPU/Latency), а не физическое исчерпание памяти (Memory Leak/Growth), которое является основной жалобой клиента [O.md §2.3].  
Использование страниц 64 КБ может увеличить потребление памяти операционной системой (kernel structures) и усилить внутреннюю фрагментацию для мелких системных файлов, хотя для самого Varnish это менее критично.32  
Переход на kernel-64k требует смены ядра и перезагрузки, а также потенциально может вызвать проблемы совместимости с некоторыми инструментами мониторинга или старым ПО, не готовым к такому размеру страниц.33  
Если Varnish настроен с использованием jemalloc и transparent huge pages (THP), операционная система может частично компенсировать недостатки 4 КБ страниц, объединяя их в большие страницы.32

## **Cᛘ₅: Отсутствие нормализации HTTP-заголовков и сжатия**

### **Суть**

Гипотеза Cᛘ₅ рассматривает вклад отсутствия нормализации ключевых HTTP-заголовков (User-Agent, Accept-Encoding, Cookie) в процесс неконтролируемого раздувания кэша.  
Varnish Cache использует механизм Vary для создания вариаций одного и того же объекта (URL) для разных клиентов, что необходимо для отдачи, например, сжатого (gzip) или несжатого контента, или мобильной версии сайта.1  
Критическая уязвимость возникает, если бэкенд приложение (RunRepeat.com) отправляет заголовок Vary: User-Agent, инструктируя Varnish хранить отдельную копию страницы для каждого уникального User-Agent.37  
Учитывая, что существует тысячи вариаций строк User-Agent (разные версии браузеров, ОС, устройства, боты), это приводит к катастрофическому дублированию контента: один URL может иметь сотни копий в кэше, каждая из которых потребляет память и метаданные.18  
Аналогичная проблема возможна с заголовком Accept-Encoding: если не нормализовать его в vcl_recv (приводя к единому виду gzip), Varnish может кэшировать отдельные копии для клиентов, присылающих gzip, deflate, deflate, gzip или просто gzip.1  
Кроме того, отсутствие правильной обработки заголовка Cookie в vcl_recv (например, удаление кук для статики или для страниц, не требующих авторизации) приводит к тому, что Varnish считает запросы персонализированными и либо не кэширует их вообще (passing), либо кэширует как уникальные вариации.39  
Клиент не упоминает о наличии специального кода VCL для нормализации заголовков, но упоминает, что «users can filter by gender...», что подразумевает сложную логику на бэкенде, которая может ошибочно выставлять широкие Vary заголовки [O.md §2.3].  
Также, если Varnish не настроен на хранение объектов в сжатом виде (gzip), он будет хранить несжатый HTML, который занимает в 5-10 раз больше места в оперативной памяти, что при больших объемах трафика существенно сокращает эффективную емкость кэша.38  
В совокупности эти факторы приводят к неэффективному использованию доступной памяти (хранение дубликатов и "воздуха"), что выглядит как быстрый рост потребления памяти при увеличении разнообразия клиентских устройств и ботов.

### **Оценка**

70

### **Доводы за**

Использование Vary: User-Agent является распространенной ошибкой конфигурации веб-серверов (Apache/Nginx) и CMS, которая при установке Varnish превращается в "бомбу замедленного действия" для памяти.18  
Современный трафик характеризуется огромным разнообразием User-Agent (мобильные приложения, встроенные браузеры, боты), что делает стратегию кэширования по User-Agent разрушительной без нормализации до групп (например, "Mobile", "Desktop").12  
Отсутствие сжатия объектов в памяти (хранение plain text) является расточительством ресурсов, и без явной настройки (do_gzip, do_stream) Varnish может работать в субоптимальном режиме.38  
Проблемы с Cookie («We also have ads») могут приводить к тому, что запросы с рекламными куками не попадают в кэш или создают вариации, если бэкенд добавляет Vary: Cookie.39  
Нормализация заголовков является стандартной практикой в профессиональных VCL, но часто отсутствует в базовых примерах или "быстрых стартах", которыми мог воспользоваться клиент.10

### **Доводы против**

Varnish версии 4.0 и выше имеет встроенную интеллектуальную обработку Accept-Encoding, автоматически выбирая лучшую схему сжатия, что снижает вероятность проблем с этим конкретным заголовком.38  
Большинство современных CMS (включая Magento, WordPress) научились избегать Vary: User-Agent в пользу адаптивной верстки или отдельных заголовков типа X-UA-Device, что снижает риск этой конкретной ошибки.18  
Даже при наличии множества вариаций, механизм LRU должен вытеснять наименее востребованные из них, предотвращая полный крах памяти, если только поток новых уникальных User-Agent не является непрерывным (атака ботов).6  
Эта проблема чаще проявляется как низкий Hit Rate, а не как бесконечный рост памяти, так как вариации являются частью одного объекта (hash), и их жизненный цикл связан.37

## **Вердикт**

Проведенный комплексный анализ ситуации, описанной клиентом ꆜ (проект P⁎), позволяет с высокой степенью уверенности идентифицировать причины нестабильности Varnish Cache.  
Ситуация классифицируется как мультифакторная проблема, где архитектурные особенности проекта накладываются на дефолтное поведение программного обеспечения и аппаратные нюансы.  
**Основные причины (P†):**

1. **Высокая кардинальность и рекламный трафик (Cᛘ₁ + Cᛘ₂):** Это доминирующий фактор. Комбинация фасетных фильтров и рекламных меток (gclid, utm) создает миллионы уникальных URL.  
   * Каждый уникальный URL порождает объект метаданных (overhead ~1KB), потребляющий память вне основного хранилища (-s malloc).  
   * Каждый рекламный переход с установкой Set-Cookie порождает объект hit-for-miss в **неограниченном** (unbounded) временном хранилище (Transient Storage).  
   * Это объясняет жалобу «changes in config haven't helped» — клиент ограничивает основной кэш, но утечка происходит через метаданные и Transient.  
2. **Проблемы аллокации и фрагментации (Cᛘ₃):** Использование системного аллокатора glibc (стандарт для Amazon Linux/RHEL) вместо рекомендованного jemalloc приводит к фрагментации памяти.  
   * Это создает видимость утечки (рост RSS), так как освобожденная память не возвращается ОС.  
   * На архитектуре Graviton (ARM64) glibc может работать менее эффективно из-за особенностей синхронизации.  
3. **Аппаратная неэффективность (Cᛘ₄):** Использование страниц памяти 4 КБ на 32 ГБ RAM для ARM64 создает высокую нагрузку на TLB, что является прямой причиной «performance degradation» и задержек в обработке памяти.

**Стратегия устранения (Action Plan):**

1. **VCL Нормализация (Critical):**  
   * Внедрить агрессивную очистку req.url в vcl_recv. Необходимо удалять все метки отслеживания (gclid, fbclid, utm_*) *до* хэширования.  
   * Использовать std.querysort(req.url) для нормализации порядка параметров фильтров.  
   * Пример:  
     Code snippet  
     import std;  
     sub vcl_recv {  
         # Удаление Google Analytics и других меток  
         set req.url = regsuball(req.url, "(?|&)(gclid|utm_[a-z]+|fbclid)=[-_A-z0-9+()%.]+&?", "");  
         set req.url = regsub(req.url, "[?|&]+$", "");  
         # Сортировка параметров  
         set req.url = std.querysort(req.url);  
     }

2. **Ограничение Transient Storage (Critical):**  
   * Изменить параметры запуска varnishd, явно ограничив временное хранилище.  
   * Добавить: -s Transient=malloc,2G (или другое разумное значение, например 10-15% от RAM). Это предотвратит OOM при атаках или всплесках hit-for-miss.  
3. **Оптимизация Аллокатора (High):**  
   * Убедиться, что используется jemalloc.  
   * Для Amazon Linux 2/2023: установить пакет jemalloc (dnf install jemalloc) и настроить systemd unit для Varnish, добавив Environment="LD_PRELOAD=/usr/lib64/libjemalloc.so.2".  
   * Это снизит фрагментацию и стабилизирует потребление памяти.  
4. **Тюнинг Graviton (Medium/High):**  
   * Если используется Amazon Linux 2023 или RHEL 9, рассмотреть установку ядра kernel-64k.  
   * Это существенно снизит TLB misses и повысит общую отзывчивость системы при работе с большими объемами кэша.  
5. **Мониторинг:**  
   * Настроить отслеживание метрик SMA.Transient.c_bytes, SMA.s0.g_bytes, MAIN.n_object, MAIN.n_vampireobject.  
   * Это позволит подтвердить теорию о том, какое именно хранилище растет.

#### **Works cited**

1. Varnish Explained - Mattias Geniar, accessed December 11, 2025, [https://ma.ttias.be/varnish-explained/](https://ma.ttias.be/varnish-explained/)  
2. PSA: You don't need that many regexes - Resources - Varnish Software, accessed December 11, 2025, [https://info.varnish-software.com/blog/psa-you-dont-need-that-many-regexes](https://info.varnish-software.com/blog/psa-you-dont-need-that-many-regexes)  
3. Strip query parameters with Varnish | by Danila Vershinin - Medium, accessed December 11, 2025, [https://medium.com/@getpagespeed/strip-query-parameters-with-varnish-bf3cb2877530](https://medium.com/@getpagespeed/strip-query-parameters-with-varnish-bf3cb2877530)  
4. How to strip UTM tags in Varnish without stripping queries I want? - Stack Overflow, accessed December 11, 2025, [https://stackoverflow.com/questions/75871726/how-to-strip-utm-tags-in-varnish-without-stripping-queries-i-want](https://stackoverflow.com/questions/75871726/how-to-strip-utm-tags-in-varnish-without-stripping-queries-i-want)  
5. Stripping out select querystring attribute/value pairs so varnish will not vary cache by them, accessed December 11, 2025, [https://stackoverflow.com/questions/13144172/stripping-out-select-querystring-attribute-value-pairs-so-varnish-will-not-vary](https://stackoverflow.com/questions/13144172/stripping-out-select-querystring-attribute-value-pairs-so-varnish-will-not-vary)  
6. Sizing your cache — Varnish version 6.0.16 documentation, accessed December 11, 2025, [https://varnish-cache.org/docs/6.0/users-guide/sizing-your-cache.html](https://varnish-cache.org/docs/6.0/users-guide/sizing-your-cache.html)  
7. Understanding Varnish Cache Memory Usage - Resources, accessed December 11, 2025, [https://info.varnish-software.com/blog/understanding-varnish-cache-memory-usage](https://info.varnish-software.com/blog/understanding-varnish-cache-memory-usage)  
8. arbal/awesome-stars: Top 18K of GitHub's finest., accessed December 11, 2025, [https://github.com/arbal/awesome-stars](https://github.com/arbal/awesome-stars)  
9. Assert in HSH_Lookup with Varnish 7.2.1 · Issue #3879 - GitHub, accessed December 11, 2025, [https://github.com/varnishcache/varnish-cache/issues/3879](https://github.com/varnishcache/varnish-cache/issues/3879)  
10. Example VCL template - Varnish Developer Portal, accessed December 11, 2025, [https://www.varnish-software.com/developers/tutorials/example-vcl-template/](https://www.varnish-software.com/developers/tutorials/example-vcl-template/)  
11. Varnish VCL "Symbol not found: std.querysort" - Stack Overflow, accessed December 11, 2025, [https://stackoverflow.com/questions/36012266/varnish-vcl-symbol-not-found-std-querysort](https://stackoverflow.com/questions/36012266/varnish-vcl-symbol-not-found-std-querysort)  
12. Hashing — Varnish version trunk documentation, accessed December 11, 2025, [https://varnish-cache.org/docs/trunk/users-guide/vcl-hashing.html](https://varnish-cache.org/docs/trunk/users-guide/vcl-hashing.html)  
13. Configuring Varnish for Magento - Varnish Developer Portal, accessed December 11, 2025, [https://www.varnish-software.com/developers/tutorials/configuring-varnish-magento/](https://www.varnish-software.com/developers/tutorials/configuring-varnish-magento/)  
14. Varnish memory usage keeps increasing - Stack Overflow, accessed December 11, 2025, [https://stackoverflow.com/questions/76209998/varnish-memory-usage-keeps-increasing](https://stackoverflow.com/questions/76209998/varnish-memory-usage-keeps-increasing)  
15. Introduction | HAProxy Enterprise 3.0r1, accessed December 11, 2025, [https://www.haproxy.com/documentation/haproxy-configuration-manual/new/3-0r1/intro/](https://www.haproxy.com/documentation/haproxy-configuration-manual/new/3-0r1/intro/)  
16. Two-Minute Tech Tuesdays - Memory Governor - Resources - Varnish Software, accessed December 11, 2025, [https://info.varnish-software.com/blog/two-minute-tech-tuesdays-memory-governor](https://info.varnish-software.com/blog/two-minute-tech-tuesdays-memory-governor)  
17. 4 Varnish Enterprise Features That Will Improve the Caching of Your Magento Store, accessed December 11, 2025, [https://info.varnish-software.com/blog/4-varnish-enterprise-features-that-will-improve-the-caching-of-your-magento-store](https://info.varnish-software.com/blog/4-varnish-enterprise-features-that-will-improve-the-caching-of-your-magento-store)  
18. varnish-book.pdf - HubSpot, accessed December 11, 2025, [https://cdn2.hubspot.net/hubfs/209523/The_Varnish_Book/varnish-book.pdf](https://cdn2.hubspot.net/hubfs/209523/The_Varnish_Book/varnish-book.pdf)  
19. Command line utilities - Lib.rs, accessed December 11, 2025, [https://lib.rs/command-line-utilities](https://lib.rs/command-line-utilities)  
20. Varnish Using Significantly More Memory than Cache? - Stack Overflow, accessed December 11, 2025, [https://stackoverflow.com/questions/78379910/varnish-using-significantly-more-memory-than-cache](https://stackoverflow.com/questions/78379910/varnish-using-significantly-more-memory-than-cache)  
21. varnish-counters — Varnish version trunk documentation, accessed December 11, 2025, [https://varnish-cache.org/docs/trunk/reference/varnish-counters.html](https://varnish-cache.org/docs/trunk/reference/varnish-counters.html)  
22. Transient storage killing memory - Varnish Cache, accessed December 11, 2025, [https://varnish-cache.org/lists/pipermail/varnish-misc/2016-November/025451.html](https://varnish-cache.org/lists/pipermail/varnish-misc/2016-November/025451.html)  
23. careful selection of hitpass vs hitmiss · Issue #2865 · varnishcache/varnish-cache - GitHub, accessed December 11, 2025, [https://github.com/varnishcache/varnish-cache/issues/2865](https://github.com/varnishcache/varnish-cache/issues/2865)  
24. Upgrading to Varnish 7.0, accessed December 11, 2025, [https://varnish-cache.org/docs/7.0/whats-new/upgrading-7.0.html](https://varnish-cache.org/docs/7.0/whats-new/upgrading-7.0.html)  
25. Concurrent large allocations: glibc malloc, jemalloc and tcmalloc - Small Datum, accessed December 11, 2025, [http://smalldatum.blogspot.com/2017/11/concurrent-large-allocations-glibc.html](http://smalldatum.blogspot.com/2017/11/concurrent-large-allocations-glibc.html)  
26. CPU and memory usage of jemalloc as compared to glibc malloc - Stack Overflow, accessed December 11, 2025, [https://stackoverflow.com/questions/13027475/cpu-and-memory-usage-of-jemalloc-as-compared-to-glibc-malloc](https://stackoverflow.com/questions/13027475/cpu-and-memory-usage-of-jemalloc-as-compared-to-glibc-malloc)  
27. Red Hat Enterprise Linux 10 10.1 Release Notes, accessed December 11, 2025, [https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/10/pdf/10.1_release_notes/%3Ctba%3E](https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/10/pdf/10.1_release_notes/%3Ctba%3E)  
28. Newest 'jemalloc' Questions - Stack Overflow, accessed December 11, 2025, [https://stackoverflow.com/questions/tagged/jemalloc?tab=Newest](https://stackoverflow.com/questions/tagged/jemalloc?tab=Newest)  
29. jemalloc vs glibc malloc: Memory Allocation Performance Comparison | by Binita Bharati, accessed December 11, 2025, [https://medium.com/@binitabharati/jemalloc-vs-glibc-malloc-memory-allocation-performance-comparison-fbaeda1740de](https://medium.com/@binitabharati/jemalloc-vs-glibc-malloc-memory-allocation-performance-comparison-fbaeda1740de)  
30. Tuning Varnish, accessed December 11, 2025, [https://docs.varnish-software.com/book/operations/tuning-varnish/](https://docs.varnish-software.com/book/operations/tuning-varnish/)  
31. Install Varnish Cache For Wordpress - Apache - Amazon Linux - Blog - Lawrence McDaniel, accessed December 11, 2025, [https://blog.lawrencemcdaniel.com/install-varnish-cache-on-amazon-linux/](https://blog.lawrencemcdaniel.com/install-varnish-cache-on-amazon-linux/)  
32. Understanding Memory Page Sizes on Arm64 - SitePoint, accessed December 11, 2025, [https://www.sitepoint.com/memory-page-sizes-on-arm64/](https://www.sitepoint.com/memory-page-sizes-on-arm64/)  
33. Chapter 2. The 64k page size kernel | Managing, monitoring, and updating the kernel | Red Hat Enterprise Linux | 9, accessed December 11, 2025, [https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9/html/managing_monitoring_and_updating_the_kernel/what-is-kernel-64k_managing-monitoring-and-updating-the-kernel](https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9/html/managing_monitoring_and_updating_the_kernel/what-is-kernel-64k_managing-monitoring-and-updating-the-kernel)  
34. 64K Kernel Page Size Performance Benefits For HPC Shown With NVIDIA's GH200 Grace CPU - Phoronix, accessed December 11, 2025, [https://www.phoronix.com/review/aarch64-64k-kernel-perf](https://www.phoronix.com/review/aarch64-64k-kernel-perf)  
35. 64K Memory page sizes - any experiences to share? - General Discussion, accessed December 11, 2025, [https://community.amperecomputing.com/t/64k-memory-page-sizes-any-experiences-to-share/2730](https://community.amperecomputing.com/t/64k-memory-page-sizes-any-experiences-to-share/2730)  
36. Setup Docker on Amazon Linux 2023 - GitHub Gist, accessed December 11, 2025, [https://gist.github.com/thimslugga/36019e15b2a47a48c495b661d18faa6d?permalink_comment_id=5057205](https://gist.github.com/thimslugga/36019e15b2a47a48c495b661d18faa6d?permalink_comment_id=5057205)  
37. Purging and banning — Varnish version 4.0.5 documentation, accessed December 11, 2025, [https://varnish-cache.org/docs/4.0/users-guide/purging.html](https://varnish-cache.org/docs/4.0/users-guide/purging.html)  
38. Varnish Administrator documentation - Read the Docs, accessed December 11, 2025, [https://readthedocs.org/projects/varnish-cache/downloads/pdf/readthedocs/](https://readthedocs.org/projects/varnish-cache/downloads/pdf/readthedocs/)  
39. Removing cookies in Varnish - Varnish Developer Portal, accessed December 11, 2025, [https://www.varnish-software.com/developers/tutorials/removing-cookies-varnish/](https://www.varnish-software.com/developers/tutorials/removing-cookies-varnish/)

# 19.
## 19.1.
`Mᚖ⠿` ≔ ⠿~ (Способы устранения `P†`)

## 19.2.
`Mᚖᵢ` : `Mᚖ⠿`

# 20. Анализ `Mᚖ⠿` (выполнен Gemini Deep Think)

# 21. Анализ `Mᚖ⠿` (выполнен экземпляром №1 Gemini Deep Research)

# 22. Анализ `Mᚖ⠿` (выполнен экземпляром №5 Gemini Deep Research)