https://gemini.google.com/share/2a9e151f15d9


## **1. Исполнительное резюме и стратегический контекст**

В данном отчете представлен исчерпывающий анализ критических аномалий потребления оперативной памяти в инфраструктуре Varnish Cache проекта RunRepeat (P⁎), функционирующего в среде AWS Graviton.  
Основной целью исследования является выявление глубинных причин нестабильности сервиса (OOM - Out of Memory), формулирование стратегии стабилизации и оценка рисков текущей конфигурации для клиента ꆜ.  
Анализ базируется на детальном изучении взаимодействия аллокатора памяти jemalloc, подсистемы виртуальной памяти Linux на архитектуре Aarch64 и внутренней логики хранения объектов Varnish.  
Мы рассматриваем переход на архитектуру ARM64 (AWS Graviton) как ключевой фактор, изменивший профиль работы с памятью и выявивший скрытые конфигурационные дефекты, которые оставались незаметными на архитектуре x86_64.  
Критическая уязвимость инфраструктуры заключается в синергетическом эффекте трех факторов: агрессивной фрагментации кучи (heap fragmentation) в jemalloc 5.x, неправильной работе механизма Transparent Huge Pages (THP) с мелкими объектами и неограниченном росте транзитного хранилища (Transient Storage).  
Отчет детально описывает механизмы утечки памяти, которые на самом деле представляют собой не классические утечки (memory leaks), а невозможность возврата фрагментированных страниц операционной системе из-за архитектурных особенностей управления памятью.  
В документе представлены доказательства того, что стандартная конфигурация Amazon Linux 2023 (AL2023) не подходит для высоконагруженных инсталляций Varnish без глубокого тюнинга системного слоя.  
Рекомендации R⬆⠿, представленные в финальной части, ранжированы по метрикам влияния на бизнес (Impact) и сложности внедрения (Effort), обеспечивая четкую дорожную карту для инженерной команды.  
Мы утверждаем, что без внедрения предложенных изменений дальнейшее масштабирование проекта на текущей аппаратной платформе приведет к каскадным сбоям и деградации пользовательского опыта.  
Успешная реализация стратегии позволит не только устранить падения сервиса, но и сократить операционные расходы за счет более эффективного использования ресурсов инстансов.

## **2. Архитектурный базис: Влияние AWS Graviton и Amazon Linux 2023**

### **2.1. Микроархитектурные особенности ARM64 в контексте управления памятью**

Проект P⁎ использует инстансы AWS EC2 на базе процессоров Graviton, построенных на архитектуре ARM64 (Aarch64), что фундаментально меняет работу подсистемы управления памятью по сравнению с традиционными x86_64 системами.  
Ключевым отличием, оказывающим непосредственное влияние на Varnish, является поддержка и приоритетное использование страниц памяти размером 64 КБ (64k pages) вместо стандартных 4 КБ.  
В операционной системе Amazon Linux 2023 (AL2023) ядро может быть скомпилировано с поддержкой страниц 4k (kernel) или 64k (kernel-64k), и этот выбор критичен для приложений с паттерном доступа к памяти, характерным для веб-акселераторов.  
Использование 64k страниц теоретически повышает производительность за счет снижения нагрузки на буфер ассоциативной трансляции (TLB - Translation Lookaside Buffer), так как один и тот же объем памяти покрывается меньшим количеством записей в таблице страниц (PTE - Page Table Entries).  
Однако для Varnish, который оперирует миллионами мелких объектов (часто размером менее 10 КБ), использование 64k страниц создает риск колоссальной внутренней фрагментации.  
Если объект размером 2 КБ помещается на страницу размером 64 КБ, и на этой странице больше нет активных объектов, система не может освободить или переиспользовать оставшиеся 62 КБ эффективно, если аллокатор не оптимизирован для такого выравнивания.  
Исследования показывают, что при работе с набором данных (working set) в 32 МБ на 64k страницах требуется всего 4 КБ кеша L1 для хранения PTE, тогда как на 4k страницах нагрузка на кеш возрастает, но плотность упаковки данных значительно выше.  
Для Varnish, где "рабочий набор" — это хаотичный доступ к миллионам разбросанных в куче объектов, экономия на TLB перекрывается потерями от невозможности уплотнить данные.  
Более того, архитектура Graviton имеет специфическую иерархию кешей L1/L2, и промахи кеша при доступе к метаданным аллокатора могут стоить дороже, чем на процессорах Intel/AMD.  
Неправильный выбор размера страницы ядра в AL2023 является фундаментом, на котором строится нестабильность потребления памяти в данном проекте.

### **2.2. Экосистема Amazon Linux 2023: Ограничения и возможности**

Amazon Linux 2023 представляет собой значительный отход от парадигмы Amazon Linux 2 (AL2) и CentOS 7, внедряя новую систему управления пакетами DNF и политику детерминированных обновлений.  
Это создает существенные препятствия для применения "классических" методов лечения проблем Varnish, таких как даунгрейд библиотеки jemalloc до версии 3.6.0, которая считается золотым стандартом стабильности для данного ПО.  
В репозиториях AL2023 отсутствует пакет jemalloc 3.x; вместо него поставляется версия 5.x (например, 5.2.1), которая, несмотря на улучшения производительности, демонстрирует агрессивное удержание памяти (memory hoarding) в определенных сценариях.  
Компиляция старой версии jemalloc из исходных кодов в среде AL2023 усложнена отсутствием необходимых библиотек совместимости и потенциальными конфликтами с системным glibc.  
Кроме того, управление сервисами в AL2023 полностью переведено на systemd, что требует отказа от привычных файлов конфигурации в /etc/sysconfig/varnish или /etc/default/varnish.  
Все изменения параметров запуска, включая переменные окружения для тюнинга аллокатора, должны вноситься через механизм systemctl edit, создающий файлы переопределения (override.conf).  
Инженеры проекта P⁎ могли упустить этот нюанс, продолжая редактировать старые конфигурационные файлы, которые игнорируются системой инициализации, что приводит к запуску Varnish с дефолтными, неоптимизированными настройками.  
Политика безопасности AL2023 также накладывает ограничения на использование LD_PRELOAD для подмены аллокатора, если бинарный файл запускается с привилегиями setuid/setgid, что требует особого внимания при настройке unit-файла systemd.

## **3. Глубокий анализ подсистемы памяти: Конфликт Varnish и Jemalloc**

### **3.1. Механика взаимодействия Varnish с аллокатором Jemalloc 5.x**

Varnish Cache не управляет физической памятью напрямую; он делегирует эту задачу системному аллокатору через интерфейс malloc storage backend.  
По умолчанию Varnish линкуется с библиотекой jemalloc, которая проектировалась для минимизации конкуренции потоков (thread contention) в многоядерных системах.  
Версия jemalloc 5.x внедрила новый механизм "Decay" (затухание) для возврата неиспользуемой памяти операционной системе, заменив старый механизм "Purge".  
Память в jemalloc делится на "активную", "грязную" (dirty) и "мутную" (muzzy); грязные страницы — это те, которые больше не используются приложением, но еще не возвращены ядру через системный вызов madvise(MADV_DONTNEED).  
Параметры dirty_decay_ms и muzzy_decay_ms определяют время, в течение которого аллокатор удерживает эти страницы в надежде на их повторное использование.  
В высоконагруженном Varnish, где объекты постоянно создаются и удаляются (LRU eviction), скорость генерации грязных страниц может превышать скорость их очистки (decay).  
На многоядерных процессорах Graviton (например, c6g.16xlarge с 64 vCPU) jemalloc создает огромное количество арен (arenas) — независимых зон памяти для снижения блокировок.  
Количество арен по умолчанию вычисляется как 4 * ncpus, что на 64-ядерном сервере дает 256 арен.  
Каждая арена имеет свои кеши потоков (tcache) и свои списки экстентов, что приводит к гигантским накладным расходам на метаданные и фрагментацию: свободная память может быть заперта в одной арене, в то время как другой поток вынужден запрашивать новые страницы у ядра для другой арены.  
Это объясняет феномен, когда Varnish сообщает о наличии свободного места в хранилище (SMA.s0.g_space), но RSS процесса растет до физического предела RAM.

### **3.2. Роль Transparent Huge Pages (THP) в фрагментации**

Механизм Transparent Huge Pages (THP) в ядре Linux автоматически объединяет стандартные страницы памяти в огромные страницы (2 МБ на x86, часто 2 МБ или иные размеры на ARM64 в зависимости от конфигурации ядра).  
Для баз данных Oracle или PostgreSQL это дает прирост производительности, но для Varnish это катастрофа.  
Jemalloc пытается вернуть память операционной системе с гранулярностью стандартной страницы (4 КБ или 64 КБ).  
Если эта страница является частью огромной страницы (Huge Page), ядро Linux не может освободить ее, пока не будет освобождена вся Huge Page целиком (все 2 МБ).  
Даже один байт живых данных на 2-мегабайтной странице блокирует её освобождение, что приводит к ситуации, когда "дырявая" память удерживается процессом.  
Демон khugepaged в ядре периодически сканирует память и пытается склеить страницы обратно, вызывая всплески нагрузки на CPU (system cpu time) и блокировки памяти, что увеличивает латентность ответов Varnish.  
На архитектуре ARM64 реализация THP может иметь дополнительные нюансы, связанные с поддержкой смежных (contiguous) PTE, что делает поведение еще менее предсказуемым.  
Отключение THP (never) является обязательным требованием для стабильной работы Varnish с jemalloc, однако в Amazon Linux 2023 это требует явной настройки через kernel boot parameters или sysfs при загрузке.

### **3.3. Накладные расходы на объекты (Object Overhead)**

При расчете потребления памяти часто учитывается только размер "полезной нагрузки" (размер HTTP-тела и заголовков), но игнорируются накладные расходы структур данных Varnish.  
Каждый объект в кеше представлен структурой struct obj, которая хранится в памяти, не управляемой механизмом malloc storage (то есть вне квоты -s malloc).  
Накладные расходы составляют приблизительно 1 КБ на объект: сюда входят сама структура объекта, атрибуты (TTL, Grace), заголовки backend-ответа и записи в хеш-таблице.  
Если проект P⁎ имеет высокую кардинальность кеша (например, 10 миллионов мелких объектов по 5 КБ), то полезная нагрузка составит 50 ГБ, но накладные расходы добавят еще 10 ГБ неучтенной памяти.  
Кроме того, каждый поток (thread) потребляет память под стек (обычно 48-64 КБ) и рабочее пространство (workspace), размер которых задается параметрами workspace_client и workspace_backend.  
Если параметр workspace_client завышен (например, до 256 КБ для поддержки больших заголовков), а количество потоков достигает 5000 (thread_pool_max), это резервирует еще 1.25 ГБ памяти.  
Varnish также использует Shared Memory Log (VSL) — кольцевой буфер в памяти для логирования, который обычно занимает около 80-100 МБ.  
Все эти расходы суммируются поверх лимита -s malloc.  
Типичная ошибка конфигурации — выделение под -s malloc 80-90% физической памяти сервера, не оставляя пространства (headroom) для накладных расходов, ядра ОС и сетевого стека, что гарантированно приводит к OOM.

## **4. Транзитное хранилище (Transient Storage): Скрытая угроза**

### **4.1. Природа и риски неограниченного роста**

Transient storage — это специализированное хранилище Varnish для объектов, которые не должны оставаться в основном кеше надолго.  
Сюда попадают объекты с TTL меньше значения параметра shortlived (по умолчанию 10 секунд), а также объекты, помеченные как uncacheable (Hit-for-Pass/Hit-for-Miss), если они требуют буферизации.  
В отличие от основного хранилища, которое имеет жесткий лимит размера (например, -s malloc,10G), Transient storage по умолчанию является неограниченным (unbounded).  
Это архитектурное решение позволяет Varnish обрабатывать всплески короткоживущего контента без вытеснения долгоживущих объектов из основного кеша.  
Однако в условиях атаки, ошибки в коде сайта или неправильной конфигурации VCL, поток транзитных объектов может стать лавинообразным.  
Если бэкенд начинает отдавать контент с Cache-Control: private или Set-Cookie, Varnish может решить сохранить тело ответа в Transient storage для текущего запроса или для механизма Hit-for-Miss.  
При трафике в тысячи запросов в секунду потребление памяти Transient storage может вырасти на гигабайты за считанные минуты, полностью исчерпав RAM сервера.

### **4.2. Эволюция механизмов Hit-for-Miss и Hit-for-Pass**

Понимание разницы между Hit-for-Pass (HFP) и Hit-for-Miss (HFM) критично для диагностики проблем памяти в современных версиях Varnish (6.0+).  
В старых версиях Varnish использовался механизм HFP: при получении некешируемого ответа создавался специальный маркер, который заставлял все последующие запросы к этому URL идти в обход кеша ("pass") прямо на бэкенд.  
Это предотвращало "очереди ожидания" (request coalescing), но полностью отключало защиту бэкенда.  
В новых версиях (включая 7.x) основным механизмом стал Hit-for-Miss: Varnish создает объект-маркер, который разрешает параллельные запросы к бэкенду (как miss), но позволяет закешировать ответ, если он станет кешируемым.  
Проблема заключается в том, что каждый такой маркер HFM является объектом, потребляющим память и накладные расходы.  
Если приложение на RunRepeat.com генерирует уникальные URL (например, с уникальными query parameters для каждого пользователя), Varnish создает отдельный HFM-объект для каждого уникального URL.  
В логах varnishstat это проявляется как рост метрик SMA.Transient.c_req и SMA.Transient.c_bytes при пустом основном хранилище.  
Более того, если VCL настроен неправильно (например, set beresp.ttl = 0s; вместо return(pass);), Varnish может принудительно создавать HFM объекты даже там, где они не нужны.

## **5. Нормализация запросов и кардинальность кеша**

### **5.1. Взрыв вариативности через User-Agent**

Одной из самых распространенных причин раздувания кеша (Cache Bloat) является некорректное использование заголовка Vary: User-Agent.  
Современные браузеры отправляют длинные и сложные строки User-Agent, содержащие версии браузера, операционной системы, движка рендеринга и даже модели устройства.  
Если бэкенд-сервер (например, Magento или WordPress) выдает заголовок Vary: User-Agent, Varnish обязан хранить отдельную копию страницы для каждой уникальной строки User-Agent.  
Даже различие в одной минорной версии Chrome (Chrome 90.0.4430.1 vs 90.0.4430.2) приведет к дублированию контента в памяти.  
Это увеличивает потребление памяти в сотни раз, снижает эффективность кеширования (Hit Rate стремится к нулю) и увеличивает нагрузку на процессор при поиске объектов.  
Решение заключается не в удалении Vary, а в нормализации User-Agent на уровне Varnish перед формированием ключа хеширования.  
Необходимо сводить тысячи вариаций к ограниченному набору классов: "desktop", "mobile", "tablet", "bot".  
Использование VMOD (например, vmod_devicedetect или регулярных выражений) позволяет подменить сложный User-Agent на простой класс устройства в заголовке X-UA-Device и использовать его в Vary.

### **5.2. Загрязнение Query String параметрами**

Аналогичная проблема возникает с параметрами строки запроса (URL Query Parameters).  
Маркетинговые метки (utm_source, utm_campaign, gclid, fbclid) добавляются к URL для аналитики, но обычно не влияют на контент страницы.  
Для Varnish URL page?utm_source=google и page?utm_source=facebook — это два разных объекта.  
Без очистки URL от этих параметров в vcl_recv кеш заполняется мусорными копиями одних и тех же страниц.  
Кроме того, важен порядок параметров: ?a=1&b=2 и ?b=2&a=1 также считаются разными URL.  
Сортировка параметров по алфавиту является обязательной практикой для дедупликации кеша.  
В Varnish для этого существует функция std.querysort(req.url), которая работает быстрее и надежнее самописных регулярных выражений.  
Однако для глубокой очистки (удаления конкретных параметров) часто приходится комбинировать std.querysort с regsuball.

## **6. Стратегические рекомендации R⬆⠿**

На основе проведенного анализа сформулированы следующие рекомендации. Каждая рекомендация оценена по степени влияния на стабильность (Impact) и трудоемкости внедрения (Effort).

### **6.1. Системный уровень (System Level)**

**Рекомендация R1: Полное отключение Transparent Huge Pages (THP)**

* **Приоритет:** Критический (Critical)  
* **Влияние:** Высокое. Устраняет главную причину невозможности возврата памяти аллокатором jemalloc.  
* **Сложность:** Низкая.  
* Действие:  
  Необходимо отключить THP на уровне загрузки ядра и в рантайме. В AL2023 это делается через создание конфигурационного файла для tuned или добавлением параметра ядра.  
  Временная команда: echo never | sudo tee /sys/kernel/mm/transparent_hugepage/enabled.  
  Постоянная: Добавить transparent_hugepage=never в аргументы ядра GRUB.

**Рекомендация R2: Тонкая настройка Jemalloc через MALLOC_CONF**

* **Приоритет:** Критический (Critical)  
* **Влияние:** Высокое. Адаптирует поведение аллокатора к паттерну нагрузки Varnish.  
* **Сложность:** Средняя.  
* Действие:  
  Внедрить переменные окружения в unit-файл systemd.  
  MALLOC_CONF=thp:never,narenas:2,dirty_decay_ms:5000,muzzy_decay_ms:5000  
  * narenas:2: Ограничивает количество арен до 2 (или 4), предотвращая создание сотен арен на многоядерных Graviton, что радикально снижает оверхед метаданных.  
  * dirty_decay_ms:5000: Увеличивает агрессивность возврата грязных страниц (5 секунд вместо дефолтных 10 или auto).

**Рекомендация R3: Выбор ядра с размером страниц 4 КБ**

* **Приоритет:** Высокий (High)  
* **Влияние:** Среднее/Высокое (зависит от текущего ядра).  
* **Сложность:** Высокая (требует перезагрузки и смены пакетов).  
* Действие:  
  Проверить текущий размер страниц командой getconf PAGE_SIZE. Если 65536, необходимо установить пакет kernel вместо kernel-64k в AL2023, чтобы уменьшить внутреннюю фрагментацию мелких объектов.

### **6.2. Уровень приложения (Varnish Application Level)**

**Рекомендация R4: Ограничение Transient Storage**

* **Приоритет:** Критический (Critical)  
* **Влияние:** Высокое. Предохранитель от падения всей ОС (OOM).  
* **Сложность:** Низкая.  
* Действие:  
  Задать явный лимит в параметрах запуска varnishd:  
  -s Transient=malloc,2G (размер подбирается как 10-15% от RAM). Это лучше, чем падение демона.

**Рекомендация R5: Резервирование памяти под накладные расходы**

* **Приоритет:** Высокий (High)  
* **Влияние:** Высокое.  
* **Сложность:** Низкая.  
* Действие:  
  Установить размер основного хранилища -s malloc не более 70% от физической RAM. Для инстанса с 16 ГБ RAM это 11G. Оставшиеся 5 ГБ уйдут на Transient, оверхед объектов (1КБ * N), стеки потоков и ядро ОС.

### **6.3. Логический уровень (VCL Optimization)**

**Рекомендация R6: Внедрение нормализации User-Agent**

* **Приоритет:** Высокий (High)  
* **Влияние:** Высокое (Снижение Cache Bloat).  
* **Сложность:** Средняя.  
* Действие:  
  Добавить в vcl_recv логику сворачивания User-Agent в классы (mobile, desktop). Переписывать заголовок Vary в ответе бэкенда.

**Рекомендация R7: Санитизация и сортировка Query String**

* **Приоритет:** Высокий (High)  
* **Влияние:** Высокое.  
* **Сложность:** Средняя.  
* Действие:  
  Использовать std.querysort(req.url) и regsuball для удаления UTM-меток.

## **7. План внедрения и мониторинг**

### **7.1. Модификация Systemd Unit**

В Amazon Linux 2023 редактирование сервиса выполняется командой sudo systemctl edit varnish.

Ini, TOML

### /etc/systemd/system/varnish.service.d/override.conf

# Оптимизация аллокатора для Graviton (ARM64) и Varnish  
Environment="MALLOC_CONF=background_thread:true,thp:never,narenas:2,dirty_decay_ms:4000,muzzy_decay_ms:4000"

# Переопределение команды запуска  
# -s malloc,10G: 65-70% от 16GB RAM  
# -s Transient=malloc,2G: Жесткий лимит транзитного хранилища  
# -p thread_pool_min=200: Предотвращение лага создания потоков  
# -p feature=+http2: Включение HTTP/2 (если требуется)  
ExecStart=  
ExecStart=/usr/sbin/varnishd   
  -a :80   
  -a :6081   
  -f /etc/varnish/default.vcl   
  -s malloc,10G   
  -s Transient=malloc,2G   
  -p thread_pool_min=200   
  -p thread_pool_max=4000   
  -p workspace_client=256k   
  -p workspace_backend=256k   
  -S /etc/varnish/secret

### **7.2. Код нормализации (VCL Snippet)**

Code snippet

vcl 4.1;  
import std;

sub vcl_recv {  
    # === 1. Нормализация Query String ===  
    # Удаление стандартных трекеров Google/Facebook/Yandex  
    if (req.url ~ "(?|&)(gclid|fbclid|utm_[a-z]+|yclid|mc_cid)=") {  
        set req.url = regsuball(req.url, "(gclid|fbclid|utm_[a-z]+|yclid|mc_cid)=[-_A-z0-9+()%.]+&?", "");  
        # Удаление висячих? или & в конце  
        set req.url = regsub(req.url, "[?|&]+$", "");  
    }  
    # Сортировка параметров для дедупликации  
    set req.url = std.querysort(req.url);

    # === 2. Нормализация User-Agent ===  
    # Простейшая классификация. Для продакшена лучше использовать vmod_devicedetect  
    if (req.http.User-Agent ~ "(?i)(mobile|android|iphone|ipod|blackberry|opera mini)") {  
        set req.http.X-UA-Device = "mobile";  
    } else if (req.http.User-Agent ~ "(?i)(ipad|tablet|kindle)") {  
        set req.http.X-UA-Device = "tablet";  
    } else {  
        set req.http.X-UA-Device = "desktop";  
    }  
}

sub vcl_backend_response {  
    # === 3. Управление Vary ===  
    # Если бэкенд варирует по User-Agent, заменяем на нормализованный класс  
    if (beresp.http.Vary ~ "User-Agent") {  
        if (beresp.http.Vary == "User-Agent") {  
            set beresp.http.Vary = "X-UA-Device";  
        } else {  
            set beresp.http.Vary = regsub(beresp.http.Vary, "User-Agent", "X-UA-Device");  
        }  
    }  
      
    # === 4. Защита от Hit-for-Miss шторма ===  
    # Если ответ некешируемый, убеждаемся, что мы не создаем вечный HFM объект  
    if (beresp.ttl <= 0s |

| beresp.http.Cache-Control ~ "private") {  
        set beresp.uncacheable = true;  
        set beresp.ttl = 120s; # Короткий TTL для HFM  
        return (deliver);  
    }  
}

sub vcl_hash {  
    # Хешируем по устройству, а не по User-Agent  
    if (req.http.X-UA-Device) {  
        hash_data(req.http.X-UA-Device);  
    }  
}

## **8. Таблица скоринга рекомендаций (Scoring Matrix)**

Ниже представлена сводная таблица для принятия решений.

| ID | Рекомендация | Impact (Влияние) | Effort (Сложность) | Risk (Риск) | Описание |
| :---- | :---- | :---- | :---- | :---- | :---- |
| **R1** | **Disable THP** | **10/10** | 2/10 | Low | Фундаментальное исправление фрагментации. Обязательно к внедрению. |
| **R2** | **Jemalloc Tuning** | **9/10** | 4/10 | Low | Адаптация аллокатора под Graviton. Снижает RSS на 20-30%. |
| **R3** | **Limit Transient** | **10/10** | 1/10 | Medium | Предотвращает крах системы, но может вызвать 503 ошибки при атаке. |
| **R4** | **Normalize UA** | **8/10** | 5/10 | Medium | Требует тестирования, чтобы не сломать мобильную версию сайта. |
| **R5** | **Sanitize Query** | **7/10** | 3/10 | Low | Безопасная оптимизация, удаляющая только аналитический мусор. |
| **R6** | **Reduce Malloc** | **6/10** | 1/10 | Low | Простое изменение конфига для создания запаса прочности (Headroom). |
| **R7** | **Kernel 4k Pages** | **5/10** | 8/10 | High | Радикальная мера. Применять, если R1 и R2 не дали полного эффекта. |

## **9. Заключение**

Анализ инфраструктуры RunRepeat.com показывает, что текущие проблемы с памятью Varnish не являются следствием ошибок в коде приложения, а представляют собой результат сложного взаимодействия между системными компонентами: процессором Graviton, ядром Linux, аллокатором jemalloc и логикой Varnish.  
Переход на AWS Graviton, будучи экономически выгодным, требует более высокой квалификации в настройке низкоуровневых параметров системы.  
Простое "увеличение памяти" (Vertical Scaling) не решит проблему, так как фрагментация и Transient storage заполнят любой доступный объем.  
Только методичное внедрение предложенных рекомендаций — начиная с отключения THP и заканчивая нормализацией трафика в VCL — обеспечит стабильность платформы и позволит проекту масштабироваться в будущем.