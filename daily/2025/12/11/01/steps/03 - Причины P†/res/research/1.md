https://gemini.google.com/share/0bd6830b26e3


## **Cᛘ1: Критический рост потребления памяти Transient-хранилища вследствие архитектурных особенностей механизма Hit-for-Miss**

### **Суть**

Архитектура Varnish Cache в своей основе опирается на модульную систему управления памятью, где различные стратегии хранения данных реализуются через интерфейсы, называемые «stevedores».  
Одним из фундаментальных, но часто недооцененных компонентов этой системы является хранилище типа Transient, которое играет роль буфера для объектов с коротким жизненным циклом.  
В контексте операционной системы Amazon Linux 2023, функционирующей на вычислительных мощностях AWS Graviton, поведение этого хранилища приобретает критическое значение для стабильности процесса varnishd.  
Согласно спецификациям 1, хранилище Transient используется по умолчанию для размещения объектов, которые движок Varnish классифицирует как не подлежащие длительному кэшированию.  
К этой категории относятся объекты, имеющие время жизни (Time To Live, TTL), меньшее, чем значение глобального параметра shortlived, который по умолчанию установлен на отметку в 10 секунд.2  
Однако наиболее коварным сценарием использования Transient является обслуживание механизма синхронизации запросов, известного как Hit-for-Miss.3  
Механизм Hit-for-Miss был внедрен в архитектуру Varnish начиная с ветки 4.0 как эволюционное развитие предыдущей концепции Hit-for-Pass, призванное устранить недостатки в обработке конкурентных запросов к одному и тому же ресурсу.3  
Основная задача этого механизма заключается в предотвращении эффекта «thundering herd» (проблемы грочущего стада), когда множество клиентов одновременно запрашивают контент, который бэкенд-сервер не может или не хочет кэшировать.  
В штатном режиме работы Varnish пытается объединить идентичные запросы (request coalescing), отправляя на бэкенд только один запрос и раздавая полученный ответ всем ожидающим клиентам.  
Если бэкенд возвращает ответ, который технически невозможно сохранить в кэше (например, ответ содержит заголовок Set-Cookie или директиву Cache-Control: private), Varnish должен принять решение о том, как обрабатывать последующие запросы к этому URL.  
В старой модели Hit-for-Pass Varnish создавал запись, которая безусловно отправляла все будущие запросы в обход кэша (pass) на определенное время, что снижало эффективность при изменении состояния бэкенда.  
Новая модель Hit-for-Miss создает в кэше специальный маркерный объект, который инструктирует Varnish обрабатывать последующие запросы как «промахи» (miss), позволяя тем самым предпринимать попытки кэширования в будущем, но отключая ожидание (coalescing) для текущего момента.3  
Критическая уязвимость данной схемы заключается в том, что этот маркерный объект Hit-for-Miss физически сохраняется в хранилище Transient.4  
Стандартная конфигурация VCL (Varnish Configuration Language), поставляемая вместе с дистрибутивом, содержит логику, которая автоматически переводит транзакцию в режим Hit-for-Miss при обнаружении заголовка Set-Cookie в ответе бэкенда.5  
Это поведение зафиксировано в процедуре vcl_backend_response и является предопределенным стандартом безопасности, предотвращающим случайное кэширование персональных сессионных данных пользователей.  
Проблема масштабируется из-за того, что время жизни (TTL) для таких объектов Hit-for-Miss по умолчанию жестко задано на уровне 120 секунд.6  
В условиях современного веб-трафика, насыщенного динамическими параметрами и трекинговыми метками, количество уникальных URL, генерирующих ответы с Set-Cookie, может исчисляться десятками тысяч в секунду.  
Каждый такой запрос инициирует создание отдельного объекта в памяти Varnish, который, несмотря на малый размер полезной нагрузки (метаданные), потребляет ресурсы оперативной памяти.  
Ситуация усугубляется тем, что хранилище Transient в Varnish реализовано через системный аллокатор памяти (обычно malloc) и, в отличие от явно конфигурируемых хранилищ (например, -s file или -s malloc,SIZE), не имеет встроенного верхнего предела потребления памяти по умолчанию.7  
Документация явно указывает, что если администратор не определил параметры Transient хранилища вручную, Varnish считает его безграничным («unbounded»).2  
Это создает опасную иллюзию контроля: администратор может ограничить основное хранилище кэша значением, например, 8 ГБ, полагая, что потребление памяти процессом не превысит 10-12 ГБ с учетом накладных расходов.  
Однако при активном создании объектов Hit-for-Miss реальное потребление памяти может линейно расти вплоть до физического предела RAM сервера, игнорируя настройки основного хранилища.8  
На архитектуре ARM64, используемой в инстансах AWS Graviton, эффективность управления памятью через стандартные аллокаторы может отличаться от x86_64, но логическая ошибка отсутствия лимита остается первичной причиной.  
Объекты Hit-for-Miss, накапливаясь в Transient хранилище, не вытесняются по алгоритму LRU (Least Recently Used) так же агрессивно, как объекты в основном хранилище, поскольку они считаются служебными и короткоживущими.  
Каждый объект в Varnish требует создания структур данных objecthead (заголовок объекта) и objectcore (ядро объекта), которые занимают около 1 КБ памяти, независимо от размера самого объекта.9  
При атаке или всплеске трафика, генерирующего 50 000 некэшируемых запросов в секунду, за двухминутное окно TTL в памяти будет создано 6 миллионов объектов.  
Простая арифметика показывает, что 6 миллионов объектов умноженные на 1 КБ накладных расходов дают 6 ГБ занятой памяти только под метаданные, не считая возможного сохранения тел ответов.  
Если бэкенд при этом отдает небольшие тела ошибок или заглушек, которые также попадают в Transient, объем потребления возрастает многократно.  
В логах varnishlog данное явление можно идентифицировать по массовому появлению тегов HitMiss и записей Storage: Transient.10  
Метрика SMA.Transient.g_bytes в утилите мониторинга varnishstat будет демонстрировать неуклонный рост, коррелирующий с количеством входящих запросов, даже если основное хранилище s0 остается полупустым.11  
Особую опасность представляет сочетание этой особенности с использованием фреймворков, которые устанавливают cookies на каждый ответ (например, PHP session start, CSRF токены), если VCL не настроен на их удаление для статики.  
Отсутствие явного лимита на Transient в строке запуска демона является распространенной ошибкой конфигурации, которая на платформе Amazon Linux 2023 проявляется особенно остро из-за высокой производительности сетевого стека, позволяющего пропускать огромный объем трафика.12  
Механизм Hit-for-Miss, задуманный как средство защиты, в данной конфигурации превращается в вектор отказа в обслуживании (DoS) через исчерпание ресурсов (Resource Exhaustion).  
Внутренние счетчики Varnish могут показывать, что система работает штатно, так как аллокации проходят успешно, пока не вмешивается OOM-killer ядра Linux.8  
Таким образом, гипотеза Cᛘ1 постулирует, что корневой причиной проблемы является архитектурное решение Varnish по использованию безлимитного хранилища для временных объектов в сочетании с агрессивной политикой создания HfM-маркеров.

### **Оценка**

95

### **Доводы за**

Документация проекта Varnish Cache недвусмысленно подтверждает, что хранилище Transient не имеет ограничений по размеру в дефолтной конфигурации, что является фундаментальным риском для любой инсталляции.2  
Многочисленные отчеты инженеров эксплуатации на платформах StackOverflow и ServerFault описывают сценарии, идентичные наблюдаемым симптомам: неконтролируемый рост потребления памяти процессом varnishd при фиксированном размере основного кэша.8  
Стандартный файл конфигурации VCL (builtin.vcl), поставляемый с пакетами Varnish, содержит логику, которая форсирует создание объектов Hit-for-Miss при наличии заголовка Set-Cookie, что делает эту проблему актуальной для большинства "коробочных" установок.5  
Значение TTL по умолчанию в 120 секунд для объектов Hit-for-Miss, зашитое в исходный код и документацию, создает достаточно широкое временное окно для накопления критической массы объектов при высокой интенсивности запросов.6  
Технический анализ накладных расходов памяти показывает, что структуры objecthead и objectcore потребляют значительный объем RAM (до 1 КБ на объект), который часто не учитывается при планировании мощностей (capacity planning).9  
В условиях облачной инфраструктуры AWS, где трафик может масштабироваться мгновенно, отсутствие жестких лимитов на служебные буферы памяти является критической уязвимостью архитектуры.12  
Появление тегов HitMiss в логах транзакций VSL является прямым доказательством работы данного механизма и позволяет однозначно связать рост памяти с конкретными типами запросов.10  
Коммерческая версия Varnish Enterprise внедрила функцию "Memory Governor" именно для решения проблемы непредсказуемого потребления памяти процессом, что косвенно подтверждает наличие этой проблемы в Open Source версии.16  
Ошибки, связанные с утечками памяти в Transient хранилище, регулярно фиксировались в баг-трекере проекта (например, issue #2654), что указывает на сложность корректного управления этим ресурсом.17  
Специфика работы с cookies в современных веб-приложениях делает сценарий Hit-for-Miss не исключением, а правилом для значительной части трафика, если не применяется агрессивная нормализация VCL.18

### **Доводы против**

Опытные системные администраторы могут предотвратить эту проблему путем явного задания параметров размера Transient хранилища в аргументах запуска демона (-s Transient=malloc,2G), что переводит проблему из разряда "утечка" в разряд "вытеснение кэша".7  
Если VCL настроен корректно и удаляет заголовок Set-Cookie для статических ресурсов и изображений, то создание объектов Hit-for-Miss для основного объема трафика будет предотвращено.19  
Современные версии Varnish включают улучшения в управлении памятью и могут использовать более агрессивные стратегии очистки короткоживущих объектов, если система находится под давлением памяти, хотя это и зависит от используемого аллокатора.20  
При использовании аллокатора jemalloc фрагментация памяти в Transient хранилище должна быть минимальной (около 20%), что позволяет эффективно переиспользовать освобожденные блоки памяти.20  
В некоторых сценариях проблема может быть вызвана не логикой Hit-for-Miss, а ошибками в модулях VMOD или утечками памяти в пользовательском C-коде, подключенном через inline C.21  
Если трафик на сайт имеет низкую кардинальность (мало уникальных URL) и высокий Hit Rate, то количество объектов Hit-for-Miss будет незначительным, и они не смогут исчерпать память современного сервера.22  
Проблема может быть ложно диагностирована как HfM, в то время как реальной причиной является буферизация больших тел ответов при медленных клиентах, что также использует Transient, но по другому механизму.11

## **Cᛘ2: Фрагментация кучи процесса вследствие неоптимальной работы аллокатора glibc на многоядерной архитектуре ARM64**

### **Суть**

Вторая критическая гипотеза переносит фокус анализа с логического уровня Varnish на системный уровень управления памятью в среде Linux, специфичный для архитектуры ARM64.  
Varnish Cache является высокопроизводительным многопоточным приложением, которое осуществляет миллионы операций выделения и освобождения памяти (malloc/free) в секунду для обработки HTTP-запросов и хранения объектов.  
Эффективность этих операций напрямую зависит от используемого системного аллокатора памяти (memory allocator).  
Стандартным аллокатором в большинстве дистрибутивов Linux, включая Amazon Linux 2023, является ptmalloc, входящий в состав стандартной библиотеки C (glibc).23  
Аллокатор glibc исторически оптимизирован для универсальных задач, но имеет известные архитектурные недостатки при работе в высоконагруженных многопоточных средах.  
Для уменьшения конкуренции потоков за блокировки (lock contention) glibc создает отдельные области памяти, называемые аренами (arenas), для каждого потока или группы потоков.24  
Инстансы AWS Graviton, построенные на архитектуре ARM64, характеризуются большим количеством физических ядер (до 64 ядер на Graviton2 и больше на последующих поколениях).12  
Поскольку Varnish масштабирует количество своих рабочих потоков (thread_pools и thread_pool_max) в зависимости от доступных ядер CPU, на мощных инстансах создаются сотни и тысячи потоков.15  
Это приводит к созданию огромного количества арен памяти в glibc, каждая из которых резервирует адресное пространство и физическую память.  
Основная проблема glibc в данном контексте — это фрагментация памяти (heap fragmentation).  
Когда Varnish освобождает память (удаляет объект из кэша), glibc помечает этот блок как свободный внутри конкретной арены, но не обязательно возвращает его операционной системе немедленно.23  
Если другой поток, привязанный к другой арене, запрашивает память, он не может использовать свободное место из первой арены и вынужден запрашивать новые страницы у ядра ОС.  
В результате процесс varnishd может удерживать значительный объем памяти (высокий RSS), которая внутри аллокатора считается свободной, но недоступна для системы.  
На архитектуре ARM64 в облаке AWS ситуация усугубляется особенностями управления страницами виртуальной памяти.  
Для повышения производительности и снижения нагрузки на TLB (Translation Lookaside Buffer), ядра Linux на Graviton часто настраиваются на использование страниц размером 64 КБ вместо стандартных для x86 4 КБ.25  
Увеличенный размер страницы означает, что минимальный квант выделения памяти, который аллокатор запрашивает у ядра (через mmap), составляет 64 КБ.  
Если Varnish необходимо сохранить объект размером 2 КБ, и аллокатор не находит места в текущих страницах, он запрашивает новую страницу на 64 КБ, используя лишь 3% её объема.  
Это явление называется внутренней фрагментацией, и оно значительно усиливает накладные расходы на память при работе с большим количеством мелких объектов, характерных для веб-кэша.  
В дистрибутиве Amazon Linux 2023, который отличается от Amazon Linux 2 обновленной пакетной базой и разрывом совместимости, пакет varnish может поставляться без жесткой привязки к альтернативному аллокатору jemalloc.26  
Аллокатор jemalloc (Jason Evans' malloc) является де-факто стандартом для Varnish, так как он специально спроектирован для минимизации фрагментации и эффективной работы на многоядерных системах.20  
Согласно тестам, jemalloc удерживает фрагментацию на уровне не более 20%, тогда как glibc в худших сценариях может потреблять в 2-3 раза больше памяти, чем реально необходимо приложению.20  
Отсутствие jemalloc в цепочке зависимостей пакета Varnish на AL2023 приводит к тому, что демон запускается с дефолтным glibc, что является «тихой» проблемой конфигурации.  
Пользователи, столкнувшиеся с этой проблемой, отмечают, что мониторинг Varnish (varnishstat) показывает корректное использование памяти кэшем (SMA.g_bytes), но системный мониторинг (top, ps) фиксирует постоянный рост RSS процесса вплоть до срабатывания OOM-killer.8  
В логах системы ldd для бинарного файла varnishd можно обнаружить отсутствие линковки с libjemalloc.so, что подтверждает использование системного аллокатора.2  
Настройка параметров glibc, таких как MALLOC_ARENA_MAX, может лишь частично смягчить проблему ценой падения производительности из-за блокировок, но не решает её корневую причину.28  
Таким образом, гипотеза Cᛘ2 утверждает, что исчерпание памяти вызвано не логической утечкой данных, а неэффективностью системного программного обеспечения (glibc) на специфической аппаратной платформе (ARM64/Graviton) при работе с паттерном нагрузки Varnish.

### **Оценка**

85

### **Доводы за**

Сравнительные тесты производительности и потребления памяти однозначно показывают преимущество jemalloc над glibc для приложений класса Varnish, особенно в долгоживущих процессах.20  
Существуют документированные подтверждения от пользователей RHEL 9 (близкого родственника AL2023), которые фиксировали трехкратное снижение потребления памяти после принудительного переключения Varnish на jemalloc.2  
Архитектура процессоров AWS Graviton с их большим количеством ядер создает экстремальную нагрузку на механизм арен памяти в glibc, провоцируя максимальную фрагментацию.12  
Использование страниц памяти размером 64 КБ на ARM64 является документированной оптимизацией в AWS, которая технически неизбежно увеличивает гранулярность выделения памяти и способствует росту потребления RAM для мелких объектов.25  
Изменения в репозиториях и политиках поддержки пакетов Amazon Linux 2023 создают реальную вероятность того, что зависимости пакета Varnish были изменены или упрощены, исключив jemalloc из установки по умолчанию.26  
Симптоматика проблемы (расхождение между метриками Varnish и системными метриками памяти) полностью соответствует картине фрагментации кучи, когда приложение "думает", что память свободна, а ОС видит её занятой.29  
Официальные рекомендации Varnish Software настоятельно советуют использовать jemalloc для предотвращения проблем с памятью, признавая glibc субоптимальным выбором.20  
Проблема "retained memory" в glibc является известным багом/особенностью, которая особенно ярко проявляется в контейнеризированных средах и на виртуальных машинах с ограниченными ресурсами.23  
В баг-трекерах RedHat и Fedora присутствуют тикеты, обсуждающие проблемы сборки jemalloc и Varnish для aarch64 (ARM64), что указывает на наличие специфических платформенных сложностей.30  
Практика использования переменных окружения типа MALLOC_CONF для тюнинга памяти в Varnish показывает, что проблема лежит именно в плоскости аллокатора.28

### **Доводы против**

Если установка Varnish производилась из официальных репозиториев varnish-cache.org или с использованием официального Docker-образа, то jemalloc обычно включен в сборку статически или настроен корректно, независимо от дистрибутива.31  
Современные версии glibc (начиная с 2.26 и выше) включают механизм tcache (thread local cache), который улучшает производительность, хотя и может способствовать дополнительному потреблению памяти, но разработчики библиотеки активно работают над уменьшением фрагментации.29  
Многие крупные инсталляции успешно работают на ARM64 без ручного вмешательства в аллокатор, что говорит о том, что проблема может проявляться только при специфических паттернах нагрузки (например, очень высокая частота аллокации/освобождения).27  
Настройка ядра Linux (например, отключение Transparent Huge Pages) может оказывать более значительное влияние на память, чем выбор между glibc и jemalloc.28  
Если проблема вызвана бесконечным ростом Transient хранилища (Cᛘ1), то смена аллокатора не решит проблему, а лишь немного отсрочит наступление OOM, так как утечка носит логический характер.8  
Диагностика через varnishstat может быть неправильно интерпретирована пользователем; высокий g_bytes в Transient — это не фрагментация, а занятая память, и аллокатор здесь ни при чем.11

## **Cᛘ3: Масштабное раздувание метаданных кэша вследствие высокой кардинальности входящих запросов**

### **Суть**

Третья гипотеза рассматривает проблему исчерпания памяти как следствие феномена "Cache Bloat" (раздувание кэша), вызванного отсутствием надлежащей нормализации запросов на уровне VCL.  
Varnish Cache идентифицирует объекты в памяти по хэш-ключу, который вычисляется в процедуре vcl_hash на основе URL запроса, заголовка Host и, опционально, других факторов.7  
В современном интернет-ландшафте URL-адреса часто содержат параметры, которые уникальны для каждого пользователя или перехода, но не влияют на содержание отдаваемого контента.  
Типичными примерами являются маркетинговые метки (Google Analytics utm_*, Facebook fbclid), идентификаторы сессий, передаваемые в строке запроса (jsessionid), или случайные параметры, добавляемые клиентами для обхода браузерного кэширования (?nocache=RANDOM).32  
Если конфигурация VCL не содержит правил для очистки этих параметров перед хэшированием, Varnish будет воспринимать каждый такой запрос как уникальный объект, подлежащий кэшированию.  
При высокой посещаемости ресурса или при активности поисковых ботов и сканеров, генерирующих миллионы уникальных ссылок, количество объектов в кэше начинает расти экспоненциально.22  
Даже если сами закэшированные страницы имеют небольшой размер, или если Varnish сохраняет только факт отсутствия контента (Hit-for-Miss), каждый объект требует выделения служебных структур данных.  
Внутренняя архитектура Varnish оперирует структурами objecthead (запись в глобальной хэш-таблице) и objectcore (описание состояния объекта, ссылки на хранилище), а также другими метаданными.33  
Совокупный размер этих накладных расходов (overhead) составляет приблизительно 1 КБ на каждый объект.9  
Это означает, что один миллион уникальных "мусорных" объектов займет в оперативной памяти около 1 ГБ, даже если полезная нагрузка равна нулю.  
В сценариях массированной атаки или неконтролируемого сканирования количество объектов может достигать десятков миллионов, что приводит к потреблению десятков гигабайт RAM исключительно на метаданные.15  
Этот оверхед обычно аллоцируется через системный malloc и не всегда учитывается в лимитах, заданных параметром -s malloc,SIZE, который ограничивает только объем данных объектов.9  
Еще одним мощным вектором раздувания кэша является некорректное использование заголовка Vary.  
Если бэкенд-сервер возвращает заголовок Vary: User-Agent (что часто встречается в дефолтных настройках веб-серверов Apache и Nginx), Varnish обязан хранить отдельную копию страницы для каждой уникальной строки User-Agent.34  
Учитывая огромное разнообразие версий браузеров, операционных систем и мобильных устройств, это приводит к фрагментации кэша на тысячи вариаций одного и того же контента.  
На платформе Amazon Linux 2023 с мощными процессорами Graviton Varnish способен обрабатывать гигантские потоки запросов, что позволяет процессу "накачивания" кэша происходить очень быстро, опережая механизмы вытеснения устаревших данных (LRU Expiry).  
Ситуация усложняется тем, что эти объекты могут попадать как в основное хранилище, так и в Transient (если они классифицированы как HfM из-за cookies), создавая комплексную нагрузку на подсистему памяти.18  
Диагностика данной проблемы требует анализа метрики MAIN.n_object в varnishstat, которая будет показывать аномально высокие значения, и использования утилиты varnishtop -i BereqURL для выявления паттернов запросов с высокой кардинальностью.22  
Решением проблемы является строгая нормализация входящих запросов в vcl_recv: удаление известных трекинговых параметров из req.url, сортировка query arguments и нормализация заголовка User-Agent перед хэшированием.32  
Без этих мер Varnish на мощном оборудовании превращается в эффективный инструмент для потребления собственной памяти.

### **Оценка**

70

### **Доводы за**

Проблема "Cache Bloat" из-за query parameters является одной из самых распространенных причин деградации производительности Varnish, подробно описанной в руководствах по эксплуатации.35  
Техническая документация подтверждает наличие фиксированного оверхеда в 1 КБ на объект, что делает хранение миллионов мелких объектов экономически неэффективным и опасным для стабильности памяти.9  
Логи веб-серверов повсеместно демонстрируют наличие "паразитного" трафика с уникальными параметрами (utm marks, click IDs), который без фильтрации гарантированно попадает в кэш как уникальный контент.32  
Механизм Vary: User-Agent является известной ловушкой для администраторов, способной увеличить потребление памяти в сотни раз без видимых причин в логике приложения.34  
Инструменты мониторинга Varnish предоставляют четкие индикаторы этой проблемы: высокий n_object, низкий cache_hit rate и большое разнообразие URL в логах.22  
В контексте AWS Graviton высокая производительность CPU позволяет Varnish обрабатывать и аллоцировать эти объекты с огромной скоростью, быстрее приводя к OOM по сравнению с более медленными системами.12  
Существуют специализированные VMOD и стандартные VCL-сниппеты, направленные именно на решение этой проблемы, что говорит о её индустриальной значимости.32  
Если "мусорные" запросы также содержат cookies, они создают объекты Hit-for-Miss, которые попадают в безлимитный Transient, объединяя риски Cᛘ1 и Cᛘ3.19

### **Доводы против**

Varnish имеет встроенный механизм LRU (Least Recently Used), который должен автоматически удалять старые и редко используемые объекты, когда выделенная под хранилище память заканчивается.18  
Если администратор корректно настроил лимит -s malloc, Varnish должен удерживать потребление памяти в заданных рамках, жертвуя Hit Rate, но не падая с OOM (за исключением оверхеда, который должен быть учтен в "запасе" памяти).37  
Для того чтобы оверхед в 1 КБ съел всю память сервера (например, 32 ГБ), нужно создать около 30 миллионов объектов, что является экстремальным значением и будет заметно в любой системе мониторинга.15  
Проблема раздувания кэша чаще приводит к снижению эффективности кэширования (thrashing), чем к полной остановке сервиса, так как Varnish агрессивно "nukes" (удаляет) объекты при нехватке места.31  
Эта гипотеза не объясняет специфику проблем именно на Amazon Linux 2023 по сравнению с другими дистрибутивами, так как логика хэширования универсальна для всех версий Varnish.

## **Cᛘ4: Исчерпание памяти транзитными буферами при обработке больших объектов или медленных клиентов**

### **Суть**

Четвертая гипотеза связывает утечку памяти с механизмами буферизации данных, передаваемых через Varnish.  
Varnish Cache выполняет роль посредника между клиентом и бэкендом, и его задача — передать контент максимально эффективно.  
Существует два основных режима передачи: буферизация (store-and-forward) и потоковая передача (streaming).3  
В режиме буферизации Varnish полностью загружает объект от бэкенда в свое хранилище, и только после завершения загрузки начинает отдавать его клиенту.  
В режиме стриминга (beresp.do_stream = true) передача клиенту начинается сразу же по мере поступления первых байтов от бэкенда.11  
Однако, если объект классифицирован как некэшируемый (uncacheable), или если Varnish решил не кэшировать его (Hit-for-Pass/Hit-for-Miss), данные все равно должны где-то храниться в процессе передачи.  
Для этих целей используется все то же хранилище Transient.1  
Проблема возникает, когда размер передаваемого объекта велик (сотни мегабайт или гигабайты), а скорость клиента значительно ниже скорости получения данных от бэкенда.  
В облачной среде AWS внутренняя сеть между инстансами (например, между EC2 с Varnish и S3 или другим EC2) имеет огромную пропускную способность (до 25-100 Гбит/с).12  
Varnish вычитывает данные от бэкенда с максимальной скоростью и заполняет ими буферы в памяти Transient.  
Если клиент подключен через мобильную сеть 3G/4G, он не может принять эти данные с такой скоростью.  
В результате Varnish вынужден хранить разницу ("backpressure") в своей оперативной памяти.  
Параметр beresp.transit_buffer предназначен для ограничения объема этой буферизации, но по умолчанию он может быть не настроен или настроен на большие значения.38  
Документация указывает "правило большого пальца" для расчета памяти под некэшируемые объекты: n * transit_buffer, где n — количество конкурентных запросов.1  
При одновременной загрузке нескольких больших файлов (например, обновлений ПО, видеофайлов) потребление памяти может мгновенно вырасти на несколько гигабайт.  
Поскольку Transient хранилище не ограничено (как выяснено в Cᛘ1), Varnish будет аллоцировать память до тех пор, пока она есть физически.  
Особый случай — когда администратор пытается ограничить кэширование больших файлов через VCL (например, if (beresp.http.Content-Length > 20MB) { set beresp.uncacheable = true; }), но не включает return(pipe) в vcl_recv.13  
В этом случае Varnish все равно пропускает трафик через свой процесс ("fetch processor"), аллоцируя память под транзитные буферы.  
На системах с ARM64 процессорами Graviton, которые часто используются для задач с высокой пропускной способностью (High Throughput), риск возникновения таких ситуаций повышается из-за способности оборудования обрабатывать огромные потоки данных.39  
Симптомы данной проблемы включают резкие скачки потребления памяти (spikes), совпадающие по времени с запросами к большим файлам, и последующее падение по OOM.2  
В статистике varnishstat это отражается в метриках SMA.Transient.c_bytes (общий объем аллоцированных байт) и SMA.Transient.g_bytes (текущий занятый объем).15  
Решением является использование механизма pipe для больших объектов, который замыкает сокет клиента напрямую на сокет бэкенда, минуя память Varnish, или тщательная настройка параметров стриминга.31

### **Оценка**

60

### **Доводы за**

Пользователи часто сообщают о падении Varnish (OOM) при попытке скачать файлы размером несколько гигабайт, если конфигурация не предусматривает использование pipe.13  
Метрика SMA.Transient.c_bytes позволяет точно отследить объем данных, проходящих через транзитное хранилище, и корреляция этой метрики с OOM является сильным индикатором проблемы.11  
Архитектура Varnish официально использует Transient для буферизации некэшируемого контента, и документация предупреждает о необходимости учета этого фактора при сайзинге памяти.1  
Высокоскоростная сетевая инфраструктура AWS способствует быстрому заполнению буферов, делая проблему более явной, чем в медленных сетях.12  
Механизм буферизации для медленных клиентов является классической проблемой прокси-серверов, и Varnish здесь не исключение.38  
В баг-трекере Varnish присутствуют обсуждения, касающиеся "висящих" транзакций Hit-for-Miss, которые удерживают буферы памяти дольше необходимого при обрыве связи клиентом.40

### **Доводы против**

В современных версиях Varnish (6.0+) механизм потоковой передачи (do_stream) включен по умолчанию для некэшируемых объектов, что должно предотвращать полную буферизацию тела ответа в память.11  
Для возникновения OOM требуется совпадение нескольких факторов: наличие очень больших файлов, медленных клиентов и высокой конкурентности запросов; для типичных веб-сайтов (e-commerce, новости) это нехарактерный профиль нагрузки.8  
Стандартной практикой администрирования Varnish является использование return(pipe) для любого контента, превышающего определенный размер, что полностью исключает этот вектор утечки.31  
Проблема носит эпизодический характер (во время загрузки), тогда как утечка памяти (memory leak) обычно характеризуется монотонным, постоянным ростом потребления ресурсов в течение длительного времени.11  
Гипотеза не объясняет, почему проблема стала острой именно на Amazon Linux 2023, если только не изменились дефолтные параметры сети или ядра, влияющие на буферизацию сокетов.

#### **Works cited**

1. Storage backends — Varnish version trunk documentation, accessed December 11, 2025, [https://varnish-cache.org/docs/trunk/users-guide/storage-backends.html](https://varnish-cache.org/docs/trunk/users-guide/storage-backends.html)  
2. Varnish Using Significantly More Memory than Cache? - Stack Overflow, accessed December 11, 2025, [https://stackoverflow.com/questions/78379910/varnish-using-significantly-more-memory-than-cache](https://stackoverflow.com/questions/78379910/varnish-using-significantly-more-memory-than-cache)  
3. The difference between Hit-for-Miss and Hit-for-Pass - Resources - Varnish Software, accessed December 11, 2025, [https://info.varnish-software.com/blog/the-difference-between-hit-for-miss-and-hit-for-pass](https://info.varnish-software.com/blog/the-difference-between-hit-for-miss-and-hit-for-pass)  
4. varnishd — Varnish version trunk documentation, accessed December 11, 2025, [https://varnish-cache.org/docs/trunk/reference/varnishd.html](https://varnish-cache.org/docs/trunk/reference/varnishd.html)  
5. varnish-cache/doc/sphinx/users-guide/increasing-your-hitrate.rst at master - GitHub, accessed December 11, 2025, [https://github.com/varnishcache/varnish-cache/blob/master/doc/sphinx/users-guide/increasing-your-hitrate.rst](https://github.com/varnishcache/varnish-cache/blob/master/doc/sphinx/users-guide/increasing-your-hitrate.rst)  
6. Under the hood - Varnish Software Documentation, accessed December 11, 2025, [https://docs.varnish-software.com/book/what-is-varnish/under-the-hood/](https://docs.varnish-software.com/book/what-is-varnish/under-the-hood/)  
7. varnishd — Varnish version 7.7.3 documentation, accessed December 11, 2025, [https://varnish-cache.org/docs/7.7/reference/varnishd.html](https://varnish-cache.org/docs/7.7/reference/varnishd.html)  
8. Why does Varnish eat up all memory despite having both transient and malloc limits?, accessed December 11, 2025, [https://serverfault.com/questions/1035846/why-does-varnish-eat-up-all-memory-despite-having-both-transient-and-malloc-limi](https://serverfault.com/questions/1035846/why-does-varnish-eat-up-all-memory-despite-having-both-transient-and-malloc-limi)  
9. Sizing your cache — Varnish version 7.4.3 documentation, accessed December 11, 2025, [https://varnish-cache.org/docs/7.4/users-guide/sizing-your-cache.html](https://varnish-cache.org/docs/7.4/users-guide/sizing-your-cache.html)  
10. Logging cache hits and misses - Varnish Developer Portal, accessed December 11, 2025, [https://www.varnish-software.com/developers/tutorials/logging-cache-hits-misses-varnish/](https://www.varnish-software.com/developers/tutorials/logging-cache-hits-misses-varnish/)  
11. Varnish memory usage keeps increasing - Stack Overflow, accessed December 11, 2025, [https://stackoverflow.com/questions/76209998/varnish-memory-usage-keeps-increasing](https://stackoverflow.com/questions/76209998/varnish-memory-usage-keeps-increasing)  
12. AWS Graviton4-based Amazon EC2 R8g instances: best price performance in Amazon EC2, accessed December 11, 2025, [https://aws.amazon.com/blogs/aws/aws-graviton4-based-amazon-ec2-r8g-instances-best-price-performance-in-amazon-ec2/](https://aws.amazon.com/blogs/aws/aws-graviton4-based-amazon-ec2-r8g-instances-best-price-performance-in-amazon-ec2/)  
13. limit readahead for private objects · Issue #2964 · varnishcache/varnish-cache - GitHub, accessed December 11, 2025, [https://github.com/varnishcache/varnish-cache/issues/2964](https://github.com/varnishcache/varnish-cache/issues/2964)  
14. Achieving a high hitrate — Varnish version 7.5.0 documentation, accessed December 11, 2025, [https://varnish-cache.org/docs/7.5/users-guide/increasing-your-hitrate.html](https://varnish-cache.org/docs/7.5/users-guide/increasing-your-hitrate.html)  
15. Varnish duplicate process 170 once - Unix & Linux Stack Exchange, accessed December 11, 2025, [https://unix.stackexchange.com/questions/632427/varnish-duplicate-process-170-once](https://unix.stackexchange.com/questions/632427/varnish-duplicate-process-170-once)  
16. Two-Minute Tech Tuesdays - Memory Governor - Resources - Varnish Software, accessed December 11, 2025, [https://info.varnish-software.com/blog/two-minute-tech-tuesdays-memory-governor](https://info.varnish-software.com/blog/two-minute-tech-tuesdays-memory-governor)  
17. Overuse of Transient storage with hit-for-miss objects · Issue #2654 · varnishcache/varnish-cache - GitHub, accessed December 11, 2025, [https://github.com/varnishcache/varnish-cache/issues/2654](https://github.com/varnishcache/varnish-cache/issues/2654)  
18. Troubleshooting Varnish - Varnish Developer Portal, accessed December 11, 2025, [https://www.varnish-software.com/developers/tutorials/troubleshooting-varnish/](https://www.varnish-software.com/developers/tutorials/troubleshooting-varnish/)  
19. how to use varnish cache with set-cookie named mp3list and phpsessionid - Server Fault, accessed December 11, 2025, [https://serverfault.com/questions/649629/how-to-use-varnish-cache-with-set-cookie-named-mp3list-and-phpsessionid](https://serverfault.com/questions/649629/how-to-use-varnish-cache-with-set-cookie-named-mp3list-and-phpsessionid)  
20. Understanding Varnish Cache Memory Usage - Resources, accessed December 11, 2025, [https://info.varnish-software.com/blog/understanding-varnish-cache-memory-usage](https://info.varnish-software.com/blog/understanding-varnish-cache-memory-usage)  
21. Reduce concurrency when using glibc-based Linux without jemalloc to help prevent memory fragmentation · Issue #2607 · lovell/sharp - GitHub, accessed December 11, 2025, [https://github.com/lovell/sharp/issues/2607](https://github.com/lovell/sharp/issues/2607)  
22. Achieving a high cache hit rate with Varnish - Resources, accessed December 11, 2025, [https://info.varnish-software.com/blog/high-hit-rate-with-varnish](https://info.varnish-software.com/blog/high-hit-rate-with-varnish)  
23. How glibc Memory Handling Affects Java Applications: The Hidden Cost of Fragmentation | by Daniyal Hassan | Medium, accessed December 11, 2025, [https://medium.com/@daniyal.hass/how-glibc-memory-handling-affects-java-applications-the-hidden-cost-of-fragmentation-8e666ee6e000](https://medium.com/@daniyal.hass/how-glibc-memory-handling-affects-java-applications-the-hidden-cost-of-fragmentation-8e666ee6e000)  
24. Why does the default glibc allocator have relatively poor performance? (What mak... | Hacker News, accessed December 11, 2025, [https://news.ycombinator.com/item?id=8612645](https://news.ycombinator.com/item?id=8612645)  
25. Improve Performance with 64K Memory Pages on AWS Graviton Processors, accessed December 11, 2025, [https://dev.to/aws-builders/improve-performance-with-64k-memory-pages-on-aws-graviton-processors-ifa](https://dev.to/aws-builders/improve-performance-with-64k-memory-pages-on-aws-graviton-processors-ifa)  
26. Package support statements - Amazon Linux 2023, accessed December 11, 2025, [https://docs.aws.amazon.com/linux/al2023/release-notes/support-info-by-support-statement.html](https://docs.aws.amazon.com/linux/al2023/release-notes/support-info-by-support-statement.html)  
27. CPU and memory usage of jemalloc as compared to glibc malloc - Stack Overflow, accessed December 11, 2025, [https://stackoverflow.com/questions/13027475/cpu-and-memory-usage-of-jemalloc-as-compared-to-glibc-malloc](https://stackoverflow.com/questions/13027475/cpu-and-memory-usage-of-jemalloc-as-compared-to-glibc-malloc)  
28. Varnish 6 LTS /w CentOS 8 not respecting memory limits? - Stack Overflow, accessed December 11, 2025, [https://stackoverflow.com/questions/65450044/varnish-6-lts-w-centos-8-not-respecting-memory-limits](https://stackoverflow.com/questions/65450044/varnish-6-lts-w-centos-8-not-respecting-memory-limits)  
29. Handling native memory fragmentation of glibc - Brice Dutheil, accessed December 11, 2025, [https://blog.arkey.fr/drafts/2021/01/22/native-memory-fragmentation-with-glibc/](https://blog.arkey.fr/drafts/2021/01/22/native-memory-fragmentation-with-glibc/)  
30. 1545539 – jemalloc(aarch64): munmap - Invalid Argument - build-time pagesize 4k != Fedora kernel (64k) - Red Hat Bugzilla, accessed December 11, 2025, [https://bugzilla.redhat.com/show_bug.cgi?id=1545539](https://bugzilla.redhat.com/show_bug.cgi?id=1545539)  
31. Varnish crashes on bigger files - cache - Server Fault, accessed December 11, 2025, [https://serverfault.com/questions/1031656/varnish-crashes-on-bigger-files](https://serverfault.com/questions/1031656/varnish-crashes-on-bigger-files)  
32. Stripping out select querystring attribute/value pairs so varnish will not vary cache by them, accessed December 11, 2025, [https://stackoverflow.com/questions/13144172/stripping-out-select-querystring-attribute-value-pairs-so-varnish-will-not-vary](https://stackoverflow.com/questions/13144172/stripping-out-select-querystring-attribute-value-pairs-so-varnish-will-not-vary)  
33. varnish-counters — Varnish version trunk documentation, accessed December 11, 2025, [https://varnish-cache.org/docs/trunk/reference/varnish-counters.html](https://varnish-cache.org/docs/trunk/reference/varnish-counters.html)  
34. Achieving a high hitrate — Varnish version 7.4.3 documentation, accessed December 11, 2025, [https://varnish-cache.org/docs/7.4/users-guide/increasing-your-hitrate.html](https://varnish-cache.org/docs/7.4/users-guide/increasing-your-hitrate.html)  
35. Stripping query strings in Varnish | Acquia Product Documentation, accessed December 11, 2025, [https://docs.acquia.com/acquia-cloud-platform/stripping-query-strings-varnish](https://docs.acquia.com/acquia-cloud-platform/stripping-query-strings-varnish)  
36. What are the commands to get top MISSES and HITS from Varnish 4? - Server Fault, accessed December 11, 2025, [https://serverfault.com/questions/649268/what-are-the-commands-to-get-top-misses-and-hits-from-varnish-4](https://serverfault.com/questions/649268/what-are-the-commands-to-get-top-misses-and-hits-from-varnish-4)  
37. 10 Varnish Cache mistakes and how to avoid them, accessed December 11, 2025, [https://varnish-software.medium.com/10-varnish-cache-mistakes-and-how-to-avoid-them-d240f452ab35](https://varnish-software.medium.com/10-varnish-cache-mistakes-and-how-to-avoid-them-d240f452ab35)  
38. Two-Minute Tech Tuesdays - Transit Buffer - Resources - Varnish Software, accessed December 11, 2025, [https://info.varnish-software.com/blog/two-minute-tech-tuesdays-transit-buffer](https://info.varnish-software.com/blog/two-minute-tech-tuesdays-transit-buffer)  
39. AWS Graviton Performance Testing: Tips for Independent Software Vendors - AWS Whitepaper - AWS Documentation, accessed December 11, 2025, [https://docs.aws.amazon.com/pdfs/whitepapers/latest/aws-graviton-performance-testing/aws-graviton-performance-testing.pdf](https://docs.aws.amazon.com/pdfs/whitepapers/latest/aws-graviton-performance-testing/aws-graviton-performance-testing.pdf)  
40. Changelog - Varnish Enterprise, accessed December 11, 2025, [https://docs.varnish-software.com/varnish-enterprise/changelog/](https://docs.varnish-software.com/varnish-enterprise/changelog/)