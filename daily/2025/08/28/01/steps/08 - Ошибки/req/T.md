# 1.
## 1.1.
`Aᨀ` ≔ (мой ответ `ꆜ`)

## 1.2.
Содержание `Aᨀ`:
~~~markdown
1) Стратегическая задача, которую вам поручил работодатель — диагностика проблем прошлых запусков ваших pipelines.
Ваше первое возможное заблуждение: попытка провести эту диагностику новым запуском pipeline.
На самом же деле, новый запуск не является первоочередным способом понять, почему конвейеры не работали в прошлом.
Вместо этого в первую очередь следует изучить журналы выполнения прошлых запусков:
1.1) Перейти в Azure Data Factory Studio.
1.2) Открыть вкладку «Monitor» на левой боковой панели.
1.3) В разделе «Pipeline runs» изучить список предыдущих выполнений целевого конвейера.
Использовать фильтры по имени конвейера («Pipeline name») и статусу (Status, например, «Failed»), чтобы найти интересующие запуски.
Убедиться, что анализируются запуски типа «Triggered».
Запуски типа «Triggered» являются производственными запусками и всегда используют ту версию конвейера, которая была опубликована (Published) в службе Azure Data Factory на момент запуска.
Запуски типа «Debug» используют текущую версию конвейера на холсте разработки («Author» canvas), которая может отличаться от опубликованной версии.
1.4) Проанализировать детали сбойного запуска.
1.4.1) Кликнуть на имя конвейера в списке, чтобы перейти к списку «Activity runs» (выполнения действий).
1.4.2) Идентифицировать действие (activity), которое завершилось сбоем.
1.4.3) Изучить детальное сообщение об ошибке. 
Для этого кликнуть на иконку в колонке «Error» для этого activity.
1.4.4) Изучить входные параметры, которые были использованы при этом запуске.
Для этого найти колонку «Parameters» (на уровне Pipeline run или в верхней части экрана Activity runs) и посмотреть значения, которые были фактически переданы в конвейер.
1.5) Проанализировать снимок (Snapshot) конфигурации конвейера, использованный во время сбойного запуска.
Цель: Увидеть точную конфигурацию и код, которые привели к сбою, так как текущая версия конвейера может отличаться.
1.5.1) Находясь в представлении «Activity runs» (п. 1.4.1), найти возможность просмотра кода конвейера.
Обычно это иконка с всплывающей подсказкой «Code» (в виде фигурных скобок), расположенная на верхней панели рядом с названием конвейера.
1.5.2) Изучить JSON-определение (JSON definition) конвейера и связанных ресурсов (e.g., Datasets) в том виде, в котором они существовали на момент этого конкретного запуска.
2) Ваше второе возможное заблуждение: вы ищете причину сбоя работы pipeline только внутри него.
На самом же деле, значительная часть сбоев pipeline связана с внешниими причинами: инфраструктурой и безопасностью, особенно в унаследованных средах.
В частности:
- Аутентификация и Авторизация: истекшие учетные данные или ключи в Linked Services, некорректная настройка Managed Identity, отсутствие доступа к Azure Key Vault или целевым хранилищам.
- Сетевые проблемы: конфигурация брандмауэров (Azure Storage, SQL DB), VNet, Private Endpoints, блокирующие доступ.
- Integration Runtime (IR): проблемы с доступностью, конфигурацией или производительностью Self-Hosted IR.

Игнорирование внешних факторов является критической ошибкой при диагностике сбоев в ADF.
Поэтому нужно провести диагностику этих внешних факторов:
2.1) Перейти на вкладку «Manage» на левой боковой панели.
2.2) Проверить Linked Services:
2.2.1) Перейти в раздел «Linked services».
2.2.2) Идентифицировать все Linked Services, используемые в целевом конвейере (их можно найти в настройках Datasets или Activities).
2.2.3) Для каждого Linked Service открыть его конфигурацию и использовать функцию «Test connection».
Это позволит проверить базовую возможность подключения к ресурсу из соответствующего Integration Runtime.
Важное примечание:
Функция «Test connection» выполняется не в контексте вашей учетной записи пользователя.
Она выполняется на инфраструктуре Integration Runtime (Azure IR или Self-Hosted IR), указанного в Linked Service.
Она использует учетные данные, определенные в конфигурации Linked Service (e.g., Managed Identity, Service Principal, Account Key).
Источник: Microsoft Learn: Integration runtime in Azure Data Factory.
Успешный «Test connection» не гарантирует работоспособность во время выполнения pipeline (Pipeline run) по следующим причинам:
2.2.3.1) Сетевые различия.
Могут существовать различия в сетевой конфигурации между интерактивным тестированием и автоматическим выполнением.
Это особенно актуально при использовании Self-Hosted IR, Virtual Networks (VNet) или Private Endpoints.
Правила брандмауэров (Firewall rules), Network Security Groups (NSG) или маршрутизация могут отличаться, блокируя доступ во время выполнения.
2.2.3.2) Недостаточные разрешения.
Успешный тест проверяет только возможность аутентификации и сетевого подключения.
Он не гарантирует наличие разрешений для выполнения конкретных операций с данными (e.g., чтение таблицы, выполнение Stored Procedure), требуемых в Pipeline (см. пункт 2.2.5).
2.2.4) Определить метод аутентификации (Authentication method), используемый в Linked Service (например, System-Assigned Managed Identity, Service Principal, Account Key, SQL Authentication).
2.2.5) Верифицировать права доступа субъекта безопасности ADF.
Необходимо проверить разрешения на двух различных уровнях, так как успешная аутентификация не означает наличие необходимой авторизации для доступа к данным.
2.2.5.1) Уровень Azure RBAC (Role-Based Access Control).
Если используется Managed Identity или Service Principal, необходимо убедиться, что этому субъекту назначены необходимые роли Azure RBAC для доступа к данным (Data Plane) на целевом ресурсе.
E.g., роль «Storage Blob Data Contributor» для Azure Storage.
Эта проверка выполняется вне ADF Studio, в настройках «Access Control (IAM)» целевого ресурса на портале Azure.
2.2.5.2) Уровень внутренних разрешений целевой системы (Data Store Permissions).
Для многих систем (e.g., Azure SQL Database, Azure Synapse Analytics) Azure RBAC не управляет доступом к объектам внутри базы данных.
Необходимо убедиться, что субъект безопасности имеет необходимые разрешения внутри целевой системы.
Субъект безопасности должен быть добавлен как пользователь базы данных (database user).
Этому пользователю должны быть назначены соответствующие роли базы данных (e.g., `db_datareader`, `db_datawriter`).
Если pipeline выполняет Stored Procedures, пользователю также требуется разрешение `EXECUTE`.
Источник: Microsoft Learn: Tutorial: Secure a database in Azure SQL Database.
Эта проверка выполняется путем подключения к базе данных с использованием инструментов управления (e.g., SQL Server Management Studio (SSMS) или Azure Data Studio).
2.3) Проверить Integration Runtimes:
2.3.1) Перейти в раздел «Integration runtimes».
2.3.2) Проверить статус Integration Runtimes, используемых в Linked Services. 
Убедиться, что они находятся в состоянии «Running», особенно если используются Self-Hosted Integration Runtimes.
2.4) Синтез результатов диагностики и определение причин исторических сбоев.
Цель: Выполнить вашу стратегическую задачу — определить, почему конвейеры не работали в прошлом, на основе собранных данных.
2.4.1) Сопоставить детальные сообщения об ошибках (п. 1.4.3) с результатами проверки среды (п. 2.2 и 2.3).
Детальные сообщения об ошибках из исторических запусков (п. 1.4.3) являются первичным источником для диагностики прошлых сбоев.
Необходимо учитывать временной контекст при интерпретации результатов текущей проверки среды.
Результаты «Test connection» (п. 2.2.3) или статуса IR (п. 2.3.2) отражают текущее состояние системы.
Это состояние могло измениться с момента исторического сбоя (e.g., обновление истекших учетных данных, изменение сетевых правил).
Нельзя полагаться исключительно на текущее состояние для диагностики прошлых проблем.
2.4.1.1) Если историческая ошибка указывает на проблемы с подключением (e.g., «Authentication failed», «Connection timed out»), и текущий «Test connection» (п. 2.2.3) также завершается неудачей, вероятно, существует постоянная проблема конфигурации инфраструктуры или безопасности.
2.4.1.2) Если историческая ошибка указывает на проблемы с подключением, но текущий «Test connection» (п. 2.2.3) успешен, это может указывать на то, что проблема была временной (e.g., таймаут сети, недоступность ресурса) или что конфигурация среды была исправлена с момента сбоя.
2.4.2) Проанализировать входные параметры, использованные при сбойных запусках (п. 1.4.4). Определить, могли ли сбои быть вызваны некорректными или неожиданными данными, переданными в конвейер (например, неверный формат даты, несуществующий путь).
2.4.3) Идентифицировать паттерны сбоев. 
Являются ли сбои постоянными (часто указывает на проблему конфигурации или доступа) или периодическими/случайными (часто указывает на проблемы производительности, блокировки ресурсов или зависимость от специфических данных).
2.4.4) Сформулировать выводы о корневой причине (Root Cause) исторических сбоев и классифицировать её (например: аутентификация, сеть, логика конвейера, качество данных).
3) После завершения диагностики исторических сбоев (п. 1-2), для понимания логики работы конвейера и его запуска необходимо идентифицировать и проанализировать Pipeline Parameters.
3.1) Определить конфигурацию Source Control.
Цель: Понять, как управляются версии кода (versioning) и как соотносятся версия на холсте («Author» canvas) и опубликованная (Published) версия.
Источник: Microsoft Learn: Source control in Azure Data Factory.
3.1.1) Перейти на вкладку «Manage» на левой боковой панели.
3.1.2) Перейти в раздел «Source control» → «Git configuration» или проверить наличие элементов управления Git (e.g., селектор веток) на верхней панели ADF Studio.
3.1.3) Определить режим работы ADF.
3.1.3.1) `Live Mode`: Если интеграция с Git не настроена (authoring directly against the data factory service).
В этом режиме изменения на холсте («Author» canvas) не сохраняются в постоянном репозитории до момента публикации через кнопку «Publish All».
Опубликованная версия является версией, используемой в «Triggered» runs.
3.1.3.2) `Git Mode` (e.g., Azure DevOps Git или GitHub): Если конфигурация указывает на репозиторий.
В этом режиме изменения на холсте («Author» canvas) сохраняются в выбранной ветке Git (e.g., feature branch) с помощью «Save» или «Save all».
Эти изменения не применяются к производственной службе (и не используются в «Triggered» runs) до момента публикации («Publish») из Collaboration branch.
3.2) Перейти на вкладку «Author» на левой боковой панели для анализа текущей разрабатываемой версии конвейера.
3.2.1) Если фабрика работает в `Git Mode` (п. 3.1.3.2), убедиться, что в селекторе веток выбрана корректная ветка для анализа (обычно Collaboration branch или актуальная feature branch).
3.2.2) Если фабрика работает в `Live Mode` (п. 3.1.3.1), проверить наличие индикатора неопубликованных изменений (e.g., активность кнопки «Publish All»).
3.3) Найти и открыть целевой конвейер.
Важное примечание: Необходимо учитывать, что эта версия на холсте может отличаться от опубликованной версии, которая анализировалась в Разделе 1 (Snapshot из п. 1.5).
3.4) Кликнуть на пустую область холста (canvas) конвейера, чтобы отобразить его общие настройки.
3.5) Перейти на вкладку «Parameters». 
Составить список всех параметров, зафиксировав их «Name», «Type» (например, `String`, `Int`, `Array`, `Object`, `SecureString`) и «Default value» (значение по умолчанию), если оно указано.
Знание типа данных критично, особенно для сложных типов (`Array`, `Object`).
Источник: Microsoft Learn: Parameters and variables in Azure Data Factory.
3.6) Изучить, как параметры используются внутри конвейера.
3.6.1) Выбрать каждое activity на холсте (например, Copy activity, Lookup, Data Flow).
3.6.2) Проверить вкладки настроек (например, «Settings», «Source», «Sink») на предмет использования динамического содержимого (dynamic content).
3.6.3) Идентифицировать выражения (expressions), которые ссылаются на параметры конвейера, используя синтаксис `@pipeline().parameters.<parameterName>`.
3.7) Сравнить текущую версию конвейера со снимком исторического запуска.
Цель: Идентифицировать расхождения между кодом, который вызвал сбой, и кодом, доступным для анализа и тестирования.
3.7.1) Получить JSON-представление текущей версии конвейера.
Для этого использовать кнопку «Code» (в виде фигурных скобок) на верхней панели вкладки «Author».
3.7.2) Сопоставить это JSON-представление с JSON-конфигурацией из снимка исторического запуска (п. 1.5.2).
3.7.3) Идентифицировать любые различия в логике, структуре, expressions или конфигурации activities и parameters.
3.7.4) Если различия существуют, дальнейший анализ логики (п. 3.6) и тестовый запуск (Раздел 6) должны учитывать эти различия.
4) Затем нужно определить Parameter Sources
Цель: Определить, как конвейер получает параметры в производственной среде (через Triggers или от родительского конвейера через `Execute Pipeline` activity), чтобы эмулировать эти значения при ручном тестировании.
4.1.1) Находясь в редакторе конвейера (вкладка «Author»), нажать кнопку «Trigger» на верхней панели и выбрать «New/Edit».
4.1.2) В открывшейся панели изучить конфигурацию существующих триггеров, связанных с этим конвейером.
4.2) Изучить параметры, передаваемые триггером.
4.2.1) Продвигаясь по конфигурации триггера, обратить внимание на шаг, где заполняются параметры конвейера.
4.2.2) Идентифицировать использование системных переменных (System Variables). 
Это выражения, начинающиеся с `@trigger()` или `@triggerBody()`. 
Примеры:
- `@trigger().outputs.windowStartTime` (для Tumbling Window Trigger).
- `@triggerBody().fileName` (для Storage Event Trigger).

Производственные конвейеры часто получают метаданные (например, временные метки или имена файлов) автоматически от триггеров через System Variables. 
При ручном тестировании (Debug) пользователь должен эмулировать эти значения самостоятельно. 
Незнание этой зависимости является частой причиной проблем с ручным запуском.
4.3) Проанализировать родительские конвейеры (Parent Pipelines) и `Execute Pipeline` activity.
Цель: Определить, вызывается ли целевой конвейер другим конвейером и какие параметры при этом передаются.
Источник: Microsoft Learn: Execute Pipeline activity in Azure Data Factory and Azure Synapse Analytics.
4.3.1) Идентифицировать Parent Pipelines.
4.3.1.1) Находясь в редакторе целевого конвейера (вкладка «Author»), открыть панель свойств конвейера (иконка «Properties»).
4.3.1.2) Перейти на вкладку «Related».
4.3.1.3) В разделе «Pipelines» изучить список конвейеров, которые ссылаются на текущий (используют `Execute Pipeline` activity для его вызова).
4.3.1.4) В качестве альтернативы или для перепроверки использовать глобальный поиск (Global Search) в Azure Data Factory Studio по имени целевого конвейера.
4.3.2) Изучить конфигурацию `Execute Pipeline` activity в Parent Pipeline.
Для каждого Parent Pipeline, идентифицированного в п. 4.3.1:
4.3.2.1) Открыть Parent Pipeline на вкладке «Author».
4.3.2.2) Найти `Execute Pipeline` activity, которое вызывает целевой конвейер.
4.3.2.3) Выбрать это activity и перейти на вкладку «Settings».
4.3.2.4) В разделе «Parameters» изучить, какие значения или выражения (dynamic content) передаются в параметры целевого конвейера.
4.3.3) Определить источники значений в Parent Pipeline.
Значения могут быть статическими, производными от параметров Parent Pipeline (e.g., `@pipeline().parameters.<ParentParameterName>`), переменных (variables) или выходов (Outputs) предыдущих activities (e.g., `@activity('<ActivityName>').output.<PropertyName>`).
4.4) Определить значения для тестирования.
Использовать комбинацию значений из исторических запусков (пункт 1.4.4 выше), значений по умолчанию (пункт 3.5), эмулированных значений триггеров (пункт 4.2.2) и значений, передаваемых из Parent Pipelines (пункт 4.3.3) для формирования набора тестовых входных данных.
5) Обеспечение безопасности тестового запуска (Safety Check)
Цель: Предотвратить случайное повреждение, модификацию, удаление или дублирование производственных данных при запуске унаследованного конвейера.
Обоснование: 
Запуск конвейера без полного понимания его логики и конфигурации приемников данных (Sinks) несет критические риски для целостности данных.
5.0) Активировать сессию «Data Flow Debug» (если применимо).
Цель: Обеспечить среду выполнения Spark для `Data Flow` activities во время отладки и интерактивного анализа.
5.0.1) Определить, содержит ли конвейер действия типа `Data Flow activity`.
5.0.2) Если `Data Flow activity` присутствуют, для их выполнения в режиме «Debug» (Раздел 6) или использования «Data Preview» (п. 5.3.2.1) требуется активная сессия отладки.
Источник: Microsoft Learn: Mapping data flow Debug Mode.
5.0.3) На верхней панели инструментов (toolbar) ADF Studio активировать переключатель «Data Flow Debug».
5.0.4) Выбрать конфигурацию `Integration Runtime` и установить `Time to live` (TTL).
5.0.5) Дождаться готовности кластера (индикатор статуса станет зеленым).
Запуск кластера (cold boot) может занять несколько минут.
5.1) Идентифицировать операции модификации данных и приемники (Sinks).
Проанализировать все действия (Activities) в конвейере, которые потенциально могут изменять данные во внешних системах:
5.1.1) `Copy activity` (изучить вкладку «Sink»).
5.1.2) `Data Flow` (изучить все Sinks внутри потока данных).
5.1.3) `Stored Procedure activity` и `Script activity` (могут выполнять DML/DDL операции: INSERT, UPDATE, DELETE, TRUNCATE).
5.1.4) `Delete activity`.
5.1.5) `Web`, `Webhook`, `Custom activities` (если они вызывают API для модификации данных).

5.2) Проанализировать целевые системы.
Для каждого действия из п. 5.1 определить, куда именно будут записываться или где будут удаляться данные.
 Изучить конфигурацию целевых Datasets и Linked Services. 
Определить, указывают ли они на производственные (Production) системы.

5.3) Применить стратегию безопасного запуска.
Если конвейер может повлиять на производственные данные, необходимо применить одну или несколько мер безопасности. 
Методы приведены в порядке предпочтения.

5.3.1) Стратегия 1: Перенаправление записи в безопасное место (Наиболее надежный метод).
5.3.1.1) Через параметры: Если конфигурация приемника (путь, имя таблицы, строка подключения) параметризована (см. п. 3.6), убедиться, что при запуске (п. 6.2) будут использованы значения, указывающие на тестовую среду (например, папка "test", схема "dev").
5.3.1.2) Через временное изменение конфигурации: Если параметры не используются, временно изменить настройки Datasets или Linked Services, чтобы они указывали на тестовую среду. 
Важно: Не сохранять и не публиковать (Publish) эти изменения.

5.3.2) Стратегия 2: Использование механизмов изоляции и контроля.
5.3.2.1) Для `Data Flow` activities: Использовать «Data Preview» для инспекции данных.
(Требует активной сессии «Data Flow Debug», см. п. 5.0).
В редакторе `Data Flow` выбрать transformation, непосредственно предшествующую `Sink`.
Перейти на вкладку «Data Preview» и нажать «Refresh», чтобы получить интерактивный снимок (interactive snapshot) данных.
Важное примечание:
При запуске `Data Flow` в режиме «Debug Mode» данные по умолчанию не записываются в `Sink` transform.
Сессия отладки предназначена служить в качестве тестового стенда (test harness).
Источник: Microsoft Learn: Mapping data flow Debug Mode (Data preview).
5.3.2.2) Для Activities на холсте: Использовать точки останова (Breakpoints) для итеративной отладки (Iterative Debugging).
Установить точку останова на действии (activity), перед выполнением которого необходимо приостановить конвейер.
Для этого кликнуть на пустой красный кружок в правом верхнем углу activity (опция «Debug Until»).
Кружок изменится на заполненный красный кружок (filled red circle).
При запуске в режиме «Debug» (Раздел 6) конвейер выполнится только до activity с точкой останова.
Само activity с точкой останова (breakpoint activity) не включается в тестовый запуск.
Источник: Microsoft Learn: Iterative development and debugging (Setting breakpoints).
Это позволяет проверить промежуточные результаты и входные данные (Input) предшествующих действий перед выполнением потенциально опасных операций.
5.3.2.3) Деактивация действий: Если анализ записи данных не является целью теста, временно деактивировать (кнопка «Deactivate» на верхней панели) действия, выполняющие модификацию.

5.3.3) Стратегия 3: Минимизация воздействия (Использовать с осторожностью).
5.3.3.1) Ограничение объема данных.
Применить методы ограничения количества обрабатываемых строк, специфичные для типа действия.
5.3.3.1.1) Для `Data Flow` activities: Открыть «Debug Settings» на панели инструментов холста `Data Flow`.
Установить «Row limit» на малое значение (e.g., 100-1000).
Эта настройка ограничивает количество строк, считываемых из источников (`Sources`) только для текущей debug session.
(Требует активной сессии «Data Flow Debug», см. п. 5.0).
Источник: Microsoft Learn: Mapping data flow Debug Mode (Debug settings).
5.3.3.1.2) Для `Copy activity` и `Lookup activity`: Настройка «Row limit» из п. 5.3.3.1.1 не применяется.
Необходимо временно модифицировать конфигурацию источника (Source).
E.g., если источником является база данных SQL, модифицировать запрос (Query), добавив `TOP N` или `LIMIT` (e.g., `SELECT TOP 100 * FROM schema.table`).
Предупреждение:
Ограничение объема данных ограничивает чтение из источника, но не обеспечивает полной безопасности, если конвейер выполняет операции, не зависящие от объема данных (e.g., `TRUNCATE TABLE` через «Pre-copy script» или удаление файлов через `Delete activity`).

5.4) Условие отмены запуска (Go/No-Go Decision).
Если ни один из методов п. 5.3 не может гарантировать безопасность производственных данных, не выполнять запуск (раздел 6). 
В этом случае требуется клонирование (Clone) и модификация конвейера для тестирования в изолированной среде.

6) Выполнить тестовый запуск (Test Run)
Цель: Запустить конвейер с корректными параметрами в контролируемом режиме и проверить его работоспособность.
6.1) Находясь на вкладке «Author» в редакторе целевого конвейера, выбрать стратегию запуска и начать выполнение в режиме отладки («Debug»).
Обоснование:
Режим «Debug» используется для тестирования текущей версии конвейера на холсте (включая неопубликованные изменения) и позволяет наблюдать за выполнением в реальном времени без необходимости публикации (Publish).
6.1.1) Выбор стратегии: Итеративная отладка (Iterative Debugging) или Полный запуск.
Для сложных или унаследованных конвейеров рекомендуется использовать итеративную отладку для пошагового и более безопасного анализа.
6.1.2) Для итеративной отладки («Debug Until»): Убедиться, что установлены точки останова (Breakpoints) (см. п. 5.3.2.2).
Нажать кнопку «Debug».
Конвейер выполнится только до первого activity с точкой останова.
6.1.3) Для полного запуска: Убедиться, что точки останова не установлены (или будут проигнорированы, если требуется выполнить конвейер целиком несмотря на них).
Нажать кнопку «Debug».
6.2) В открывшейся панели (обычно называется «Pipeline Debug» или «Pipeline run parameters») ввести значения для параметров, определённые на пункте 4.4 выше.
6.3) Соблюдать корректный формат ввода данных:
6.3.1) При эмуляции временных меток триггера использовать формат ISO 8601 (например, `2025-08-27T10:00:00Z`).
6.3.2) Для параметров типа `Array` ввести значение в формате JSON массива. 
Например: `["item1", "item2"]`.
6.3.3. Для параметров типа Object ввести значение в формате JSON объекта. 
Например: `{"key1": "value1", "key2": "value2"}`.
Обоснование: Корректный ввод параметров, особенно сложных типов (`Array`, `Object`), необходим для успешного запуска. 
Неправильный формат JSON приведет к ошибкам валидации еще до начала выполнения.
6.4) Нажать «OK», чтобы начать выполнение.
6.5) Наблюдать за ходом выполнения на вкладке «Output» под холстом конвейера. 
Проверить входные (Input) и выходные (Output) данные для каждого Activity после его завершения, чтобы убедиться, что параметры были интерпретированы корректно.
~~~

# 2. `᛭T`
Проанализируй `Aᨀ`:
1) Есть ли там логические ошибки?
2) Есть ли там фактические ошибки?
3) Упущено ли в `Aᨀ` нечто важное?

# 3. Требования к твоему ответу
## 3.1.
Отвечай на русском языке.
## 3.2.
Мой вопрос не пересказывай.
## 3.3.
Уже сформулированную мной информацию не пересказывай.
## 3.4.
Писать свою версию `Aᨀ` не нужно: просто укажи свои замечания по пунктам.
## 3.5.
До и после списка замечаний ничего не пиши.
## 3.6.
Нумерация замечаний должна быть сквозной.