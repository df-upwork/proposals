https://gemini.google.com/share/190e9fecf894

## **1. Контекстуальный анализ и декомпозиция технического ландшафта (᛭T)**

В рамках задачи ᛭T был проведен всесторонний аудит архитектурных требований и ограничений проекта P⁎. Проект представляет собой критически важную инициативу по созданию слоя ежедневной аналитики ("daily stats layer") для агрегации действий пользователей (клики, сохранения, пропуски, просмотры). Текущее состояние экосистемы клиента ꆜ характеризуется гибридной архитектурой, включающей фронтенд на React (P1⁎) и бэкенд на платформе No-Code Bubble.io (P4⁎, S༄), что создает специфический набор вызовов, связанных с интеграцией, консистентностью данных и производительностью.

Детальный анализ онтологии проекта ᛭O выявил, что клиент ꆜ обладает высокой технической грамотностью, о чем свидетельствует точная формулировка проблем: страх перед блокировкой ввода-вывода ("heavy IO load") и понимание ограничений репликации ("limit built in replication support"). Эти опасения, обозначенные как P1† и P2†, являются не просто гипотетическими рисками, а фундаментальными архитектурными барьерами, присущими выбранному технологическому стеку.

Целью данного отчета является не только подтверждение или опровержение опасений клиента, но и предоставление исчерпывающей доказательной базы, опирающейся на техническую документацию, бенчмарки и опыт инженерного сообщества, а также разработка архитектурной стратегии, гарантирующей точность ("accurate"), возможность перезапуска ("rerunnable") и низкие эксплуатационные расходы ("low maintenance").

### **1.1. Профиль нагрузки и природа данных**

Для понимания масштаба проблем P1† и P2† необходимо квалифицировать характер данных, с которыми предстоит работать системе. "User actions" (клики, просмотры) относятся к категории событийных данных (Time-Series / Event Streams).

* **Высокая кардинальность и объем:** В отличие от транзакционных данных (профили пользователей, заказы), событийные данные генерируются на порядки быстрее. Если один пользователь создает 1 заказ в месяц, он может генерировать 50-100 событий "просмотра" или "клика" за одну сессию.  
* **Неизменяемость (Immutability):** События, как правило, не изменяются после записи. Это упрощает некоторые аспекты хранения, но требует специфических подходов к агрегации, отличных от стандартных CRUD-операций, оптимизированных в Bubble.  
* **Требования к задержке (Latency):** Клиент запрашивает "daily analytics", что подразумевает пакетную обработку (Batch Processing), однако сбор данных должен происходить в режиме, близком к реальному времени, чтобы избежать потери событий при сбоях на клиенте.

### **1.2. Идентификация и классификация выявленных проблем**

В ходе декомпозиции описания проекта (PD) и сопутствующих материалов были выделены следующие классы проблем, требующих детального анализа:

1. **Проблема P1† (Ограничения репликации):** Риск невозможность извлечения данных из операционной базы Bubble с достаточной скоростью и надежностью для внешнего анализа. Это проблема **Data Gravity** (притяжения данных) — данные легко поместить в PaaS-систему, но крайне сложно извлечь в сыром виде.  
2. **Проблема P2† (Производительность IO):** Риск деградации производительности основного приложения при выполнении аналитических запросов внутри той же базы данных. Это проблема **Resource Contention** (конкуренции за ресурсы) между OLTP (транзакции пользователей) и OLAP (аналитические расчеты) нагрузками.  
3. **Скрытая проблема P3† (Масштабируемость структур данных):** Ограничения Bubble на размеры списков и массивов, которые делают "наивную" архитектуру физически нереализуемой при росте данных.  
4. **Скрытая проблема P4† (Идемпотентность и целостность):** Обеспечение точности данных при сбоях и перезапусках (Duplicate execution protection), что критично для финансовой или поведенческой аналитики.

## ---

**2. Глубокий аудит проблемы P1†: Ограничения репликации данных в PaaS-средах (᛭T-2)**

Проблема P1†, сформулированная клиентом как "our current setup may limit built in replication support", является **абсолютно обоснованной** и представляет собой ключевой архитектурный риск. В данном разделе проводится техническая вивисекция механизмов хранения данных Bubble.io для демонстрации физической невозможности стандартной репликации.

### **2.1. Природа "Walled Garden" и отсутствие доступа к WAL**

В классической архитектуре баз данных (например, PostgreSQL, MySQL) "золотым стандартом" для построения аналитических хранилищ является физическая или логическая репликация.

* **Механизм:** База данных пишет все изменения в журнал предзаписи (Write-Ahead Log, WAL). Реплика (Replica) подключается к мастеру и читает этот поток изменений в реальном времени. Это позволяет создать точную копию данных с минимальной нагрузкой на мастер.  
* **Ситуация в Bubble:** Исследование технических форумов и документации 1 подтверждает, что Bubble использует PostgreSQL "под капотом". Однако, архитектура платформы является многопользовательской (Multi-tenant). Тысячи приложений могут делить один кластер базы данных.  
  * **Блокировка доступа:** Предоставление прямого доступа к WAL или слотам репликации (Replication Slots) невозможно из соображений безопасности, так как это дало бы доступ к данным других клиентов ("noisy neighbors").  
  * **Следствие:** Клиент ꆜ физически лишен доступа к низкоуровневым механизмам синхронизации. Единственным "окном" в данные остается прикладной уровень (Application Layer) через API или встроенные коннекторы.

![][image1]

### **2.2. Анализ альтернативы "API Polling" и её несостоятельность**

Поскольку прямая репликация невозможна, часто рассматривается вариант периодического опроса API (Polling) для выгрузки новых данных. Анализ источников выявляет критические недостатки этого метода для задачи T⁎ (ежедневная аналитика):

#### **2.2.1. Алгоритмическая сложность пагинации**

Data API Bubble использует стандартную пагинацию (limit/offset или cursor). Для выгрузки 100,000 событий, накопившихся за день, системе потребуется выполнить серию запросов.

* **Проблема Offset:** В PostgreSQL (и других RDBMS) запрос OFFSET 50000 LIMIT 100 требует от базы данных прочитать 50,100 строк, отбросить первые 50,000 и вернуть последние 100. Чем "глубже" мы уходим в историю событий, тем медленнее работает каждый следующий запрос. Это создает нагрузку $O(N^2)$ при полной выгрузке таблицы, что катастрофически сказывается на производительности при больших объемах данных.3

#### **2.2.2. Rate Limiting и исчерпание квот**

Согласно документации 1, Bubble накладывает жесткие лимиты на количество запросов к API.

* **Тариф Starter:** 15,000 запросов в минуту (совокупно для Workflow API и Data API).  
* Тариф Growth: 25,000 запросов.  
  Хотя эти цифры кажутся большими, реальная пропускная способность ограничивается временем обработки каждого запроса на стороне сервера (server-side processing time). Тяжелые запросы на чтение данных с фильтрацией могут потреблять значительную долю "Capacity", что приведет к тайм-аутам (код 503) задолго до достижения лимита по количеству запросов.

#### **2.2.3. Нарушение целостности данных (Consistency)**

При выгрузке данных страницами через API (особенно если процесс занимает минуты или часы) невозможно гарантировать "Snapshot Isolation". Если во время выгрузки 50-й страницы пользователь добавит новое событие, которое должно было попасть на 1-ю страницу (из-за сортировки), это событие может быть пропущено или привести к сдвигу смещения, вызывая дублирование данных. Это прямо противоречит требованию клиента о точности ("The job must be accurate").

### **2.3. Ограничения массового экспорта (CSV)**

В качестве альтернативы O⌖1 часто предлагается использование экспорта CSV. Однако, анализ источников 4 показывает, что нативная функция экспорта в Bubble имеет серьезные ограничения:

* **Лимиты строк:** Пользователи сообщают о сбоях и тайм-аутах при попытке экспортировать более 10,000 - 50,000 строк за раз.  
* **Отсутствие автоматизации:** Нативный экспорт часто требует ручного запуска из редактора, что нарушает требование "low maintenance".  
* **Плагины:** Использование плагинов (например, "1T CSV Creator" 6) переносит нагрузку генерации файла на браузер клиента или на серверные мощности приложения (Server-Side Actions), что возвращает нас к проблеме потребления ресурсов (Capacity) и рискам P2†.

**Вывод по разделу 2:** Проблема P1† не только обоснована, но и является критическим блокирующим фактором для реализации архитектуры O⌖1 в её "наивном" виде (выгрузка из Bubble). Платформа не предоставляет инструментов для надежной и дешевой эксфильтрации больших объемов данных.

## ---

**3. Глубокий аудит проблемы P2†: Риски производительности OLAP-нагрузок (᛭T-2)**

Проблема P2† ("naive scheduled job could be intensive and create heavy IO load") касается попытки реализовать аналитику *внутри* Bubble (O⌖2). Клиент опасается, что сканирование всех сущностей "положит" продакшн.

### **3.1. Экономика Workload Units (WU) и стоимость вычислений**

С 2023 года Bubble перешел на модель тарификации на основе Workload Units (WU).8 Каждая операция с базой данных (создание, поиск, изменение) имеет свою "цену" в WU.

* **Стоимость поиска (Search):** Поиск по базе данных является одной из самых дорогих операций, особенно если он включает сложные фильтры ("Constraint") или сортировку.  
* **Стоимость агрегации:** Операции типа "Count", "Sum", выполняемые над списком результатов поиска, потребляют WU пропорционально количеству обрабатываемых записей.  
* **Сценарий клиента:** Ежедневный джоб, который должен просканировать, например, 100,000 событий для 5,000 пользователей, вызовет лавинообразный расход WU.  
  * Если стоимость обработки одной сущности составляет, скажем, 0.5 WU (оптимистичная оценка), то ежедневная обработка будет стоить 50,000 WU.  
  * В месяц это 1.5 млн WU, что может потребовать перехода на дорогостоящие тарифные планы (от $300-$500/мес и выше), делая аналитику непропорционально дорогой по сравнению с прямым доходом от клиента ($1300 total spent).

### **3.2. Алгоритмическая ловушка $O(N)$ и Recursive Workflows**

Для обработки больших списков в Bubble используется паттерн "Recursive Backend Workflows" (рекурсивные бэкенд-процессы), так как цикл Schedule API Workflow on a list имеет лимит на 100,000 элементов 1 и может работать нестабильно на больших объемах.10

Рекурсивный процесс обрабатывает одну запись (или пакет записей), а затем вызывает сам себя для следующей.

* **Преимущество:** Это позволяет избежать тайм-аута *одного* процесса.  
* **Недостаток (Риск P2†):** Такой процесс создает непрерывную фоновую нагрузку на базу данных. Если обработка занимает 3 часа, то в течение этих 3 часов база данных находится под постоянным давлением операций чтения/записи.  
* **Блокировки:** Источники 11 подтверждают, что при высокой утилизации Capacity ("app too busy") запросы от реальных пользователей начинают замедляться. Это классическая проблема конкуренции ресурсов (Resource Contention), когда аналитическая задача (низкий приоритет) мешает транзакционной задаче (высокий приоритет).

![][image2]

### **3.3. Жесткие лимиты структур данных (Скрытая проблема P3†)**

Анализ источников 1 вскрывает еще одну фундаментальную проблему, которая делает опцию O⌖2 технически несостоятельной, даже если бы ресурсов было достаточно.

* **Лимит 10,000 элементов:** Поле типа List в Bubble не может надежно хранить более 10,000 элементов.  
* **Сценарий:** Если мы попытаемся хранить список "Просмотров" (Views) прямо внутри объекта "Статья" (Article) для удобства подсчета, популярная статья исчерпает этот лимит за несколько дней или недель.  
* **Последствия:** При превышении лимита операции добавления в список начинают сбоить или замедляться до неприемлемых значений. Это вынуждает разработчика создавать отдельные таблицы-связки (join tables), что возвращает нас к проблеме медленного поиска по миллионам строк.

**Вывод по разделу 3:** Проблема P2† полностью обоснована. Внутренняя аналитика на больших объемах данных в Bubble экономически неэффективна (расход WU) и технически рискованна (блокировка IO, лимиты списков).

## ---

**4. Сравнительный анализ архитектурных паттернов решения (᛭T-2, O.md)**

На основе анализа проблем P1† и P2†, мы приходим к выводу, что ни O⌖1 (репликация постфактум), ни O⌖2 (расчет внутри) не являются оптимальными. Требуется гибридный подход. Рассмотрим детально три возможных архитектурных паттерна.

### **4.1. Паттерн А: In-App Analytics (Отвергается)**

Этот паттерн соответствует опции O⌖2.

* **Суть:** Хранение событий в Bubble, расчет Backend Workflow.  
* **Вердикт:** **Непригоден.**  
* **Причины:**  
  1. Непредсказуемая стоимость (WU).  
  2. Риск "положить" приложение (IO Load).  
  3. Лимит 10k элементов на список делает невозможной эффективную денормализацию.

### **4.2. Паттерн В: Traditional ETL / Pull (Отвергается)**

Этот паттерн соответствует опции O⌖1 в "наивной" реализации.

* **Суть:** Внешний скрипт (Python/Node.js) периодически опрашивает Bubble API, вытягивает новые события и сохраняет их в DWH.  
* **Вердикт:** **Рискован.**  
* **Причины:**  
  1. Медленно из-за пагинации.  
  2. Риск пропуска данных (Consistency issues) из-за отсутствия транзакционных снапшотов.  
  3. Высокая нагрузка на API Capacity.

### **4.3. Паттерн С: "Dual-Write" / Event Beacon (Рекомендуется)**

Это "третий путь", который обходит ограничения Bubble, изменяя точку входа данных.

* **Суть:** Поскольку у клиента есть React-фронтенд (P1⁎), события (клики, просмотры) должны отправляться **напрямую** в аналитическое хранилище, минуя базу данных Bubble.  
* **Механика:**  
  1. Пользователь совершает действие в React-приложении.  
  2. React отправляет асинхронный запрос (fire-and-forget) в API аналитической БД (например, через Next.js API Route или Serverless Function).  
  3. Параллельно критические данные (если это сохранение профиля) идут в Bubble.  
  4. Bubble используется только как источник метаданных (ID пользователей, названия сущностей), которые синхронизируются с аналитической БД редко и небольшими порциями.

![][image3]

## ---

**5. Технологический стек реализации: Анализ внешних баз данных**

Для реализации Паттерна С (Dual-Write) необходимо выбрать внешнюю базу данных, которая соответствует требованиям: дешевое хранение, поддержка SQL (для гибкости), возможность легкого подключения к React (Serverless friendly). Рассмотрим три основных кандидата, актуальных на 2025 год.

### **5.1. Supabase (PostgreSQL)**

Supabase позиционируется как "Open Source Firebase alternative".

* **Преимущества:**  
  * Встроенный API (PostgREST) позволяет писать данные прямо с фронтенда (с RLS политиками безопасности).  
  * Удобный интерфейс управления.  
* Ограничения Free Tier 15:  
  * База данных: 500 MB (это очень мало для логов событий).  
  * Лимит на 50,000 MAU.  
  * Стоимость Pro плана начинается от $25/мес + плата за превышение ($0.125 за GB).  
* **Вердикт:** Хорошо для старта, но лимит в 500 MB на бесплатном тарифе может быть исчерпан быстро при активном логгировании событий.

### **5.2. Neon (Serverless PostgreSQL)**

Neon предоставляет "бессерверный" Postgres с разделением хранения и вычислений.

* Преимущества 18:  
  * **Scale to Zero:** База "засыпает", когда не используется, что идеально для аналитических джобов, запускаемых раз в день (снижение костов).  
  * **Branching:** Возможность создавать ветки базы данных для тестов (как в Git), что упрощает разработку.  
  * **Free Tier:** 0.5 GB хранилища (аналогично Supabase), но более гибкая модель "Autoscaling" на платных тарифах.  
* **Вердикт:** Отличный вариант для "Serverless" архитектуры, особенно в связке с Vercel.

### **5.3. ClickHouse / Tinybird (Специализированная аналитика)**

Если объем событий действительно велик (миллионы в месяц), реляционные базы (Postgres) могут стать узким местом при агрегации.

* **Tinybird:** Платформа поверх ClickHouse, предоставляющая API для инжестирования событий.  
* Преимущества 21:  
  * Предназначена специально для "user-facing analytics".  
  * Молниеносные агрегации (Sub-second queries).  
* **Вердикт:** Возможно, "overkill" (избыточно) для текущей стадии проекта, но идеальный путь для масштабирования в будущем.

**Рекомендация:** Начать с **Neon** или **Supabase** (Pro план), так как клиент уже знаком с реляционными моделями, а объем данных пока позволяет использовать Postgres. Postgres 15+ с партиционированием таблиц по времени (Time-Partitioning) справится с нагрузкой в десятки миллионов строк без проблем.

## ---

**6. Стратегия реализации идемпотентности и Backfilling (P4†)**

Клиент особо подчеркнул требование: "The job must be... rerunnable". Это критически важно для аналитики. Если джоб упал на середине, повторный запуск не должен приводить к удвоению метрик.

### **6.1. Почему простые INSERT опасны**

Если джоб делает INSERT INTO daily_stats (entity_id, views) VALUES (1, 10), и мы запустим его дважды, мы получим две записи и сумму 20 просмотров вместо 10.

### **6.2. Техника "Upsert" (Idempotent Write)**

В Postgres (как в Supabase/Neon, так и в Vercel Postgres) необходимо использовать конструкцию ON CONFLICT.

Пример SQL-паттерна для ежедневной агрегации:

SQL

INSERT INTO analytics_daily (entity_id, date, views_count)  
SELECT entity_id, DATE(created_at), COUNT(*)  
FROM raw_events  
WHERE created_at >= CURRENT_DATE - INTERVAL '1 day'  
GROUP BY entity_id, DATE(created_at)  
ON CONFLICT (entity_id, date)   
DO UPDATE SET   
    views_count = EXCLUDED.views_count,  
    updated_at = NOW();

* **Механизм:** Уникальный индекс по паре (entity_id, date) гарантирует, что для одной сущности за одну дату будет только одна запись.  
* **Результат:** Сколько бы раз мы ни запускали этот джоб, результат всегда будет идентичным (идемпотентным). Последний запуск просто "перезапишет" или обновит данные актуальными значениями.

### **6.3. Стратегия Backfill (Пересчет истории)**

Для требования "Backfill plan" рекомендуется использовать подход **Delete-then-Write** или **Partition Swap** (для больших объемов).23

* **Алгоритм:**  
  1. При необходимости пересчитать данные за прошлый месяц (например, изменилась логика подсчета "просмотров"), мы сначала удаляем агрегаты за этот период:  
     DELETE FROM analytics_daily WHERE date BETWEEN '2025-01-01' AND '2025-01-31';  
  2. Запускаем скрипт агрегации за этот период заново.

Это безопасно, так как мы храним **сырые события** (Raw Events) во внешней базе данных бесконечно долго (или с политикой хранения 1 год), а агрегаты ("daily stats layer") являются производными данными, которые всегда можно восстановить.

## ---

**7. Заключение и план действий**

Проведенный анализ подтвердил, что текущая архитектура клиента (Bubble.io для всего) не подходит для поставленной задачи "daily analytics layer" из-за проблем P1† (невозможность эффективной репликации) и P2† (риски производительности и стоимости). Попытка решить задачу "в лоб" приведет к созданию хрупкой, дорогой системы, склонной к сбоям.

Рекомендуемая стратегия — **"Dual-Write Architecture"**:

1. **Frontend (React):** Модифицировать код для отправки событий аналитики (клики, просмотры) напрямую во внешнюю PostgreSQL базу данных (Supabase/Neon).  
2. **Storage (External DB):** Использовать эту внешнюю БД для хранения сырых логов и расчета ежедневных агрегатов.  
3. **Visualization:** Строить дашборды, запрашивая данные из этой внешней БД, или (при необходимости) возвращать *только готовые агрегаты* обратно в Bubble для отображения в UI, что дешево и безопасно.

Данный подход полностью удовлетворяет требованиям:

* **Accurate:** Сырые данные не теряются и не семплируются.  
* **Rerunnable:** Идемпотентность обеспечена на уровне SQL (ON CONFLICT).  
* **Low Maintenance:** Нет сложных ETL-пайплайнов, данные пишутся сразу в целевое хранилище.

### **Итоговая матрица рисков**

| Проблема | Обоснованность | Уровень риска | Основная причина |
| :---- | :---- | :---- | :---- |
| **P1† (Replication Limits)** | **Высокая** | Блокирующий | Отсутствие доступа к WAL, лимиты API, проприетарный формат данных. |
| **P2† (Heavy IO Load)** | **Высокая** | Критический | Модель "Capacity/WU", неэффективность поисковых алгоритмов O(N), риск блокировок. |
| **P3† (List Limits 10k)** | **Высокая** | Скрытый/Технический | Архитектурное ограничение Bubble на размер массивов. |

Этот план действий обеспечивает надежный фундамент для масштабирования проекта P⁎ и минимизирует зависимость от ограничений одной платформы.

#### **Works cited**

1. Hard limits | Bubble Docs, accessed December 18, 2025, [https://manual.bubble.io/help-guides/maintaining-an-application/performance-and-scaling/hard-limits](https://manual.bubble.io/help-guides/maintaining-an-application/performance-and-scaling/hard-limits)  
2. What are the limitations of Bubble.is in terms of database capabilities? : r/Bubbleio - Reddit, accessed December 18, 2025, [https://www.reddit.com/r/Bubbleio/comments/vcqkhi/what_are_the_limitations_of_bubbleis_in_terms_of/](https://www.reddit.com/r/Bubbleio/comments/vcqkhi/what_are_the_limitations_of_bubbleis_in_terms_of/)  
3. Moving workflow to backend using API workflow to avoid capacity issues - Bubble Forum, accessed December 18, 2025, [https://forum.bubble.io/t/moving-workflow-to-backend-using-api-workflow-to-avoid-capacity-issues/109844](https://forum.bubble.io/t/moving-workflow-to-backend-using-api-workflow-to-avoid-capacity-issues/109844)  
4. Uploading 50,000-100,000 rows CSV - Database - Bubble Forum, accessed December 18, 2025, [https://forum.bubble.io/t/uploading-50-000-100-000-rows-csv/235000](https://forum.bubble.io/t/uploading-50-000-100-000-rows-csv/235000)  
5. Exporting large volume of data - Database - Bubble Forum, accessed December 18, 2025, [https://forum.bubble.io/t/exporting-large-volume-of-data/8081](https://forum.bubble.io/t/exporting-large-volume-of-data/8081)  
6. 1T - CSV Creator Plugin - Bubble, accessed December 18, 2025, [https://bubble.io/plugin/1t---csv-creator-1582601241392x653181519983018000](https://bubble.io/plugin/1t---csv-creator-1582601241392x653181519983018000)  
7. Native Bubble Table: Any way to export to csv? - Need help, accessed December 18, 2025, [https://forum.bubble.io/t/native-bubble-table-any-way-to-export-to-csv/329734](https://forum.bubble.io/t/native-bubble-table-any-way-to-export-to-csv/329734)  
8. Best Practices for Optimizing Workflow Performance - Questions - Bubble Forum, accessed December 18, 2025, [https://forum.bubble.io/t/best-practices-for-optimizing-workflow-performance/329161](https://forum.bubble.io/t/best-practices-for-optimizing-workflow-performance/329161)  
9. Optimizing Workload - Bubble, accessed December 18, 2025, [https://bubble.io/video/optimizing-workload-1724688716736x840729339541848000](https://bubble.io/video/optimizing-workload-1724688716736x840729339541848000)  
10. Schedule API Workflow on List mistakenly uses 100% capacity. Why? - Bubble Forum, accessed December 18, 2025, [https://forum.bubble.io/t/schedule-api-workflow-on-list-mistakenly-uses-100-capacity-why/219704](https://forum.bubble.io/t/schedule-api-workflow-on-list-mistakenly-uses-100-capacity-why/219704)  
11. macOS deprecating scripting language runtimes, including Python, Ruby, and Perl | Hacker News, accessed December 18, 2025, [https://news.ycombinator.com/item?id=20109469](https://news.ycombinator.com/item?id=20109469)  
12. Backend Workflow taking too much time - Need help - Bubble Forum, accessed December 18, 2025, [https://forum.bubble.io/t/backend-workflow-taking-too-much-time/290141](https://forum.bubble.io/t/backend-workflow-taking-too-much-time/290141)  
13. Database record limit - Bubble Forum, accessed December 18, 2025, [https://forum.bubble.io/t/database-record-limit/29891](https://forum.bubble.io/t/database-record-limit/29891)  
14. What is the maximum allowed number of things a list can contain? - Bubble Forum, accessed December 18, 2025, [https://forum.bubble.io/t/what-is-the-maximum-allowed-number-of-things-a-list-can-contain/218242](https://forum.bubble.io/t/what-is-the-maximum-allowed-number-of-things-a-list-can-contain/218242)  
15. About billing on Supabase, accessed December 18, 2025, [https://supabase.com/docs/guides/platform/billing-on-supabase](https://supabase.com/docs/guides/platform/billing-on-supabase)  
16. Supabase Pricing in 2025: Full Breakdown of Plans | UI Bakery Blog, accessed December 18, 2025, [https://uibakery.io/blog/supabase-pricing](https://uibakery.io/blog/supabase-pricing)  
17. Supabase pricing model: How it works and how Orb helped, accessed December 18, 2025, [https://www.withorb.com/blog/supabase-pricing](https://www.withorb.com/blog/supabase-pricing)  
18. Neon for Vercel, accessed December 18, 2025, [https://vercel.com/marketplace/neon](https://vercel.com/marketplace/neon)  
19. Neon Read Replicas - Neon Docs, accessed December 18, 2025, [https://neon.com/docs/introduction/read-replicas](https://neon.com/docs/introduction/read-replicas)  
20. Neon plans - Neon Docs, accessed December 18, 2025, [https://neon.com/docs/introduction/plans](https://neon.com/docs/introduction/plans)  
21. Honest guide to the best ClickHouse® alternatives in 2025 - Tinybird, accessed December 18, 2025, [https://www.tinybird.co/blog/clickhouse-alternatives](https://www.tinybird.co/blog/clickhouse-alternatives)  
22. Best database for real time analytics in 2025 and how to choose - Tinybird, accessed December 18, 2025, [https://www.tinybird.co/blog/best-database-for-real-time-analytics](https://www.tinybird.co/blog/best-database-for-real-time-analytics)  
23. Idempotent Data Pipelines with Spark and SQLMesh | by Andymadson - Medium, accessed December 18, 2025, [https://medium.com/@andymadson/idempotent-data-pipelines-with-spark-and-sqlmesh-eda8056b07c5](https://medium.com/@andymadson/idempotent-data-pipelines-with-spark-and-sqlmesh-eda8056b07c5)  
24. “From Idempotency to Backfills: Safely RewritingYour Data's Past” | by Sagar Iyer - Medium, accessed December 18, 2025, [https://medium.com/@sagarsiyer/from-idempotency-to-backfills-safely-rewritingyour-datas-past-492ac80f49ea](https://medium.com/@sagarsiyer/from-idempotency-to-backfills-safely-rewritingyour-datas-past-492ac80f49ea)

