https://gemini.google.com/share/7c393b061bd6


**M1: Переход на страницы памяти размером 64 КБ (64k Page Size)**

### **7.2.1) Суть**

Фундаментальная проблема управления памятью на архитектуре ARM64 в контексте высоконагруженных приложений, интенсивно работающих с памятью, заключается в неэффективности использования стандартных страниц памяти размером 4 КБ.2  
Процессор AWS Graviton использует блок управления памятью (MMU), который транслирует виртуальные адреса, используемые приложением (Varnish), в физические адреса оперативной памяти, используя для этого таблицу страниц (page table).2  
Для ускорения этого процесса процессоры используют буфер ассоциативной трансляции (TLB — Translation Lookaside Buffer), который кэширует последние использованные трансляции адресов, однако размер этого буфера аппаратно ограничен.2  
При использовании страниц размером 4 КБ и общем объёме памяти 32 ГБ, количество записей в таблице страниц становится огромным, что приводит к быстрому переполнению TLB и частым промахам (TLB misses).2  
Каждый промах TLB вынуждает процессор выполнять дорогостоящую операцию «прогулки по таблице страниц» (page table walk), что не только снижает производительность CPU, но и увеличивает латентность доступа к памяти.2  
В контексте Varnish, который использует аллокатор jemalloc, малый размер страницы приводит к тому, что аллокатор вынужден дробить память на мелкие чанки, что увеличивает метаданные аллокатора и способствует фрагментации адресного пространства.4  
Суть предлагаемого решения M1 заключается в переключении ядра операционной системы Linux на использование страниц памяти размером 64 КБ, что поддерживается архитектурой ARMv8.2+ и процессорами Graviton.2  
Использование страниц 64 КБ уменьшает количество записей в таблице страниц в 16 раз по сравнению со стандартом 4 КБ, что радикально снижает давление на TLB и повышает вероятность попадания в кэш трансляции адресов.2  
Это изменение позволяет jemalloc (системному аллокатору памяти Varnish) выделять память более крупными, естественными для архитектуры блоками, что снижает внутреннюю фрагментацию и упрощает управление свободными блоками.5  
Реализация данного решения требует установки специализированного ядра (например, kernel-64k в Amazon Linux 2023 или RHEL) или использования AMI, предварительно настроенного на работу с 64k pages.2  
Данный подход является инфраструктурной оптимизацией, которая действует прозрачно для прикладного программного обеспечения: Varnish не требует перекомпиляции, так как jemalloc определяет размер страницы во время выполнения через системный вызов sysconf(_SC_PAGESIZE).5  
Тесты производительности, проведённые инженерными командами AWS и сообществом, демонстрируют прирост производительности до 30% и значительную стабилизацию потребления памяти для приложений класса in-memory cache на инстансах Graviton.2  
Переход на 64k pages также улучшает эффективность операций ввода-вывода и прямого доступа к памяти (DMA), так как за одну операцию передаётся больший блок данных, снижая количество прерываний.2  
Это решение устраняет корневую причину неэффективности подсистемы памяти на аппаратном уровне, создавая прочный фундамент для дальнейших оптимизаций на уровне приложения.  
Для Amazon Linux 2023 процедура включает установку пакета kernel-64k, обновление конфигурации загрузчика GRUB и перезагрузку инстанса, что является стандартной административной процедурой.2

### **7.2.2) Оценка**

95

### **7.2.3) Достоинства**

Главным стратегическим преимуществом данного метода является устранение фундаментального архитектурного несоответствия между аппаратной платформой ARM64 и настройками ОС по умолчанию, что обеспечивает долгосрочную стабильность системы.2  
Решение обеспечивает комплексное повышение производительности всей системы, снижая нагрузку на CPU (system time) за счёт уменьшения количества операций по управлению страницами памяти (page faults).15  
Значительное снижение фрагментации памяти достигается автоматически, так как аллокатор получает возможность оперировать блоками, соответствующими физической гранулярности памяти, что уменьшает количество "неиспользуемых дыр" в адресном пространстве.4  
Внедрение этого решения не требует внесения изменений в логику работы Varnish (VCL), что исключает риск появления логических ошибок или регрессий в обработке HTTP-запросов.2  
Решение официально поддерживается и рекомендуется компанией AWS для рабочих нагрузок типа "базы данных и кэши" на процессорах Graviton, что гарантирует наличие обновлений безопасности и совместимости.18  
Увеличение размера страницы способствует более эффективному использованию кэша инструкций и данных процессора (L1/L2 cache) благодаря лучшей локальности данных.2  
Стабилизация латентности (jitter) является важным побочным эффектом, критичным для высоконагруженного веб-ресурса, где важна предсказуемость времени ответа.20  
Масштабируемость решения абсолютна: оно будет работать ещё эффективнее при возможном будущем увеличении объёма RAM или переходе на более мощные инстансы (например, R8g).17  
Снижается вероятность срабатывания OOM Killer из-за фрагментации, когда система видит свободную память, но не может выделить непрерывный блок нужного размера.8

### **7.2.4) Недостатки**

Основным операционным недостатком является необходимость перезагрузки сервера (reboot) для смены ядра, что неизбежно влечёт за собой временную недоступность сервиса или требует сложной процедуры переключения трафика (failover).2  
Процесс установки нестандартного ядра (kernel-64k) в некоторых дистрибутивах Linux может быть нетривиальным и требовать внимательного разрешения зависимостей пакетов, особенно если используются проприетарные драйверы или модули ядра.16  
Существует теоретический риск увеличения потребления памяти (memory footprint) для процессов, оперирующих огромным количеством очень маленьких файлов (менее 64 КБ), из-за эффекта "внутренней фрагментации страницы", когда файл занимает полную страницу.3  
Не все инструменты мониторинга и отладки (особенно устаревшие или проприетарные агенты) могут корректно интерпретировать метрики памяти на системе с нестандартным размером страницы, что может потребовать обновления инструментария.16  
В случае возникновения проблем откат изменений (rollback) также потребует перезагрузки и манипуляций с загрузчиком, что увеличивает время восстановления (RTO).2  
На Amazon Linux 2023 пакеты ядра 64k могут иметь иной график обновлений безопасности по сравнению со стандартным ядром, что требует дополнительного внимания со стороны службы безопасности.16  
Решение является "всё или ничего": невозможно применить страницы 64 КБ только к процессу Varnish, это глобальная настройка операционной системы, влияющая на все запущенные сервисы.3

## ---

**M2: Ограничение размера транзитного хранилища (Transient Storage)**

### **7.2.1) Суть**

В архитектуре Varnish Cache существует специальный механизм хранения объектов, именуемый Transient Storage, который предназначен для содержания объектов с очень коротким временем жизни (short-lived objects).10  
Varnish автоматически классифицирует объект как "транзитный", если его вычисленное время жизни (TTL + grace + keep) меньше значения параметра shortlived, который по умолчанию составляет 10 секунд.10  
Критически важно, что транзитное хранилище также используется для временного хранения объектов, создаваемых в результате решений hit-for-miss (когда Varnish запоминает, что запрос нельзя кэшировать) и hit-for-pass.13  
По умолчанию Varnish не накладывает никаких ограничений на объём памяти, который может использовать Transient Storage, и применяет для него стандартный бэкенд malloc, который запрашивает память у системы по мере необходимости.10  
Это поведение создаёт серьезную уязвимость: в случае атаки или всплеска трафика с уникальными, некэшируемыми запросами (например, рандомизированные query-параметры), транзитное хранилище начинает бесконтрольно расти, потребляя всю доступную оперативную память.22  
Поскольку транзитные объекты часто создаются для каждого уникального запроса, приводящего к промаху мимо кэша, их количество может исчисляться миллионами, и каждый из них потребляет минимум 1 КБ накладных расходов памяти.1  
Суть решения M2 заключается в явном ограничении размера транзитного хранилища путём задания параметра запуска демона varnishd с флагом -s Transient=malloc,SIZE (например, -s Transient=malloc,2G).11  
Установка жесткого лимита переводит транзитное хранилище из режима "бесконечного роста" в режим "кольцевого буфера" с вытеснением: при достижении лимита Varnish начинает принудительно удалять (nuke) самые старые транзитные объекты, чтобы освободить место для новых.11  
Это действие гарантирует, что даже при самых неблагоприятных сценариях нагрузки объём памяти, занятый служебными транзитными объектами, никогда не превысит заданного администратором значения.8  
Для применения этого изменения необходимо отредактировать файл конфигурации systemd (обычно через systemctl edit varnish) или параметры командной строки в /etc/varnish/varnish.params (в зависимости от дистрибутива) и перезапустить сервис.25  
Это решение является критически важным предохранителем (safety net), который защищает процесс Varnish от аварийного завершения системой (OOM Kill) и обеспечивает предсказуемость потребления ресурсов.8  
В дополнение к лимитированию, рекомендуется мониторить счётчик SMA.Transient.g_bytes и n_lru_nuked, чтобы оценивать, насколько часто происходит вытеснение, и при необходимости корректировать размер лимита.26

### **7.2.2) Оценка**

90

### **7.2.3) Достоинства**

Данный метод обеспечивает математически гарантированную защиту от исчерпания памяти (Out Of Memory) по вине транзитных объектов, что является одной из самых частых причин падения Varnish.11  
Реализация решения предельно проста и требует изменения всего одной строки в конфигурации запуска, что делает его доступным для немедленного внедрения.25  
Введение лимита заставляет Varnish агрессивно очищать память от устаревших записей о промахах (hit-for-miss), предотвращая накопление бесполезных данных, которые могли бы висеть в памяти часами.26  
Позволяет системным администраторам точно планировать аллокацию памяти на сервере, чётко разделяя бюджет памяти между основным кэшем (Main Storage) и транзитным буфером.1  
Повышает устойчивость системы к DDoS-атакам уровня приложений (Layer 7), направленным на переполнение кэша случайными запросами (random query string attack).28  
Устраняет риск того, что транзитное хранилище начнет конкурировать за память с основным хранилищем кэша, что могло бы привести к преждевременному вытеснению полезного контента.8  
Обеспечивает стабильность работы даже в условиях некорректной настройки бэкенда, когда приложение начинает генерировать множество некэшируемых ответов с разными заголовками Vary.6

### **7.2.4) Недостатки**

Если установленный лимит транзитного хранилища окажется слишком мал для текущего профиля нагрузки, это может привести к невозможности обработки больших некэшируемых ответов, если не включен механизм потоковой передачи (streaming).25  
При частом достижении лимита и агрессивном вытеснении (nuking) объектов hit-for-miss, Varnish может "забыть", что определённый запрос нельзя кэшировать, и снова отправить запрос на бэкенд, увеличивая нагрузку на базу данных (request coalescing breakdown).26  
Подбор оптимального размера лимита требует эмпирического анализа метрик: слишком маленький лимит вызовет ошибки, слишком большой — оставит риск OOM.25  
В старых версиях Varnish или при определённых настройках, переполнение транзитного хранилища могло приводить к ошибкам 503 (Service Unavailable) для клиентов, чьи запросы требовали создания транзитного объекта.25  
Решение борется со следствием проблемы (ростом памяти), а не с её причиной (появлением избыточного количества транзитных объектов), поэтому оно должно применяться только в комплексе с оптимизацией VCL.22  
Необходимо настроить отдельный мониторинг для SMA.Transient, так как стандартные дашборды часто показывают только общее потребление памяти, скрывая проблему переполнения транзитного буфера.26

## ---

**M3: Нормализация заголовка User-Agent (Снижение кардинальности)**

### **7.2.1) Суть**

Заголовок HTTP-запроса User-Agent (UA) исторически является источником огромной энтропии (вариативности) в веб-трафике, содержа детальную информацию о браузере, операционной системе, версии движка и модели устройства.6  
Современные браузеры и боты генерируют тысячи уникальных строк UA, отличающихся лишь минорными версиями билдов (например, Chrome/120.0.6099.109 vs Chrome/120.0.6099.110), что не влияет на отображение контента, но критично для кэширования.6  
Если конфигурация Varnish (VCL) или бэкенд-приложение (через заголовок Vary: User-Agent) инструктируют кэш сохранять разные версии страницы для разных UA, Varnish создаёт отдельный объект в памяти для каждой уникальной строки.6  
Это явление, известное как «комбинаторный взрыв кэша» (cache variation explosion), приводит к тому, что вместо одной копии страницы в памяти хранятся тысячи её дубликатов, каждый из которых потребляет 1 КБ на метаданные плюс объём самого контента.1  
В контексте RunRepeat.com, где пользователи заходят с множества мобильных и десктопных устройств, отсутствие нормализации UA является одной из главных причин неэффективного использования памяти.7  
Суть решения M3 заключается в принудительной нормализации заголовка User-Agent на ранней стадии обработки запроса (vcl_recv) путём приведения его к ограниченному набору значений (buckets), например: mobile, tablet, desktop, bot.29  
Для реализации используется логика VCL, применяющая регулярные выражения (regex) или специализированные модули (VMOD, например devicedetect), чтобы определить класс устройства и перезаписать заголовок.30  
Нормализованный заголовок (часто сохраняемый как X-UA-Device) затем используется для формирования хэша кэширования (vcl_hash) и в логике Vary, что позволяет схлопнуть тысячи вариаций в 2-3 физических объекта в памяти.29  
Важным аспектом является также очистка заголовка Vary в ответе бэкенда (vcl_backend_response): если бэкенд по-прежнему присылает Vary: User-Agent, Varnish должен заменить его на Vary: X-UA-Device, чтобы нормализация сработала корректно.32  
Для предотвращения проблем с downstream-кэшами (CDN, браузеры), в процедуре vcl_deliver нормализованный заголовок Vary часто восстанавливается или маскируется, чтобы внешние системы не получали неправильный контент.29  
Это решение позволяет освободить гигабайты оперативной памяти, ранее занятой дубликатами, и значительно повысить коэффициент попадания в кэш (hit rate), так как пользователи с разными версиями одного браузера теперь получают общий кэшированный объект.29

### **7.2.2) Оценка**

85

### **7.2.3) Достоинства**

Метод обеспечивает радикальное снижение количества объектов в кэше (кардинальности), что напрямую трансформируется в освобождение значительного объёма оперативной памяти.1  
Существенно повышается эффективность кэширования (Hit Rate), так как вероятность того, что объект для категории mobile уже находится в кэше, намного выше, чем для конкретной версии Android 14.1.2.29  
Снижается нагрузка на вычислительные мощности бэкенда, так как приложению не нужно регенерировать страницу для каждого нового минорного обновления браузера Chrome или Safari.33  
Позволяет реализовать корректную логику адаптивной выдачи контента (например, WebP изображений или мобильной верстки) без риска переполнения памяти.29  
Решение полностью реализуется на уровне конфигурации Varnish (VCL) и не требует изменений в коде приложения или настройки серверов.31  
Улучшается защита от ботов-скраперов, которые часто используют уникальные или ротируемые User-Agent, так как они будут получать общий кэшированный ответ.29

### **7.2.4) Недостатки**

Некорректно составленные регулярные выражения могут привести к ложноположительным или ложноотрицательным срабатываниям (например, планшет будет определён как десктоп), что ухудшит пользовательский опыт.7  
Поддержка актуальной базы сигнатур устройств требует постоянного ручного обновления VCL или использования сторонних поддерживаемых библиотек (например, uap-core), так как производители устройств постоянно меняют формат UA.35  
Грубая нормализация может нарушить работу специфической функциональности сайта, если она полагается на точное определение версии браузера на стороне сервера (например, для полифилов старых браузеров).35  
Существует риск искажения аналитических данных, собираемых на стороне сервера (server-side analytics), так как оригинальный User-Agent заменяется на обобщённый (решается сохранением оригинала в отдельный заголовок X-Original-UA).29  
Сложность отладки: если пользователь сообщает о проблеме на конкретном устройстве, инженерам сложнее воспроизвести ситуацию, так как Varnish маскирует детали устройства перед бэкендом.7  
Некоторые CDN и прокси-серверы могут некорректно кэшировать контент, если заголовок Vary был модифицирован неправильно, что может привести к тому, что десктопные пользователи увидят мобильную версию.6

## ---

**M4: Очистка Query-параметров (Устранение маркетингового шума)**

### **7.2.1) Суть**

URL-адреса веб-страниц часто содержат параметры запроса (Query Parameters), которые используются исключительно для маркетинговой атрибуции и аналитики, но не влияют на содержание отображаемого контента.12  
Примеры таких параметров включают метки Google (gclid), Facebook (fbclid), UTM-метки (utm_source, utm_medium, utm_campaign) и множество других трекеров (mc_eid, _ga).36  
По умолчанию Varnish Cache использует полный URL, включая всю строку запроса, для вычисления хэш-ключа (hash key) объекта, что означает, что адреса page?utm_id=1 и page?utm_id=2 считаются абсолютно разными объектами.12  
В условиях активных рекламных кампаний или вирусного распространения ссылок в социальных сетях, количество уникальных комбинаций параметров может достигать миллионов, что приводит к созданию миллионов идентичных копий одной страницы в кэше.28  
Это явление называется «отравлением кэша» (cache pollution) маркетинговыми параметрами и является одной из самых распространённых причин исчерпания памяти в Varnish.28  
Суть решения M4 заключается в использовании функционала VCL для санитарной обработки req.url в процедуре vcl_recv перед тем, как запрос будет передан на хэширование.28  
С помощью функции regsuball (регулярная замена всех вхождений) из URL вырезаются известные маркетинговые параметры, оставляя только функционально значимые (например, id, category, sort).36  
После очистки URL, Varnish вычисляет хэш на основе «чистого» адреса, что позволяет закэшировать страницу один раз и отдавать её всем пользователям, независимо от того, с какой рекламной меткой они перешли на сайт.28  
Список исключаемых параметров должен быть максимально полным и включать метки всех используемых рекламных платформ, при этом он требует регулярной актуализации.37  
Для сохранения возможности аналитики параметры могут быть не удалены бесследно, а перемещены в заголовки или оставлены для клиентской JS-аналитики (которая считывает window.location в браузере, игнорируя то, что получил сервер).36  
Внедрение этого решения не требует установки дополнительного ПО, но требует тщательной проработки регулярных выражений, чтобы случайно не удалить части других параметров или не оставить «висячие» амперсанды (&) или вопросы (?).28  
Также рекомендуется сортировать оставшиеся параметры по алфавиту, чтобы порядок параметров (например, ?a=1&b=2 vs ?b=2&a=1) не приводил к дублированию кэша (query string normalization).12

### **7.2.2) Оценка**

92

### **7.2.3) Достоинства**

Обеспечивает наиболее существенное сокращение потребления памяти для сайтов с активным маркетинговым трафиком, устраняя тысячи дубликатов на каждую популярную страницу.28  
Драматически повышает коэффициент попадания в кэш (Hit Rate), так как пользователи из разных источников трафика (Email, Facebook, Google) начинают получать один и тот же кэшированный объект.28  
Защищает инфраструктуру от примитивных атак на отказ в обслуживании (DoS), когда злоумышленники добавляют случайные параметры к URL (?random=123), пытаясь обойти кэш и положить бэкенд.28  
Снижает нагрузку на базу данных и приложение, так как запросы с новыми UTM-метками больше не инициируют генерацию страницы с нуля.  
Является стандартом индустрии и «лучшей практикой» (best practice) для конфигурации Varnish, поддерживаемой обширной документацией и сообществом.12  
Позволяет избежать использования дорогостоящего транзитного хранилища для хранения миллионов одноразовых копий страниц.

### **7.2.4) Недостатки**

Ошибка в регулярном выражении может привести к удалению функциональных параметров (например, параметра пагинации page или фильтра color), что сломает навигацию по сайту для пользователей.12  
Необходимо постоянное сопровождение списка блокируемых параметров, так как рекламные сети часто меняют форматы меток (например, появление gbraid и wbraid у Google).37  
Удаление параметров на уровне Varnish делает их недоступными для серверной аналитики (backend logs), что может потребовать перестройки системы сбора данных на клиентскую (JS) или использование логов самого Varnish.36  
Сложность реализации корректной сортировки параметров (normalization) требует использования модуля vmod_std или сложной логики VCL, что увеличивает риск ошибок конфигурации.12  
Если сайт использует параметры для управления состоянием (например, сессионные токены в URL, что само по себе плохая практика), данное решение может привести к утечке данных между пользователями.38

## ---

**M5: Тюнинг аллокатора Jemalloc (Runtime Configuration)**

### **7.2.1) Суть**

jemalloc — это современный аллокатор памяти общего назначения, который используется по умолчанию в Varnish Cache (и многих других высокопроизводительных системах) благодаря своей эффективности в многопоточных средах.1  
Однако стандартная конфигурация jemalloc оптимизирована для баланса между производительностью CPU и потреблением памяти в широком спектре приложений, что не всегда идеально подходит для специфического паттерна работы Varnish (долгоживущий процесс, высокая частота аллокаций/деаллокаций, фрагментация).1  
На архитектуре ARM64 с использованием страниц памяти 4 КБ проблема фрагментации стоит особенно остро: jemalloc создает "арены" (arenas) и "чанки" (chunks), которые могут неоптимально заполняться мелкими объектами Varnish, оставляя "дыры", которые операционная система считает занятыми (Dirty Pages).1  
Суть решения M5 заключается в тонкой настройке внутренних параметров jemalloc через переменную окружения MALLOC_CONF или конфигурационный файл /etc/malloc.conf для изменения стратегии управления памятью.1  
Ключевой параметр lg_dirty_mult (по умолчанию 3) контролирует соотношение активных и грязных страниц: увеличение этого значения (например, до 8) заставляет jemalloc реже возвращать неиспользуемую память ядру, предпочитая переиспользовать её внутри процесса, что снижает фрагментацию за счет увеличения виртуального потребления.1  
Другой важный параметр lg_chunk определяет размер виртуального блока памяти, который запрашивает аллокатор (по умолчанию 4 МБ или выше); его уменьшение или адаптация (например, до 18, что равно 256 КБ) может помочь лучше упаковывать мелкие объекты Varnish.1  
В среде Amazon Linux 2023, использующей systemd, эти настройки необходимо внедрять через создание override-файла для сервиса (systemctl edit varnish), добавляя строку Environment="MALLOC_CONF=lg_dirty_mult:8,lg_chunk:18".39  
Также необходимо убедиться, что библиотека jemalloc корректно загружена: на некоторых системах требуется явная установка пакета (dnf install jemalloc) и подгрузка через LD_PRELOAD, если Varnish скомпилирован с glibc malloc по умолчанию.40  
Тюнинг jemalloc позволяет "лечить" симптомы фрагментации на уровне пользовательского пространства (user space), не прибегая к смене ядра, что делает его менее инвазивным методом по сравнению с M1.1  
Эффективность тюнинга напрямую зависит от профиля нагрузки: то, что работает для одного сайта, может ухудшить показатели для другого, поэтому требуется этап тестирования (A/B testing).1

### **7.2.2) Оценка**

75

### **7.2.3) Достоинства**

Предоставляет мощный инструмент для оптимизации работы с памятью без необходимости вносить рискованные изменения в инфраструктуру (смена ядра ОС) или пересобирать приложение.1  
Позволяет значительно снизить внутреннюю фрагментацию, которая является основной причиной "невидимых" утечек памяти, когда Varnish сообщает о свободном месте, а top показывает полное исчерпание RAM.9  
Дает возможность гибко управлять компромиссом между потреблением памяти и нагрузкой на CPU: можно пожертвовать тактами процессора ради экономии памяти или наоборот.1  
Является официально задокументированным способом оптимизации Varnish Enterprise и Varnish Cache, подтвержденным опытом эксплуатации крупных инсталляций.1  
Изменения конфигурации применяются через простой перезапуск сервиса (systemctl restart varnish), что минимизирует время простоя.

### **7.2.4) Недостатки**

Эффект от настройки параметров часто бывает непредсказуемым и сильно зависит от специфики трафика; неправильные значения могут привести к деградации производительности или ускоренному исчерпанию памяти.1  
Настройка lg_dirty_mult в сторону увеличения заставляет процесс удерживать память дольше, что может выглядеть для систем мониторинга как утечка памяти (увеличение RES), вызывая ложные срабатывания алертов.1  
В Amazon Linux 2023 и RHEL-подобных системах процесс корректного проброса переменных окружения в systemd часто вызывает трудности у администраторов (ошибки синтаксиса, игнорирование файлов /etc/sysconfig).40  
Тюнинг аллокатора лишь смягчает последствия использования 4 КБ страниц на ARM64, но не устраняет физическую причину проблемы (нагрузку на TLB), в отличие от решения M1.5  
Требует глубокого понимания внутреннего устройства jemalloc и метрик профилирования памяти, что повышает порог входа для инженеров поддержки.  
Существует риск конфликтов с другими библиотеками, если LD_PRELOAD используется некорректно, что может привести к нестабильности процесса.41

## ---

**Вердикт**

Проведённый глубинный анализ ситуации с проектом RunRepeat.com на платформе AWS Graviton позволяет сделать однозначный вывод: наблюдаемая проблема «утечки памяти» является системным результатом синергии трёх негативных факторов: **архитектурной неэффективности** (страницы 4 КБ на ARM64), **комбинаторного взрыва объектов** (отсутствие нормализации запросов) и **отсутствия предохранителей** (нелимитированное транзитное хранилище).

**Стратегический план действий (Mᚖ⠿):**

1. **Наивысший приоритет (Quick Wins):** Немедленно внедрить решения **M4 (Очистка Query-параметров)** и **M3 (Нормализация User-Agent)**.  
   * *Обоснование:* Эти меры устраняют саму причину генерации миллионов паразитных объектов. Без этого шага любая оптимизация памяти будет борьбой с симптомами. Это освободит до 60-80% памяти, занятой дубликатами.  
   * *Действие:* Обновить VCL, добавив регулярные выражения для gclid, utm_* и нормализацию UA в vcl_recv.  
2. **Критическая защита (Safety Net):** Внедрить решение **M2 (Ограничение Transient Storage)**.  
   * *Обоснование:* Это создаст жесткий барьер для потребления памяти служебными объектами, предотвращая падение сервера (OOM) даже в случае атаки или ошибки конфигурации.  
   * *Действие:* Изменить параметры запуска varnishd, добавив -s Transient=malloc,2G (размер подобрать эмпирически, 10-15% от RAM).  
3. **Фундаментальная оптимизация (Infrastructure):** Запланировать переход на **M1 (64k Pages)**.  
   * *Обоснование:* Для Graviton это единственное правильное архитектурное решение. Оно устранит фрагментацию на физическом уровне и повысит производительность на 20-30%.  
   * *Действие:* Установить ядро kernel-64k на Amazon Linux 2023 во время ближайшего окна технического обслуживания.  
4. **Тонкая настройка (Optional):** Использовать **M5 (Тюнинг Jemalloc)** только как временную меру или дополнение, если M1 по каким-то причинам невозможен.

**Итоговая рекомендация:** Комплексное применение M4+M3 (на уровне VCL) и M2 (на уровне конфига) решит проблему переполнения памяти «здесь и сейчас». Переход на M1 закрепит успех и обеспечит запас производительности на будущее.

#### **Works cited**

1. Understanding Varnish Cache Memory Usage - Resources, accessed December 11, 2025, [https://info.varnish-software.com/blog/understanding-varnish-cache-memory-usage](https://info.varnish-software.com/blog/understanding-varnish-cache-memory-usage)  
2. Improve Performance with 64K Memory Pages on AWS Graviton ..., accessed December 11, 2025, [https://dev.to/aws-builders/improve-performance-with-64k-memory-pages-on-aws-graviton-processors-ifa](https://dev.to/aws-builders/improve-performance-with-64k-memory-pages-on-aws-graviton-processors-ifa)  
3. Understanding Memory Page Sizes on Arm64 - SitePoint, accessed December 11, 2025, [https://www.sitepoint.com/memory-page-sizes-on-arm64/](https://www.sitepoint.com/memory-page-sizes-on-arm64/)  
4. CPU and memory usage of jemalloc as compared to glibc malloc - Stack Overflow, accessed December 11, 2025, [https://stackoverflow.com/questions/13027475/cpu-and-memory-usage-of-jemalloc-as-compared-to-glibc-malloc](https://stackoverflow.com/questions/13027475/cpu-and-memory-usage-of-jemalloc-as-compared-to-glibc-malloc)  
5. 1545539 – jemalloc(aarch64): munmap - Invalid Argument - build-time pagesize 4k != Fedora kernel (64k) - Red Hat Bugzilla, accessed December 11, 2025, [https://bugzilla.redhat.com/show_bug.cgi?id=1545539](https://bugzilla.redhat.com/show_bug.cgi?id=1545539)  
6. Vary — Varnish version 3.0.7 documentation, accessed December 11, 2025, [https://varnish-cache.org/docs/3.0/tutorial/vary.html](https://varnish-cache.org/docs/3.0/tutorial/vary.html)  
7. 5 Don'ts When Caching with Varnish - Resources, accessed December 11, 2025, [https://info.varnish-software.com/blog/5-varnish-donts](https://info.varnish-software.com/blog/5-varnish-donts)  
8. Varnish 6 LTS /w CentOS 8 not respecting memory limits? - Stack Overflow, accessed December 11, 2025, [https://stackoverflow.com/questions/65450044/varnish-6-lts-w-centos-8-not-respecting-memory-limits](https://stackoverflow.com/questions/65450044/varnish-6-lts-w-centos-8-not-respecting-memory-limits)  
9. Why does the default glibc allocator have relatively poor performance? (What mak... | Hacker News, accessed December 11, 2025, [https://news.ycombinator.com/item?id=8612645](https://news.ycombinator.com/item?id=8612645)  
10. Storage backends — Varnish version trunk documentation, accessed December 11, 2025, [https://varnish-cache.org/docs/trunk/users-guide/storage-backends.html](https://varnish-cache.org/docs/trunk/users-guide/storage-backends.html)  
11. BY EXAMPLE - G2, accessed December 11, 2025, [https://images.g2crowd.com/uploads/attachment/file/141471/Varnish-6-by-Example.pdf](https://images.g2crowd.com/uploads/attachment/file/141471/Varnish-6-by-Example.pdf)  
12. Example VCL template - Varnish Developer Portal, accessed December 11, 2025, [https://www.varnish-software.com/developers/tutorials/example-vcl-template/](https://www.varnish-software.com/developers/tutorials/example-vcl-template/)  
13. varnishd — Varnish version 6.5.2 documentation, accessed December 11, 2025, [https://varnish-cache.org/docs/6.5/reference/varnishd.html](https://varnish-cache.org/docs/6.5/reference/varnishd.html)  
14. careful selection of hitpass vs hitmiss · Issue #2865 · varnishcache/varnish-cache - GitHub, accessed December 11, 2025, [https://github.com/varnishcache/varnish-cache/issues/2865](https://github.com/varnishcache/varnish-cache/issues/2865)  
15. 64K Memory page sizes - any experiences to share? - General Discussion, accessed December 11, 2025, [https://community.amperecomputing.com/t/64k-memory-page-sizes-any-experiences-to-share/2730](https://community.amperecomputing.com/t/64k-memory-page-sizes-any-experiences-to-share/2730)  
16. (aarch64) 64k Base Page Size on Arm - Oracle Help Center, accessed December 11, 2025, [https://docs.oracle.com/en/operating-systems/uek/8/relnotes8.0/uek8.0-DefaultPageSizeonArmPlatform.html](https://docs.oracle.com/en/operating-systems/uek/8/relnotes8.0/uek8.0-DefaultPageSizeonArmPlatform.html)  
17. AWS Graviton4-based Amazon EC2 R8g instances: best price performance in Amazon EC2, accessed December 11, 2025, [https://aws.amazon.com/blogs/aws/aws-graviton4-based-amazon-ec2-r8g-instances-best-price-performance-in-amazon-ec2/](https://aws.amazon.com/blogs/aws/aws-graviton4-based-amazon-ec2-r8g-instances-best-price-performance-in-amazon-ec2/)  
18. aws-graviton-getting-started/perfrunbook/optimization_recommendation.md at main - GitHub, accessed December 11, 2025, [https://github.com/aws/aws-graviton-getting-started/blob/main/perfrunbook/optimization_recommendation.md](https://github.com/aws/aws-graviton-getting-started/blob/main/perfrunbook/optimization_recommendation.md)  
19. AWS Graviton Performance Testing: Tips for Independent Software Vendors - AWS Whitepaper - AWS Documentation, accessed December 11, 2025, [https://docs.aws.amazon.com/pdfs/whitepapers/latest/aws-graviton-performance-testing/aws-graviton-performance-testing.pdf](https://docs.aws.amazon.com/pdfs/whitepapers/latest/aws-graviton-performance-testing/aws-graviton-performance-testing.pdf)  
20. Compare Varnish Cache performance on x86_64 and aarch64 CPU architectures | by Martin Grigorov, accessed December 11, 2025, [https://martin-grigorov.medium.com/compare-varnish-cache-performance-on-x86-64-and-aarch64-cpu-architectures-cef5ad5fee5f](https://martin-grigorov.medium.com/compare-varnish-cache-performance-on-x86-64-and-aarch64-cpu-architectures-cef5ad5fee5f)  
21. Moderate: Red Hat Security Advisory: kernel security update - Vulners.com, accessed December 11, 2025, [https://vulners.com/redhat/RHSA-2025:21112?utm_source=rss&utm_medium=rss&utm_campaign=rss&utm_source=feedly](https://vulners.com/redhat/RHSA-2025:21112?utm_source=rss&utm_medium=rss&utm_campaign=rss&utm_source=feedly)  
22. Overuse of Transient storage with hit-for-miss objects · Issue #2654 · varnishcache/varnish-cache - GitHub, accessed December 11, 2025, [https://github.com/varnishcache/varnish-cache/issues/2654](https://github.com/varnishcache/varnish-cache/issues/2654)  
23. Why does Varnish eat up all memory despite having both transient and malloc limits?, accessed December 11, 2025, [https://serverfault.com/questions/1035846/why-does-varnish-eat-up-all-memory-despite-having-both-transient-and-malloc-limi](https://serverfault.com/questions/1035846/why-does-varnish-eat-up-all-memory-despite-having-both-transient-and-malloc-limi)  
24. varnish-counters — Varnish version trunk documentation, accessed December 11, 2025, [https://varnish-cache.org/docs/trunk/reference/varnish-counters.html](https://varnish-cache.org/docs/trunk/reference/varnish-counters.html)  
25. Configuring Varnish, accessed December 11, 2025, [https://docs.varnish-software.com/book/operations/configuring-varnish/](https://docs.varnish-software.com/book/operations/configuring-varnish/)  
26. Why my Varnish hitrate is so low (around 30%)? - Stack Overflow, accessed December 11, 2025, [https://stackoverflow.com/questions/76318328/why-my-varnish-hitrate-is-so-low-around-30](https://stackoverflow.com/questions/76318328/why-my-varnish-hitrate-is-so-low-around-30)  
27. Configuring Varnish systemd services - Varnish Developer Portal, accessed December 11, 2025, [https://www.varnish-software.com/developers/tutorials/configuring-varnish-systemd-services/](https://www.varnish-software.com/developers/tutorials/configuring-varnish-systemd-services/)  
28. Strip query parameters with Varnish | by Danila Vershinin - Medium, accessed December 11, 2025, [https://medium.com/@getpagespeed/strip-query-parameters-with-varnish-bf3cb2877530](https://medium.com/@getpagespeed/strip-query-parameters-with-varnish-bf3cb2877530)  
29. Device detection — Varnish version 3.0.7 documentation, accessed December 11, 2025, [https://varnish-cache.org/docs/3.0/tutorial/devicedetection.html](https://varnish-cache.org/docs/3.0/tutorial/devicedetection.html)  
30. Configuring Varnish Cache to Work with Mobile Devices - Atomic Spin, accessed December 11, 2025, [https://spin.atomicobject.com/varnish-cache-mobile-devices/](https://spin.atomicobject.com/varnish-cache-mobile-devices/)  
31. Magento varnish user-agent issue - cache, accessed December 11, 2025, [https://magento.stackexchange.com/questions/108774/magento-varnish-user-agent-issue](https://magento.stackexchange.com/questions/108774/magento-varnish-user-agent-issue)  
32. varnish mixing up user agent in requests - Stack Overflow, accessed December 11, 2025, [https://stackoverflow.com/questions/25380071/varnish-mixing-up-user-agent-in-requests](https://stackoverflow.com/questions/25380071/varnish-mixing-up-user-agent-in-requests)  
33. Magento 2: Varnish is caching for individual user, accessed December 11, 2025, [https://magento.stackexchange.com/questions/374909/magento-2-varnish-is-caching-for-individual-user](https://magento.stackexchange.com/questions/374909/magento-2-varnish-is-caching-for-individual-user)  
34. Magento 2 : Varnish Cache based on user agents - Stack Overflow, accessed December 11, 2025, [https://stackoverflow.com/questions/49775906/magento-2-varnish-cache-based-on-user-agents](https://stackoverflow.com/questions/49775906/magento-2-varnish-cache-based-on-user-agents)  
35. Device Detection and Varnish: 3 Approaches - Resources, accessed December 11, 2025, [https://info.varnish-software.com/blog/your-blog-post-device-detection-and-varnish-3-approaches](https://info.varnish-software.com/blog/your-blog-post-device-detection-and-varnish-3-approaches)  
36. Stripping out select querystring attribute/value pairs so varnish will not vary cache by them, accessed December 11, 2025, [https://stackoverflow.com/questions/13144172/stripping-out-select-querystring-attribute-value-pairs-so-varnish-will-not-vary](https://stackoverflow.com/questions/13144172/stripping-out-select-querystring-attribute-value-pairs-so-varnish-will-not-vary)  
37. Ignoring GET parameters in Varnish VCL - Server Fault, accessed December 11, 2025, [https://serverfault.com/questions/112531/ignoring-get-parameters-in-varnish-vcl](https://serverfault.com/questions/112531/ignoring-get-parameters-in-varnish-vcl)  
38. Performance Boosting with Varnish Cache - maxcluster, accessed December 11, 2025, [https://maxcluster.de/en/knowledge/blog/article/performance-page-speed-boosting-varnish-cache](https://maxcluster.de/en/knowledge/blog/article/performance-page-speed-boosting-varnish-cache)  
39. Limiting process resource usage in AL2023 using systemd - Amazon Linux 2023, accessed December 11, 2025, [https://docs.aws.amazon.com/linux/al2023/ug/resource-limiting-systemd.html](https://docs.aws.amazon.com/linux/al2023/ug/resource-limiting-systemd.html)  
40. Can't enable jemalloc for MySQL 5.7 - Stack Overflow, accessed December 11, 2025, [https://stackoverflow.com/questions/66314933/cant-enable-jemalloc-for-mysql-5-7](https://stackoverflow.com/questions/66314933/cant-enable-jemalloc-for-mysql-5-7)  
41. MariaDB & Amazon Linux 2: ERROR: ld.so: object '/usr/lib64/libjemalloc.so.1' from LD_PRELOAD cannot be preloaded, accessed December 11, 2025, [https://unix.stackexchange.com/questions/677387/mariadb-amazon-linux-2-error-ld-so-object-usr-lib64-libjemalloc-so-1-fro](https://unix.stackexchange.com/questions/677387/mariadb-amazon-linux-2-error-ld-so-object-usr-lib64-libjemalloc-so-1-fro)