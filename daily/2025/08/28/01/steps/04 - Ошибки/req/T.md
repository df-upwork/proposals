# 1.
## 1.1.
`Aᨀ` ≔ (мой ответ `ꆜ`)

## 1.2.
Содержание `Aᨀ`:
~~~markdown
1) Стратегическая задача, которую вам поручил работодатель — диагностика проблем прошлых запусков ваших pipelines.
Ваше первое возможное заблуждение: попытка провести эту диагностику новым запуском pipeline.
На самом же деле, новый запуск не является первоочередным способом понять, почему конвейеры не работали в прошлом.
Вместо этого в первую очередь следует изучить журналы выполнения прошлых запусков:
1.1) Перейти в Azure Data Factory Studio.
1.2) Открыть вкладку «Monitor» на левой боковой панели.
1.3) В разделе «Pipeline runs» изучить список предыдущих выполнений целевого конвейера. 
Использовать фильтры по имени конвейера (Pipeline name) и статусу (Status, например, «Failed»), чтобы найти интересующие запуски. 
Убедиться, что анализируются запуски типа «Triggered» (производственные запуски), а не «Debug».
1.4) Проанализировать детали сбойного запуска.
1.4.1) Кликнуть на имя конвейера в списке, чтобы перейти к списку «Activity runs» (выполнения действий).
1.4.2) Идентифицировать действие (activity), которое завершилось сбоем.
1.4.3) Изучить детальное сообщение об ошибке. Для этого кликнуть на иконку в колонке «Error» для этого activity.
1.4.4) Изучить входные параметры, которые были использованы при этом запуске.
Для этого найти колонку «Parameters» (на уровне Pipeline run или в верхней части экрана Activity runs) и посмотреть значения, которые были фактически переданы в конвейер.
2) Ваше второе возможное заблуждение: вы ищете причину сбоя работы pipeline только внутри него.
На самом же деле, значительная часть сбоев pipeline связана с внешниими причинами: инфраструктурой и безопасностью, особенно в унаследованных средах.
В частности:
- Аутентификация и Авторизация: истекшие учетные данные или ключи в Linked Services, некорректная настройка Managed Identity, отсутствие доступа к Azure Key Vault или целевым хранилищам.
- Сетевые проблемы: конфигурация брандмауэров (Azure Storage, SQL DB), VNet, Private Endpoints, блокирующие доступ.
- Integration Runtime (IR): проблемы с доступностью, конфигурацией или производительностью Self-Hosted IR.

Игнорирование внешних факторов является критической ошибкой при диагностике сбоев в ADF.
Поэтому нужно провести диагностику этих внешних факторов:
2.1) Перейти на вкладку «Manage» на левой боковой панели.
2.2) Проверить Linked Services:
2.2.1) Перейти в раздел «Linked services».
2.2.2) Идентифицировать все Linked Services, используемые в целевом конвейере (их можно найти в настройках Datasets или Activities).
2.2.3) Для каждого Linked Service открыть его конфигурацию и использовать функцию «Test connection». 
Убедиться, что аутентификация (например, Managed Identity, Service Principal, ключи в Azure Key Vault) настроена корректно и нет сетевых ограничений (Firewall, VNet).
2.3) Проверить Integration Runtimes:
2.3.1) Перейти в раздел «Integration runtimes».
2.3.2) Проверить статус Integration Runtimes, используемых в Linked Services. Убедиться, что они находятся в состоянии «Running», особенно если используются Self-Hosted Integration Runtimes.
3) Далее, нужно идентифицировать и проанализировать Pipeline Parameters
3.1) Перейти на вкладку «Author» на левой боковой панели.
3.2) Найти и открыть целевой конвейер.
3.3) Кликнуть на пустую область холста (canvas) конвейера, чтобы отобразить его общие настройки.
3.4) Перейти на вкладку «Parameters». 
Составить список всех параметров, зафиксировав их «Name», «Type» (например, `String`, `Int`, `Array`, `Object`, `SecureString`) и «Default value» (значение по умолчанию), если оно указано.
Знание типа данных критично, особенно для сложных типов (`Array`, `Object`).
Источник: Microsoft Learn: Parameters and variables in Azure Data Factory.
3.5) Изучить, как параметры используются внутри конвейера.
3.5.1) Выбрать каждое activity на холсте (например, Copy activity, Lookup, Data Flow).
3.5.2) Проверить вкладки настроек (например, «Settings», «Source», «Sink») на предмет использования динамического содержимого (dynamic content).
3.5.3) Идентифицировать выражения (expressions), которые ссылаются на параметры конвейера, используя синтаксис `@pipeline().parameters.<parameterName>`.

4) Затем нужно определить Parameter Sources
Цель: Определить, как конвейер получает параметры в производственной среде (часто автоматически через триггеры), чтобы эмулировать эти значения при ручном тестировании.
4.1) Проанализировать связанные триггеры (Triggers).
4.1.1) Находясь в редакторе конвейера (вкладка «Author»), нажать кнопку «Trigger» на верхней панели и выбрать «New/Edit».
4.1.2) В открывшейся панели изучить конфигурацию существующих триггеров, связанных с этим конвейером.
4.2) Изучить параметры, передаваемые триггером.
4.2.1) Продвигаясь по конфигурации триггера, обратить внимание на шаг, где заполняются параметры конвейера.
4.2.2) Идентифицировать использование системных переменных (System Variables). 
Это выражения, начинающиеся с `@trigger()` или `@triggerBody()`. 
Примеры:
- `@trigger().outputs.windowStartTime` (для Tumbling Window Trigger).
- `@triggerBody().fileName` (для Storage Event Trigger).

Производственные конвейеры часто получают метаданные (например, временные метки или имена файлов) автоматически от триггеров через System Variables. 
При ручном тестировании (Debug) пользователь должен эмулировать эти значения самостоятельно. 
Незнание этой зависимости является частой причиной проблем с ручным запуском.
4.3) Определить значения для тестирования. 
Использовать комбинацию значений из исторических запусков (пункт 1.4.4 выше), значений по умолчанию (пункт 3.4) и эмулированных значений триггеров (пункт 4.2.2) для формирования набора тестовых входных данных.
5) Выполнить тестовый запуск (Test Run)
Цель: Запустить конвейер с корректными параметрами в контролируемом режиме и проверить его работоспособность.
5.1) Находясь на вкладке «Author» в редакторе целевого конвейера, начать выполнение в режиме отладки, нажав кнопку «Debug» на верхней панели инструментов.
Обоснование: 
Режим «Debug» используется для тестирования текущей версии конвейера на холсте (включая неопубликованные изменения) и позволяет наблюдать за выполнением в реальном времени без необходимости публикации (Publish). 
Он предпочтителен для итеративной разработки и тестирования.
5.2) В открывшейся панели (обычно называется «Pipeline Debug» или «Pipeline run parameters») ввести значения для параметров, определённые на пункте 4.3 выше.
5.3) Соблюдать корректный формат ввода данных:
5.3.1) При эмуляции временных меток триггера использовать формат ISO 8601 (например, `2025-08-27T10:00:00Z`).
5.3.2) Для параметров типа `Array` ввести значение в формате JSON массива. 
Например: `["item1", "item2"]`.
5.3.3. Для параметров типа Object ввести значение в формате JSON объекта. 
Например: `{"key1": "value1", "key2": "value2"}`.
Обоснование: Корректный ввод параметров, особенно сложных типов (`Array`, `Object`), необходим для успешного запуска. 
Неправильный формат JSON приведет к ошибкам валидации еще до начала выполнения.
5.4) Нажать «OK», чтобы начать выполнение.
5.5) Наблюдать за ходом выполнения на вкладке «Output» под холстом конвейера. 
Проверить входные (Input) и выходные (Output) данные для каждого Activity после его завершения, чтобы убедиться, что параметры были интерпретированы корректно.
~~~

# 2. `᛭T`
Проанализируй `Aᨀ`:
1) Есть ли там логические ошибки?
2) Есть ли там фактические ошибки?
3) Упущено ли в `Aᨀ` нечто важное?

# 3. Требования к твоему ответу
## 3.1.
Отвечай на русском языке.
## 3.2.
Мой вопрос не пересказывай.
## 3.3.
Уже сформулированную мной информацию не пересказывай.
## 3.4.
Писать свою версию `Aᨀ` не нужно: просто укажи свои замечания по пунктам.
## 3.5.
До и после списка замечаний ничего не пиши.
## 3.6.
Нумерация замечаний должна быть сквозной.