# 1.
## 1.1. 
`L_SOURCE` ≔ (Русский язык)

## 1.2. 
`L_TARGET` ≔ (English)

# 2.
## 2.1.
`D` ≔ (мой ответ `ꆜ`)

## 2.2.
Содержание `D`:
~~~markdown
1) Для диагностики прошлых сбоев Azure Data Factory предоставляет функциональность повторного запуска («Rerun») на вкладке «Monitor».
Эта функциональность позволяет перезапустить pipeline с использованием точных исторических параметров и конфигурации (Snapshot), которые использовались во время сбойного запуска.
Это часто является самым приоритетным способом проверки временных проблем (e.g., таймауты сети) или воспроизведения сбоя.
Этот этап, наряду с анализом журналов, я описываю в разделе 4 ниже.
Если же требуется запустить pipeline с новыми параметрами (e.g., для тестирования исправлений или обработки новых данных), то необходимо понимать логику его работы и требования к входным данным.
Это я описываю в разделах 7-10 ниже.
2) Вашим вероятным упущением является сужение области поиска источника сбоя до проблемного pipeline.
На самом же деле, значительная часть сбоев pipeline связана с внешними причинами: инфраструктурой и безопасностью, особенно в унаследованных средах.
В частности:
- Аутентификация и Авторизация: истекшие учетные данные или ключи в Linked Services, некорректная настройка Managed Identity, отсутствие доступа к Azure Key Vault или целевым хранилищам.
- Сетевые проблемы: конфигурация брандмауэров (Azure Storage, SQL DB), VNet, Private Endpoints, блокирующие доступ.
- Integration Runtime (IR): проблемы с доступностью, конфигурацией или производительностью Self-Hosted IR.

Игнорирование внешних факторов является критической ошибкой при диагностике сбоев в Azure Data Factory.
Анализ внешних факторов — следующий по приоритетности этап диагностики сбоев после анализа журналов.
Я описываю его в разделе 5 ниже.

3) Самое же главное, с чего вообще надо начать подобную диагностику — определенить конфигурацию Source Control и режима работы Azure Data Factory.
Проще говоря, надо понять, как управляются версии кода (versioning) и как соотносятся версия на холсте («Author» canvas) и опубликованная (Published) версия, которая используется в производственных запусках.
Это критически важно для корректной диагностики исторических сбоев (Раздел 3) и анализа текущей логики (Раздел 5).
Для этого надо проверить конфигурацию Git:
3.1) Перейти на вкладку «Manage» на левой боковой панели.
3.2) Перейти в раздел «Source control» → «Git configuration» или проверить наличие элементов управления Git (e.g., селектор веток) на верхней панели ADF Studio.
3.3) Определить режим работы ADF.
3.3.1) `Live Mode` (Authoring directly against the data factory service): Если интеграция с Git не настроена.
В этом режиме изменения на холсте («Author» canvas) можно сохранить с помощью кнопок «Save» или «Save all».
Эти сохраненные изменения доступны для запусков в режиме отладки («Debug» runs).
Однако эти изменения не активируются для запусков по триггеру («Triggered» runs) до момента их публикации непосредственно в службу Data Factory с помощью кнопки «Publish all».
Только опубликованная версия является версией, используемой в «Triggered» runs.
3.3.2) `Git Mode` (e.g., Azure DevOps Git или GitHub): Если конфигурация указывает на репозиторий.
В этом режиме изменения на холсте («Author» canvas) сохраняются в выбранной ветке Git (e.g., feature branch) с помощью «Save» или «Save all».
Эти изменения не применяются к производственной службе (и не используются в «Triggered» runs) до момента публикации («Publish») из Collaboration branch.

4) Анализ журналов
4.1) Перейти в Azure Data Factory Studio.
4.2) Открыть вкладку «Monitor» на левой боковой панели.
4.3) В разделе «Pipeline runs» изучить список предыдущих выполнений целевого конвейера.
Использовать фильтры по имени конвейера («Pipeline name») и статусу (Status, например, «Failed»), чтобы найти интересующие запуски.
Убедиться, что анализируются запуски типа «Triggered».
Запуски типа «Triggered» являются производственными запусками и всегда используют ту версию конвейера, которая была опубликована (Published) в службе Azure Data Factory на момент запуска.
Это соответствует опубликованной версии в `Live Mode` (пункт 3.3.1 выше) или версии, опубликованной из Collaboration branch в `Git Mode` (пункт 3.3.2).
Запуски типа «Debug» используют текущую версию конвейера на холсте разработки («Author» canvas).
В `Git Mode` это версия из текущей выбранной ветки.
В `Live Mode` это текущая версия на холсте, которая может содержать неопубликованные изменения.
4.4) Проанализировать детали сбойного запуска.
4.4.1) Кликнуть на имя конвейера в списке, чтобы перейти к списку «Activity runs» (выполнения действий).
4.4.2) Идентифицировать действие (activity), которое завершилось сбоем.
4.4.3) Изучить детальное сообщение об ошибке. 
Для этого кликнуть на иконку в колонке «Error» для этого activity.
4.4.4) Изучить входные параметры, которые были использованы при этом запуске.
Для этого найти колонку «Parameters» (на уровне Pipeline run или в верхней части экрана Activity runs) и посмотреть значения, которые были фактически переданы в конвейер.
4.5) Выполнить повторный запуск («Rerun») сбойного выполнения.
Цель: Проверить, была ли причина сбоя временной (e.g., таймаут сети, недоступность ресурса) или она является постоянной (e.g., ошибка конфигурации, логики или данных).
Функциональность «Rerun» использует те же самые входные параметры (п. 4.4.4) и ту же самую конфигурацию pipeline (Snapshot, см. п. 4.6), которые использовались в оригинальном запуске.
4.5.1) Повторный запуск с начала pipeline.
Находясь в списке «Pipeline runs» (п. 4.3), навести курсор на сбойный запуск и нажать кнопку «Rerun».
4.5.2) Повторный запуск с неудавшегося действия («Rerun from failed activity»).
Это предпочтительный вариант для многошаговых конвейеров, позволяющий пропустить успешно завершенные шаги и начать выполнение непосредственно с действия, которое завершилось сбоем.
Находясь в представлении «Activity runs» (п. 4.4.1), использовать опцию «Rerun from failed activity» (на верхней панели) или «Rerun from activity» (для конкретного действия).
4.5.3) Проанализировать результат повторного запуска.
Если повторный запуск успешен, вероятно, причина оригинального сбоя была временной.
Если повторный запуск также завершается сбоем с той же ошибкой, это указывает на постоянную проблему, требующую дальнейшего анализа (начиная с п. 4.6).
4.6) Проанализировать снимок (Snapshot) конфигурации конвейера, использованный во время сбойного запуска.
Цель: Увидеть точную конфигурацию и код, которые привели к сбою, так как текущая версия конвейера может отличаться.
4.6.1) Находясь в представлении «Activity runs» (пункт 4.4.1), найти возможность просмотра кода конвейера.
Обычно это иконка с всплывающей подсказкой «Code» (в виде фигурных скобок), расположенная на верхней панели рядом с названием конвейера.
4.6.2) Изучить JSON-определение (JSON definition) конвейера и связанных ресурсов (e.g., Datasets) в том виде, в котором они существовали на момент этого конкретного запуска.

5) Анализ внешних факторов
5.1) Перейти на вкладку «Manage» на левой боковой панели.
5.2) Проверить Linked Services:
5.2.1) Перейти в раздел «Linked services».
5.2.2) Идентифицировать все Linked Services, используемые в целевом конвейере (их можно найти в настройках Datasets или Activities).
5.2.3) Для каждого Linked Service открыть его конфигурацию и использовать функцию «Test connection».
Это позволит проверить базовую возможность подключения к ресурсу из соответствующего Integration Runtime.
Важное примечание:
Функция «Test connection» выполняется не в контексте вашей учетной записи пользователя.
Она выполняется на инфраструктуре Integration Runtime (Azure IR или Self-Hosted IR), указанного в Linked Service.
Она использует учетные данные, определенные в конфигурации Linked Service (e.g., Managed Identity, Service Principal, Account Key).
Успешный «Test connection» не гарантирует работоспособность во время выполнения pipeline (Pipeline run) по следующим причинам:
5.2.3.1) Сетевые различия.
Могут существовать различия в сетевой конфигурации между интерактивным тестированием и автоматическим выполнением.
Это особенно актуально при использовании Self-Hosted IR, Virtual Networks (VNet) или Private Endpoints.
Правила брандмауэров (Firewall rules), Network Security Groups (NSG) или маршрутизация могут отличаться, блокируя доступ во время выполнения.
5.2.3.2) Недостаточные разрешения.
Успешный тест проверяет только возможность аутентификации и сетевого подключения.
Он не гарантирует наличие разрешений для выполнения конкретных операций с данными (e.g., чтение таблицы, выполнение Stored Procedure), требуемых в Pipeline (см. пункт 5.2.5).
5.2.4) Определить метод аутентификации (Authentication method), используемый в Linked Service (например, System-Assigned Managed Identity, Service Principal, Account Key, SQL Authentication).
5.2.5) Верифицировать права доступа субъекта безопасности ADF.
Необходимо проверить разрешения на двух различных уровнях, так как успешная аутентификация не означает наличие необходимой авторизации для доступа к данным.
5.2.5.1) Уровень Azure RBAC (Role-Based Access Control).
Если используется Managed Identity или Service Principal, необходимо убедиться, что этому субъекту назначены необходимые роли Azure RBAC для доступа к данным (Data Plane) на целевом ресурсе.
E.g., роль «Storage Blob Data Contributor» для Azure Storage.
Эта проверка выполняется вне ADF Studio, в настройках «Access Control (IAM)» целевого ресурса на портале Azure.
5.2.5.2) Уровень внутренних разрешений целевой системы (Data Store Permissions).
Для систем, таких как Azure SQL Database и SQL Pools в Azure Synapse Analytics, стандартный Azure RBAC (упомянутый в п. 5.2.5.1) не управляет детальным доступом к объектам внутри базы данных (Data Plane).
Даже если аутентификация происходит через Microsoft Entra ID (Azure AD), авторизация управляется через разрешения T-SQL.
Необходимо убедиться, что субъект безопасности имеет необходимые разрешения внутри целевой системы.
Субъект безопасности (e.g., Managed Identity) должен быть добавлен как пользователь базы данных (database user), например, с использованием `CREATE USER […] FROM EXTERNAL PROVIDER`.
Этому пользователю должны быть назначены соответствующие роли базы данных (e.g., `db_datareader`, `db_datawriter`) или предоставлены прямые разрешения (GRANT).
Если pipeline выполняет Stored Procedures, пользователю также требуется разрешение `EXECUTE`.
Эта проверка выполняется путем подключения к базе данных с использованием инструментов управления (e.g., SQL Server Management Studio (SSMS) или Azure Data Studio).
5.3) Проверить Integration Runtimes:
5.3.1) Перейти в раздел «Integration runtimes».
5.3.2) Проверить статус Integration Runtimes, используемых в Linked Services. 
Убедиться, что они находятся в состоянии «Running», особенно если используются Self-Hosted Integration Runtimes.

6) Синтез результатов диагностики и определение причин исторических сбоев
Цель: Выполнить вашу стратегическую задачу — определить, почему конвейеры не работали в прошлом, на основе собранных данных.
6.1) Сопоставить детальные сообщения об ошибках (раздел 4) с результатами проверки среды (раздел 5).
Детальные сообщения об ошибках из исторических запусков  являются первичным источником для диагностики прошлых сбоев.
Необходимо учитывать временной контекст при интерпретации результатов текущей проверки среды.
Результаты «Test connection» или статуса IR отражают текущее состояние системы.
Это состояние могло измениться с момента исторического сбоя (e.g., обновление истекших учетных данных, изменение сетевых правил).
Нельзя полагаться исключительно на текущее состояние для диагностики прошлых проблем.
6.1.1) Если историческая ошибка указывает на проблемы с подключением (e.g., «Authentication failed», «Connection timed out»), и текущий «Test connection» также завершается неудачей, вероятно, существует постоянная проблема конфигурации инфраструктуры или безопасности.
6.1.2) Если историческая ошибка указывает на проблемы с подключением, но текущий «Test connection» (п. 2.2.3) успешен, это может указывать на то, что проблема была временной (e.g., таймаут сети, недоступность ресурса) или что конфигурация среды была исправлена с момента сбоя.
6.2) Проанализировать входные параметры, использованные при сбойных запусках. 
Определить, могли ли сбои быть вызваны некорректными или неожиданными данными, переданными в конвейер (например, неверный формат даты, несуществующий путь).
6.3) Идентифицировать паттерны сбоев. 
Являются ли сбои постоянными (часто указывает на проблему конфигурации или доступа) или периодическими/случайными (часто указывает на проблемы производительности, блокировки ресурсов или зависимость от специфических данных).
6.4) Сформулировать выводы о корневой причине (Root Cause) исторических сбоев и классифицировать её (например: аутентификация, сеть, логика конвейера, качество данных).

7) Идентификация и анализ pipeline parameters
7.1) Перейти на вкладку «Author» на левой боковой панели для анализа текущей разрабатываемой версии конвейера.
7.1.1) Если фабрика работает в `Git Mode`, убедиться, что в селекторе веток выбрана корректная ветка для анализа (обычно Collaboration branch или актуальная feature branch).
7.1.2) Если фабрика работает в `Live Mode`, проверить наличие индикатора неопубликованных изменений (e.g., активность кнопки «Publish All»).
7.2) Найти и открыть целевой конвейер.
Важное примечание: Необходимо учитывать, что эта версия на холсте может отличаться от опубликованной версии, которая анализировалась в разделе 4.
7.3) Кликнуть на пустую область холста (canvas) конвейера, чтобы отобразить его общие настройки.
7.4) Перейти на вкладку «Parameters». 
Составить список всех параметров, зафиксировав их «Name», «Type» (например, `String`, `Int`, `Array`, `Object`, `SecureString`) и «Default value» (значение по умолчанию), если оно указано.
Знание типа данных критично, особенно для сложных типов (`Array`, `Object`).
7.5) Изучить, как параметры используются внутри конвейера (Parameter Usage Analysis).
Цель: Проследить поток данных от параметров конвейера до конечных ресурсов (Linked Services, Datasets, Activities) для понимания динамической конфигурации.
7.5.1) Анализ использования в Activities.
7.5.1.1) Выбрать каждое activity на холсте (например, Copy activity, Lookup, Data Flow).
7.5.1.2) Проверить вкладки настроек (например, «Settings», «Source», «Sink») на предмет использования динамического содержимого (dynamic content).
7.5.1.3) Идентифицировать выражения (expressions), которые ссылаются на параметры конвейера напрямую, используя синтаксис `@pipeline().parameters.<parameterName>`.
7.5.2) Анализ использования в Datasets.
Многие Activities (e.g., Copy, Lookup, Data Flow) используют Datasets для определения источника (Source) и приемника (Sink).
Конвейер может передавать свои параметры в параметры Dataset.
7.5.2.1) Для каждого activity, использующего Dataset (см. п. 7.5.1), проверить конфигурацию Source или Sink.
7.5.2.2) Идентифицировать значения, передаваемые в «Dataset properties» (или «Parameters» в зависимости от типа Activity).
Определить, являются ли эти значения статическими или динамическими выражениями, ссылающимися на параметры конвейера.
7.5.2.3) Открыть конфигурацию соответствующего Dataset (кнопка «Open»).
7.5.2.4) В Dataset перейти на вкладку «Parameters», чтобы увидеть список параметров, которые он ожидает.
7.5.2.5) В Dataset перейти на вкладку «Connection».
Изучить, как параметры Dataset используются для динамической конфигурации свойств (e.g., `File path`, `Table name`), используя синтаксис `@dataset().<datasetParameterName>`.
7.5.3) Анализ использования в Linked Services.
Datasets используют Linked Services для подключения к хранилищам данных.
Dataset может передавать свои параметры в параметры Linked Service.
7.5.3.1) В конфигурации Dataset (вкладка «Connection», п. 7.5.2.5), изучить раздел «Linked service properties».
Идентифицировать значения, передаваемые в параметры Linked Service.
Определить, ссылаются ли они на параметры Dataset.
7.5.3.2) Открыть конфигурацию соответствующего Linked Service (перейти в «Manage» → «Linked services» или использовать редактирование из Dataset).
7.5.3.3) В Linked Service изучить раздел «Parameters».
7.5.3.4) Изучить, как параметры Linked Service используются в строке подключения (`Connection string`), URL или других свойствах подключения (e.g., `Database name`, `Secret name` для Azure Key Vault), используя синтаксис `@linkedService().<linkedServiceParameterName>`.
7.6) Сравнить текущую версию конвейера со снимком исторического запуска.
Цель: Идентифицировать расхождения между кодом, который вызвал сбой, и кодом, доступным для анализа и тестирования.
7.6.1) Получить JSON-представление текущей версии конвейера.
Для этого использовать кнопку «Code» (в виде фигурных скобок) на верхней панели вкладки «Author».
7.6.2) Сопоставить это JSON-представление с JSON-конфигурацией из снимка исторического запуска (п. 4.5.2).
7.6.3) Идентифицировать любые различия в логике, структуре, expressions или конфигурации activities и parameters.
7.6.4) Если различия существуют, дальнейший анализ логики (п. 7.5) и тестовый запуск (раздел 10 ниже) должны учитывать эти различия.

8) Идентификация parameter sources
Цель: Определить, как конвейер получает параметры в производственной среде (через Triggers или от родительского конвейера через `Execute Pipeline` activity), чтобы эмулировать эти значения при ручном тестировании.
8.1.1) Находясь в редакторе конвейера (вкладка «Author»), нажать кнопку «Trigger» на верхней панели и выбрать «New/Edit».
8.1.2) В открывшейся панели изучить конфигурацию существующих триггеров, связанных с этим конвейером.
8.2) Изучить параметры, передаваемые триггером.
8.2.1) Продвигаясь по конфигурации триггера, обратить внимание на шаг, где заполняются параметры конвейера.
8.2.2) Идентифицировать использование системных переменных (System Variables). 
Это выражения, начинающиеся с `@trigger()` или `@triggerBody()`. 
Примеры:
- `@trigger().outputs.windowStartTime` (для Tumbling Window Trigger).
- `@triggerBody().fileName` (для Storage Event Trigger).

Производственные конвейеры часто получают метаданные (например, временные метки или имена файлов) автоматически от триггеров через System Variables. 
При ручном тестировании (Debug) пользователь должен эмулировать эти значения самостоятельно. 
Незнание этой зависимости является частой причиной проблем с ручным запуском.
8.3) Проанализировать родительские конвейеры (Parent Pipelines) и `Execute Pipeline` activity.
Цель: Определить, вызывается ли целевой конвейер другим конвейером и какие параметры при этом передаются.
8.3.1) Идентифицировать Parent Pipelines.
8.3.1.1) Находясь в редакторе целевого конвейера (вкладка «Author»), открыть панель свойств конвейера (иконка «Properties»).
8.3.1.2) Перейти на вкладку «Related».
8.3.1.3) В разделе «Pipelines» изучить список конвейеров, которые ссылаются на текущий (используют `Execute Pipeline` activity для его вызова).
8.3.1.4) В качестве альтернативы или для перепроверки использовать глобальный поиск (Global Search) в Azure Data Factory Studio по имени целевого конвейера.
8.3.2) Изучить конфигурацию `Execute Pipeline` activity в Parent Pipeline.
Для каждого Parent Pipeline, идентифицированного в п. 8.3.1:
8.3.2.1) Открыть Parent Pipeline на вкладке «Author».
8.3.2.2) Найти `Execute Pipeline` activity, которое вызывает целевой конвейер.
8.3.2.3) Выбрать это activity и перейти на вкладку «Settings».
8.3.2.4) В разделе «Parameters» изучить, какие значения или выражения (dynamic content) передаются в параметры целевого конвейера.
8.3.3) Определить источники значений в Parent Pipeline.
Значения могут быть статическими, производными от параметров Parent Pipeline (e.g., `@pipeline().parameters.<ParentParameterName>`), переменных (variables) или выходов (Outputs) предыдущих activities (e.g., `@activity('<ActivityName>').output.<PropertyName>`).
8.4) Определить значения для тестирования.
Использовать комбинацию значений из исторических запусков (раздел 4), значений по умолчанию (пункт 7.4), эмулированных значений триггеров (пункт 8.2.2) и значений, передаваемых из Parent Pipelines (пункт 8.3.3) для формирования набора тестовых входных данных.

9) Обеспечение безопасности тестового запуска (Safety Check)
Цель: Предотвратить случайное повреждение, модификацию, удаление или дублирование производственных данных при запуске унаследованного конвейера.
Обоснование: 
Запуск конвейера без полного понимания его логики и конфигурации приемников данных (Sinks) несет критические риски для целостности данных.
9.1) Активировать сессию «Data Flow Debug» (если применимо).
Цель: Обеспечить среду выполнения Spark для `Data Flow` activities во время отладки и интерактивного анализа.
9.1.1) Определить, содержит ли конвейер действия типа `Data Flow activity`.
9.1.2) Если `Data Flow activity` присутствуют, для их выполнения в режиме «Debug» (раздел 10) или использования «Data Preview» (п. 9.4.2.1) требуется активная сессия отладки.
9.1.3) На верхней панели инструментов (toolbar) ADF Studio активировать переключатель «Data Flow Debug».
9.1.4) Выбрать конфигурацию `Integration Runtime` и установить `Time to live` (TTL).
9.1.5) Дождаться готовности кластера (индикатор статуса станет зеленым).
Запуск кластера (cold boot) может занять несколько минут.
9.2) Идентифицировать операции модификации данных и приемники (Sinks).
Проанализировать все действия (Activities) в конвейере, которые потенциально могут изменять данные во внешних системах:
9.2.1) `Copy activity` (изучить вкладку «Sink»).
9.2.2) `Data Flow` (изучить все Sinks внутри потока данных).
9.2.3) `Stored Procedure activity` и `Script activity` (могут выполнять DML/DDL операции: INSERT, UPDATE, DELETE, TRUNCATE).
9.2.4) `Delete activity`.
9.2.5) `Web`, `Webhook`, `Custom activities` (если они вызывают API для модификации данных).

9.3) Проанализировать целевые системы.
Для каждого действия из пунктов раздела 9.2 определить, куда именно будут записываться или где будут удаляться данные.
Изучить конфигурацию целевых Datasets и Linked Services. 
Определить, указывают ли они на производственные (Production) системы.

9.4) Применить стратегию безопасного запуска.
Если конвейер может повлиять на производственные данные, необходимо применить одну или несколько мер безопасности. 
Методы приведены в порядке предпочтения.

9.4.1) Стратегия 1: Перенаправление записи в безопасное место (Наиболее надежный метод).
9.4.1.1) Через параметры: Если конфигурация приемника (путь, имя таблицы, строка подключения) параметризована (см. раздел 3), убедиться, что при запуске (раздел 10) будут использованы значения, указывающие на тестовую среду (например, папка `test`, схема `dev`).
9.4.1.2) Через временное изменение конфигурации: Если параметры не используются, временно изменить настройки Datasets или Linked Services, чтобы они указывали на тестовую среду. 
Важно: Не сохранять и не публиковать (Publish) эти изменения.

9.4.2) Стратегия 2: Использование механизмов изоляции и контроля.
9.4.2.1) Для `Data Flow` activities: Использовать «Data Preview» для инспекции данных.
Это требует активной сессии «Data Flow Debug» (пункт 9.1).
В редакторе `Data Flow` выбрать transformation, непосредственно предшествующую `Sink`.
Перейти на вкладку «Data Preview» и нажать «Refresh», чтобы получить интерактивный снимок (interactive snapshot) данных.
Это позволяет проверить логику трансформаций без записи данных в целевую систему.
Критическое примечание о Pipeline Debug Run:
Существует фундаментальное различие между интерактивной отладкой («Data Preview») и запуском конвейера в режиме «Debug» (раздел 10).
Утверждение о том, что данные не записываются в `Sink`, справедливо только для «Data Preview» внутри редактора `Data Flow`.
При запуске всего конвейера в режиме «Debug», `Data Flow activity` будет выполнять запись в `Sink` transformations.
Поэтому для предотвращения записи при запуске конвейера необходимо использовать другие стратегии (например, п. 9.4.1 или 9.4.2.2).
9.4.2.2) Для Activities на холсте: Использовать точки останова (Breakpoints) для итеративной отладки (Iterative Debugging).
Установить точку останова на действии (activity), перед выполнением которого необходимо приостановить конвейер.
Для этого кликнуть на пустой красный кружок в правом верхнем углу activity (опция «Debug Until»).
Кружок изменится на заполненный красный кружок (filled red circle).
При запуске в режиме «Debug» конвейер выполнится только до activity с точкой останова.
Само activity с точкой останова (breakpoint activity) не включается в тестовый запуск.
Это позволяет проверить промежуточные результаты и входные данные (Input) предшествующих действий перед выполнением потенциально опасных операций.
9.4.2.3) Деактивация действий: Если анализ записи данных не является целью теста, временно деактивировать (кнопка «Deactivate» на верхней панели) действия, выполняющие модификацию.

9.4.3) Стратегия 3: Минимизация воздействия (Использовать с осторожностью).
9.4.3.1) Ограничение объема данных.
Применить методы ограничения количества обрабатываемых строк, специфичные для типа действия.
9.4.3.1.1) Для `Data Flow` activities: Открыть «Debug Settings» на панели инструментов холста `Data Flow`.
Установить «Row limit» на малое значение (e.g., 100-1000).
Эта настройка ограничивает количество строк, считываемых из источников (`Sources`) только для текущей debug session.
Это требует активной сессии «Data Flow Debug» (пункт. 9.1).
9.4.3.1.2) Для `Copy activity` и `Lookup activity`: Настройка «Row limit» из п. 9.4.3.1.1 не применяется.
Необходимо временно модифицировать конфигурацию источника (Source).
E.g., если источником является база данных SQL, модифицировать запрос (Query), добавив `TOP N` или `LIMIT` (e.g., `SELECT TOP 100 * FROM schema.table`).
Предупреждение:
Ограничение объема данных ограничивает чтение из источника, но не обеспечивает полной безопасности, если конвейер выполняет операции, не зависящие от объема данных (e.g., `TRUNCATE TABLE` через «Pre-copy script» или удаление файлов через `Delete activity`).

9.5) Условие отмены запуска (Go/No-Go Decision).
Если ни один из методов п. 9.4 не может гарантировать безопасность производственных данных, не выполнять запуск (раздел 10). 
В этом случае требуется клонирование (Clone) и модификация конвейера для тестирования в изолированной среде.

10) Test Run
Цель: Запустить конвейер с корректными параметрами в контролируемом режиме и проверить его работоспособность.
10.1) Находясь на вкладке «Author» в редакторе целевого конвейера, выбрать стратегию запуска и начать выполнение в режиме отладки («Debug»).
Обоснование:
Режим «Debug» используется для тестирования текущей версии конвейера на холсте (включая неопубликованные изменения) и позволяет наблюдать за выполнением в реальном времени без необходимости публикации (Publish).
10.1.1) Выбор стратегии: Итеративная отладка (Iterative Debugging) или Полный запуск.
Для сложных или унаследованных конвейеров рекомендуется использовать итеративную отладку для пошагового и более безопасного анализа.
10.1.2) Для итеративной отладки («Debug Until»): Убедиться, что установлены точки останова (Breakpoints) (раздел 9).
Нажать кнопку «Debug».
Конвейер выполнится только до первого activity с точкой останова.
10.1.3) Для полного запуска: Убедиться, что точки останова не установлены (или будут проигнорированы, если требуется выполнить конвейер целиком несмотря на них).
Нажать кнопку «Debug».
10.2) В открывшейся панели (обычно называется «Pipeline Debug» или «Pipeline run parameters») ввести значения для параметров, определённые в разделе 8.
10.3) Соблюдать корректный формат ввода данных:
10.3.1) При эмуляции временных меток триггера использовать формат ISO 8601 (например, `2025-08-27T10:00:00Z`).
10.3.2) Для параметров типа `Array` ввести значение в формате JSON массива. 
Например: `["item1", "item2"]`.
10.3.3) Для параметров типа Object ввести значение в формате JSON объекта. 
Например: `{"key1": "value1", "key2": "value2"}`.
Обоснование: Корректный ввод параметров, особенно сложных типов (`Array`, `Object`), необходим для успешного запуска. 
Неправильный формат JSON приведет к ошибкам валидации еще до начала выполнения.
10.4) Нажать «OK», чтобы начать выполнение.
10.5) Наблюдать за ходом выполнения на вкладке «Output» под холстом конвейера. 
Проверить входные (Input) и выходные (Output) данные для каждого Activity после его завершения, чтобы убедиться, что параметры были интерпретированы корректно.
~~~

# 3.
## 3.1.
`D2` ≔ (начальная часть `D`, переведённая с `L_SOURCE` на `L_TARGET`)

## 3.2.
Содержание `D2`:
~~~markdown
~~~

# 4.
## 4.1.
`F` ≔ (фрагмент `D`)

## 4.2.
Содержание `F`:
~~~markdown
STUB
~~~

# 5. `᛭T`
Переведи `F` на `L_TARGET`, с учётом:
- контекста `D`
- `D2`: уже переведённой части `D`
- `᛭O`

# 6. Правила перевода
## 6.1.
Переводи именно в той стилистике, как написано на `L_SOURCE`.
Не делай перевод более вежливым, чем оригинал.

## 6.2.
Те предложения, которые сейчас полностью на `L_TARGET` — оставь без изменения.

## 6.3.
### 6.3.1.
Не используй Markdown: только plain text.
### 6.3.2.
При этом можно и нужно использовать то форматирование, которое уже есть в оригинале: его не убирай.
### 6.3.3.
Не форматируй веб-ссылки посредством Markdown, если они не отформатированы так в оригинале. 
Например, не пиши так:
```
[https://www.eca.web.tr/eca-nita-esnek-uclu-eviye-bataryasi-beyaz-102118110-308](https://www.eca.web.tr/eca-nita-esnek-uclu-eviye-bataryasi-beyaz-102118110-308)
```
если в оригинале скобок `[]()` нет.

## 6.4.
Форматируй перевод в точности как оригинал. 
В частности:
*) каждый абзац должен содержать ровно одно предложение
*) между абзацами не должно оставаться пустых строк.
*) кавычки используй те же, что и в оригинале: «» и ``.

## 6.5.
Не используй сокращения типа «don't». Все подобные фразы пиши полностью: «do not».

## 6.6.
Не используй жаргон.
Вместо этого используй официальные термины.
### 6.6.1.
В частности, фразы в кавычках используй только в том случае, когда они являются точными цитатами.
Не используй фразы в кавычках для применения жаргонных фраз.
Например, следующий фрагмент текста недопустим, потому что там используется жаргонная фраза «пролетел»: 
```
Например, код, который пушит данные о покупке, подключён асинхронно и загружается с небольшой задержкой, а триггер уже «пролетел».
```

## 6.7.
При обсуждении программного обеспечения используй точные официальные термины на английском языке: именно в том виде, как они указаны в официальной англоязычной документации к этому программному обеспечению.

## 6.8.
Не используй «you need» и другие подобные обращённые к клиенту фразы, перекладывающие действия на него.
Помни: я пишу клиенту или потенциальному клиенту.
Делать в любом случае буду я, а не клиент.
Вместо «you need» используй 2 альтернативы:
### 6.8.1.
Нейтральные фразы типа «it is necessary».
### 6.8.2.
Глаголы в неопределённой форме.
Например, во фрагменте ниже использованы подобные глаголы «set up», «create»:
```
1.2) Set up the transfer of login events from WordPress to Power BI using Fabric / OneLake.
1.2.1) Set up a «Data Pipeline» from the WordPress database table that stores login events (see point 1.1) to Fabric / OneLake.
1.2.2) Set up a connection from Power BI to Fabric / OneLake to pass login events.
1.3) Create the data model in Power BI.
```
Обрати внимание, в этом фрагменте не говорится, кто именно будет выполнять описанные действия: ответственность не перекладывается на клиента, в отличие от «you need».

## 6.9.
Никогда не переводи понятие «сайт» / «веб-сайт» как «site». 
Вместо этого используй форму «website»: это является более профессиональным.

## 6.10.
Никогда не переводи понятие «пункт нумерованного списка» как «item».
Всегда переводи это как «point».

## 6.11.
Вместо «for example» используй «e.g.».
При этом не забывай, что в начале предложения эта фраза должна начинатся с заглавной буквы: «E.g.»