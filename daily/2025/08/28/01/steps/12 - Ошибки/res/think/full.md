1. (Логическая ошибка: Стратегия) Критическое несоответствие ответа профилю клиента и формату запроса. Контекст (`O.md` §2.3, §7.2) указывает, что клиент обладает недостаточными знаниями ADF («i just don't know how to go about it») и запрашивает интерактивную помощь («show me how to run it»). `Aᨀ` представляет собой исчерпывающее, но крайне сложное техническое руководство, предполагающее высокий уровень экспертизы. Предоставление такого документа новичку вместо предложения о совместной рабочей сессии (например, звонок с демонстрацией экрана) является стратегически неверным.
2. (Логическая ошибка: Структура) Инвертированная структура и нарушение приоритетов. Основная и срочная проблема клиента (`P†`) — незнание того, как запустить параметризованный конвейер. `Aᨀ` адресует этот вопрос только в разделах 7-10, вынуждая клиента сначала разбираться в комплексной диагностике и конфигурации (разделы 1-6).
3. (Фактическая ошибка) Ошибка в описании `Live Mode` (п. 3.3.1). Утверждается, что в `Live Mode` изменения сохраняются с помощью кнопок «Save» или «Save all». Это неверно. Эти кнопки присутствуют только в `Git Mode`. В `Live Mode` (без интеграции с Git) единственным механизмом сохранения изменений в службе Data Factory является кнопка «Publish all».
4. (Важное упущение) Отсутствие проверки разрешений пользователя (`ꆜ`) (Azure RBAC). `Aᨀ` неявно предполагает наличие у клиента необходимых разрешений (например, «Data Factory Contributor») для выполнения Rerun, Debug, Test Connection. У нового сотрудника доступ может быть ограничен (например, ролью «Reader»), что сделает выполнение инструкций невозможным.
5. (Важное упущение) Не учтена политика хранения данных (Data Retention Policy) (Раздел 4). Анализ исторических сбоев на вкладке «Monitor» ограничен стандартным сроком хранения журналов в ADF (обычно 45 дней). Если сбои произошли ранее, журналы и снимки будут недоступны.
6. (Важное упущение) Маскирование конфиденциальных данных в журналах (п. 4.4.4). Не указано, что если параметр имеет тип `SecureString` или если для Activity активированы настройки «Secure input»/«Secure output», значения будут маскированы (*****) в журналах «Monitor». Это делает невозможным увидеть фактические значения, использованные при сбойном запуске.
7. (Фактическая неточность/Упущение) Неполное описание контекста безопасности при отладке (Debug Run) с использованием Azure Key Vault (AKV). В `Aᨀ` не указано, что в Debug Run (Раздел 10) доступ к AKV для извлечения секретов часто осуществляется в контексте интерактивного пользователя (`ꆜ`), а не Managed Identity фабрики (которая используется в Triggered Run). Если у пользователя нет разрешений на чтение секретов в AKV, Debug Run завершится сбоем.
8. (Важное упущение) Недостаточная детализация диагностики Azure Key Vault (AKV) (Раздел 5.2).
8.1. Необходимость учета двух моделей доступа к AKV (п. 5.2.5.1): Azure RBAC и «Access Policies». Проверки Azure RBAC недостаточно, если используются Access Policies; нужно проверить разрешения (например, Secret Get/List) непосредственно в конфигурации «Access Policies» AKV.
8.2. Ограничения «Test connection» (п. 5.2.3): Не уточнено, что «Test connection» к AKV проверяет только доступность сервиса, но не гарантирует наличие и доступность конкретного секрета.
9. (Важное упущение) Недостаточная детализация диагностики Self-Hosted Integration Runtime (SHIR) (п. 5.3). Если используется SHIR, проверки статуса в ADF Studio недостаточно. Диагностика должна включать анализ на хост-машине: проверка системных журналов (Event Viewer), мониторинг ресурсов, проверка сетевой связности с источниками/приемниками и верификация наличия драйверов.
10. (Важное упущение) Анализ производительности и ограничений (Раздел 6). При анализе причин сбоев не уделено внимание проблемам, связанным с достижением лимитов ресурсов (например, Throttling в Azure SQL DB) или лимитов параллелизма (Concurrency) на уровне ADF или IR.
11. (Упущение) Анализ переменных (п. 7.5.1). Анализ использования параметров фокусируется только на прямом использовании в Activities. Упущена необходимость анализа действий `Set Variable` и `Append Variable`, так как параметры часто используются для инициализации переменных, которые затем управляют логикой.
12. (Важное упущение) Использование "Debug Sink" / "Sink to null" для `Data Flow` (п. 9.4.2). Упущен эффективный механизм безопасности для тестирования `Data Flow` во время Debug Run. В настройках отладки («Debug Settings») можно настроить поведение приемника (Sink Properties) на запись в кэш или "Sink to null", что гарантирует, что данные не будут записаны в целевую систему.
13. (Важное упущение) Проверка деструктивных операций в конфигурации приемников (Sinks) (Раздел 9.4). Недостаточно акцентировано внимание на проверке настроек, которые могут привести к потере данных независимо от объема обрабатываемых строк. Необходимо явно проверить «Pre-copy script» в `Copy activity` (может содержать TRUNCATE/DELETE) и «Table action» (например, «Recreate table», «Truncate table») в Sinks.
14. (Упущение) Анализ содержимого `Stored Procedure` и `Script` activity (п. 9.2.3). Не указано, что для обеспечения безопасности необходимо проинспектировать фактический код T-SQL хранимой процедуры или содержимое скрипта, чтобы понять, какие операции DML/DDL они выполняют.
15. (Упущение) Предостережение о семплировании данных (п. 9.4.3.1.1). При описании ограничения строк (Row limit) для отладки `Data Flow` упущено, что результаты отладки на ограниченном наборе данных могут вводить в заблуждение, если логика включает операции, зависящие от полноты данных (например, Join, Aggregate).
16. (Упущение) Графическое представление снимка (Snapshot) (п. 4.6.1). Описание анализа снимка ограничивается просмотром JSON-определения («Code»). Упущено, что ADF Studio также предоставляет графическое представление исторического снимка, которое проще для восприятия новичком.
17. (Упущение) Ограничения «Test connection» для параметризованных Linked Services (п. 5.2.3). Если Linked Service использует параметры без значений по умолчанию для критически важных частей строки подключения, функция «Test connection» на вкладке «Manage» может быть недоступна. Следует упомянуть альтернативный метод: тестирование подключения из конфигурации Dataset.