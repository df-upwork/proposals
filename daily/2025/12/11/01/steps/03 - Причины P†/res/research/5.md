https://gemini.google.com/share/d5ef05331eb4

## **Cᛘ₁: Взрыв кэша из-за высокой кардинальности запросов**

### **Суть**

Данная гипотеза постулирует, что исчерпание оперативной памяти сервера вызвано комбинаторным взрывом количества уникальных объектов кэша, возникающим вследствие отсутствия агрессивной нормализации URL-адресов в условиях фасетной навигации и активного рекламного трафика.  
Ключевым механизмом, лежащим в основе этой проблемы, является дефолтное поведение Varnish Cache, который использует полную строку URL, включая все параметры запроса (query string), в качестве ключа для вычисления хэша объекта, что при малейшем изменении порядка параметров или их состава приводит к созданию новой записи в памяти.1  
В контексте проекта RunRepeat.com, архитектура которого включает фильтрацию товаров по полу, размеру и цвету, количество возможных перестановок параметров (например, /shoe?size=42&color=red против /shoe?color=red&size=42) растет факториально, создавая множественные копии одного и того же контента.1  
Ситуация критически усугубляется наличием рекламного трафика, о чем свидетельствует упоминание клиента «We also have ads», что неизбежно привносит в URL уникальные идентификаторы кликов, такие как gclid (Google Click ID), fbclid (Facebook Click ID) и различные utm_* метки.3  
Эти метки, предназначенные исключительно для клиентской аналитики или трекинга на стороне сервера, делают каждый входящий запрос технически уникальным с точки зрения Varnish, заставляя его сохранять копию страницы для каждого отдельного перехода пользователя по рекламе.3  
Даже если сам размер кэшируемых данных (HTML-тела страницы) ограничен параметром запуска -s malloc,SIZE, каждый создаваемый объект требует выделения структур метаданных, таких как struct obj и struct objcore, которые хранятся в оперативной памяти вне области, отведенной под хранилище данных (storage payload).6  
Согласно технической документации, накладные расходы (overhead) на один объект составляют приблизительно 1 КБ памяти, которая аллоцируется системным malloc и не учитывается в лимитах -s, задаваемых администратором при старте демона.6  
При сценарии, когда сайт получает около 4 миллионов сессий в месяц, и значительная часть этого трафика является рекламной или создается ботами, перебирающими фильтры, количество мелких объектов в памяти может достигать десятков миллионов.6  
Это приводит к тому, что метаданные начинают занимать гигабайты оперативной памяти (например, 10 миллионов объектов потребуют около 10 ГБ RAM только под структуры управления), что в условиях 32 ГБ общей памяти сервера создает критическое давление на ресурсы.6  
Более того, огромное количество объектов в хэш-таблице замедляет операции поиска (HSH_Lookup), увеличивает длину цепочек коллизий и создает дополнительную нагрузку на процессор, что клиент описывает как «performance degradation».7  
Отсутствие в описании проблемы упоминаний о применении модуля vmod_std и функции std.querysort для сортировки параметров или регулярных выражений для очистки трекинговых меток делает эту гипотезу наиболее вероятной технической причиной наблюдаемого поведения.10  
Если VCL (Varnish Configuration Language) не содержит явных инструкций по нормализации req.url до этапа vcl_hash, Varnish будет послушно кэшировать бесконечное множество вариаций одного URL, быстро исчерпывая физическую память сервера, независимо от того, какой лимит установлен для полезной нагрузки.12

### **Оценка**

95

### **Доводы за**

Фундаментальная архитектура E-commerce проектов с фасетным поиском («users can filter by gender, size, color») является хрестоматийным примером уязвимости к проблеме Cache Bloat, так как количество возможных комбинаций фильтров стремится к бесконечности.8  
Прямое указание клиента на наличие рекламы («We also have ads») служит практически гарантией присутствия в запросах высокоэнтропийных параметров отслеживания (gclid, utm), которые без специальной обработки приводят к коэффициенту кэширования (Hit Rate) близкому к нулю и переполнению памяти уникальными объектами.3  
Техническая спецификация Varnish Cache подтверждает наличие неустранимых накладных расходов в размере ~1 КБ на объект, которые находятся вне контроля параметра -s malloc, что полностью объясняет симптом «Varnish repeatedly grows the memory... regardless of what config we've tried».6  
Клиент отмечает, что «pages are not fully static», что подразумевает высокую динамику генерации контента и, вероятно, использование различных параметров запроса для управления отображением, что усиливает риск дублирования кэша [O.md §2.3].  
Отсутствие сортировки параметров запроса (std.querysort) приводит к тому, что идентичные по семантике запросы /A?x=1&y=2 и /A?y=2&x=1 обрабатываются как разные сущности, что эффективно удваивает потребление памяти для популярных страниц категорий.10  
Масштаб трафика в 4 миллиона сессий в месяц является достаточным для того, чтобы даже небольшой процент "мусорных" запросов (например, от поисковых ботов, сканирующих все комбинации фильтров) привел к созданию миллионов объектов за короткий промежуток времени.15  
Указание на то, что «config changes haven't helped», свидетельствует о том, что администраторы пытаются тюнить параметры размера хранилища, не понимая, что утечка происходит через метаданные объектов, количество которых не ограничено стандартными настройками.6  
В документации Varnish Enterprise проблема управления памятью через Massive Storage Engine (MSE) и Memory Governor выделяется как ключевое преимущество перед Open Source версией именно в сценариях с большим количеством объектов, что косвенно подтверждает уязвимость бесплатной версии к таким проблемам.14  
Использование Graviton CPU с большим количеством ядер (8 Cores) позволяет обрабатывать запросы параллельно с высокой скоростью, что может ускорить процесс заполнения памяти «мусорными» объектами при DDoS-подобной активности ботов [O.md §2.3].  
Существующие в открытом доступе рекомендации по настройке Varnish для Magento и других E-commerce платформ часто упускают нюансы глубокой очистки URL, ограничиваясь лишь базовыми правилами, что оставляет систему уязвимой для специфических трекеров.13

### **Доводы против**

Если команда разработчика клиента использует профессионально подготовленные шаблоны VCL для E-commerce (например, официальный VCL для Magento 2), то базовые правила нормализации URL и удаления технических параметров (utm_source и т.д.) могут быть уже включены в конфигурацию по умолчанию.13  
Механизм LRU (Least Recently Used), встроенный в Varnish, предназначен для автоматического удаления старых объектов при исчерпании выделенного лимита хранилища, что теоретически должно стабилизировать потребление памяти на заданном уровне, если только рост метаданных не происходит быстрее, чем процесс очистки.6  
В некоторых случаях, если сайт использует Vary заголовки корректно, Varnish может эффективно управлять вариациями контента без создания полностью независимых объектов, хотя это требует сложной настройки бэкенда.18  
Если бы проблема заключалась исключительно в дублировании URL, логи доступа (varnishlog) показали бы очевидную картину с огромным количеством уникальных ключей, что квалифицированный специалист должен был заметить на ранних этапах диагностики.19  
Утверждение клиента о «persistent memory issues» может указывать на то, что память не освобождается даже при снижении трафика, что более характерно для утечек памяти (memory leaks) в коде или фрагментации, чем для простого заполнения кэша, который должен реагировать на команды очистки или перезагрузки.14

## **Cᛘ₂: Неограниченное потребление памяти во временном хранилище**

### **Суть**

Гипотеза Cᛘ₂ утверждает, что наблюдаемая «утечка» памяти на самом деле является штатным, но неконтролируемым накоплением данных во временном хранилище (Transient Storage), которое в архитектуре Varnish Cache спроектировано как неограниченное по размеру пространство.  
Временное хранилище используется Varnish для размещения объектов с очень коротким временем жизни (определяется параметром shortlived, по умолчанию 10 секунд), а также для транзитных объектов, которые не подлежат длительному кэшированию.14  
Критически важным аспектом является механизм обработки ответов, которые нельзя кэшировать (uncacheable): когда Varnish решает не помещать объект в основной кэш (например, из-за наличия заголовка Set-Cookie или Cache-Control: private), он создает специальную запись hit-for-miss или hit-for-pass.21  
Эти технические записи, предназначенные для предотвращения "thundering herd" проблемы (когда множество запросов одновременно идут на бэкенд), сохраняются именно в Transient хранилище.22  
В сценарии E-commerce с активной рекламой, каждый переход пользователя по ссылке с gclid часто инициирует создание новой сессии на бэкенде, который отвечает установкой Set-Cookie.17  
В результате, Varnish вынужден создавать уникальный hit-for-miss объект для каждого такого запроса, сохраняя его в Transient хранилище на время действия TTL (по умолчанию 120 секунд для hit-for-miss).22  
Поскольку Transient хранилище по умолчанию использует системный аллокатор malloc без ограничения максимального размера (unbounded), при высокой интенсивности трафика (4 млн сессий) объем накопленных транзитных объектов может расти лавинообразно.14  
Этот рост происходит параллельно с использованием основного хранилища (определенного через -s malloc,SIZE), и суммарное потребление памяти процессом varnishd становится равным Storage Size + Transient Size + Overhead.7  
Клиент, наблюдая рост памяти, может пытаться уменьшить основной кэш, но это не влияет на Transient, что объясняет фразу «regardless of what config we've tried».14  
Особенно опасна ситуация с медленными клиентами или большими объемами передаваемых данных, так как Varnish буферизирует тело ответа в Transient хранилище во время его передачи от бэкенда к клиенту (streaming/buffering), и память освобождается только после полного завершения передачи.14  
Если на сайте присутствуют большие страницы или файлы, и множество пользователей с медленным интернетом (например, мобильных) одновременно загружают их, объем занятой в Transient памяти может достигать гигантских значений.14  
Данная проблема является архитектурной особенностью Open Source версии Varnish, где отсутствуют продвинутые механизмы управления памятью, доступные в Enterprise версии (Memory Governor), которые могли бы лимитировать Transient.14  
Таким образом, «утечка» памяти является фактически накоплением легитимных, но короткоживущих данных, которые система не успевает освобождать или накапливает в объемах, превышающих физические возможности сервера.22

### **Оценка**

90

### **Доводы за**

Документация Varnish Cache и многочисленные обсуждения в сообществе (StackOverflow, mailing lists) однозначно определяют Transient Storage как «unbounded memory space», что является известным источником проблем стабильности (OOM).14  
Анализ реальных инцидентов показывает, что метрика SMA.Transient.c_bytes может многократно превышать размер основного хранилища SMA.s0.c_bytes в ситуациях с высоким трафиком и некорректной политикой кэширования.22  
Клиентская жалоба на неэффективность изменений конфигурации («config changes haven't helped») прямо указывает на то, что проблема находится вне зоны действия стандартного параметра -s, который ограничивает только основной кэш.14  
Наличие на сайте рекламы и динамического контента («users can filter... ads on the site») генерирует паттерн трафика, богатый запросами, которые нельзя кэшировать (из-за кук или уникальности), что массово порождает объекты hit-for-miss в Transient.3  
Механизм hit-for-pass (в старых версиях) и hit-for-miss (в новых) специально разработан для защиты бэкенда, но ценой потребления памяти Varnish, что при атаке или всплеске трафика перекладывает нагрузку с CPU бэкенда на RAM прокси.21  
При 4 миллионах сессий в месяц, даже небольшой процент запросов, попадающих в Transient (например, корзина, чекаут, личный кабинет), создает постоянный базовый уровень потребления памяти, который может иметь пики, превышающие доступные 32 ГБ.7  
Отсутствие явного указания параметра -s Transient=malloc,SIZE в стандартных конфигурациях означает, что в 99% случаев эта настройка остается дефолтной (неограниченной), оставляя систему уязвимой.23  
Проблема усугубляется, если используются медленные бэкенды, так как объекты задерживаются в Transient на время ожидания и передачи, увеличивая время жизни аллокаций.14

### **Доводы против**

Теоретически, объекты в Transient хранилище имеют короткий жизненный цикл и должны освобождаться автоматически и быстро, что должно приводить к пилообразному графику потребления памяти, а не к постоянному линейному росту, описываемому клиентом.14  
В современных версиях Varnish (6.0+) механизм обработки hit-for-miss был оптимизирован по сравнению со старым hit-for-pass, чтобы уменьшить накладные расходы и время жизни записей, что должно снижать остроту проблемы.24  
Если сайт обслуживает преимущественно мелкие страницы (HTML), то буферизация ответов не должна занимать гигабайты памяти, если только не происходит массовая загрузка больших медиа-файлов через Varnish (что обычно выносится на CDN).14  
Клиент может использовать параметр shortlived с очень маленьким значением, что заставляет Varnish агрессивнее считать объекты транзитными, но это обычно требует осознанной настройки, а не происходит само собой.20

## **Cᛘ₃: Фрагментация памяти из-за системного аллокатора**

### **Суть**

Гипотеза Cᛘ₃ фокусируется на проблеме внутренней и внешней фрагментации оперативной памяти, возникающей из-за взаимодействия Varnish Cache с системным аллокатором памяти (glibc malloc) на операционной системе Linux.  
Varnish Cache работает по модели интенсивного выделения и освобождения памяти: миллионы объектов создаются, живут разное время и удаляются, что создает колоссальную нагрузку на аллокатор памяти.7  
Стандартный аллокатор glibc (ptmalloc), используемый по умолчанию в большинстве дистрибутивов Linux (RHEL, CentOS, Amazon Linux), исторически плохо справляется с паттерном нагрузки, характеризующимся высокой конкурентностью потоков и множеством мелких разнородных аллокаций.25  
В результате работы glibc образуется фрагментация кучи (heap fragmentation): память, освобожденная процессом (free()), остается закрепленной за процессом и не возвращается операционной системе, при этом она может быть разбита на мелкие блоки, непригодные для повторного использования под крупные объекты.7  
Это приводит к ситуации, когда метрика RSS (Resident Set Size) процесса Varnish постоянно растет, создавая видимость утечки памяти, хотя внутри самого Varnish (по метрикам счетчиков) объем используемых данных может быть стабильным.7  
Документация Varnish Software настоятельно рекомендует использовать альтернативный аллокатор jemalloc, который специально оптимизирован для предотвращения фрагментации и лучшей работы в многопоточных средах.7  
jemalloc использует механизм арен (arenas) и экстентов (extents), что позволяет удерживать уровень фрагментации на уровне не более 20% в худшем случае, тогда как для glibc этот показатель может быть значительно выше и непредсказуем.7  
Однако, в дистрибутивах семейства Red Hat (к которым относится Amazon Linux), jemalloc часто не является аллокатором по умолчанию и даже может отсутствовать в зависимостях пакета, требуя ручной установки и настройки через переменную окружения LD_PRELOAD или конфигурацию systemd.27  
На архитектуре ARM64 (Graviton), которая имеет отличную от x86 модель памяти и примитивы синхронизации, проблемы с блокировками (lock contention) и управлением памятью в glibc могут проявляться более остро, влияя не только на потребление памяти, но и на производительность CPU.25  
Клиент упоминает использование «Gravitron CPU» и «persistent memory issues», что делает версию с неэффективным аллокатором крайне правдоподобной, особенно если используется стандартный образ ОС без тюнинга [O.md §2.3].  
Важно отметить, что Varnish выделяет память не только под объекты, но и под рабочие пространства потоков (workspace_client, workspace_backend), размер которых также влияет на общую картину потребления и фрагментации.30  
Если фрагментация достигает 50% и более (что возможно с glibc в долгосрочной перспективе), сервер с 32 ГБ RAM может исчерпать память при реальном объеме полезных данных всего в 15-20 ГБ.7

### **Оценка**

85

### **Доводы за**

Официальный блог Varnish Software и документация прямо указывают на то, что jemalloc является рекомендованным стандартом, и использование других аллокаторов чревато высокой фрагментацией.7  
В release notes для Red Hat Enterprise Linux 10 интеграция jemalloc 5.3.0 в пакет Varnish подается как исправление критической проблемы «excessive memory usage... despite setting explicit memory limits», что подтверждает массовый характер проблемы на системах RHEL/Amazon Linux с glibc.27  
Бенчмарки баз данных (MySQL) и других кэширующих систем показывают, что переход с glibc на jemalloc может снизить потребление RSS в 2 раза при той же полезной нагрузке, что доказывает масштаб влияния аллокатора.25  
Проблема фрагментации объясняет «бесконечный» рост памяти: по мере работы процесса куча становится все более фрагментированной, и аллокатор вынужден запрашивать новые страницы у ОС, увеличивая RSS, даже если старые страницы формально свободны (но фрагментированы).7  
На Amazon Linux (основанном на RHEL/Fedora) пакет jemalloc может не быть установлен или активирован по умолчанию для Varnish, что является частой ловушкой для инженеров, мигрирующих с Debian/Ubuntu, где это часто сделано из коробки.27  
Специфика архитектуры Graviton (ARM64) может усугублять накладные расходы glibc из-за особенностей реализации спинлоков и атомарных операций, что коррелирует с жалобой на деградацию производительности.29

### **Доводы против**

Если клиент использует Varnish Enterprise или грамотно собранный Docker-контейнер, вероятность того, что jemalloc уже настроен, высока, так как это best practice.14  
В последних версиях glibc (начиная с 2.26) был внедрен per-thread cache (tcache), который значительно улучшил производительность и уменьшил фрагментацию, приблизив показатели к jemalloc в некоторых сценариях.25  
Проблема фрагментации обычно приводит к выходу на "плато" потребления памяти (saturation point), а не к бесконечному линейному росту до OOM, если только нагрузка не растет постоянно.26  
Диагностировать эту проблему достаточно легко с помощью утилит типа pmap или встроенных счетчиков jemalloc (если он подключен), и квалифицированный разработчик мог бы заметить разницу между g_bytes и RSS.7

## **Cᛘ₄: Неэффективность размера страниц памяти на архитектуре ARM64**

### **Суть**

Гипотеза Cᛘ₄ связывает проблемы производительности и, косвенно, управления памятью с использованием субоптимального размера страниц памяти (page size) на архитектуре процессоров AWS Graviton (ARM64).  
В отличие от архитектуры x86_64, где размер страницы памяти жестко зафиксирован на уровне 4 КБ (с опциональными Huge Pages), архитектура ARM64 поддерживает выбор размера страницы на уровне ядра ОС: 4 КБ, 16 КБ или 64 КБ.32  
Стандартные образы операционных систем (Amazon Linux 2, RHEL 8, Ubuntu) для ARM64 часто поставляются с ядром, настроенным на использование страниц 4 КБ для обеспечения максимальной совместимости с программным обеспечением.33  
Однако для приложений с интенсивным использованием памяти, таких как Varnish Cache (выделенный объем 32 ГБ), использование мелких страниц 4 КБ создает колоссальную нагрузку на подсистему управления памятью процессора (MMU) и буфер ассоциативной трансляции (TLB - Translation Lookaside Buffer).32  
При объеме памяти 32 ГБ и размере страницы 4 КБ таблица страниц (page table) может содержать миллионы записей, которые не помещаются в TLB, вызывая частые промахи (TLB misses).35  
Каждый промах TLB заставляет процессор выполнять дорогостоящую процедуру "прогулки по таблице страниц" (page walk), затрачивая циклы CPU и увеличивая латентность доступа к памяти.35  
Это явление напрямую коррелирует с жалобой клиента на «performance degradation», так как процессор тратит значительное время на обслуживание памяти, а не на обработку запросов.34  
Переход на ядро с поддержкой страниц 64 КБ (kernel-64k) позволяет уменьшить размер таблицы страниц в 16 раз и значительно повысить эффективность TLB, покрывая больший объем памяти меньшим количеством записей.33  
Хотя использование страниц 64 КБ может привести к некоторому увеличению потребления памяти для очень мелких файлов (внутренняя фрагментация, так как минимальный аллоцируемый блок равен 64 КБ), для Varnish, который управляет памятью большими чанками внутри malloc, это влияние нивелируется общим выигрышем в производительности.32  
Amazon Linux 2023 и RHEL 9 предоставляют пакет kernel-64k как опцию для высоконагруженных систем, баз данных и кэшей, работающих на Graviton.33  
Если клиент использует стандартное ядро 4 КБ на мощном инстансе Graviton с 32 ГБ памяти, он искусственно ограничивает пропускную способность системы и создает предпосылки для нестабильной работы под нагрузкой.34

### **Оценка**

60

### **Доводы за**

Документация Red Hat и Amazon AWS явно рекомендует использование kernel-64k для «memory-intensive workloads» и «large datasets» на платформе ARM64, к которым безусловно относится кэширующий сервер.33  
Независимые тесты производительности (Phoronix) демонстрируют значительный прирост производительности и снижение системных накладных расходов при переходе с 4 КБ на 64 КБ страницы на процессорах ARM64 серверного класса.34  
Проблема TLB Misses является классическим «бутылочным горлышком» для приложений с произвольным доступом к большим массивам памяти, что характерно для алгоритмов работы хэш-таблиц Varnish.35  
Упоминание клиентом конкретной аппаратной платформы «Gravitron CPU» (вероятно, опечатка от Graviton) намекает на то, что проблема может иметь аппаратно-зависимый характер, который не проявлялся бы на x86 [O.md §2.3].  
Снижение нагрузки на CPU за счет уменьшения page walks освобождает ресурсы для обработки большего количества запросов и сборки мусора, что может косвенно помочь в стабилизации памяти.35

### **Доводы против**

Данная проблема объясняет в первую очередь деградацию производительности (CPU/Latency), а не физическое исчерпание памяти (Memory Leak/Growth), которое является основной жалобой клиента [O.md §2.3].  
Использование страниц 64 КБ может увеличить потребление памяти операционной системой (kernel structures) и усилить внутреннюю фрагментацию для мелких системных файлов, хотя для самого Varnish это менее критично.32  
Переход на kernel-64k требует смены ядра и перезагрузки, а также потенциально может вызвать проблемы совместимости с некоторыми инструментами мониторинга или старым ПО, не готовым к такому размеру страниц.33  
Если Varnish настроен с использованием jemalloc и transparent huge pages (THP), операционная система может частично компенсировать недостатки 4 КБ страниц, объединяя их в большие страницы.32

## **Cᛘ₅: Отсутствие нормализации HTTP-заголовков и сжатия**

### **Суть**

Гипотеза Cᛘ₅ рассматривает вклад отсутствия нормализации ключевых HTTP-заголовков (User-Agent, Accept-Encoding, Cookie) в процесс неконтролируемого раздувания кэша.  
Varnish Cache использует механизм Vary для создания вариаций одного и того же объекта (URL) для разных клиентов, что необходимо для отдачи, например, сжатого (gzip) или несжатого контента, или мобильной версии сайта.1  
Критическая уязвимость возникает, если бэкенд приложение (RunRepeat.com) отправляет заголовок Vary: User-Agent, инструктируя Varnish хранить отдельную копию страницы для каждого уникального User-Agent.37  
Учитывая, что существует тысячи вариаций строк User-Agent (разные версии браузеров, ОС, устройства, боты), это приводит к катастрофическому дублированию контента: один URL может иметь сотни копий в кэше, каждая из которых потребляет память и метаданные.18  
Аналогичная проблема возможна с заголовком Accept-Encoding: если не нормализовать его в vcl_recv (приводя к единому виду gzip), Varnish может кэшировать отдельные копии для клиентов, присылающих gzip, deflate, deflate, gzip или просто gzip.1  
Кроме того, отсутствие правильной обработки заголовка Cookie в vcl_recv (например, удаление кук для статики или для страниц, не требующих авторизации) приводит к тому, что Varnish считает запросы персонализированными и либо не кэширует их вообще (passing), либо кэширует как уникальные вариации.39  
Клиент не упоминает о наличии специального кода VCL для нормализации заголовков, но упоминает, что «users can filter by gender...», что подразумевает сложную логику на бэкенде, которая может ошибочно выставлять широкие Vary заголовки [O.md §2.3].  
Также, если Varnish не настроен на хранение объектов в сжатом виде (gzip), он будет хранить несжатый HTML, который занимает в 5-10 раз больше места в оперативной памяти, что при больших объемах трафика существенно сокращает эффективную емкость кэша.38  
В совокупности эти факторы приводят к неэффективному использованию доступной памяти (хранение дубликатов и "воздуха"), что выглядит как быстрый рост потребления памяти при увеличении разнообразия клиентских устройств и ботов.

### **Оценка**

70

### **Доводы за**

Использование Vary: User-Agent является распространенной ошибкой конфигурации веб-серверов (Apache/Nginx) и CMS, которая при установке Varnish превращается в "бомбу замедленного действия" для памяти.18  
Современный трафик характеризуется огромным разнообразием User-Agent (мобильные приложения, встроенные браузеры, боты), что делает стратегию кэширования по User-Agent разрушительной без нормализации до групп (например, "Mobile", "Desktop").12  
Отсутствие сжатия объектов в памяти (хранение plain text) является расточительством ресурсов, и без явной настройки (do_gzip, do_stream) Varnish может работать в субоптимальном режиме.38  
Проблемы с Cookie («We also have ads») могут приводить к тому, что запросы с рекламными куками не попадают в кэш или создают вариации, если бэкенд добавляет Vary: Cookie.39  
Нормализация заголовков является стандартной практикой в профессиональных VCL, но часто отсутствует в базовых примерах или "быстрых стартах", которыми мог воспользоваться клиент.10

### **Доводы против**

Varnish версии 4.0 и выше имеет встроенную интеллектуальную обработку Accept-Encoding, автоматически выбирая лучшую схему сжатия, что снижает вероятность проблем с этим конкретным заголовком.38  
Большинство современных CMS (включая Magento, WordPress) научились избегать Vary: User-Agent в пользу адаптивной верстки или отдельных заголовков типа X-UA-Device, что снижает риск этой конкретной ошибки.18  
Даже при наличии множества вариаций, механизм LRU должен вытеснять наименее востребованные из них, предотвращая полный крах памяти, если только поток новых уникальных User-Agent не является непрерывным (атака ботов).6  
Эта проблема чаще проявляется как низкий Hit Rate, а не как бесконечный рост памяти, так как вариации являются частью одного объекта (hash), и их жизненный цикл связан.37

## **Вердикт**

Проведенный комплексный анализ ситуации, описанной клиентом ꆜ (проект P⁎), позволяет с высокой степенью уверенности идентифицировать причины нестабильности Varnish Cache.  
Ситуация классифицируется как мультифакторная проблема, где архитектурные особенности проекта накладываются на дефолтное поведение программного обеспечения и аппаратные нюансы.  
**Основные причины (P†):**

1. **Высокая кардинальность и рекламный трафик (Cᛘ₁ + Cᛘ₂):** Это доминирующий фактор. Комбинация фасетных фильтров и рекламных меток (gclid, utm) создает миллионы уникальных URL.  
   * Каждый уникальный URL порождает объект метаданных (overhead ~1KB), потребляющий память вне основного хранилища (-s malloc).  
   * Каждый рекламный переход с установкой Set-Cookie порождает объект hit-for-miss в **неограниченном** (unbounded) временном хранилище (Transient Storage).  
   * Это объясняет жалобу «changes in config haven't helped» — клиент ограничивает основной кэш, но утечка происходит через метаданные и Transient.  
2. **Проблемы аллокации и фрагментации (Cᛘ₃):** Использование системного аллокатора glibc (стандарт для Amazon Linux/RHEL) вместо рекомендованного jemalloc приводит к фрагментации памяти.  
   * Это создает видимость утечки (рост RSS), так как освобожденная память не возвращается ОС.  
   * На архитектуре Graviton (ARM64) glibc может работать менее эффективно из-за особенностей синхронизации.  
3. **Аппаратная неэффективность (Cᛘ₄):** Использование страниц памяти 4 КБ на 32 ГБ RAM для ARM64 создает высокую нагрузку на TLB, что является прямой причиной «performance degradation» и задержек в обработке памяти.

**Стратегия устранения (Action Plan):**

1. **VCL Нормализация (Critical):**  
   * Внедрить агрессивную очистку req.url в vcl_recv. Необходимо удалять все метки отслеживания (gclid, fbclid, utm_*) *до* хэширования.  
   * Использовать std.querysort(req.url) для нормализации порядка параметров фильтров.  
   * Пример:  
     Code snippet  
     import std;  
     sub vcl_recv {  
         # Удаление Google Analytics и других меток  
         set req.url = regsuball(req.url, "(?|&)(gclid|utm_[a-z]+|fbclid)=[-_A-z0-9+()%.]+&?", "");  
         set req.url = regsub(req.url, "[?|&]+$", "");  
         # Сортировка параметров  
         set req.url = std.querysort(req.url);  
     }

2. **Ограничение Transient Storage (Critical):**  
   * Изменить параметры запуска varnishd, явно ограничив временное хранилище.  
   * Добавить: -s Transient=malloc,2G (или другое разумное значение, например 10-15% от RAM). Это предотвратит OOM при атаках или всплесках hit-for-miss.  
3. **Оптимизация Аллокатора (High):**  
   * Убедиться, что используется jemalloc.  
   * Для Amazon Linux 2/2023: установить пакет jemalloc (dnf install jemalloc) и настроить systemd unit для Varnish, добавив Environment="LD_PRELOAD=/usr/lib64/libjemalloc.so.2".  
   * Это снизит фрагментацию и стабилизирует потребление памяти.  
4. **Тюнинг Graviton (Medium/High):**  
   * Если используется Amazon Linux 2023 или RHEL 9, рассмотреть установку ядра kernel-64k.  
   * Это существенно снизит TLB misses и повысит общую отзывчивость системы при работе с большими объемами кэша.  
5. **Мониторинг:**  
   * Настроить отслеживание метрик SMA.Transient.c_bytes, SMA.s0.g_bytes, MAIN.n_object, MAIN.n_vampireobject.  
   * Это позволит подтвердить теорию о том, какое именно хранилище растет.

#### **Works cited**

1. Varnish Explained - Mattias Geniar, accessed December 11, 2025, [https://ma.ttias.be/varnish-explained/](https://ma.ttias.be/varnish-explained/)  
2. PSA: You don't need that many regexes - Resources - Varnish Software, accessed December 11, 2025, [https://info.varnish-software.com/blog/psa-you-dont-need-that-many-regexes](https://info.varnish-software.com/blog/psa-you-dont-need-that-many-regexes)  
3. Strip query parameters with Varnish | by Danila Vershinin - Medium, accessed December 11, 2025, [https://medium.com/@getpagespeed/strip-query-parameters-with-varnish-bf3cb2877530](https://medium.com/@getpagespeed/strip-query-parameters-with-varnish-bf3cb2877530)  
4. How to strip UTM tags in Varnish without stripping queries I want? - Stack Overflow, accessed December 11, 2025, [https://stackoverflow.com/questions/75871726/how-to-strip-utm-tags-in-varnish-without-stripping-queries-i-want](https://stackoverflow.com/questions/75871726/how-to-strip-utm-tags-in-varnish-without-stripping-queries-i-want)  
5. Stripping out select querystring attribute/value pairs so varnish will not vary cache by them, accessed December 11, 2025, [https://stackoverflow.com/questions/13144172/stripping-out-select-querystring-attribute-value-pairs-so-varnish-will-not-vary](https://stackoverflow.com/questions/13144172/stripping-out-select-querystring-attribute-value-pairs-so-varnish-will-not-vary)  
6. Sizing your cache — Varnish version 6.0.16 documentation, accessed December 11, 2025, [https://varnish-cache.org/docs/6.0/users-guide/sizing-your-cache.html](https://varnish-cache.org/docs/6.0/users-guide/sizing-your-cache.html)  
7. Understanding Varnish Cache Memory Usage - Resources, accessed December 11, 2025, [https://info.varnish-software.com/blog/understanding-varnish-cache-memory-usage](https://info.varnish-software.com/blog/understanding-varnish-cache-memory-usage)  
8. arbal/awesome-stars: Top 18K of GitHub's finest., accessed December 11, 2025, [https://github.com/arbal/awesome-stars](https://github.com/arbal/awesome-stars)  
9. Assert in HSH_Lookup with Varnish 7.2.1 · Issue #3879 - GitHub, accessed December 11, 2025, [https://github.com/varnishcache/varnish-cache/issues/3879](https://github.com/varnishcache/varnish-cache/issues/3879)  
10. Example VCL template - Varnish Developer Portal, accessed December 11, 2025, [https://www.varnish-software.com/developers/tutorials/example-vcl-template/](https://www.varnish-software.com/developers/tutorials/example-vcl-template/)  
11. Varnish VCL "Symbol not found: std.querysort" - Stack Overflow, accessed December 11, 2025, [https://stackoverflow.com/questions/36012266/varnish-vcl-symbol-not-found-std-querysort](https://stackoverflow.com/questions/36012266/varnish-vcl-symbol-not-found-std-querysort)  
12. Hashing — Varnish version trunk documentation, accessed December 11, 2025, [https://varnish-cache.org/docs/trunk/users-guide/vcl-hashing.html](https://varnish-cache.org/docs/trunk/users-guide/vcl-hashing.html)  
13. Configuring Varnish for Magento - Varnish Developer Portal, accessed December 11, 2025, [https://www.varnish-software.com/developers/tutorials/configuring-varnish-magento/](https://www.varnish-software.com/developers/tutorials/configuring-varnish-magento/)  
14. Varnish memory usage keeps increasing - Stack Overflow, accessed December 11, 2025, [https://stackoverflow.com/questions/76209998/varnish-memory-usage-keeps-increasing](https://stackoverflow.com/questions/76209998/varnish-memory-usage-keeps-increasing)  
15. Introduction | HAProxy Enterprise 3.0r1, accessed December 11, 2025, [https://www.haproxy.com/documentation/haproxy-configuration-manual/new/3-0r1/intro/](https://www.haproxy.com/documentation/haproxy-configuration-manual/new/3-0r1/intro/)  
16. Two-Minute Tech Tuesdays - Memory Governor - Resources - Varnish Software, accessed December 11, 2025, [https://info.varnish-software.com/blog/two-minute-tech-tuesdays-memory-governor](https://info.varnish-software.com/blog/two-minute-tech-tuesdays-memory-governor)  
17. 4 Varnish Enterprise Features That Will Improve the Caching of Your Magento Store, accessed December 11, 2025, [https://info.varnish-software.com/blog/4-varnish-enterprise-features-that-will-improve-the-caching-of-your-magento-store](https://info.varnish-software.com/blog/4-varnish-enterprise-features-that-will-improve-the-caching-of-your-magento-store)  
18. varnish-book.pdf - HubSpot, accessed December 11, 2025, [https://cdn2.hubspot.net/hubfs/209523/The_Varnish_Book/varnish-book.pdf](https://cdn2.hubspot.net/hubfs/209523/The_Varnish_Book/varnish-book.pdf)  
19. Command line utilities - Lib.rs, accessed December 11, 2025, [https://lib.rs/command-line-utilities](https://lib.rs/command-line-utilities)  
20. Varnish Using Significantly More Memory than Cache? - Stack Overflow, accessed December 11, 2025, [https://stackoverflow.com/questions/78379910/varnish-using-significantly-more-memory-than-cache](https://stackoverflow.com/questions/78379910/varnish-using-significantly-more-memory-than-cache)  
21. varnish-counters — Varnish version trunk documentation, accessed December 11, 2025, [https://varnish-cache.org/docs/trunk/reference/varnish-counters.html](https://varnish-cache.org/docs/trunk/reference/varnish-counters.html)  
22. Transient storage killing memory - Varnish Cache, accessed December 11, 2025, [https://varnish-cache.org/lists/pipermail/varnish-misc/2016-November/025451.html](https://varnish-cache.org/lists/pipermail/varnish-misc/2016-November/025451.html)  
23. careful selection of hitpass vs hitmiss · Issue #2865 · varnishcache/varnish-cache - GitHub, accessed December 11, 2025, [https://github.com/varnishcache/varnish-cache/issues/2865](https://github.com/varnishcache/varnish-cache/issues/2865)  
24. Upgrading to Varnish 7.0, accessed December 11, 2025, [https://varnish-cache.org/docs/7.0/whats-new/upgrading-7.0.html](https://varnish-cache.org/docs/7.0/whats-new/upgrading-7.0.html)  
25. Concurrent large allocations: glibc malloc, jemalloc and tcmalloc - Small Datum, accessed December 11, 2025, [http://smalldatum.blogspot.com/2017/11/concurrent-large-allocations-glibc.html](http://smalldatum.blogspot.com/2017/11/concurrent-large-allocations-glibc.html)  
26. CPU and memory usage of jemalloc as compared to glibc malloc - Stack Overflow, accessed December 11, 2025, [https://stackoverflow.com/questions/13027475/cpu-and-memory-usage-of-jemalloc-as-compared-to-glibc-malloc](https://stackoverflow.com/questions/13027475/cpu-and-memory-usage-of-jemalloc-as-compared-to-glibc-malloc)  
27. Red Hat Enterprise Linux 10 10.1 Release Notes, accessed December 11, 2025, [https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/10/pdf/10.1_release_notes/%3Ctba%3E](https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/10/pdf/10.1_release_notes/%3Ctba%3E)  
28. Newest 'jemalloc' Questions - Stack Overflow, accessed December 11, 2025, [https://stackoverflow.com/questions/tagged/jemalloc?tab=Newest](https://stackoverflow.com/questions/tagged/jemalloc?tab=Newest)  
29. jemalloc vs glibc malloc: Memory Allocation Performance Comparison | by Binita Bharati, accessed December 11, 2025, [https://medium.com/@binitabharati/jemalloc-vs-glibc-malloc-memory-allocation-performance-comparison-fbaeda1740de](https://medium.com/@binitabharati/jemalloc-vs-glibc-malloc-memory-allocation-performance-comparison-fbaeda1740de)  
30. Tuning Varnish, accessed December 11, 2025, [https://docs.varnish-software.com/book/operations/tuning-varnish/](https://docs.varnish-software.com/book/operations/tuning-varnish/)  
31. Install Varnish Cache For Wordpress - Apache - Amazon Linux - Blog - Lawrence McDaniel, accessed December 11, 2025, [https://blog.lawrencemcdaniel.com/install-varnish-cache-on-amazon-linux/](https://blog.lawrencemcdaniel.com/install-varnish-cache-on-amazon-linux/)  
32. Understanding Memory Page Sizes on Arm64 - SitePoint, accessed December 11, 2025, [https://www.sitepoint.com/memory-page-sizes-on-arm64/](https://www.sitepoint.com/memory-page-sizes-on-arm64/)  
33. Chapter 2. The 64k page size kernel | Managing, monitoring, and updating the kernel | Red Hat Enterprise Linux | 9, accessed December 11, 2025, [https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9/html/managing_monitoring_and_updating_the_kernel/what-is-kernel-64k_managing-monitoring-and-updating-the-kernel](https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9/html/managing_monitoring_and_updating_the_kernel/what-is-kernel-64k_managing-monitoring-and-updating-the-kernel)  
34. 64K Kernel Page Size Performance Benefits For HPC Shown With NVIDIA's GH200 Grace CPU - Phoronix, accessed December 11, 2025, [https://www.phoronix.com/review/aarch64-64k-kernel-perf](https://www.phoronix.com/review/aarch64-64k-kernel-perf)  
35. 64K Memory page sizes - any experiences to share? - General Discussion, accessed December 11, 2025, [https://community.amperecomputing.com/t/64k-memory-page-sizes-any-experiences-to-share/2730](https://community.amperecomputing.com/t/64k-memory-page-sizes-any-experiences-to-share/2730)  
36. Setup Docker on Amazon Linux 2023 - GitHub Gist, accessed December 11, 2025, [https://gist.github.com/thimslugga/36019e15b2a47a48c495b661d18faa6d?permalink_comment_id=5057205](https://gist.github.com/thimslugga/36019e15b2a47a48c495b661d18faa6d?permalink_comment_id=5057205)  
37. Purging and banning — Varnish version 4.0.5 documentation, accessed December 11, 2025, [https://varnish-cache.org/docs/4.0/users-guide/purging.html](https://varnish-cache.org/docs/4.0/users-guide/purging.html)  
38. Varnish Administrator documentation - Read the Docs, accessed December 11, 2025, [https://readthedocs.org/projects/varnish-cache/downloads/pdf/readthedocs/](https://readthedocs.org/projects/varnish-cache/downloads/pdf/readthedocs/)  
39. Removing cookies in Varnish - Varnish Developer Portal, accessed December 11, 2025, [https://www.varnish-software.com/developers/tutorials/removing-cookies-varnish/](https://www.varnish-software.com/developers/tutorials/removing-cookies-varnish/)