https://gemini.google.com/share/a9009130d00c

## **Введение**

В данном отчете представлен исчерпывающий технический аудит и анализ обоснованности опасений клиента ꆜ (далее Клиент) относительно реализации проекта P⁎. В условиях современного рынка цифровых продуктов выбор технологического стека является не просто вопросом предпочтений разработчика, но фундаментальным бизнес-решением, определяющим экономику проекта (unit economics), его способность к масштабированию и долгосрочную жизнеспособность.

Клиент выразил ряд тревог, касающихся стоимости инфраструктуры, целостности данных, задержек в аналитике и общей стабильности системы, построенной на базе Bubble.io с интеграцией внешних сервисов (Supabase, Vercel). Наш анализ, базирующийся на детальном изучении технической документации, дискуссий в профессиональных сообществах и бенчмарков производительности, показывает, что эти опасения не являются беспочвенными страхами. Напротив, они указывают на классические структурные проблемы, возникающие при попытке масштабировать No-Code решения до уровня Enterprise-систем без соответствующей адаптации архитектуры.

Отчет структурирован таким образом, чтобы последовательно деконструировать каждую проблемную область: от механики ценообразования Workload Units (WU) в Bubble до нюансов конкурентного доступа к данным (Race Conditions) и ограничений serverless-вычислений. Мы рассмотрим обоснованность каждой проблемы через призму технических фактов и предложим архитектурные паттерны для их решения.

## ---

**1. Парадокс масштабируемости и стоимости в экосистеме Bubble.io**

Одной из центральных проблем, беспокоящих Клиента, является экономическая эффективность текущей архитектуры на базе Bubble.io, особенно в свете перехода платформы на модель тарификации по единицам рабочей нагрузки (Workload Units — WU). Данное беспокойство полностью обосновано и подтверждается анализом механики потребления ресурсов.

### **1.1 Механика и экономика Workload Units (WU)**

Традиционно хостинг веб-приложений оплачивался на основе выделенных мощностей (CPU, RAM), где стоимость была фиксированной, а производительность — переменной. Bubble.io изменил эту парадигму, введя метрику Workload Unit. Согласно документации, WU — это агрегированный показатель работы, выполняемой платформой для обеспечения функционирования приложения.1 Он включает в себя операции с базой данных, выполнение рабочих процессов (workflows) и веб-взаимодействия.2

Проблема для проекта P⁎, который, судя по запросу, предполагает интенсивную работу с данными и аналитикой, заключается в том, что модель WU создает своего рода «налог на активность». В то время как на традиционном сервере (например, AWS EC2) оптимизированный SQL-запрос, обрабатывающий 10 000 строк, может стоить доли цента и занимать миллисекунды процессорного времени, в экосистеме Bubble каждая операция чтения, изменения и каждое действие в рабочем процессе суммируются в счет.3

Если приложение Клиента превышает лимит WU, включенный в тарифный план, система автоматически начинает взимать плату за превышение (overages) по ставке $0.30 за 1 000 WU.1 Для приложений с высокой интенсивностью транзакций или сложной бизнес-логикой это создает риск неконтролируемого роста расходов. Разработчики в сообществе отмечают случаи, когда даже на этапе разработки, без реальных пользователей, приложения потребляли значительные объемы WU из-за неоптимизированных триггеров базы данных и API-вызовов.4 Это подтверждает опасения Клиента: без глубокой оптимизации затраты могут стать запретительными.

### **1.2 Сравнительный анализ методов массовой обработки данных**

Особую техническую сложность и источник затрат представляет собой обработка больших массивов данных (Bulk Operations). В контексте Bubble существует два основных подхода к решению этой задачи, и выбор между ними оказывает драматическое влияние на потребление WU и надежность системы. Исследования показывают существенную разницу в "цене" этих методов.

#### **Рекурсивные рабочие процессы (Recursive Backend Workflows)**

Этот метод предполагает создание API Workflow, который обрабатывает один элемент списка, а затем вызывает сам себя для обработки следующего.

* **Преимущества:** Обеспечивает строгую последовательность выполнения, что критично для предотвращения гонок данных (race conditions). Позволяет управлять нагрузкой и избегать тайм-аутов.5  
* **Недостатки:** Крайне высокое потребление WU. Поскольку каждое "перепланирование" (rescheduling) само по себе является действием, умноженным на количество элементов в списке, затраты растут линейно и быстро. Бенчмарки показывают, что обработка списка из 2 000 элементов рекурсивным методом может стоить около 4 793 WU.6 Кроме того, процесс выполняется медленнее из-за последовательной природы.

#### **Планирование API Workflow на списке (Schedule API Workflow on a List)**

Этот метод использует встроенную функцию Bubble для запуска рабочего процесса параллельно для каждого элемента в списке.

* **Преимущества:** Скорость. Bubble пытается выполнить задачи параллельно, стремясь завершить их как можно быстрее.5  
* **Недостатки:** Парадоксально, но этот метод может быть еще дороже в некоторых сценариях из-за накладных расходов на планирование тысяч задач одновременно (7 225 WU в одном из тестов 6), хотя другие источники указывают на его экономичность при правильном использовании. Главный риск здесь — отсутствие гарантии порядка выполнения и высокий риск возникновения состояния гонки, если процессы пытаются изменить одни и те же данные одновременно.7

#### **Нативные массовые операции (Native Bulk Operations)**

Использование действий типа "Make changes to a list of things" непосредственно в интерфейсе данных или простых рабочих процессах.

* **Эффективность:** Это наиболее экономичный способ с точки зрения WU (1 149 WU для того же списка из 2 000 элементов 6), так как операция выполняется на уровне базы данных пакетом. Однако функциональность этого метода ограничена простыми изменениями полей и не позволяет выполнять сложную логику или вызовы внешних API для каждого элемента.

Ниже представлена визуализация различий в стоимости и рисках, подтверждающая необходимость тщательного выбора архитектурного паттерна.

![][image1]

### **1.3 Ограничения нативных типов данных и вложенности**

Помимо прямых финансовых затрат, архитектура базы данных Bubble накладывает жесткие ограничения на структуру данных, что становится критичным для аналитических задач проекта P⁎. В отличие от реляционных баз данных (SQL), где связи реализуются через внешние ключи (foreign keys) и эффективные JOIN-операции, Bubble использует списки "Things".

Исследования показывают, что когда родительский объект содержит список дочерних объектов (например, "Список Пользователей" внутри объекта "Событие"), Bubble загружает *весь* этот список в память при обращении к родительскому объекту.7 Это архитектурное решение приемлемо для списков до 100 элементов, но при масштабировании до тысяч или десятков тысяч записей производительность деградирует катастрофически. Загрузка списка из 1000 пользователей потребляет значительно больше ресурсов, чем 100, и этот процесс повторяется при каждом обращении.7

Кроме того, существуют жесткие лимиты на поиск с сортировкой — максимум 50 000 объектов.8 Это означает, что если в базе данных проекта накопится миллион событий аналитики, нативные инструменты Bubble просто не смогут выполнить запрос "найти последние 100 событий, отсортированных по дате", если предварительная выборка превышает 50 000. Это делает построение нативной аналитики на больших объемах данных технически невозможным без использования внешних хранилищ.

## ---

**2. Целостность данных и проблема состояния гонки (Race Conditions)**

Второй, и, возможно, более критичной проблемой, вызывающей беспокойство Клиента, является целостность данных. В частности, речь идет о дублировании записей при параллельной обработке запросов, например, при получении вебхуков от платежных систем или внешних API. Анализ показывает, что это не ошибка реализации конкретного разработчика, а фундаментальное свойство асинхронной архитектуры Bubble.

### **2.1 Анатомия провала логики "Найти или Создать"**

Типичный сценарий, который должен реализовать проект P⁎, — это идемпотентность создания записей. Например, при поступлении сигнала о новом пользователе система должна проверить, существует ли он уже в базе, и создать запись только в случае отсутствия. В Bubble это реализуется последовательностью действий в рабочем процессе (workflow):

1. **Поиск (Search):** Найти пользователя с Email = X.  
2. **Условие (Condition):** Выполнять следующий шаг только, если Search:count is 0.  
3. **Действие (Create):** Создать нового пользователя.

Однако, как подтверждают многочисленные жалобы разработчиков и технический анализ 9, эта логика фатально уязвима для состояния гонки (Race Condition). Поскольку рабочие процессы Bubble выполняются на сервере параллельно и не имеют механизмов блокировки транзакций (transaction isolation), возникает следующая хронология событий при одновременном поступлении нескольких запросов:

Представим временную шкалу, где три параллельных потока (Поток A, Поток B, Поток C) обрабатывают вебхуки для одного и того же нового пользователя:

* **T=0ms:** Все три потока одновременно инициируют поиск по базе данных.  
* **T=10ms:** База данных возвращает результат каждому потоку: "Записей не найдено (Count = 0)", так как ни один из потоков еще не совершил запись.  
* **T=20ms:** Все три потока проходят проверку условия, так как для каждого из них условие "Count is 0" истинно.  
* **T=30ms:** Поток A создает запись.  
* **T=35ms:** Поток B создает дубликат записи.  
* **T=40ms:** Поток C создает третий дубликат.

В результате вместо одной уникальной записи в базе данных появляются три, что полностью нарушает целостность данных и приводит к ошибкам в дальнейшей аналитике и биллинге.

### **2.2 Неэффективность стандартных методов обхода**

Сообщество разработчиков Bubble предлагает различные методы обхода этой проблемы, но наш анализ показывает их несостоятельность для серьезных проектов уровня P⁎:

* **Уникальные поля (Unique Constraints):** Хотя Bubble позволяет пометить поле как "уникальное", на практике это часто приводит к тому, что рабочий процесс просто падает с ошибкой, не предоставляя удобного способа обработки исключения ("catch"), или же проверка уникальности не срабатывает достаточно быстро при высоконагруженном потоке.9  
* **Искусственные задержки:** Некоторые разработчики добавляют случайные паузы (random delays) перед выполнением поиска, надеясь "развести" потоки во времени.9 Это решение является ненадежным "костылем" (hack), который замедляет работу системы и не дает 100% гарантии отсутствия коллизий.  
* **Очереди на стороне Bubble:** Создание собственной системы очередей внутри Bubble возможно 11, но требует значительных усилий по администрированию и увеличивает потребление WU, так как требует дополнительных операций записи и чтения для управления самой очередью.

### **2.3 Единственное надежное решение: Атомарность внешних баз данных**

Обоснованность беспокойства Клиента подтверждается тем, что внутри самого Bubble надежного решения для высоконагруженных систем не существует. Единственным валидным архитектурным решением является вынос логики обеспечения уникальности на уровень базы данных, поддерживающей ACID-транзакции, такой как PostgreSQL (Supabase).

Использование конструкции INSERT... ON CONFLICT DO NOTHING (или UPSERT) в SQL позволяет гарантировать уникальность на уровне движка базы данных.12 В этом случае база данных сама блокирует соответствующий индекс на время транзакции, и даже если 10 запросов придут одновременно, успешно выполнится только один, а остальные будут либо проигнорированы, либо обновят существующую запись, но не создадут дубликат. Это подтверждает необходимость гибридной архитектуры для проекта P⁎.

# ---

**3. Дилемма аналитической архитектуры: Build vs. Buy**

Третья группа проблем Клиента связана с необходимостью построения "ежедневной аналитики". Здесь Клиент оказывается зажат между тремя огнями: высокой стоимостью готовых SaaS-решений, низкой производительностью нативных инструментов Bubble и технической сложностью разработки собственной системы.

### **3.1 Экономическая ловушка SaaS-аналитики (Mixpanel, Amplitude)**

Использование специализированных инструментов продуктовой аналитики, таких как Mixpanel или Amplitude, часто рассматривается как стандарт де-факто. Однако для стартапов и проектов с большим количеством событий (events) модель ценообразования этих сервисов может стать финансовой ловушкой.

Исследования рынка показывают, что стоимость таких инструментов часто не соответствует предоставляемой ценности на ранних этапах.14

* **Непропорциональность затрат:** За отслеживание 50 000 просмотров страниц или событий в месяц компании могут платить от $200 до $700 в год. При этом функционально сервис предоставляет базовые агрегации (count, sum, group by) и визуализацию, которые технически являются простыми SQL-запросами.  
* **Барьеры роста:** Бесплатные тарифы (например, 20M событий у Mixpanel) часто имеют функциональные ограничения, такие как отсутствие групповой аналитики или доступа к истории данных за длительный период.15 Переход на платный тариф часто сопровождается резким скачком стоимости ("pricing cliff").  
* **Блокировка данных (Vendor Lock-in):** Экспорт сырых данных из этих систем для собственной обработки часто доступен только на дорогих корпоративных тарифах 16, что делает Клиента заложником платформы.

### **3.2 Собственное решение на базе PostgreSQL (Supabase)**

Альтернативой является построение аналитики на базе PostgreSQL (через Supabase). Это решает проблему стоимости хранения данных (всего ~$0.125 за ГБ 17), но создает проблемы производительности. PostgreSQL — это транзакционная (OLTP), а не аналитическая (OLAP) база данных. Выполнение тяжелых агрегирующих запросов (например, подсчет суммы транзакций за год для миллиона пользователей) на "живой" базе данных приведет к замедлению работы всего приложения.

#### **Решение через материализованные представления (Materialized Views)**

Для реализации требования "ежедневной аналитики" в среде PostgreSQL оптимальным паттерном является использование материализованных представлений.18

* **Механизм:** Материализованное представление — это физический снимок результатов сложного SQL-запроса, сохраненный на диске. Чтение из него происходит мгновенно, так как вычисления уже выполнены.  
* **Автоматизация:** Для поддержания актуальности данных необходимо настроить их регулярное обновление. В экосистеме Supabase это реализуется с помощью расширения pg_cron, которое позволяет запускать команду REFRESH MATERIALIZED VIEW по расписанию (например, каждую ночь).21  
* **Ограничения:** Данный подход идеален для отчетности с задержкой (например, "вчерашние данные"), но не подходит для аналитики реального времени, так как данные обновляются дискретно. Кроме того, при объемах данных свыше 500 000 - 1 000 000 строк даже обновление представлений может стать слишком ресурсоемким.

В следующей таблице представлен анализ применимости различных инструментов в зависимости от требований к задержке данных и их объему, помогающий выбрать верный инструмент.

| Объем Данных | Требование к свежести: Ежедневно/Пакетно | Требование к свежести: Реальное время |
| :---- | :---- | :---- |
| **Низкий (< 500k строк)** | **Postgres Materialized Views** (Supabase). Оптимально по цене и сложности. | **Bubble Native / Supabase Direct Query**. Возможно, но нагружает основной интерфейс. |
| **Высокий (> 10M строк)** | **Data Warehouse** (Snowflake, BigQuery). Требует ETL-процессов. | **Columnar Database** (Tinybird, ClickHouse). Единственный вариант для sub-second аналитики на больших данных. |

### **3.3 Высоконагруженная аналитика: Tinybird и ClickHouse**

Если проект P⁎ предполагает работу с миллионами событий (high-volume time-series data), то даже Postgres перестанет справляться с аналитической нагрузкой. В этом случае обоснован переход на колоночные базы данных (Columnar Databases), такие как ClickHouse, или их управляемые версии, например, Tinybird.23

Колоночные базы данных хранят данные по столбцам, а не по строкам, что позволяет выполнять аналитические запросы (например, "средняя цена по всем заказам") в 10-100 раз быстрее традиционных баз данных.25 Tinybird позволяет превращать SQL-запросы над такими данными в мгновенные API-эндпоинты. Однако, это решение является "избыточным" (overkill) для малых объемов данных и добавляет сложности в интеграцию.

# ---

**4. Проблема синхронизации данных (Гибридная архитектура)**

Четвертая критическая зона — это попытка Клиента поддерживать "зеркальные" базы данных: одну в Bubble и одну внешнюю (SQL). Исследования категорически предостерегают от такого подхода.

### **4.1 Миф о двусторонней синхронизации**

Попытка иметь две идентичные синхронизированные базы данных — это архитектурный анти-паттерн.26

* **Стоимость:** Постоянная пересылка данных туда и обратно через API или плагины (SQL Connector) генерирует огромный объем WU и трафика.  
* **Рассинхронизация:** В отсутствие сложных механизмов разрешения конфликтов (conflict resolution), базы данных неизбежно начнут различаться. Сбой вебхука, тайм-аут API или ошибка валидации приведут к тому, что в Bubble у пользователя будет один статус, а в SQL — другой.  
* **Задержка:** Внешняя база данных всегда будет отставать от Bubble на время выполнения транзакции и передачи данных, что создает проблемы для пользовательского интерфейса.

### **4.2 Стратегия разделения ответственности**

Вместо синхронизации рекомендуется стратегия **разделения ответственности** 27:

1. **Транзакционные данные ("Горячие"):** Профили пользователей, настройки, текущие активные сессии. Эти данные должны жить в Bubble для обеспечения максимальной скорости работы UI.  
2. **Аналитические данные и Логи ("Холодные/Теплые"):** История событий, кликстрим, завершенные транзакции, аудиторские следы. Эти данные должны писаться **напрямую** во внешнюю базу данных (Supabase/Tinybird), минуя базу Bubble.

Такой подход устраняет необходимость в синхронизации, так как данные не дублируются, а распределяются по системам в зависимости от их назначения. Bubble читает аналитику из внешней базы только в момент необходимости (например, для построения графика), используя SQL Connector как "окно" во внешние данные, а не как хранилище.

# ---

**5. Ограничения серверной инфраструктуры (Serverless Timeouts)**

Стремление Клиента перенести тяжелую логику обработки данных (ETL) из Bubble на внешнюю платформу, такую как Vercel (Next.js), является логичным шагом, но оно сталкивается с новыми ограничениями — **тайм-аутами serverless-функций**.

### **5.1 Стена тайм-аутов**

Serverless-функции (Function-as-a-Service) спроектированы для коротких операций "запрос-ответ", характерных для веб-трафика, а не для длительных фоновых процессов. Исследование документации Vercel выявляет жесткие лимиты 29:

* **Hobby Plan:** Максимальное время выполнения функции — 10 секунд (по умолчанию) или до 60 секунд при настройке.  
* **Pro Plan:** Максимальное время — 15 секунд (по умолчанию) или до 300 секунд (5 минут).

Это создает критический риск для задач "ежедневной аналитики". Если скрипт, который должен собрать данные за день, агрегировать их и записать в базу, будет выполняться 5 минут и 1 секунду, платформа Vercel принудительно прервет его выполнение (kill process). Это приведет к тому, что данные будут обработаны лишь частично, база данных останется в некорректном состоянии, а Клиент не получит никакого уведомления об успешном завершении, кроме лога ошибки.31

### **5.2 Иллюзия Cron Jobs**

Хотя Vercel поддерживает Cron Jobs (планировщик задач), технически это просто механизм, который отправляет HTTP-запрос к вашей функции по расписанию.33 Этот запрос подчиняется тем же самым лимитам тайм-аута. Если ваша функция падает через 10 секунд при ручном вызове, она упадет через 10 секунд и при вызове через Cron.

### **5.3 Решения для асинхронной оркестрации**

Для решения этой проблемы необходимо переходить от синхронного выполнения к асинхронной оркестрации задач.

* **Fluid Compute:** Vercel предлагает новую модель Fluid Compute, которая позволяет увеличить время выполнения за счет изменения модели биллинга (оплата за время работы CPU), но даже она имеет пределы.35  
* **Внешние очереди (Inngest, Trigger.dev):** Это наиболее надежный паттерн. Вместо того чтобы функция Vercel сама выполняла всю работу, она лишь инициирует задачу ("событие") и отправляет её в специализированный сервис оркестрации (например, Inngest). Этот сервис затем управляет выполнением задачи, разбивает её на шаги (steps), обеспечивает повторные попытки (retries) в случае сбоев и может поддерживать выполнение процессов длительностью в часы или дни.36

Ниже представлен график, иллюстрирующий, почему стандартные serverless-функции не подходят для ETL-задач, и где проходит граница применимости различных решений.

![][image2]

## ---

**6. Стратегические рекомендации и Дорожная карта**

На основе проведенного анализа мы подтверждаем, что проблемы, беспокоящие Клиента ꆜ, не только обоснованы, но и являются критическими индикаторами того, что проект P⁎ перерос архитектурные рамки MVP (Minimum Viable Product). Текущая реализация пытается решать задачи корпоративного уровня (высокая конкурентность, массовая обработка данных) инструментами, предназначенными для прототипирования.

Для стабилизации проекта и обеспечения его масштабируемости рекомендуется следующая дорожная карта:

### **Фаза 1: Стабилизация данных (Немедленно)**

1. **Устранение Race Conditions:** Полностью отказаться от логики "Search then Create" внутри Bubble для входящих вебхуков.  
2. **Внедрение SQL-Constraints:** Настроить таблицы в Supabase с уникальными индексами (UNIQUE index) по ключевым полям (email, transaction_id).  
3. **Прямая запись:** Перенастроить вебхуки на запись данных напрямую в Supabase через Edge Functions с использованием ON CONFLICT DO NOTHING. Это мгновенно остановит создание дубликатов.

### **Фаза 2: Оптимизация аналитики (1 месяц)**

1. **Создание Материализованных Представлений:** Перенести логику агрегации данных из Bubble в PostgreSQL Materialized Views.  
2. **Настройка pg_cron:** Автоматизировать обновление представлений в Supabase.  
3. **Интеграция UI:** Настроить SQL Connector в Bubble на чтение из этих представлений для отображения графиков, сняв нагрузку с основного движка Bubble.

### **Фаза 3: Оркестрация процессов (1-3 месяца)**

1. **Внедрение Inngest:** Для всех процессов обработки данных, занимающих более 10 секунд, внедрить платформу оркестрации Inngest поверх Vercel. Это решит проблему тайм-аутов и обеспечит надежность выполнения фоновых задач.  
2. **Оптимизация WU:** Провести ревизию всех оставшихся в Bubble рабочих процессов. Заменить рекурсивные потоки на "Schedule API Workflow on a List" там, где риск гонки данных устранен переносом логики в SQL, или перенести их на внешний бэкенд.

Реализация этого плана позволит трансформировать проект P⁎ из хрупкого прототипа в надежную масштабируемую систему, сохранив при этом скорость разработки фронтенда на Bubble.

#### **Works cited**

1. FAQ: Pricing and Workload - Bubble Docs, accessed December 18, 2025, [https://manual.bubble.io/account-and-marketplace/account-and-billing/pricing-plans/pricing-faq](https://manual.bubble.io/account-and-marketplace/account-and-billing/pricing-plans/pricing-faq)  
2. Workload Explained | Bubble, accessed December 18, 2025, [https://bubble.io/blog/what-is-workload/](https://bubble.io/blog/what-is-workload/)  
3. Workload - Bubble Docs, accessed December 18, 2025, [https://manual.bubble.io/help-guides/workload](https://manual.bubble.io/help-guides/workload)  
4. Understanding Bubble Workload Unit - Need help, accessed December 18, 2025, [https://forum.bubble.io/t/understanding-bubble-workload-unit/263672](https://forum.bubble.io/t/understanding-bubble-workload-unit/263672)  
5. Bulk operation methods compared - Bubble Docs, accessed December 18, 2025, [https://manual.bubble.io/help-guides/maintaining-an-application/database-maintenance/bulk-operations/bulk-operation-methods-compared](https://manual.bubble.io/help-guides/maintaining-an-application/database-maintenance/bulk-operations/bulk-operation-methods-compared)  
6. Does "Schedule API on a list" work better with new pricing? - Bubble Forum, accessed December 18, 2025, [https://forum.bubble.io/t/does-schedule-api-on-a-list-work-better-with-new-pricing/260765](https://forum.bubble.io/t/does-schedule-api-on-a-list-work-better-with-new-pricing/260765)  
7. Why is this costing so much Workload Usage? - Need help - Bubble Forum, accessed December 18, 2025, [https://forum.bubble.io/t/why-is-this-costing-so-much-workload-usage/312421](https://forum.bubble.io/t/why-is-this-costing-so-much-workload-usage/312421)  
8. Hard limits | Bubble Docs, accessed December 18, 2025, [https://manual.bubble.io/help-guides/maintaining-an-application/performance-and-scaling/hard-limits](https://manual.bubble.io/help-guides/maintaining-an-application/performance-and-scaling/hard-limits)  
9. Race conditions - APIs - Bubble Forum, accessed December 18, 2025, [https://forum.bubble.io/t/race-conditions/26271](https://forum.bubble.io/t/race-conditions/26271)  
10. Race conditions in bubble - Database, accessed December 18, 2025, [https://forum.bubble.io/t/race-conditions-in-bubble/269758](https://forum.bubble.io/t/race-conditions-in-bubble/269758)  
11. Avoiding a race condition in "find or create" logic with db triggers + bulk API - Bubble Forum, accessed December 18, 2025, [https://forum.bubble.io/t/avoiding-a-race-condition-in-find-or-create-logic-with-db-triggers-bulk-api/295040](https://forum.bubble.io/t/avoiding-a-race-condition-in-find-or-create-logic-with-db-triggers-bulk-api/295040)  
12. PostgreSQL Past, Present, and Future: Moving The Goalposts - Robert Haas, accessed December 18, 2025, [http://rhaas.blogspot.com/2016/01/postgresql-past-present-and-future.html](http://rhaas.blogspot.com/2016/01/postgresql-past-present-and-future.html)  
13. The complete PostgreSQL 16 handbook — design, optimize, and secure | UnfoldAI, accessed December 18, 2025, [https://unfoldai.com/postgresql-16-handbook/](https://unfoldai.com/postgresql-16-handbook/)  
14. Analytics is the most overpriced category in SaaS - change my mind - Reddit, accessed December 18, 2025, [https://www.reddit.com/r/SaaS/comments/1n8c1d7/analytics_is_the_most_overpriced_category_in_saas/](https://www.reddit.com/r/SaaS/comments/1n8c1d7/analytics_is_the_most_overpriced_category_in_saas/)  
15. Mixpanel Pricing: Is It Worth the Cost? (+ Better Alternatives) - Userpilot, accessed December 18, 2025, [https://userpilot.com/blog/mixpanel-pricing/](https://userpilot.com/blog/mixpanel-pricing/)  
16. BigQuery - Mixpanel Docs, accessed December 18, 2025, [https://docs.mixpanel.com/docs/data-pipelines/integrations/bigquery](https://docs.mixpanel.com/docs/data-pipelines/integrations/bigquery)  
17. Pricing & Fees - Supabase, accessed December 18, 2025, [https://supabase.com/pricing](https://supabase.com/pricing)  
18. Materialized Views in Postgres: Our Experience and Insights | Senacor Blog, accessed December 18, 2025, [https://senacor.blog/materialized-views-in-postgres-our-experience-and-insights/](https://senacor.blog/materialized-views-in-postgres-our-experience-and-insights/)  
19. Materialized View: Pros and Cons Explained - RisingWave, accessed December 18, 2025, [https://risingwave.com/blog/materialized-view-pros-and-cons-explained/](https://risingwave.com/blog/materialized-view-pros-and-cons-explained/)  
20. Optimize Read Performance in Supabase with Postgres Materialized Views, accessed December 18, 2025, [https://dev.to/kovidr/optimize-read-performance-in-supabase-with-postgres-materialized-views-12k5](https://dev.to/kovidr/optimize-read-performance-in-supabase-with-postgres-materialized-views-12k5)  
21. How do you automate refreshing of materialized views : r/PostgreSQL - Reddit, accessed December 18, 2025, [https://www.reddit.com/r/PostgreSQL/comments/1pbbv80/how_do_you_automate_refreshing_of_materialized/](https://www.reddit.com/r/PostgreSQL/comments/1pbbv80/how_do_you_automate_refreshing_of_materialized/)  
22. Postgresql: Caching with pg_cron and Materialized Views | by Eric Hosick | The Opinionated Software Architect | Medium, accessed December 18, 2025, [https://medium.com/full-stack-architecture/postgresql-caching-with-pg-cron-and-materialized-views-3403697eadbf](https://medium.com/full-stack-architecture/postgresql-caching-with-pg-cron-and-materialized-views-3403697eadbf)  
23. The Best 8 Real-Time Data Analytics Tools in 2025 - Tinybird, accessed December 18, 2025, [https://www.tinybird.co/blog/best-real-time-data-analytics-tools](https://www.tinybird.co/blog/best-real-time-data-analytics-tools)  
24. Best 8 Managed Data Platforms for Real-Time Analytics - Tinybird, accessed December 18, 2025, [https://www.tinybird.co/blog/managed-data-platforms](https://www.tinybird.co/blog/managed-data-platforms)  
25. Fastest database for analytics in 2025 compared with real benchmarks - Tinybird, accessed December 18, 2025, [https://www.tinybird.co/blog/fastest-database-for-analytics](https://www.tinybird.co/blog/fastest-database-for-analytics)  
26. How to load data from external db into bubble db - Database, accessed December 18, 2025, [https://forum.bubble.io/t/how-to-load-data-from-external-db-into-bubble-db/306772](https://forum.bubble.io/t/how-to-load-data-from-external-db-into-bubble-db/306772)  
27. Data for SaaS Workloads on Azure - Microsoft Azure Well-Architected Framework, accessed December 18, 2025, [https://learn.microsoft.com/en-us/azure/well-architected/saas/data](https://learn.microsoft.com/en-us/azure/well-architected/saas/data)  
28. Bubble Database vs external, accessed December 18, 2025, [https://forum.bubble.io/t/bubble-database-vs-external/364952](https://forum.bubble.io/t/bubble-database-vs-external/364952)  
29. Limits - Vercel, accessed December 18, 2025, [https://vercel.com/docs/limits](https://vercel.com/docs/limits)  
30. Configuring Maximum Duration for Vercel Functions, accessed December 18, 2025, [https://vercel.com/docs/functions/configuring-functions/duration](https://vercel.com/docs/functions/configuring-functions/duration)  
31. Exceeded the written data with Vercel postgres. : r/nextjs - Reddit, accessed December 18, 2025, [https://www.reddit.com/r/nextjs/comments/17nkedl/exceeded_the_written_data_with_vercel_postgres/](https://www.reddit.com/r/nextjs/comments/17nkedl/exceeded_the_written_data_with_vercel_postgres/)  
32. Serverless Functions are increasing response time over time - Help - Vercel Community, accessed December 18, 2025, [https://community.vercel.com/t/serverless-functions-are-increasing-response-time-over-time/2854](https://community.vercel.com/t/serverless-functions-are-increasing-response-time-over-time/2854)  
33. How to Setup Cron Jobs on Vercel, accessed December 18, 2025, [https://vercel.com/kb/guide/how-to-setup-cron-jobs-on-vercel](https://vercel.com/kb/guide/how-to-setup-cron-jobs-on-vercel)  
34. Managing Cron Jobs - Vercel, accessed December 18, 2025, [https://vercel.com/docs/cron-jobs/manage-cron-jobs](https://vercel.com/docs/cron-jobs/manage-cron-jobs)  
35. How to solve Next.js timeouts - Inngest Blog, accessed December 18, 2025, [https://www.inngest.com/blog/how-to-solve-nextjs-timeouts](https://www.inngest.com/blog/how-to-solve-nextjs-timeouts)  
36. CRON Vercel Alternative : r/nextjs - Reddit, accessed December 18, 2025, [https://www.reddit.com/r/nextjs/comments/1dbvi4n/cron_vercel_alternative/](https://www.reddit.com/r/nextjs/comments/1dbvi4n/cron_vercel_alternative/)  
37. Cron jobs exceeding maximum duration limits : r/nextjs - Reddit, accessed December 18, 2025, [https://www.reddit.com/r/nextjs/comments/1apbxai/cron_jobs_exceeding_maximum_duration_limits/](https://www.reddit.com/r/nextjs/comments/1apbxai/cron_jobs_exceeding_maximum_duration_limits/)  
38. Getting error for long running tasks - Help - Vercel Community, accessed December 18, 2025, [https://community.vercel.com/t/getting-error-for-long-running-tasks/16817](https://community.vercel.com/t/getting-error-for-long-running-tasks/16817)

