# 0.
Сегодня 2025-12-11.

# 1.
## 1.1.
`UW` ≔ (Upwork: https://en.wikipedia.org/wiki/Upwork)

## 1.2.
`ꆜ` ≔ (Некий конкретный потенциальный клиент на `UW`)

## 1.3.
`P⁎` ≔ (Некий конкретный потенциальный проект, опубликованный `ꆜ` на `UW`)

# 2. Информация о `P⁎`
## 2.1. URL
https://www.upwork.com/jobs/~021999029723057542100

## 2.2. Title
Varnish Cache Expert (consultancy) - Memory Management

## 2.3. Description
`PD` ≔ 
```text
#
Me an my developer are looking for a Varnish Cache specialist to help us diagnose and resolve persistent memory issues in our caching layer on our website RunRepeat.com

#
Our frontend is on a Gravitron CPU 8 Cores, 32Gb RAM. 

#
Basically, Varnish repeatedly grows the memory, which leads to performance degradation - regardless of what config we've tried. 

#
We need help with VCL configuration, cache policies, proper memory allocation, TTLs, eviction strategies and guidance on monitoring and alerting best practices.

#
Our site receives about 4M monthly sessions and the complexity is that our pages are not fully static, as users can filter by gender, size, color, which is then used throughout the site. We also have ads on the site. 

#
This is a one-time-consultantion for now, but we might need more help on server-setup things in the future, and it would be amazing to have you as a point of contact.
```

## 2.4. Tags
STUB

## 2.5. Questions
### 2.5.1.
STUB

### 2.5.2.
STUB

### 2.5.3.
STUB

### 2.5.4.
STUB

### 2.5.5.
STUB

# 5. Информация о `ꆜ`
## 5.1. Местоположение
Denmark
Frederiksberg

## 5.2. Характеристики компании
### 5.2.1. Сектор экономики
Sports & Recreation

### 5.2.2. Количество сотрудников
10-99

## 5.3. Характеристики учётной записи на `UW`
### 5.3.1. Member since
Jun 8, 2013
### 5.3.2. Hire rate (%)
93
### 5.3.3. Количество опубликованных проектов (jobs posted)
113
### 5.3.4. Total spent (USD)
540K
### 5.3.5. Количество оплаченных часов в почасовых проектах
42423
### 5.3.6. Средняя почасовая ставка (USD)
12.46 

# 6. Другие проекты `ꆜ` на `UW`
## 6.1. `P1⁎`

### 6.1.1. URL
https://www.upwork.com/jobs/~013caa0ae3e610c8bb

### 6.1.2. Title
Large-scale NLP and AI copy for book reviews

### 6.1.3. Description
`P1D` ≔ 
```text
I’m Jens, founder of RunRepeat.com. We’re a 25 people team and I have worked on this for 7 years. 

I’m now starting a new project aggregating and summarizing reviews of books. It’s a huge project that depends on two main skills: (1) heavy scraping and (2) NLP and AI copy. This post is about NLP and AI copy. I have created a separate one for the scraping part as I figured we might need a separate person for that part.

Why this job is cool:
(1) it's a huge project = stable income, and you can combine with other freelance jobs as you like
(2) I have a profitable business (RunRepeat), which means that we would not run out of money. 
(3) A lot of decision-making on your end, and zero bureaucracy. 

It’s a big project, and you will be part of defining the direction of where we’ll go. Below are the bare fundamentals on where we want to get at. I understand that some of these require different skill sets, and you might not have them all. But, if you have fundamental skills in these areas and hands-on experience with something similar, I’d love to chat with you about this and see how we could work together. The tasks below are for both scrapings, NLP and AI copy - just to give you the overview of the entire project. 

(a) Scrape Amazon and Goodreads for all book titles and store basic information about the book, author, categories etc. (Millions of books). Millions of books. Example page: https://www.amazon.com/Zero-to-One-audiobook/dp/B00M284NY2/ref=sr_1_1

(b) Find all critic reviews of that book title and consider how to match variations, e.g. some only mentioning the first part of the title, or another word for it.

(c) Do text analysis of each critic review to rate them 1-100 in how positive the critic is about the review itself. I understand that it will be hard/impossible to reach such a granular score, but maybe we’ll end up with a 1 to 4 rating scale like what this site has or similar: https://bookmarks.reviews/reviews/something-new-under-the-sun/

(d) Find the best way to make AI writeups summarizing critic opinions as well as book summary/introduction to have unique copy on our pages. 

(e) Look for all “lists” where books are mentioned. For example “best business books” or “most recommended books to read in 2021” and suggest an algorithm how we incorporate these “buying guides” into our overall scoring system. How to weigh the first book listed, the 10th etc?  

(f) Get an overview of all cases of where the book has been recommended by some person or entity. The end goal is that product pages would have sections like “Recommneded by: Elon Musk, Bill Gates” and then users can click on these tags to land on a page with all books recommended by Elon Musk. Store quotes. 

(g) Scrape all user reviews and make text analysis to extract characteristics of the books.

(h) Get all awards for each book. 

(i) Overview of all forum discussions, e.g. scraping of reddit and other sites that users can click on to read more. Provide short snippets. 

(j) Based on user and critic reviews, get to an overall score, and create our own lists for all possible categories, like “best python programming books” or “most recommended” that can then be narrowed down with filters. 

I know, it’s not something that you’ll have done by tomorrow. As a first step, let’s see if there’s a match between you, I and the project. 
```

### 6.1.4. Publication Date
4 years ago

# 7.
## 7.1.
`POs` ≔⠿ {`P1⁎`}

## 7.2.
`Ps` ≔ (⠿{`P⁎`} ⋃ `POs`)

## 7.3.
`Pi` : `Ps`

# 8.
## 8.1.
`С⁎` ≔ 
```
Компания `ꆜ`:
~~~
RunRepeat.com
~~~
```

## 8.2.
⊤ (Все `Pi` касаются `С⁎`)

## 8.3.
Сайт `С⁎`: https://runrepeat.com

# 9.
`P†` ≔†
```
Проблема, о которой `ꆜ` пишет в `PD`:
~~~
Varnish repeatedly grows the memory, which leads to performance degradation - regardless of what config we've tried
~~~
```

# 10. Что беспокоит `ꆜ` (анализ выполнен Gemini Deep Think)
https://gemini.google.com/share/91e87ec1062c

## 1. Выявление проблем в проекте `P⁎`

На основе анализа описания задачи `PD` и онтологии `O.md`, можно выделить следующие ключевые проблемы, которые беспокоят клиента `ꆜ`:

1.  **Неконтролируемый рост потребления оперативной памяти (Memory Leak / Unbounded Growth).** Varnish постоянно увеличивает потребление RAM вплоть до исчерпания ресурсов сервера (32 ГБ), несмотря на установленные лимиты.
2.  **Деградация производительности (Performance Degradation).** Исчерпание памяти приводит к замедлению работы сайта. Вероятно, это связано с уходом системы в swap, повышением нагрузки на CPU из-за агрессивной работы сборщика мусора (LRU nuking) или фрагментацией памяти.
3.  **Неэффективность конфигурации («Config changes haven't helped»).** Клиент утверждает, что стандартные методы тюнинга не решают проблему. Это указывает на то, что корень проблемы лежит вне стандартных настроек размера кэша (`-s malloc,SIZE`).
4.  **Сложность кэширования динамического контента (High Cardinality).** Наличие фасетного поиска (фильтры по полу, размеру, цвету) и рекламных меток создает высокую вариативность запросов.
5.  **Влияние аппаратной архитектуры (Graviton CPU).** Использование процессоров ARM64 (AWS Graviton) может вносить специфику в управление памятью, если используемое ПО не оптимизировано под эту архитектуру.

## 2. Анализ обоснованности выявленных проблем

Выявленные проблемы технически обоснованы. Ситуация `RunRepeat.com` представляет собой классический анти-паттерн конфигурации Varnish для E-commerce проектов с высокой вариативностью.

### 2.1. Проблема «Взрыва кэша» (Cache Bloat / High Cardinality)
Эта проблема является **наиболее вероятной первопричиной** и полностью обоснована техническим устройством Varnish.
*   **Механизм:** Varnish по умолчанию использует полный URL (включая строку запроса `query string`) для формирования ключа объекта.
*   **Анализ:**
    *   Фильтры (`gender`, `size`, `color`) создают множество перестановок. Запросы `/shoe?size=42&color=red` и `/shoe?color=red&size=42` считаются разными объектами.
    *   Реклама на сайте («We also have ads») подразумевает наличие меток (gclid, fbclid, utm), уникальных для каждого пользователя. Это заставляет Varnish кэшировать копию страницы для каждого клика.
*   **Влияние на память:** Даже если размер *данных* ограничен параметром `-s malloc`, каждый объект потребляет около **1 КБ** оперативной памяти на **метаданные** (структуры `struct obj`, `struct objcore`), которые хранятся вне основного хранилища. При миллионах мелких объектов (из-за фильтров и рекламы) одни только метаданные могут занять десятки гигабайт RAM, вызывая переполнение памяти.

### 2.2. Проблема Transient Storage (Временное хранилище)
Эта проблема обосновывает жалобу клиента на то, что «изменения конфигов не помогают».
*   **Обоснование:** В Varnish существует отдельное хранилище `Transient` для объектов с коротким TTL и технических записей `hit-for-pass` / `hit-for-miss` (меток о том, что объект нельзя кэшировать).
*   **Анализ:**
    *   По умолчанию размер `Transient` хранилища **не ограничен** (unbounded).
    *   Если бэкенд сайта выставляет заголовок `Set-Cookie` или `Cache-Control: private` в ответ на запросы с рекламными метками, Varnish создает запись `hit-for-miss` для каждого такого запроса.
    *   Эти записи накапливаются в Transient-хранилище, потребляя память бесконтрольно, игнорируя основной лимит кэша. Это выглядит как утечка памяти, которую невозможно устранить стандартными настройками `-s`.

### 2.3. Фрагментация памяти (Memory Fragmentation)
Обоснована, учитывая архитектуру `P⁎`.
*   **Обоснование:** Varnish часто использует системный аллокатор памяти (`glibc malloc`). В сценариях с активным созданием и удалением миллионов мелких объектов (фильтры, сессии) возникает сильная фрагментация кучи.
*   **Анализ:** Операционная система может сообщать, что процесс занимает всю память (RSS), хотя полезных данных в кэше гораздо меньше. Стандартным решением является использование аллокатора **jemalloc**, который лучше справляется с фрагментацией, но он может требовать явной настройки.

### 2.4. Специфика Graviton (ARM64)
Является важным фактором обоснованности проблем с производительностью.
*   **Анализ:** Для архитектуры ARM64 критически важен размер страниц памяти. Стандартные настройки Linux (4K pages) могут создавать высокую нагрузку на TLB (Translation Lookaside Buffer) при работе с большими объемами памяти (32 ГБ) и огромным количеством объектов. Переход на 64K pages часто дает прирост производительности и стабильности, но требует поддержки со стороны ОС и сборки Varnish.

# 11. Что беспокоит `ꆜ` (анализ выполнен Gemini Deep Research) 
https://gemini.google.com/share/abbaebeb2f0d

## **1. Стратегический обзор архитектурных вызовов в условиях высокой кардинальности**

Проект RunRepeat.com (в дальнейшем именуемый "Проект P⁎"), представляющий собой масштабную платформу агрегации обзоров и электронной коммерции, столкнулся с рядом критических проблем производительности и стабильности инфраструктуры кэширования. Анализ симптоматики, предоставленной технической командой клиента, указывает на классическую, но сложную в диагностике дихотомию между "утечкой памяти" (memory leak) и "раздуванием кэша" (cache bloat). В контексте высоконагруженных систем, использующих Varnish Cache в качестве HTTP-акселератора, эти понятия часто смешиваются, приводя к ошибочным стратегиям оптимизации.

Современные архитектуры e-commerce, подобные RunRepeat, характеризуются использованием фасетной навигации — системы глубокой фильтрации контента по множеству атрибутов (размер, цвет, бренд, технические характеристики обуви).1 Это создает среду с экстремально высокой кардинальностью URL-адресов. В отсутствие строгих механизмов нормализации запросов, Varnish Cache вынужден обрабатывать комбинаторный взрыв уникальных объектов, что неизбежно приводит к исчерпанию ресурсов оперативной памяти. Однако, как показывает детальное изучение технических данных, проблема RunRepeat выходит за рамки простого управления объектами и затрагивает фундаментальные механизмы взаимодействия демона varnishd с подсистемой управления памятью операционной системы Linux.

Центральной гипотезой данного исследования является утверждение, что наблюдаемая нестабильность вызвана тремя взаимосвязанными факторами:

1. **Фрагментация кучи (Heap Fragmentation):** Неэффективность стандартного аллокатора glibc при работе с паттернами аллокации Varnish, приводящая к росту RSS (Resident Set Size) процесса без реального увеличения полезной нагрузки.3  
2. **Аномалии временного хранилища (Transient Storage):** Неконтролируемый рост "Transient" хранилища, которое по умолчанию не имеет верхнего лимита памяти и используется для короткоживущих объектов и буферизации потоковой передачи данных.5  
3. **Кэш-блоттинг (Cache Bloat):** Заполнение хранилища дубликатами контента из-за отсутствия нормализации Query String и заголовков User-Agent, что превращает полезный кэш в хранилище мусорных данных.7

В данном отчете представлен исчерпывающий анализ каждого из этих слоев, подкрепленный техническими данными и рекомендациями по переходу к устойчивой архитектуре.

## ---

**2. Глубинный анализ подсистемы управления памятью: Аллокаторы и Фрагментация**

Для понимания природы "утечек памяти", о которых сообщает клиент, необходимо рассмотреть механизм взаимодействия Varnish с системной памятью. Varnish не управляет физической памятью напрямую; вместо этого, при использовании бэкенда хранения malloc, он делегирует эту задачу стандартному системному аллокатору через вызовы malloc() и free().8

### **2.1. Механика взаимодействия Varnish и системного аллокатора**

Когда Varnish настроен с параметром -s malloc,256G, это создает иллюзию, что потребление памяти жестко ограничено 256 гигабайтами. В реальности этот лимит применяется только к *полезной нагрузке* кэшированных объектов. Он не учитывает накладные расходы на структуры данных ядра Varnish (overhead), такие как struct object, struct objcore и struct objhead, которые необходимы для отслеживания заголовков, сроков действия (TTL) и состояния объектов. Оценки показывают, что накладные расходы составляют примерно 1 КБ на каждый объект.8

Для сайта масштаба RunRepeat, где количество объектов может исчисляться десятками миллионов (из-за вариативности фильтров), накладные расходы могут составлять десятки гигабайт сверх установленного лимита -s.

| Тип памяти | Описание | Управляемость лимитом -s |
| :---- | :---- | :---- |
| **Object Storage** | Тело кэшированного объекта (HTML, JSON, изображения) | **Да** (Жесткий лимит) |
| **Object Overhead** | Метаданные (заголовки, баны, указатели) ~1KB/объект | **Нет** (Линейный рост от кол-ва объектов) |
| **Transient Storage** | Временные объекты, streaming buffers, hit-for-miss | **Нет** (По умолчанию unbounded) |
| **Workspace Memory** | Память потоков (workspace_client, thread_pool_stack) | **Нет** (Зависит от кол-ва потоков) |
| **Fragmentation** | Потерянная память внутри аллокатора ("дыры") | **Нет** (Зависит от эффективности аллокатора) |

### **2.2. Проблема фрагментации в glibc malloc**

Стандартным аллокатором в большинстве дистрибутивов Linux (RHEL, Debian, Ubuntu) является реализация malloc из библиотеки glibc (основанная на ptmalloc). Анализ источников указывает на то, что glibc крайне неэффективен для паттернов нагрузки, характерных для Varnish: высокая конкурентность, частые аллокации и деаллокации объектов различного размера.3

Проблема заключается в механизме работы с "аренами" (arenas). Для уменьшения блокировок (lock contention) в многопоточной среде, glibc создает несколько арен памяти. Когда память освобождается (free()), она возвращается в арену, но не всегда возвращается операционной системе. Если Varnish запрашивает блок памяти, который не помещается в существующие "дыры" фрагментированной кучи, аллокатор запрашивает новые страницы у ОС. Это приводит к росту виртуальной памяти (VSZ) и резидентной памяти (RSS), даже если внутренние счетчики Varnish показывают наличие свободного места в хранилище.4

Клиент интерпретирует это как утечку памяти, так как процесс varnishd потребляет все больше RAM, в то время как объем полезных данных в кэше может оставаться стабильным. Это классический пример внешней фрагментации. В особо тяжелых случаях, описанных в технических отчетах, переключение с glibc на альтернативные аллокаторы позволяло сократить потребление памяти с 192 ГБ до 18 ГБ.10

### **2.3. Превосходство jemalloc в высоконагруженных средах**

Техническим стандартом де-факто для высокопроизводительных приложений управления памятью (таких как Redis, Varnish, Firefox) является использование аллокатора jemalloc, разработанного Джейсоном Эвансом.

jemalloc использует принципиально иную стратегию управления памятью, разделяя объекты на классы по размеру (size classes) и используя структуру "chunks" и "runs". Это позволяет минимизировать фрагментацию, так как объекты одного размера группируются вместе. Освобождение блока памяти в jemalloc с гораздо большей вероятностью приводит к освобождению целого чанка, который может быть немедленно возвращен операционной системе.3

Кроме того, jemalloc предоставляет расширенные возможности интроспекции и настройки, такие как параметры "decay", управляющие скоростью возврата "грязных" страниц (dirty pages) ядру ОС. Установка агрессивных параметров decay может существенно снизить RSS процесса ценой незначительного увеличения нагрузки на CPU.12

Для RunRepeat.com критически важно верифицировать, с какой библиотекой слинкован исполняемый файл varnishd. В системах на базе RHEL/CentOS jemalloc часто не является дефолтным и требует явной установки пакета jemalloc и настройки systemd unit-файла для предзагрузки библиотеки или использования специально скомпилированной версии Varnish.14 Игнорирование этого фактора делает любые настройки VCL косметическими мерами на фоне фундаментальной утечки ресурсов.

## ---

**3. Парадокс временного хранилища (Transient Storage)**

Одной из наиболее коварных и наименее очевидных причин нестабильности Varnish является механизм Transient Storage. Анализ конфигурации и симптомов указывает на высокую вероятность того, что именно этот компонент ответственен за неконтролируемые всплески потребления памяти, приводящие к срабатыванию OOM Killer.15

### **3.1. Архитектура Transient Storage**

В архитектуре Varnish предусмотрено специальное хранилище для объектов, которые считаются "короткоживущими". По умолчанию, любой объект, чей TTL (Time To Live) меньше значения параметра shortlived (по умолчанию 10.0 секунд), автоматически помещается в Transient Storage, а не в основное хранилище (например, malloc или file).17

Критическая уязвимость конфигурации по умолчанию заключается в том, что Transient Storage использует **неограниченный** (unbounded) бэкенд malloc. Это означает, что если сайт подвергается атаке, или бэкенд начинает отдавать массовые ошибки с коротким TTL, или происходит всплеск посещаемости на страницах с отключенным кэшированием (hit-for-miss), Varnish будет аллоцировать память под эти объекты до полного исчерпания физической RAM сервера, игнорируя любые лимиты, установленные для основного хранилища.5

### **3.2. Векторы атаки через короткоживущие объекты**

Для RunRepeat.com существует несколько сценариев, при которых Transient Storage становится вектором отказа в обслуживании:

1. **Массовое создание объектов Hit-For-Miss:** Если Varnish настроен на создание hit-for-miss объектов (запоминание того, что страница не кэшируется) для запросов с уникальными параметрами, и TTL этих записей мал (например, 2 минуты, что является дефолтом для uncacheable_ttl 20), они могут попадать в Transient Storage, если параметр shortlived настроен некорректно или если логика VCL явно не переопределяет хранилище.  
2. **Буферизация потоков (Streaming Buffering):** Когда Varnish получает ответ от бэкенда, который нельзя кэшировать (например, из-за заголовка Set-Cookie), но который нужно передать медленному клиенту, данные буферизируются. Эти байты учитываются в счетчиках Transient Storage (SMA.Transient.c_bytes). При большом количестве одновременных подключений (high concurrency) объем этих буферов может достигать гигабайт.6  
3. **Синтетические ответы:** Ошибки, генерируемые внутри Varnish (vcl_backend_error), также часто попадают в Transient Storage. При сбое бэкенда лавина ошибок 503 может заполнить память.22

### **3.3. Стратегия ограничения (Bounding)**

Решение проблемы Transient Storage является императивным требованием для стабильности. Необходимо явно определить лимит для этого хранилища в параметрах запуска демона varnishd.

Синтаксис для ограничения Transient Storage:

Bash

-s malloc,20G   
-s Transient=malloc,2G

В данной конфигурации основное хранилище получает 20 ГБ, а временное жестко ограничено 2 ГБ. При достижении лимита в 2 ГБ Varnish начнет применять политику вытеснения (LRU) к временным объектам, вместо того чтобы аварийно завершать работу всего процесса.23

Также рекомендуется пересмотреть значение параметра shortlived. Установка его в 0s заставит Varnish помещать все объекты, независимо от их TTL, в основное хранилище, которое имеет строгие лимиты. Это предотвратит "скрытое" потребление памяти, хотя может усилить фрагментацию основного хранилища из-за частого удаления короткоживущих объектов.

## ---

**4. Феномен Cache Bloat в условиях фасетной навигации**

Проект RunRepeat.com обладает архитектурной особенностью, которая делает его экстремально уязвимым к раздуванию кэша (Cache Bloat) — это сложная система фильтрации товаров. Исследование структуры URL показывает наличие множественных параметров фильтрации: size, width, brand, color, drop, terrain и других.2

### **4.1. Комбинаторный взрыв URL-адресов**

Varnish кэширует объекты, используя хэш, вычисляемый (по умолчанию) на основе URL и заголовка Host. Это означает, что порядок параметров в строке запроса имеет значение.

Рассмотрим два запроса:

1. /running-shoes?brand=Nike&size=10&color=Black  
2. /running-shoes?size=10&brand=Nike&color=Black

С точки зрения логики приложения (бэкенда), эти запросы идентичны и возвращают одинаковый HTML. С точки зрения Varnish, это **два разных объекта**.

Количество возможных перестановок параметров растет факториально. Если пользователь может выбрать 5 фильтров из доступных 20, количество уникальных URL-адресов превышает количество атомов во вселенной. Поисковые боты и сканеры, перебирающие фильтры в произвольном порядке, могут генерировать миллионы уникальных запросов в сутки. Это явление называется "Cache Bloat" — заполнение кэша низкополезными дубликатами, что приводит к вытеснению (eviction) действительно востребованного контента (например, главной страницы или популярных категорий).7

Счетчик n_lru_nuked в varnishstat является главным индикатором этой проблемы. Высокие значения этого счетчика свидетельствуют о том, что Varnish вынужден агрессивно удалять объекты, чтобы освободить место для новых, зачастую бесполезных вариаций.27

### **4.2. Маркетинговые метки и "мусорные" параметры**

Помимо функциональных фильтров, e-commerce трафик насыщен маркетинговыми параметрами: utm_source, utm_medium, gclid, fbclid и уникальными идентификаторами сессий. Если эти параметры попадают в хэш кэша, каждый переход пользователя из рекламной рассылки создает уникальную копию страницы в памяти.

Для сайта с посещаемостью RunRepeat один популярный newsletter может мгновенно инвалидировать эффективность кэширования для целевых страниц, заполнив память тысячами копий одной и той же страницы, отличающихся лишь меткой utm_id.

## ---

**5. Стратегии нормализации VCL: От хаоса к порядку**

Решение проблемы Cache Bloat лежит исключительно в плоскости конфигурации VCL (Varnish Configuration Language). Необходима жесткая нормализация входящих запросов в процедуре vcl_recv **до** того, как будет вычислен хэш объекта.

### **5.1. Алгоритмическая сортировка параметров (Query String Sorting)**

Единственным надежным способом борьбы с комбинаторным взрывом перестановок является алфавитная сортировка параметров запроса. Это гарантирует, что запросы ?a=1&b=2 и ?b=2&a=1 будут преобразованы в единую каноническую форму перед поиском в кэше.

Использование модуля vmod_querystring (или функционала std в современных версиях Varnish) позволяет реализовать это одной строкой кода.

**Пример реализации (VCL):**

Code snippet

import std;  
import querystring;

sub vcl_recv {  
    # Сортировка параметров для канонизации URL  
    set req.url = std.querysort(req.url);  
      
    # Альтернативно с использованием vmod_querystring для очистки  
    set req.url = querystring.sort(req.url);  
}

Внедрение сортировки немедленно устраняет дублирование, вызванное произвольным порядком кликов пользователя или поведением ботов.29

### **5.2. Санитизация маркетинговых параметров**

Необходимо внедрить белый (whitelist) или черный (blacklist) список параметров. Для RunRepeat, учитывая сложность фильтров, черный список (удаление известного мусора) может быть более безопасным стартом, но белый список (разрешение только известных фильтров) является идеалом архитектурной чистоты.

**Рекомендуемый VCL для очистки:**

Code snippet

sub vcl_recv {  
    # Удаление стандартных меток Google Analytics и Facebook  
    if (req.url ~ "(?|&)(utm_source|utm_medium|utm_campaign|gclid|fbclid|cx|ie|cof|siteurl)=") {  
        set req.url = regsuball(req.url, "&(utm_source|utm_medium|utm_campaign|gclid|fbclid|cx|ie|cof|siteurl)=([A-z0-9_-.%25]+)", "");  
        set req.url = regsub(req.url, "(?&)", "?");  
        set req.url = regsub(req.url, "?$", "");  
    }  
}

Этот код удаляет параметры, которые нужны только клиентскому JavaScript (Google Analytics), но не влияют на генерацию HTML на бэкенде. Это позволяет отдавать один и тот же кэшированный объект пользователям, пришедшим из разных рекламных каналов.7

### **5.3. Нормализация заголовка User-Agent**

Еще одним вектором раздувания кэша является заголовок Vary: User-Agent. Если бэкенд RunRepeat выдает этот заголовок (что часто случается в PHP-фреймворках для разделения мобильной и десктопной версий), Varnish будет хранить копию страницы для *каждой* версии браузера Chrome, Safari, Firefox и т.д.

Учитывая тысячи вариаций User-Agent, это катастрофически снижает Hit Rate. Решением является нормализация User-Agent в vcl_recv до ограниченного набора бакетов: "mobile", "tablet", "desktop".

Code snippet

sub vcl_recv {  
    if (req.http.User-Agent ~ "(?i)(mobile|android|iphone)") {  
        set req.http.X-UA-Device = "mobile";  
    } else {  
        set req.http.X-UA-Device = "desktop";  
    }  
    # Опционально: перезаписать User-Agent для бэкенда или использовать X-UA-Device в vcl_hash  
}

Если сайт использует адаптивный дизайн (Responsive Design) и HTML не меняется в зависимости от устройства, заголовок Vary: User-Agent следует принудительно удалять в vcl_backend_response.30

## ---

**6. Тонкая настройка инфраструктуры и многопоточности**

Помимо управления памятью и нормализации запросов, стабильность Varnish под нагрузкой зависит от конфигурации пулов потоков (thread pools) и рабочих областей памяти (workspaces).

### **6.1. Динамика Thread Pools**

Клиент может наблюдать большое количество потоков или "дубликатов процессов". Varnish использует модель пула потоков для обработки соединений. Параметры thread_pool_min и thread_pool_max определяют границы масштабирования.

Распространенной ошибкой является установка слишком низкого значения thread_pool_min (по умолчанию 100). В условиях трафика RunRepeat резкие всплески нагрузки (micro-bursts) могут приводить к задержкам, пока Varnish спавнит новые потоки. Это явление, известное как "Thundering Herd" на уровне планировщика потоков.

**Рекомендация:** Увеличить thread_pool_min до 500-1000, чтобы держать "горячий" резерв потоков. При этом thread_pool_max не должен превышать лимиты файловых дескрипторов системы. Важно мониторить счетчик sess_dropped, который показывает количество соединений, сброшенных из-за переполнения очереди ожидания потоков.6

### **6.2. Расчет Workspace Memory**

Каждый поток Varnish имеет выделенную область памяти (workspace_client и workspace_backend) для обработки заголовков и выполнения логики VCL. Для e-commerce сайтов с большим количеством Cookie и длинными URL (из-за фильтров), дефолтный размер (обычно 64k) может быть недостаточен.

Переполнение workspace приводит к ошибкам 500/503. Увеличение workspace_client до 128k или 256k является безопасной мерой оптимизации, незначительно влияющей на общее потребление памяти, но критически важной для стабильности обработки сложных запросов.32

## ---

**7. Мониторинг, Наблюдаемость и Форензика**

Переход от реактивного устранения сбоев к проактивному управлению требует внедрения правильных метрик. Утилита varnishstat предоставляет сырые данные, которые необходимо интерпретировать в контексте бизнес-логики.

### **7.1. Матрица критических метрик**

В таблице ниже представлены ключевые счетчики, мониторинг которых обязателен для диагностики описанных проблем.

| Метрика (Counter) | Описание | Интерпретация для RunRepeat | Порог тревоги |
| :---- | :---- | :---- | :---- |
| **SMA.s0.g_bytes** | Байты в основном хранилище | Должна выходить на плато у лимита -s. Если падает резко — возможен перезапуск. | > 95% от лимита |
| **SMA.Transient.g_bytes** | Байты во временном хранилище | **Главный индикатор утечки.** Неконтролируемый рост указывает на проблему unbounded storage. | > 1-2 ГБ |
| **n_lru_nuked** | Принудительно удаленные объекты | Индикатор Cache Bloat. Высокая скорость роста означает, что полезный кэш вымывается мусорными вариациями. | Рост > 100/сек |
| **n_object** | Количество объектов | Сравнить с каталогом товаров. Если n_object >> кол-ва товаров * вариации, значит нормализация не работает. | Аномальный рост |
| **cache_hit** / **cache_miss** | Попадания/Промахи | Hit Rate = hits / (hits + misses). Низкий Hit Rate при высоком n_object подтверждает проблему дубликатов. | < 60-70% |
| **sess_dropped** | Сброшенные сессии | Нехватка потоков или перегрузка CPU. | > 0 |

21

### **7.2. Интерпретация сценариев сбоя**

* **Сценарий А: OOM Killer убивает Varnish.**  
  * Проверка: Если SMA.s0.g_bytes стабилен, а системный RAM исчерпан, виноват либо glibc (фрагментация), либо SMA.Transient (скрытый рост).  
  * Действие: Сверить графики RSS процесса и SMA.Transient.g_bytes.  
* **Сценарий Б: Низкая производительность, высокий Backend Load.**  
  * Проверка: Высокий n_lru_nuked. Varnish "молотит" память, постоянно записывая и удаляя объекты.  
  * Действие: Внедрить нормализацию Query String.

## ---

**8. Перспективы Enterprise-решений: MSE и Memory Governor**

В контексте долгосрочной стратегии развития RunRepeat.com стоит рассмотреть возможности коммерческой версии Varnish Enterprise, которая предлагает архитектурные решения описанных проблем "из коробки".

### **8.1. Massive Storage Engine (MSE)**

В отличие от malloc (память) и file (файл с mmap), движок MSE разработан для работы с большими наборами данных (dataset), превышающими объем RAM. Он использует собственную систему аллокации, которая полностью устраняет проблему фрагментации, присущую glibc. Кроме того, MSE поддерживает персистентность (сохранение кэша при перезагрузке), что критично для минимизации нагрузки на бэкенд при обслуживании ("Cache Warming").8

### **8.2. Memory Governor**

Функция Memory Governor в Varnish Enterprise динамически управляет размером кэша. Вместо жесткого лимита на *объекты*, администратор задает целевой объем памяти для *всего процесса*. Memory Governor автоматически уменьшает размер хранилища объектов, если растут накладные расходы или потребление Transient Storage, гарантируя, что процесс никогда не выйдет за пределы выделенного бюджета памяти и не будет убит OOM Killer.16

## ---

**9. Стратегический план ремедиации (Remediation Roadmap)**

На основании проведенного аудита предлагается следующий пошаговый план действий для стабилизации инфраструктуры RunRepeat.com.

### **Фаза 1: Немедленная стабилизация (Infrastructure & Config)**

1. **Замена Аллокатора:**  
   * Проверить текущий линковщик: ldd /usr/sbin/varnishd.  
   * Внедрить jemalloc. Если используется systemd, добавить в override.conf:  
     Environment="LD_PRELOAD=/usr/lib64/libjemalloc.so.2" (путь может отличаться).  
   * Это решит проблему фрагментации и снизит RSS на 15-30%.9  
2. **Ограничение Transient Storage:**  
   * Изменить параметры запуска varnishd.  
   * Было: -s malloc,24G (пример).  
   * Стало: -s malloc,20G -s Transient=malloc,2G.  
   * Это предотвратит OOM при атаках на некэшируемый контент.  
3. **Корректировка параметров потоков:**  
   * Установить thread_pool_min=500.

### **Фаза 2: Логическая оптимизация (VCL)**

1. **Нормализация запросов (Query Sort):**  
   * Внедрить модуль std или vmod_querystring.  
   * Добавить в vcl_recv: set req.url = std.querysort(req.url);.  
   * Реализовать удаление utm_* меток.  
2. **Управление Vary:**  
   * Проанализировать заголовки бэкенда.  
   * Удалить или нормализовать Vary: User-Agent.  
   * Заменить на Vary: X-UA-Device с предварительным детектированием устройства в VCL.

### **Фаза 3: Мониторинг и валидация**

1. **Настройка Dashboard:**  
   * Вывести графики SMA.Transient.g_bytes и n_lru_nuked в систему мониторинга (Grafana/Datadog).  
   * Настроить алертинг на превышение 80% заполнения Transient Storage.  
2. **Стресс-тестирование:**  
   * Провести нагрузочное тестирование с использованием рандомизированных URL (имитация ботов) для проверки эффективности нормализации и стабильности памяти при новом аллокаторе.

Реализация данного плана трансформирует Varnish Cache из источника нестабильности в надежный и предсказуемый слой акселерации, способный эффективно справляться с высокой кардинальностью данных проекта RunRepeat.

#### **Works cited**

1. RunRepeat: 1000+ shoes reviewed and cut in half, accessed December 11, 2025, [https://runrepeat.com/](https://runrepeat.com/)  
2. 100+ Running Shoe Reviews - RunRepeat, accessed December 11, 2025, [https://runrepeat.com/catalog/running-shoes](https://runrepeat.com/catalog/running-shoes)  
3. libmalloc, jemalloc, tcmalloc, mimalloc - Exploring Different Memory Allocators, accessed December 11, 2025, [https://dev.to/frosnerd/libmalloc-jemalloc-tcmalloc-mimalloc-exploring-different-memory-allocators-4lp3](https://dev.to/frosnerd/libmalloc-jemalloc-tcmalloc-mimalloc-exploring-different-memory-allocators-4lp3)  
4. Solving unbounded Java Process memory growth using JEMalloc - Medium, accessed December 11, 2025, [https://medium.com/@sohelcts/solving-unbounded-java-process-memory-growth-using-jemalloc-a43de47e5d0b](https://medium.com/@sohelcts/solving-unbounded-java-process-memory-growth-using-jemalloc-a43de47e5d0b)  
5. Storage backends - Varnish Cache - Read the Docs, accessed December 11, 2025, [https://varnish-cache.readthedocs.io/users-guide/storage-backends.html](https://varnish-cache.readthedocs.io/users-guide/storage-backends.html)  
6. Varnish memory usage keeps increasing - Stack Overflow, accessed December 11, 2025, [https://stackoverflow.com/questions/76209998/varnish-memory-usage-keeps-increasing](https://stackoverflow.com/questions/76209998/varnish-memory-usage-keeps-increasing)  
7. Example VCL template - Varnish Developer Portal, accessed December 11, 2025, [https://www.varnish-software.com/developers/tutorials/example-vcl-template/](https://www.varnish-software.com/developers/tutorials/example-vcl-template/)  
8. Understanding Varnish Cache Memory Usage - Resources, accessed December 11, 2025, [https://info.varnish-software.com/blog/understanding-varnish-cache-memory-usage](https://info.varnish-software.com/blog/understanding-varnish-cache-memory-usage)  
9. jemalloc vs glibc malloc: Memory Allocation Performance Comparison | by Binita Bharati, accessed December 11, 2025, [https://medium.com/@binitabharati/jemalloc-vs-glibc-malloc-memory-allocation-performance-comparison-fbaeda1740de](https://medium.com/@binitabharati/jemalloc-vs-glibc-malloc-memory-allocation-performance-comparison-fbaeda1740de)  
10. Picking a global allocator : r/rust - Reddit, accessed December 11, 2025, [https://www.reddit.com/r/rust/comments/1ifjzvv/picking_a_global_allocator/](https://www.reddit.com/r/rust/comments/1ifjzvv/picking_a_global_allocator/)  
11. Background · jemalloc/jemalloc Wiki - GitHub, accessed December 11, 2025, [https://github.com/jemalloc/jemalloc/wiki/Background](https://github.com/jemalloc/jemalloc/wiki/Background)  
12. How to trace the fragmentation? · Issue #2850 · jemalloc/jemalloc - GitHub, accessed December 11, 2025, [https://github.com/jemalloc/jemalloc/issues/2850](https://github.com/jemalloc/jemalloc/issues/2850)  
13. Jemalloc Memory Analysis - Apache Doris, accessed December 11, 2025, [https://doris.apache.org/docs/3.x/admin-manual/trouble-shooting/memory-management/memory-analysis/jemalloc-memory-analysis/](https://doris.apache.org/docs/3.x/admin-manual/trouble-shooting/memory-management/memory-analysis/jemalloc-memory-analysis/)  
14. 1656034 – Varnish is compiled without jemalloc. jemalloc is missing. - Red Hat Bugzilla, accessed December 11, 2025, [https://bugzilla.redhat.com/show_bug.cgi?id=1656034](https://bugzilla.redhat.com/show_bug.cgi?id=1656034)  
15. Varnish duplicate process 170 once - Unix & Linux Stack Exchange, accessed December 11, 2025, [https://unix.stackexchange.com/questions/632427/varnish-duplicate-process-170-once](https://unix.stackexchange.com/questions/632427/varnish-duplicate-process-170-once)  
16. Two-Minute Tech Tuesdays - Memory Governor - Resources - Varnish Software, accessed December 11, 2025, [https://info.varnish-software.com/blog/two-minute-tech-tuesdays-memory-governor](https://info.varnish-software.com/blog/two-minute-tech-tuesdays-memory-governor)  
17. Parameters — Varnish version 4.0.5 documentation, accessed December 11, 2025, [https://varnish-cache.org/docs/4.0/users-guide/params.html](https://varnish-cache.org/docs/4.0/users-guide/params.html)  
18. Storage backends — Varnish version trunk documentation, accessed December 11, 2025, [https://varnish-cache.org/docs/trunk/users-guide/storage-backends.html](https://varnish-cache.org/docs/trunk/users-guide/storage-backends.html)  
19. Storage backends - malloc - Varnish Cache, accessed December 11, 2025, [https://varnish-cache.org/docs/4.1/users-guide/storage-backends.html](https://varnish-cache.org/docs/4.1/users-guide/storage-backends.html)  
20. varnishd — Varnish version trunk documentation, accessed December 11, 2025, [https://varnish-cache.org/docs/trunk/reference/varnishd.html](https://varnish-cache.org/docs/trunk/reference/varnishd.html)  
21. varnish-counters — Varnish version trunk documentation, accessed December 11, 2025, [https://varnish-cache.org/docs/trunk/reference/varnish-counters.html](https://varnish-cache.org/docs/trunk/reference/varnish-counters.html)  
22. VSV00002 Data leak - '-sfile' Stevedore transient objects — Varnish HTTP Cache, accessed December 11, 2025, [https://varnish-cache.org/security/VSV00002.html](https://varnish-cache.org/security/VSV00002.html)  
23. Varnish crashes on bigger files - cache - Server Fault, accessed December 11, 2025, [https://serverfault.com/questions/1031656/varnish-crashes-on-bigger-files](https://serverfault.com/questions/1031656/varnish-crashes-on-bigger-files)  
24. Limiting memory for varnish process - caching - Stack Overflow, accessed December 11, 2025, [https://stackoverflow.com/questions/58909821/limiting-memory-for-varnish-process](https://stackoverflow.com/questions/58909821/limiting-memory-for-varnish-process)  
25. 90+ Knit Running Shoe Reviews - RunRepeat, accessed December 11, 2025, [https://runrepeat.com/catalog/knit-running-shoes](https://runrepeat.com/catalog/knit-running-shoes)  
26. Performance Boosting with Varnish Cache - maxcluster, accessed December 11, 2025, [https://maxcluster.de/en/knowledge/blog/article/performance-page-speed-boosting-varnish-cache](https://maxcluster.de/en/knowledge/blog/article/performance-page-speed-boosting-varnish-cache)  
27. Varnish monitoring - Varnish Developer Portal, accessed December 11, 2025, [https://www.varnish-software.com/developers/tutorials/varnish-monitoring/](https://www.varnish-software.com/developers/tutorials/varnish-monitoring/)  
28. Top Varnish performance metrics | Datadog, accessed December 11, 2025, [https://www.datadoghq.com/blog/top-varnish-performance-metrics/](https://www.datadoghq.com/blog/top-varnish-performance-metrics/)  
29. querystring.sort | Fastly Documentation, accessed December 11, 2025, [https://www.fastly.com/documentation/reference/vcl/functions/query-string/querystring-sort/](https://www.fastly.com/documentation/reference/vcl/functions/query-string/querystring-sort/)  
30. Vary — Varnish version 3.0.7 documentation, accessed December 11, 2025, [https://varnish-cache.org/docs/3.0/tutorial/vary.html](https://varnish-cache.org/docs/3.0/tutorial/vary.html)  
31. 5 Don'ts When Caching with Varnish - Resources, accessed December 11, 2025, [https://info.varnish-software.com/blog/5-varnish-donts](https://info.varnish-software.com/blog/5-varnish-donts)  
32. Varnish Using Significantly More Memory than Cache? - Stack Overflow, accessed December 11, 2025, [https://stackoverflow.com/questions/78379910/varnish-using-significantly-more-memory-than-cache](https://stackoverflow.com/questions/78379910/varnish-using-significantly-more-memory-than-cache)  
33. Varnish Cache extension — Dynatrace Docs, accessed December 11, 2025, [https://docs.dynatrace.com/docs/observe/infrastructure-observability/databases/extensions/varnish-cache-1](https://docs.dynatrace.com/docs/observe/infrastructure-observability/databases/extensions/varnish-cache-1)

# 12.
## 12.1.
`D𐊑⠿` ≔ ⠿~ (Заблуждения `ꆜ` относительно `P⁎`)

## 12.2.
`D𐊑ᵢ` : `D𐊑⠿`

## 12.3.
`Pⰳ(D𐊑ᵢ)` ≔
```
Правдоподобность `D𐊑ᵢ`.
Правдоподобность заблуждения `D𐊑ᵢ` означает оценку того, насколько утверждение `D𐊑ᵢ` действительно является заблуждением `ꆜ`. 
```

# 13. Анализ `D𐊑⠿` (выполнен Gemini Deep Think)
https://gemini.google.com/share/8d6a27ba5b92

## 2.1. Идентификация `D𐊑⠿`
Основываясь на глубоком анализе описания проблемы `PD` и онтологии `O.md` (в частности, разделов §10 и §11), я выделяю следующее множество заблуждений `ꆜ` (`D𐊑⠿`), которые блокируют решение задачи `P⁎`:

*   **`D𐊑₁`**: «Наблюдаемый рост потребления памяти является программным сбоем («утечкой»), а не следствием архитектурного устройства Varnish (Overhead + Transient)».
*   **`D𐊑₂`**: «Параметр запуска `-s malloc,SIZE` устанавливает жесткий физический лимит («стену») для процесса Varnish, который тот не может превысить при штатной работе».
*   **`D𐊑₃`**: «Проблема высокой вариативности запросов (фильтры, реклама) решается настройкой политик вытеснения (cache policies/eviction strategies), а не предварительной нормализацией входящих данных».
*   **`D𐊑₄`**: «Выбор системного аллокатора памяти (стандартный `glibc` vs `jemalloc`) не является критическим фактором на архитектуре AWS Graviton (ARM64)».

## 2.2. Анализ `D𐊑⠿`

### Анализ `D𐊑₁` (Миф об утечке)
**Суть:** `ꆜ` трактует постоянный рост потребления RAM («repeatedly grows the memory») как аномалию или баг, который нужно «диагностировать», тогда как это ожидаемое поведение при текущей конфигурации.

#### 2.2.1. Доводы за `Pⰳ(D𐊑₁)`
*   **Свидетельства веры клиента:** В `PD` клиент пишет о «persistent memory issues» и «performance degradation», явно ожидая, что память должна быть стабильной.
*   **Техническое опровержение веры:** В реальности память потребляется легитимно двумя механизмами, о которых клиент не подозревает:
    1.  **Transient Storage:** Временное хранилище для объектов `hit-for-miss` (создаются при наличии cookies/рекламных меток) по умолчанию **не ограничено** (unbounded). Оно может занимать всю свободную память сервера.
    2.  **Overhead:** Метаданные (структуры `struct obj`) занимают ~1 КБ на объект. При миллионах объектов (High Cardinality) это гигабайты неучтенной памяти.

#### 2.2.2. Доводы против `Pⰳ(D𐊑₁)`
*   Теоретически возможна реальная утечка памяти в конкретной версии Varnish или VMOD, но вероятность этого исчезающе мала по сравнению с архитектурными причинами.

#### 2.3. Оценка `Pⰳ(D𐊑₁)`
**95**

---

### Анализ `D𐊑₂` (Миф о жестком лимите)
**Суть:** `ꆜ` убежден, что настройка `-s` (Storage) должна гарантировать потребление памяти в заданных пределах.

#### 2.2.1. Доводы за `Pⰳ(D𐊑₂)`
*   **Свидетельства веры клиента:** Фраза «regardless of what config we've tried» подразумевает, что они пытались менять размеры хранилища, но RSS процесса все равно уходил за пределы.
*   **Техническое опровержение веры:** Параметр `-s malloc` ограничивает только **Payload** (тело объектов). Он игнорирует фрагментацию памяти (Heap Fragmentation), память потоков (Thread Stacks) и, самое главное, накладные расходы на огромное количество мелких объектов, генерируемых фильтрами сайта.

#### 2.2.2. Доводы против `Pⰳ(D𐊑₂)`
*   Отсутствуют. Это классическое заблуждение администраторов, не знакомых с внутренним устройством аллокации памяти в Varnish.

#### 2.3. Оценка `Pⰳ(D𐊑₂)`
**98**

---

### Анализ `D𐊑₃` (Миф об Eviction vs Normalization)
**Суть:** Клиент ищет спасение в настройке правил удаления старых объектов («eviction strategies»), вместо того чтобы предотвращать создание дубликатов.

#### 2.2.1. Доводы за `Pⰳ(D𐊑₃)`
*   **Свидетельства веры клиента:** Прямой запрос в описании задачи: «We need help with... eviction strategies».
*   **Техническое опровержение веры:** Сайт `RunRepeat.com` использует фасетный поиск (цвет, размер) и рекламные метки (`gclid`, `utm`). Это создает комбинаторный взрыв URL (Cache Bloat). Varnish по умолчанию считает `/shoe?color=red` и `/shoe?gclid=123` разными объектами. Если не делать агрессивную **нормализацию** (очистку и сортировку параметров) *до* кэширования, память будет забиваться "мусором" быстрее, чем любые политики eviction смогут её освободить.

#### 2.2.2. Доводы против `Pⰳ(D𐊑₃)`
*   Возможно, клиент понимает необходимость нормализации, но включает её в широкое понятие «VCL configuration». Однако акцент на eviction выдает неверный вектор мышления.

#### 2.3. Оценка `Pⰳ(D𐊑₃)`
**90**

---

### Анализ `D𐊑₄` (Игнорирование системного уровня)
**Суть:** Клиент не осознает связь между архитектурой CPU (Graviton) и выбором аллокатора памяти.

#### 2.2.1. Доводы за `Pⰳ(D𐊑₄)`
*   **Свидетельства веры клиента:** Упоминание «Gravitron CPU» идет просто как факт конфигурации. Нет запроса на системный тюнинг (Linux tuning).
*   **Техническое опровержение веры:** Стандартный аллокатор `glibc` на Linux склонен к сильной фрагментации памяти при работе с Varnish, особенно на ARM64 (Graviton), где размер страниц памяти может отличаться (64k vs 4k). Без перехода на **jemalloc** (который эффективно борется с фрагментацией) процесс Varnish будет занимать гораздо больше памяти, чем реально использует, из-за «дыр» в куче.

#### 2.2.2. Доводы против `Pⰳ(D𐊑₄)`
*   Возможно, в их сборке OS `jemalloc` уже является дефолтным, хотя это редкость для стандартных дистрибутивов.

#### 2.3. Оценка `Pⰳ(D𐊑₄)`
**85**

## 2.4. Вердикт
Клиент `ꆜ` находится в плену **«Конфигурационной иллюзии»**. Он пытается решить проблему **архитектурного несоответствия** (High Cardinality Data vs Standard Memory Allocator) методами **прикладной настройки** (VCL Eviction Policies).

`ꆜ` ошибочно полагает, что Varnish «течет» или сломан (`D𐊑₁`), в то время как система работает технически корректно в условиях **Cache Bloat** (взрывного роста дубликатов кэша), усугубленного отсутствием лимитов на временное хранилище (`Transient`) и использованием неэффективного аллокатора (`glibc`) на архитектуре Graviton. Решение лежит не в подборе параметров кэша, а в **санитизации трафика** (нормализация URL) и **системном тюнинге** (переход на jemalloc).

# 14. Анализ `D𐊑⠿` (выполнен Gemini Deep Research)
https://gemini.google.com/share/614be88df46e

**1. Анализ заблуждения D𐊑₁: Иллюзия детерминированного лимитирования памяти параметром -s malloc**

Центральным элементом в понимании проблем проекта P⁎ является интерпретация того, как Varnish управляет выделением памяти. Клиент ꆜ в описании проблемы (PD) указывает на то, что потребление памяти растет «regardless of what config we've tried». Это свидетельствует о наличии устойчивого заблуждения D𐊑₁, согласно которому параметр конфигурации -s malloc,SIZE воспринимается как жесткий, физический ограничитель (hard limit) для всего процесса демона.

### **1.1. Доводы в пользу правдоподобности заблуждения (Pⰳ(D𐊑₁))**

Анализ технической документации и архитектурных принципов Varnish Cache позволяет с высокой точностью реконструировать логику возникновения этого заблуждения и подтвердить его критическое влияние на эксплуатацию системы.

**Архитектурная дихотомия: Хранилище данных против Метаданных**

Фундаментальная ошибка заключается в непонимании того, что параметр -s в Varnish ограничивает исключительно пространство, выделяемое под *тела* кэшируемых объектов (Object Payload).1 В экосистеме Varnish память расходуется по двум основным векторам, из которых -s контролирует только первый:

1. **Storage Memory (Управляемая):** Это байты, составляющие контент (HTML, изображения, JSON), которые сервер отдает клиенту. Именно этот объем регулируется параметром -s malloc,25G.  
2. **Overhead Memory (Неуправляемая):** Это память, необходимая для поддержания структур данных, обеспечивающих функционирование кэша. Сюда входят хеш-таблицы, списки LRU (Least Recently Used), структуры объектов (struct obj), заголовки (struct objhead) и ссылки (struct objcore).2

В контексте проекта RunRepeat с его фасетной навигацией и высокой посещаемостью (4 млн сессий), количество объектов в кэше может достигать экстремальных значений. Исследования показывают, что накладные расходы (overhead) на один объект в Varnish составляют приблизительно 1 КБ.1 Это значение кажется незначительным для единичного объекта, но масштабируется линейно.

Рассмотрим математическую модель потребления памяти для P⁎:  
Предположим, что из-за вариативности URL (см. анализ D𐊑₅) в кэше находится 15 миллионов объектов.

$$text{Memory}_{text{overhead}} approx N_{text{objects}} times 1 text{ KB}$$

$$text{Memory}_{text{overhead}} approx 15,000,000 times 1024 text{ bytes} approx 14.3 text{ GB}$$  
Если клиент выделил под хранилище данных 25 ГБ (-s malloc,25G) на сервере с 32 ГБ RAM, то реальное потребление памяти процессом составит:

$$text{Total RAM} = text{Storage} (25 text{ GB}) + text{Overhead} (14.3 text{ GB}) + text{System} approx 39.3 text{ GB}$$  
Это значение превышает физически доступную память (32 ГБ), что неизбежно приводит к вмешательству механизма OOM Killer (Out-Of-Memory Killer) операционной системы, который принудительно завершает процесс varnishd.1 Клиент, наблюдая это, интерпретирует ситуацию как «утечку», не осознавая, что система ведет себя абсолютно корректно в рамках заданных (ошибочных) ограничений.

**Скрытое потребление: Рабочие области и Потоки**

Помимо метаданных объектов, значительный объем памяти расходуется на инфраструктуру обработки запросов. Varnish использует многопоточную архитектуру, где каждый запрос обрабатывается отдельным потоком (worker thread).

* **Thread Stack:** Каждый поток требует собственного стека. Параметр thread_pool_stack (по умолчанию часто 48-52 КБ) определяет этот размер.5  
* **Workspace Memory:** Для обработки HTTP-заголовков, выполнения VCL-логики и манипуляций с данными каждому потоку выделяются рабочие области: workspace_client (память для запроса клиента), workspace_backend (память для ответа бэкенда) и workspace_session.5

В конфигурации по умолчанию или при агрессивном тюнинге под высокую нагрузку (например, thread_pool_max=5000), суммарное потребление памяти потоками может быть значительным:

$$text{Memory}_{text{threads}} = N_{text{threads}} times (text{stack} + text{workspace}_{text{client}} + text{workspace}_{text{backend}})$$

$$text{Memory}_{text{threads}} approx 5000 times (48text{K} + 64text{K} + 64text{K}) approx 880 text{ MB}$$  
Хотя 1 ГБ кажется небольшим объемом по сравнению с 32 ГБ, в условиях, когда память уже исчерпана данными и метаданными, этот гигабайт становится критическим фактором нестабильности.7 Клиент ꆜ, вероятно, не учитывает эти расходы в своей калькуляции ресурсов, полагая, что -s malloc охватывает все потребности процесса.

### **1.2. Доводы против правдоподобности заблуждения (Pⰳ(D𐊑₁))**

Единственным сценарием, при котором данное утверждение не являлось бы заблуждением, было бы использование клиентом специализированных версий Varnish Enterprise с включенным механизмом **Memory Governor**.

Технология Memory Governor, являющаяся частью движка Massive Storage Engine (MSE), фундаментально меняет парадигму управления памятью. В этом режиме администратор задает не размер кэша, а целевой лимит потребления памяти для всего процесса (Memory Target). Движок автоматически масштабирует размер хранилища объектов, уменьшая его при росте накладных расходов или потребления временного хранилища, гарантируя, что процесс никогда не выйдет за пределы установленного лимита.8

Однако в описании задачи (PD) и онтологии (O.md) отсутствуют какие-либо указания на использование коммерческой лицензии Varnish Enterprise. Напротив, описание проблем («Varnish repeatedly grows...») прямо противоречит логике работы Memory Governor, который призван предотвращать именно такое поведение. Следовательно, использование стандартной Community-версии (Varnish Cache) является практически достоверным фактом, что делает заблуждение D𐊑₁ высоковероятным.

### **1.3. Вердикт и оценка правдоподобности**

**Оценка Pⰳ(D𐊑₁): 95/100.**

Анализ подтверждает, что клиент ꆜ находится в плену иллюзии полного контроля над памятью через параметр -s malloc. Это заблуждение является корневой причиной неправильной оценки необходимых ресурсов. Вместо того чтобы оставить запас памяти (Headroom) в размере 25-30% для метаданных и операционных расходов, клиент, вероятно, устанавливает лимит хранилища близко к физическому объему RAM, провоцируя нестабильность.

Рекомендация по устранению данного заблуждения заключается в пересмотре формулы расчета памяти:

$$text{Malloc Limit} = (text{Total RAM} - text{System Reserved} - text{Transient Max}) times 0.75$$

Для сервера с 32 ГБ RAM безопасным значением параметра -s malloc будет не 25G, а диапазон 16G - 18G.

## ---

**2. Анализ заблуждения D𐊑₂: Ложная идентификация утечки памяти (Memory Leak) вместо Фрагментации (Fragmentation)**

Вторым критическим заблуждением является классификация проблемы. Клиент описывает ситуацию терминами «persistent memory issues» и «grows memory», подразумевая утечку памяти (Memory Leak) — ошибку программирования, при которой выделенная память не освобождается. Однако глубокий анализ среды исполнения (AWS Graviton, Linux) указывает на совершенно иную природу феномена: **фрагментацию кучи** (Heap Fragmentation).

### **2.1. Доводы в пользу правдоподобности заблуждения (Pⰳ(D𐊑₂))**

Фрагментация памяти в контексте Varnish — это сложный процесс взаимодействия прикладного ПО и системного аллокатора, который внешне (для утилит мониторинга типа top или htop) неотличим от утечки.

**Аллокатор glibc vs jemalloc: Битва за эффективность**

Стандартным аллокатором памяти в большинстве дистрибутивов Linux (включая Amazon Linux 2023 и RHEL 9, используемых на AWS) является реализация malloc из библиотеки glibc (основанная на ptmalloc). Этот аллокатор оптимизирован для универсальных задач, но демонстрирует низкую эффективность в сценариях, характерных для Varnish:

* Высокая конкурентность (тысячи потоков).  
* Интенсивная аллокация и деаллокация мелких объектов разного размера.  
* Долгоживущий процесс.10

В многопоточной среде glibc создает множество арен (memory arenas) для снижения блокировок (lock contention). Когда память освобождается (free()) внутри Varnish, она возвращается в конкретную арену аллокатора, но далеко не всегда возвращается операционной системе. Образуются «дыры» — фрагментированные участки свободной памяти внутри процесса, которые слишком малы для размещения новых объектов, но удерживают целые страницы памяти от возврата ОС.

В результате метрика RSS (Resident Set Size) процесса растет, хотя внутренние счетчики Varnish (varnishstat) показывают наличие свободного места в хранилище (SMA.s0.g_space). Клиент видит рост потребления RAM и делает вывод об утечке, хотя технически вся память учтена, но не может быть эффективно использована.11

**Критический фактор среды AWS Graviton**

Ситуация усугубляется спецификой современных дистрибутивов Linux на архитектуре ARM64. В старых версиях Varnish или в других дистрибутивах аллокатор jemalloc часто поставлялся как зависимость или был слинкован статически. jemalloc (разработанный Джейсоном Эвансом) де-факто является стандартом для приложений типа Varnish, Redis и браузеров, так как он использует изощренные стратегии (size classes, runs, chunks) для минимизации фрагментации.5

Однако, как показывают отчеты сообщества 5, на новых платформах (RHEL 9, Amazon Linux 2023) бинарный файл varnishd часто слинкован с glibc по умолчанию. Пользователи, не знающие об этом нюансе, запускают Varnish «из коробки» и сталкиваются с двукратным (и более) ростом потребления памяти по сравнению с ожидаемым.

Источник 5 приводит прямой эмпирический опыт: «I've installed version 6.0.13... it looks like varnish is using glibc's malloc... Memory usage for a 1GB cache has gone down from ~3.7GB to ~2GB [after installing jemalloc]». Это подтверждает, что разница в потреблении памяти между glibc и jemalloc может достигать **100% от полезной нагрузки**.

### **2.2. Доводы против правдоподобности заблуждения (Pⰳ(D𐊑₂))**

Теоретически возможно, что клиент столкнулся с реальным багом в коде Varnish (software defect). Например, известная уязвимость CVE-2017-8807 14 приводила к утечке данных и памяти при некорректной обработке синтетических объектов в Transient Storage. Также существуют редкие баги, связанные с JIT-компиляцией PCRE (регулярных выражений) на специфических платформах.13

Однако вероятность столкнуться с неизвестным багом ядра Varnish (проект с более чем 15-летней историей стабильности) на порядки ниже, чем вероятность эксплуатации неоптимизированного аллокатора. Фраза клиента «regardless of what config we've tried» указывает на перебор параметров конфигурации (.vcl, -p), но не на системные изменения уровня линковки библиотек (LD_PRELOAD), что усиливает гипотезу о заблуждении.

### **2.3. Вердикт и оценка правдоподобности**

**Оценка Pⰳ(D𐊑₂): 90/100.**

Клиент ꆜ, с высокой долей вероятности, не различает истинную утечку памяти (потерю указателей на выделенные блоки) и внешнюю фрагментацию аллокатора. Отсутствие явного упоминания jemalloc в описании проблемы является сильным индикатором того, что Varnish работает на дефолтном glibc.

Рекомендация:  
Для устранения этой проблемы необходимо не «искать утечку» в VCL, а изменить среду исполнения:

1. Установить пакет jemalloc (например, dnf install jemalloc на Amazon Linux).  
2. Настроить systemd юнит для предзагрузки библиотеки:  
   Environment="LD_PRELOAD=/usr/lib64/libjemalloc.so.2"  
3. Перезапустить сервис и мониторить метрику RSS. Ожидается снижение потребления памяти на 30-50%.5

## ---

**3. Анализ заблуждения D𐊑₃: Игнорирование опасности и природы Transient Storage**

Третье заблуждение касается компонента Varnish, который часто остается «в слепой зоне» администраторов — Временного Хранилища (Transient Storage). Клиент, фокусируясь на настройках основного кэша (-s malloc), упускает из виду механизм, способный потребить всю память сервера за считанные минуты.

### **3.1. Доводы в пользу правдоподобности заблуждения (Pⰳ(D𐊑₃))**

Transient Storage предназначено для хранения короткоживущих объектов (чей TTL меньше параметра shortlived, по умолчанию 10 секунд) и объектов, созданных в результате решений о некэшируемости (hit-for-miss, hit-for-pass).16

**Архитектурная ловушка: Unbounded by Default**

Критическая особенность Transient Storage заключается в его конфигурации по умолчанию. Если администратор явно не задает параметры для Transient Storage (через -s Transient=...), Varnish автоматически создает для него хранилище на базе malloc, которое **не имеет лимита по размеру** (unbounded).5

В документации это описано так: «If no Transient storage is defined, the default is an unbound malloc storage». Это означает, что Varnish будет запрашивать у ОС память под временные объекты бесконечно, пока не исчерпает физические ресурсы, игнорируя любые ограничения, установленные для основного кэша.

**Механизм катастрофы: Hit-For-Miss шторм**

Проект RunRepeat имеет характеристики, делающие его чрезвычайно уязвимым для этой архитектурной особенности:

1. **Высокая посещаемость (4M сессий):** Огромный поток запросов.  
2. **Наличие рекламы и трекинга:** Ссылки с метками gclid, fbclid, utm_* часто обрабатываются бэкендом с установкой cookies или заголовков Cache-Control: private.  
3. **Логика Varnish:** Когда Varnish получает ответ с Set-Cookie или запретом кэширования, он создает специальный объект hit-for-miss (или hit-for-pass в старых версиях).18 Этот объект служит маркером: «не отправляй запросы на этот URL в очередь (request coalescing), а пропускай сразу на бэкенд».  
4. **Лавинообразный эффект:** Поскольку каждый запрос с уникальным gclid является уникальным URL, Varnish создает уникальную запись hit-for-miss для каждого клика по рекламе. Если TTL этих записей (по умолчанию 120 секунд) попадает под критерий shortlived или если они явно помещаются в Transient, память начинает заполняться миллионами мелких служебных объектов.

В ситуации RunRepeat, где трафик интенсивен, а нормализация URL (вероятно) отсутствует, Transient Storage может разрастись до нескольких гигабайт за минуты. Клиент видит, что основной кэш заполнен лишь частично, но память сервера исчерпана. Жалоба «config changes haven't helped» идеально укладывается в этот сценарий: клиент меняет параметры *основного* хранилища, которые никак не влияют на *временное*.

### **3.2. Доводы против правдоподобности заблуждения (Pⰳ(D𐊑₃))**

Единственным аргументом против может быть наличие в конфигурации явного ограничения (например, -s Transient=malloc,1G). Однако, если бы такое ограничение было установлено, Varnish начал бы применять LRU-вытеснение к временным объектам при достижении лимита, а не падал бы с OOM. Симптоматика «неконтролируемого роста» однозначно указывает на отсутствие лимита (unbounded nature).

### **3.3. Вердикт и оценка правдоподобности**

**Оценка Pⰳ(D𐊑₃): 95/100.**

Клиент с вероятностью, близкой к 100%, не осведомлен о существовании или принципах работы Transient Storage. Это «тихий убийца» производительности Varnish в e-commerce проектах.

Рекомендация:  
Необходимо изменить строку запуска демона varnishd, явно ограничив временное хранилище:  
-s malloc,18G -s Transient=malloc,2G  
Это создаст жесткий барьер для роста временных объектов. При достижении 2 ГБ старые временные объекты будут удаляться, освобождая место новым, но процесс Varnish останется в рамках выделенного бюджета памяти.

## ---

**4. Анализ заблуждения D𐊑₄: Игнорирование специфики управления памятью на архитектуре ARM64 (Graviton)**

Четвертое заблуждение связано с аппаратной платформой. Клиент упоминает использование «Gravitron CPU» (правильно: Graviton) как данность, но, по всей видимости, не связывает выбор архитектуры процессора с необходимостью низкоуровневого тюнинга операционной системы.

### **4.1. Доводы в пользу правдоподобности заблуждения (Pⰳ(D𐊑₄))**

Архитектура ARM64 (aarch64), на которой построены процессоры AWS Graviton, имеет существенные отличия от традиционной x86_64 в работе подсистемы управления памятью (MMU - Memory Management Unit).

**Проблема размера страниц (Page Size): 4k vs 64k**

В операционных системах Linux память управляется страницами. Стандартный размер страницы для x86_64 и большинства дефолтных ядер ARM64 составляет 4 КБ (4k pages). Для трансляции виртуальных адресов в физические процессор использует таблицу страниц (Page Table) и кэш трансляций (TLB - Translation Lookaside Buffer).20

При использовании 32 ГБ RAM и приложения типа Varnish, которое активно обращается к огромным массивам памяти в случайном порядке (random access pattern к объектам в куче), использование 4k страниц создает колоссальную нагрузку на TLB.

* Количество записей в TLB ограничено.  
* При 4k страницах 32 ГБ памяти требуют $32 times 1024^3 / 4096 approx 8,388,608$ записей в таблице страниц.  
* Это приводит к высокому уровню промахов TLB (TLB misses). При каждом промахе процессор вынужден выполнять дорогостоящую операцию «прогулки по таблице страниц» (page table walk), что увеличивает латентность доступа к памяти и нагрузку на CPU.20

**Решение: 64k Pages**

Архитектура ARM64 оптимизирована для работы со страницами размером 64 КБ. Использование ядра с поддержкой 64k pages:

1. Увеличивает охват памяти одной записью TLB в 16 раз.  
2. Радикально снижает количество промахов TLB.  
3. Уменьшает размер самой таблицы страниц, освобождая системную память.  
4. Улучшает производительность дискового ввода-вывода и DMA операций, так как снижается количество пересечений границ страниц.5

Большинство пользователей, мигрирующих с x86, просто не знают об этом нюансе. Стандартные AMI (Amazon Machine Images) часто поставляются с ядром 4k для максимальной совместимости.

### **4.2. Доводы против правдоподобности заблуждения (Pⰳ(D𐊑₄))**

Можно возразить, что Varnish способен работать и на 4k страницах. Это так, но в условиях «борьбы за каждый байт» и высокой нагрузки (4M сессий) игнорирование этой оптимизации является технической халатностью. Влияние 64k страниц на фрагментацию также может быть положительным, так как аллокации становятся более крупнулярными.

### **4.3. Вердикт и оценка правдоподобности**

**Оценка Pⰳ(D𐊑₄): 75/100.**

Клиент, вероятно, использует стандартное ядро Linux (4k pages), упуская возможность бесплатной оптимизации производительности и снижения накладных расходов системы. Хотя это не является единственной причиной «утечки», это важный фактор общей неэффективности системы.

Рекомендация:  
Проверить текущий размер страниц командой getconf PAGESIZE. Если результат 4096, рассмотреть переход на ядро с поддержкой 64k (например, установка пакета kernel-64k в Amazon Linux 2023 или использование соответствующего AMI Ubuntu arm64+largemem).22

## ---

**5. Анализ заблуждения D𐊑₅: Приоритет инфраструктурного тюнинга над нормализацией данных (Cache Bloat)**

Пятое и, возможно, самое разрушительное заблуждение касается уровня приложения. Клиент ищет решение проблемы в «memory allocation» и «server-setup», в то время как первопричиной является бизнес-логика сайта, генерирующая «мусорный» трафик.

### **5.1. Доводы в пользу правдоподобности заблуждения (Pⰳ(D𐊑₅))**

Проблема проекта RunRepeat классифицируется как **Cache Bloat** (Раздувание кэша) вследствие **High Cardinality** (Высокой кардинальности) запросов.

**Комбинаторный взрыв URL**

Сайт использует фасетную навигацию с фильтрами по полу, размеру, цвету и другим параметрам.

$$text{URL} = text{/shoes?color=red&size=42&gender=men}$$

$$text{URL} = text{/shoes?size=42&gender=men&color=red}$$  
Для Varnish эти два URL — это **два разных объекта**, требующих раздельного кэширования, хранения метаданных и памяти. Количество возможных перестановок параметров растет факториально. При наличии 10 активных фильтров количество уникальных URL может исчисляться миллиардами. Поисковые боты и сканеры часто перебирают эти фильтры в хаотичном порядке, заполняя кэш дубликатами одного и того же контента.23

**Маркетинговый шум**

Клиент упоминает наличие рекламы («We also have ads»). Это означает приход пользователей по ссылкам с метками:  
?utm_source=google&utm_campaign=summer&gclid=ABC...  
Поскольку gclid (Google Click ID) уникален для каждого клика, каждый визит пользователя создает новую копию страницы в кэше.  
Если на сайте 4 миллиона сессий в месяц, и значительная часть трафика приходит с рекламы или использует фильтры, Varnish вынужден создавать миллионы объектов. Это приводит к:

1. Исчерпанию памяти под метаданные (см. D𐊑₁).  
2. Высокой фрагментации памяти из-за постоянной записи и удаления (Eviction) объектов (см. D𐊑₂).  
3. Заполнению Transient Storage объектами hit-for-miss (см. D𐊑₃).

Клиент фокусируется на том, как *вместить* эти объекты в память (увеличивая -s malloc), вместо того чтобы *предотвратить* их создание.

### **5.2. Доводы против правдоподобности заблуждения (Pⰳ(D𐊑₅))**

В описании задачи (PD) клиент пишет: «We need help with VCL configuration». Это указывает на понимание того, что VCL играет роль. Однако контекст перечисления («cache policies, proper memory allocation...») говорит о том, что они видят VCL как инструмент настройки *кэширования*, а не *нормализации*. Если бы они понимали масштаб проблемы Cache Bloat, они бы упомянули «URL normalization» или «parameter stripping» как приоритетные задачи.

### **5.3. Вердикт и оценка правдоподобности**

**Оценка Pⰳ(D𐊑₅): 85/100.**

Клиент недооценивает тот факт, что никакое количество RAM (даже 128 ГБ) не спасет от комбинаторного взрыва URL без строгой нормализации на уровне VCL.

Рекомендация:  
Внедрить агрессивную нормализацию в процедуре vcl_recv:

1. **Сортировка параметров:** Использовать std.querysort(req.url) для приведения параметров к каноническому порядку.14  
2. **Санитизация:** Удалять все маркетинговые метки (utm_*, gclid, fbclid) из req.url перед хэшированием. Эти параметры нужны только клиентскому JavaScript (Google Analytics), бэкенду для генерации страницы они не требуются.  
3. **Нормализация User-Agent:** Приводить заголовок User-Agent к ограниченному набору значений (mobile/desktop) перед добавлением в Vary, чтобы избежать кэширования версий для каждого минорного релиза браузера.19

## ---

**6. Синтез и итоговая стратегия ремедиации**

Проведенный анализ (᛭T) показал, что критическая ситуация в проекте RunRepeat обусловлена не единичной ошибкой, а системным эффектом наложения пяти фундаментальных заблуждений. Клиент пытается решить проблему переполнения памяти («Memory Leak»), не понимая, что его конфигурация сама провоцирует это переполнение через множественные векторы (Overhead, Fragmentation, Transient, Cache Bloat).

### **Сводная таблица диагноза**

| Заблуждение (D𐊑ᵢ) | Реальная проблема | Вклад в сбой | Оценка Pⰳ |
| :---- | :---- | :---- | :---- |
| **D𐊑₁ (Hard Limit)** | Игнорирование Overhead (1KB/obj) | Критический | 95/100 |
| **D𐊑₂ (Leak vs Frag)** | Фрагментация glibc vs jemalloc | Высокий | 90/100 |
| **D𐊑₃ (Safe Transient)** | Unbounded Transient Storage | Критический | 95/100 |
| **D𐊑₄ (Arch Neutral)** | 4k pages on ARM64 | Средний | 75/100 |
| **D𐊑₅ (Infra Priority)** | Cache Bloat / High Cardinality | Высокий | 85/100 |

### **План действий для эксперта (Action Plan)**

Для успешного выполнения консалтингового проекта P⁎ необходимо реализовать следующую стратегию:

1. **Инфраструктурный слой:**  
   * Проверить текущий аллокатор: ldd /usr/sbin/varnishd.  
   * Установить и активировать **jemalloc** через systemd override (LD_PRELOAD).  
   * (Опционально) Мигрировать на ядро с поддержкой **64k pages** для AWS Graviton.  
2. **Конфигурационный слой:**  
   * Пересчитать лимиты памяти. Установить -s malloc с запасом на overhead (например, 18GB).  
   * **Жестко ограничить Transient Storage:** Добавить флаг -s Transient=malloc,2G. Это предотвратит падение сервера при атаках и всплесках некэшируемого трафика.  
   * Оптимизировать параметры потоков (thread_pool_min/max) и workspaces под реальную нагрузку.  
3. **Прикладной слой (VCL):**  
   * Написать логику нормализации Query String (сортировка + очистка мусорных параметров).  
   * Настроить нормализацию заголовка Vary: User-Agent.  
   * Реализовать защиту от создания hit-for-miss объектов для уникальных, но бесполезных запросов.

Только комплексное устранение всех пяти заблуждений позволит стабилизировать работу Varnish на проекте RunRepeat и вернуть производительность к приемлемым показателям.

#### **Works cited**

1. Why isn't varnish taking into account the malloc limit? - Stack Overflow, accessed December 11, 2025, [https://stackoverflow.com/questions/16693677/why-isnt-varnish-taking-into-account-the-malloc-limit](https://stackoverflow.com/questions/16693677/why-isnt-varnish-taking-into-account-the-malloc-limit)  
2. Understanding Varnish Cache Memory Usage - Resources, accessed December 11, 2025, [https://info.varnish-software.com/blog/understanding-varnish-cache-memory-usage](https://info.varnish-software.com/blog/understanding-varnish-cache-memory-usage)  
3. Understanding Varnish Cache Memory Usage, accessed December 11, 2025, [https://varnish-software.medium.com/understanding-varnish-cache-memory-usage-6f1cab5e20ff](https://varnish-software.medium.com/understanding-varnish-cache-memory-usage-6f1cab5e20ff)  
4. Varnish crashes on bigger files - cache - Server Fault, accessed December 11, 2025, [https://serverfault.com/questions/1031656/varnish-crashes-on-bigger-files](https://serverfault.com/questions/1031656/varnish-crashes-on-bigger-files)  
5. Varnish Using Significantly More Memory than Cache? - Stack Overflow, accessed December 11, 2025, [https://stackoverflow.com/questions/78379910/varnish-using-significantly-more-memory-than-cache](https://stackoverflow.com/questions/78379910/varnish-using-significantly-more-memory-than-cache)  
6. varnishd — Varnish version 6.5.2 documentation, accessed December 11, 2025, [https://varnish-cache.org/docs/6.5/reference/varnishd.html](https://varnish-cache.org/docs/6.5/reference/varnishd.html)  
7. Varnish duplicate process 170 once - Unix & Linux Stack Exchange, accessed December 11, 2025, [https://unix.stackexchange.com/questions/632427/varnish-duplicate-process-170-once](https://unix.stackexchange.com/questions/632427/varnish-duplicate-process-170-once)  
8. Two-Minute Tech Tuesdays - Memory Governor - Resources - Varnish Software, accessed December 11, 2025, [https://info.varnish-software.com/blog/two-minute-tech-tuesdays-memory-governor](https://info.varnish-software.com/blog/two-minute-tech-tuesdays-memory-governor)  
9. Auto-scaling memory usage to increase cache size in Varnish - Resources, accessed December 11, 2025, [https://info.varnish-software.com/blog/auto-scaling-memory-usage-to-increase-cache-size-in-varnish](https://info.varnish-software.com/blog/auto-scaling-memory-usage-to-increase-cache-size-in-varnish)  
10. Improve MySQL and MariaDB performance with memory allocators like Jemalloc and TCMalloc - Managed Server, accessed December 11, 2025, [https://www.managedserver.eu/Improve-mysql-and-mariadb-performance-with-memory-allocators-like-jemalloc-and-tcmalloc/](https://www.managedserver.eu/Improve-mysql-and-mariadb-performance-with-memory-allocators-like-jemalloc-and-tcmalloc/)  
11. jemalloc vs glibc malloc: Memory Allocation Performance Comparison | by Binita Bharati, accessed December 11, 2025, [https://medium.com/@binitabharati/jemalloc-vs-glibc-malloc-memory-allocation-performance-comparison-fbaeda1740de](https://medium.com/@binitabharati/jemalloc-vs-glibc-malloc-memory-allocation-performance-comparison-fbaeda1740de)  
12. How glibc Memory Handling Affects Java Applications: The Hidden Cost of Fragmentation | by Daniyal Hassan | Medium, accessed December 11, 2025, [https://medium.com/@daniyal.hass/how-glibc-memory-handling-affects-java-applications-the-hidden-cost-of-fragmentation-8e666ee6e000](https://medium.com/@daniyal.hass/how-glibc-memory-handling-affects-java-applications-the-hidden-cost-of-fragmentation-8e666ee6e000)  
13. 1656034 – Varnish is compiled without jemalloc. jemalloc is missing. - Red Hat Bugzilla, accessed December 11, 2025, [https://bugzilla.redhat.com/show_bug.cgi?id=1656034](https://bugzilla.redhat.com/show_bug.cgi?id=1656034)  
14. VSV00002 Data leak - '-sfile' Stevedore transient objects — Varnish HTTP Cache, accessed December 11, 2025, [https://varnish-cache.org/security/VSV00002.html](https://varnish-cache.org/security/VSV00002.html)  
15. Reducing Rails Memory Use on Amazon Linux with Jemalloc - HackerNoon, accessed December 11, 2025, [https://hackernoon.com/reducing-rails-memory-use-on-amazon-linux-with-jemalloc](https://hackernoon.com/reducing-rails-memory-use-on-amazon-linux-with-jemalloc)  
16. Storage backends — Varnish version @VERSION@ documentation, accessed December 11, 2025, [https://varnish-cache.readthedocs.io/users-guide/storage-backends.html](https://varnish-cache.readthedocs.io/users-guide/storage-backends.html)  
17. Storage backends — Varnish version 7.3.2 documentation, accessed December 11, 2025, [https://varnish-cache.org/docs/7.3/users-guide/storage-backends.html](https://varnish-cache.org/docs/7.3/users-guide/storage-backends.html)  
18. Achieving a high hitrate — Varnish version 6.1.1 documentation, accessed December 11, 2025, [https://varnish-cache.org/docs/6.1/users-guide/increasing-your-hitrate.html](https://varnish-cache.org/docs/6.1/users-guide/increasing-your-hitrate.html)  
19. 10 Varnish Cache mistakes and how to avoid them, accessed December 11, 2025, [https://varnish-software.medium.com/10-varnish-cache-mistakes-and-how-to-avoid-them-d240f452ab35](https://varnish-software.medium.com/10-varnish-cache-mistakes-and-how-to-avoid-them-d240f452ab35)  
20. Improve Performance with 64K Memory Pages on AWS Graviton ..., accessed December 11, 2025, [https://dev.to/aws-builders/improve-performance-with-64k-memory-pages-on-aws-graviton-processors-ifa](https://dev.to/aws-builders/improve-performance-with-64k-memory-pages-on-aws-graviton-processors-ifa)  
21. AWS Graviton4 demonstrates leading performance for HPC - Arm Developer, accessed December 11, 2025, [https://developer.arm.com/community/arm-community-blogs/b/servers-and-cloud-computing-blog/posts/leading-hpc-performance-with-graviton4](https://developer.arm.com/community/arm-community-blogs/b/servers-and-cloud-computing-blog/posts/leading-hpc-performance-with-graviton4)  
22. Choose between the arm64 and arm64+largemem installer options - Ubuntu documentation, accessed December 11, 2025, [https://documentation.ubuntu.com/server/how-to/installation/choosing-between-the-arm64-and-arm64-largemem-installer-options/](https://documentation.ubuntu.com/server/how-to/installation/choosing-between-the-arm64-and-arm64-largemem-installer-options/)  
23. Achieving a high hitrate — Varnish version 6.0.16 documentation, accessed December 11, 2025, [https://varnish-cache.org/docs/6.0/users-guide/increasing-your-hitrate.html](https://varnish-cache.org/docs/6.0/users-guide/increasing-your-hitrate.html)  
24. Example VCL template - Varnish Developer Portal, accessed December 11, 2025, [https://www.varnish-software.com/developers/tutorials/example-vcl-template/](https://www.varnish-software.com/developers/tutorials/example-vcl-template/)  
25. 10 Varnish Cache mistakes and how to avoid them - Resources, accessed December 11, 2025, [https://info.varnish-software.com/blog/10-varnish-cache-mistakes-and-how-avoid-them](https://info.varnish-software.com/blog/10-varnish-cache-mistakes-and-how-avoid-them)