https://gemini.google.com/share/bd60eae2f0fe

## **Рекомендация 1: Переход на использование страниц памяти размером 64KB на уровне ядра Linux (ARM64 Optimization)**

### **Суть**

Данная стратегическая рекомендация предписывает фундаментальное изменение конфигурации операционной системы, обеспечивающей работу Varnish Cache, посредством замены стандартного ядра Linux с размером страницы памяти 4KB на специализированное ядро, скомпилированное с поддержкой страниц размером 64KB, что является нативной и высокоэффективной опцией для архитектуры ARM64 (AWS Graviton).1  
Центральный процессор Graviton, базирующийся на микроархитектуре Neoverse N1, обладает усовершенствованным блоком управления памятью (MMU), который аппаратно поддерживает множественные размеры страниц, однако стандартные дистрибутивы, такие как Amazon Linux 2023, по умолчанию используют консервативный размер 4KB для обеспечения максимальной совместимости с legacy-приложениями.1  
Механизм виртуальной памяти в операционных системах Linux опирается на иерархические таблицы страниц для трансляции виртуальных адресов процесса в физические адреса оперативной памяти, и эффективность этого процесса критически зависит от работы буфера ассоциативной трансляции (TLB).4  
При эксплуатации Varnish Cache на сервере с 32GB оперативной памяти использование стандартных страниц размером 4KB приводит к необходимости создания и обслуживания миллионов записей в таблицах страниц, что вызывает феномен "загрязнения" TLB (TLB pollution).4  
Высокая частота промахов TLB (TLB misses) вынуждает процессор выполнять дорогостоящие операции обхода таблиц страниц (page table walks), которые могут занимать сотни процессорных тактов, отнимая ресурсы у основного потока обработки HTTP-запросов.1  
Переход на использование страниц размером 64KB позволяет одной записи в буфере TLB покрывать непрерывный участок памяти, который в 16 раз превышает стандартный объем, что приводит к радикальному снижению давления на подсистему трансляции адресов.7  
Эта архитектурная оптимизация особенно критична для приложений класса in-memory cache, таких как Varnish, которые характеризуются паттернами произвольного доступа к огромным массивам памяти (Random Access Memory patterns) и высокой интенсивностью аллокаций.4  
Внедрение данного изменения требует установки пакета kernel-64k для Amazon Linux 2023 или linux-aws-64k для Ubuntu, последующего обновления конфигурации загрузчика GRUB и полной перезагрузки инстанса.8  
Важно понимать, что данная мера является оптимизацией "нулевого уровня", которая улучшает производительность всей системы ввода-вывода и подсистемы памяти, создавая фундамент для дальнейших настроек на уровне приложения.1  
Увеличение размера страницы также способствует повышению эффективности операций прямого доступа к памяти (DMA) и снижает накладные расходы на обработку прерываний при сетевом вводе-выводе, что критично для высоконагруженного веб-сервера.1

### **Оценка**

95

### **Достоинства**

Главным преимуществом является существенное снижение накладных расходов процессора на управление виртуальной памятью, что подтверждается многочисленными бенчмарками на архитектуре AArch64.1  
Улучшение показателя TLB hit rate приводит к снижению латентности при доступе к объектам в кэше, что особенно заметно на больших объемах памяти (32GB и выше), используемых в проекте RunRepeat.4  
Оптимизация не требует внесения изменений в исходный код Varnish Cache или модификации VCL-логики, являясь полностью прозрачной для прикладного уровня.1  
Использование страниц 64KB обеспечивает прирост производительности в диапазоне 10-20% для широкого спектра нагрузок, связанных с базами данных и кэшированием, что фактически является "бесплатным" увеличением мощности имеющегося оборудования.7  
Снижение количества страничных ошибок (page faults) уменьшает вероятность возникновения микро-задержек (jitter), обеспечивая более предсказуемое время отклика (Time to First Byte) для конечных пользователей.5  
Решение официально поддерживается Amazon Web Services и включено в репозитории Amazon Linux 2023 как рекомендованная опция для высокопроизводительных вычислений.2  
Улучшенная смежность физической памяти (physical contiguity) при использовании больших страниц повышает эффективность аппаратных префетчеров процессора Graviton.5  
Это решение устраняет узкое место на аппаратном уровне, которое невозможно компенсировать никакими программными настройками самого Varnish.4

### **Недостатки**

Основным технологическим недостатком является неизбежное увеличение внутренней фрагментации памяти (internal fragmentation), поскольку минимальной единицей выделения памяти становится блок в 64KB.4  
Для Varnish Cache, который часто оперирует мелкими объектами (заголовки, небольшие JSON-ответы), это может привести к росту видимого потребления памяти (RSS), так как даже объект размером 1 байт займет целую страницу.4  
Этот эффект, однако, частично нивелируется использованием современных аллокаторов памяти (таких как jemalloc), которые умеют эффективно управлять пулами внутри больших страниц, но риск повышенного потребления RAM остается.12  
Внедрение требует обязательной перезагрузки сервера, что влечет за собой необходимость планирования окна обслуживания и полную потерю "прогретого" кэша, если не используется персистентное хранилище.9  
Некоторые старые инструменты мониторинга или специфические драйверы могут некорректно интерпретировать статистику памяти при использовании нестандартного размера страницы, что может затруднить диагностику.7  
Существует теоретическая вероятность несовместимости с проприетарным ПО, которое жестко завязано на размер страницы 4KB, хотя для экосистемы Linux на ARM64 это становится все большей редкостью.1  
Если файловая система на диске была создана с размером блока 4KB, возможны накладные расходы при операциях чтения-записи, не выровненных по границе 64KB, хотя современные файловые системы (XFS, EXT4) обычно справляются с этим корректно.5  
В случае использования Varnish с хранилищем file, увеличение размера страницы может привести к более агрессивному использованию page cache операционной системой, что требует более тщательного мониторинга свободной памяти.13

## **Рекомендация 2: Замена системного аллокатора памяти glibc на jemalloc**

### **Суть**

Данная рекомендация предполагает замену стандартного системного аллокатора памяти glibc malloc, который используется Varnish Cache по умолчанию, на специализированный аллокатор jemalloc, разработанный для высоконагруженных многопоточных систем.12  
Стандартный аллокатор glibc использует механизм "арен" (arenas) для управления памятью в многопоточной среде, создавая по умолчанию 8 арен на каждое процессорное ядро, что на 8-ядерном процессоре Graviton приводит к созданию до 64 арен.12  
Такая архитектура в условиях высокой конкуренции потоков (high concurrency), характерной для Varnish, приводит к значительной фрагментации кучи (heap fragmentation), когда освобожденные блоки памяти не могут быть эффективно возвращены операционной системе из-за блокировки соседними занятыми чанками.15  
Varnish Cache, работающий с миллионами мелких объектов, создает идеальный шторм для glibc: постоянные циклы аллокации и деаллокации (malloc/free) приводят к тому, что показатель RSS (Resident Set Size) процесса непрерывно растет, несмотря на то, что полезный объем данных в кэше остается стабильным.17  
Аллокатор jemalloc применяет принципиально иную стратегию, используя классы размеров (size classes) и отдельные кэши для потоков (tcache), что позволяет группировать объекты схожего размера и минимизировать внешнюю фрагментацию.14  
Jemalloc активно использует системный вызов madvise с флагом MADV_DONTNEED, принудительно возвращая неиспользуемые страницы памяти ядру операционной системы, что предотвращает ложные срабатывания OOM-killer.15  
Для внедрения jemalloc на Amazon Linux 2023 требуется подключение репозитория EPEL или ручная компиляция, так как пакет может отсутствовать в базовой поставке.18  
Активация нового аллокатора осуществляется через переменную окружения LD_PRELOAD в unit-файле systemd, указывающую на библиотеку libjemalloc.so, либо через пересборку Varnish с прямой линковкой.20  
Jemalloc предоставляет расширенные возможности профилирования памяти, которые позволяют детально анализировать структуру потребления RAM и выявлять утечки на уровне отдельных функций, что критически важно для диагностики проблем, описанных клиентом.12  
Использование jemalloc является признанным индустриальным стандартом для инсталляций Varnish Enterprise и высоконагруженных Open Source сборок, рекомендованным разработчиками Varnish Software.17

### **Оценка**

98

### **Достоинства**

Ключевым преимуществом является радикальное снижение фрагментации памяти, что напрямую устраняет проблему "бесконечного роста памяти", на которую жалуется клиент RunRepeat.com.11  
Стабилизация потребления памяти позволяет безопасно увеличить размер кэша (-s malloc), минимизируя необходимый "запас" (headroom) и повышая эффективность использования доступных 32GB RAM.17  
Уменьшение конкуренции за блокировки (lock contention) в jemalloc обеспечивает прирост производительности CPU в многопоточных сценариях, что особенно актуально для многоядерной архитектуры Graviton.14  
Механизм thread-local cache (tcache) в jemalloc значительно ускоряет операции выделения памяти для короткоживущих объектов, характерных для HTTP-запросов.14  
Наличие встроенной статистики (malloc_stats_print) дает администраторам прозрачный инструмент для мониторинга здоровья подсистемы памяти без необходимости использования внешних дебаггеров.12  
Jemalloc демонстрирует лучшую масштабируемость при росте количества ядер CPU, что делает это решение перспективным с учетом возможного масштабирования инфраструктуры клиента.11  
Снижение фрагментации уменьшает нагрузку на подсистему виртуальной памяти ядра Linux, что косвенно улучшает отзывчивость всей системы.15

### **Недостатки**

Внедрение jemalloc на Amazon Linux 2023 сопряжено с определенными административными сложностями, так как требует установки пакетов из сторонних репозиториев (EPEL), поддержка которых может быть ограничена.19  
Некорректная настройка путей в LD_PRELOAD может привести к тому, что Varnish продолжит использовать glibc без каких-либо предупреждений, создавая иллюзию решения проблемы.20  
В некоторых синтетических тестах с однопоточной нагрузкой jemalloc может показывать незначительно большее потребление CPU по сравнению с glibc из-за более сложной логики управления метаданными.11  
Смена аллокатора памяти является глубоким вмешательством в среду выполнения (runtime environment) и теоретически может выявить скрытые ошибки работы с памятью (memory corruption bugs) в сторонних VMOD, если таковые используются.12  
Процедура обновления библиотеки jemalloc требует перезапуска процесса Varnish, что усложняет обслуживание по сравнению с обновлением системной glibc.18  
Настройка параметров самого jemalloc (через переменную MALLOC_CONF) может потребовать экспертных знаний для достижения оптимального баланса между производительностью и потреблением памяти в специфических условиях.17

## **Рекомендация 3: Нормализация Query String и устранение проблемы "Взрыва кэша" (Cache Bloat)**

### **Суть**

Данная рекомендация направлена на устранение фундаментальной причины избыточного потребления памяти — высокой вариативности (cardinality) ключей кэширования, вызванной наличием множества параметров в строке запроса (Query String).23  
Архитектура сайта RunRepeat.com включает фасетный поиск с фильтрами (gender, size, color) и использует рекламные метки, что приводит к генерации тысяч уникальных URL для одного и того же контента (например, ?size=42&color=red и ?color=red&size=42), каждый из которых Varnish по умолчанию считает отдельным объектом.23  
Каждый объект, сохраненный в кэше, потребляет около 1KB оперативной памяти исключительно на хранение метаданных (struct objcore, struct objhead), независимо от размера самого объекта.16  
Наличие миллиона уникальных вариаций URL, созданных ботами или рекламным трафиком, приводит к потреблению 1GB RAM только на метаданные, вызывая быстрое исчерпание ресурсов и принудительное вытеснение полезных данных (LRU nuking).16  
Решение заключается в реализации строгой логики нормализации в процедуре vcl_recv, которая должна приводить все входящие URL к каноническому виду до начала процесса поиска в кэше (hash lookup).24  
Необходимо безусловно удалять все маркетинговые параметры (такие как gclid, fbclid, utm_*), так как они используются исключительно клиентским JavaScript (Google Analytics) и не влияют на генерацию HTML-страницы на бэкенде.25  
Оставшиеся функциональные параметры (фильтры поиска) должны быть отсортированы в алфавитном порядке, чтобы гарантировать, что любой порядок следования параметров в запросе приводил к идентичному хэшу.26  
Для реализации этой логики настоятельно рекомендуется использовать специализированный модуль vmod_querystring (или std.querysort в новых версиях Varnish), так как попытки реализовать сортировку с помощью регулярных выражений (regsuball) крайне неэффективны с точки зрения CPU и сложны в поддержке.26  
Эффективный подход предполагает использование стратегии "белого списка" (whitelisting), когда в запросе оставляются только явно разрешенные параметры, необходимые приложению, а все остальные удаляются.29  
Также критически важно нормализовать заголовок Vary: User-Agent, который часто устанавливается бэкендом и приводит к дублированию кэша для каждой версии браузера; его следует либо удалять, либо приводить к ограниченному набору значений (например, Mobile и Desktop).30

### **Оценка**

100

### **Достоинства**

Нормализация URL устраняет первопричину (root cause) проблемы утечки памяти, сокращая количество объектов в кэше на порядки и высвобождая гигабайты RAM для полезных данных.23  
Драматическое повышение коэффициента попадания в кэш (Hit Rate) снижает нагрузку на бэкенд-серверы, позволяя им быстрее обрабатывать действительно уникальные запросы.23  
Использование белых списков параметров повышает безопасность приложения, защищая его от атак типа "Cache Poisoning" и "Cache Busting" с использованием случайных параметров.29  
Реализация данной логики происходит полностью на уровне VCL и не требует простоя серверов или изменения конфигурации инфраструктуры, вступая в силу мгновенно после перезагрузки правил.24  
Снижение количества объектов в кэше уменьшает накладные расходы на работу внутренних механизмов Varnish, таких как сборщик мусора (expiry thread) и LRU-списки.23  
Улучшение пользовательского опыта за счет того, что посетители, пришедшие по разным рекламным ссылкам, получают мгновенный ответ из кэша.32

### **Недостатки**

Существует риск нарушения функциональности сайта, если в процессе нормализации будут случайно удалены параметры, необходимые для работы приложения (например, параметры пагинации или AJAX-запросов).33  
Удаление маркетинговых меток (utm_*) на уровне Varnish делает невозможным анализ источников трафика через серверные логи (access logs), что требует полного перехода на клиентскую аналитику.33  
Использование vmod_querystring требует установки дополнительного модуля, который может отсутствовать в стандартной поставке Varnish, требуя компиляции под конкретную версию.28  
Сложная логика нормализации может незначительно увеличить время обработки запроса (processing latency) в Varnish, однако этот оверхед ничтожен по сравнению с выигрышем от кэширования.23  
Необходимость постоянного обновления "белого списка" параметров при изменении функционала сайта требует синхронизации работы разработчиков и администраторов Varnish.26

## **Рекомендация 4: Контроль временного хранилища (Transient Storage) и предотвращение утечек Hit-for-Miss**

### **Суть**

Данная рекомендация адресована проблеме неконтролируемого роста потребления памяти во временном хранилище (Transient Storage), которое в Varnish по умолчанию не имеет ограничений по объему (unbounded).34  
Transient Storage используется для хранения короткоживущих объектов (чей TTL меньше значения параметра shortlived, по умолчанию 10с) и, что более важно, для хранения технических записей hit-for-miss и hit-for-pass.35  
Записи hit-for-miss создаются Varnish автоматически, когда бэкенд возвращает ответ с заголовками, запрещающими кэширование (например, Set-Cookie или Cache-Control: private), но Varnish должен запомнить этот факт, чтобы предотвратить "слияние запросов" (request coalescing) для данного URL.35  
В условиях проекта RunRepeat.com, где присутствует множество запросов с уникальными рекламными метками, бэкенд, вероятно, устанавливает индивидуальные куки для каждого такого запроса, заставляя Varnish создавать миллионы записей hit-for-miss.37  
Поскольку Transient Storage использует malloc и не ограничено по размеру, накопление этих записей приводит к исчерпанию всей доступной памяти сервера и аварийному завершению процесса (crash), даже если основное хранилище настроено корректно.34  
Для устранения этой уязвимости необходимо жестко ограничить размер Transient хранилища при запуске демона, добавив параметр -s Transient=malloc,2G (размер следует подобрать эмпирически), что заставит Varnish принудительно удалять старые записи при переполнении.13  
Дополнительно следует оптимизировать логику в vcl_backend_response: для ответов, которые гарантированно не должны кэшироваться, можно явно устанавливать set beresp.uncacheable = false;, превращая их в hit-for-pass с коротким TTL, или полностью отключать создание таких записей, если риск перегрузки бэкенда (thundering herd) минимален.37  
Также необходимо провести аудит бэкенда и принудительно удалять заголовок Set-Cookie в VCL для публичного контента, чтобы предотвратить создание некэшируемых ответов там, где это не требуется.23  
Мониторинг счетчиков SMA.Transient.c_bytes и SMA.Transient.g_bytes через утилиту varnishstat является обязательным для контроля эффективности принятых мер.35

### **Оценка**

90

### **Достоинства**

Установка жесткого лимита на Transient Storage действует как "аварийный клапан", гарантируя, что Varnish никогда не потребит больше памяти, чем выделено, предотвращая падение сервера.35  
Оптимизация обработки hit-for-miss объектов снижает количество метаданных в памяти и уменьшает нагрузку на хэш-таблицы, повышая общую производительность системы.36  
Предотвращение создания hit-for-miss записей для уникальных одноразовых запросов освобождает ресурсы для кэширования действительно востребованного контента.37  
Удаление лишних кук (Set-Cookie) может значительно повысить Hit Rate, превращая ранее некэшируемый трафик в кэшируемый.23  
Понимание механики Transient Storage позволяет администраторам принимать осознанные решения о балансе между защитой бэкенда и потреблением памяти.37

### **Недостатки**

При достижении лимита Transient Storage новые записи не смогут быть созданы, что может привести к изменению поведения Varnish: запросы будут проходить на бэкенд без защиты от слияния (request coalescing), что может вызвать кратковременные пики нагрузки на базу данных.35  
Отключение логики hit-for-miss требует осторожности, так как в случае атаки на "тяжелый" URL все запросы пройдут на бэкенд одновременно, что может привести к отказу в обслуживании (DoS).37  
Ошибочное удаление заголовка Set-Cookie для критически важных страниц (корзина, личный кабинет) нарушит пользовательские сессии и функционал сайта.23  
Диагностика переполнения Transient Storage может быть неочевидной, так как стандартные инструменты не всегда явно показывают, какие именно URL занимают это пространство.35

## **Рекомендация 5: Тонкая настройка параметров запуска Varnish (Threads & Workspace)**

### **Суть**

Данная рекомендация фокусируется на оптимизации параметров времени выполнения (runtime parameters) Varnish, которые определяют статическое потребление памяти (overhead), не связанное с хранением данных кэша.38  
Каждый рабочий поток (worker thread) в Varnish потребляет оперативную память на собственный стек и на специализированные рабочие области (workspaces): workspace_client для обработки запроса, workspace_backend для ответа сервера и workspace_session для данных сессии.39  
В конфигурации по умолчанию Varnish может создавать тысячи потоков (thread_pool_max часто установлен в 5000), что при значениях workspace_client (например, 96KB) может привести к потреблению сотен мегабайт памяти только на пустые структуры потоков.39  
На 8-ядерном процессоре Graviton рекомендуется ограничить максимальное количество потоков разумным значением (например, thread_pool_max=2000) и использовать два пула потоков (thread_pools=2), чтобы избежать избыточных переключений контекста и неконтролируемого роста потребления RAM при штормах трафика.35  
Размеры рабочих областей (workspace_*) должны быть тщательно откалиброваны: они должны быть достаточными для работы всех VMOD и обработки длинных заголовков, но не чрезмерными, так как эта память выделяется для каждого активного запроса.40  
Недостаточный размер workspace приводит к ошибкам "workspace overflow" и сбоям обработки запросов (503 Guru Meditation), в то время как избыточный размер — к пустой трате памяти.35  
Важно также настроить параметр lru_interval, чтобы оптимизировать частоту обновления списков LRU и снизить конкуренцию за блокировки (lock contention) в многопоточной среде.41  
Регулярный мониторинг метрик MAIN.threads, MAIN.threads_failed и SMA.Transient.g_bytes необходим для валидации выбранных настроек.23

### **Оценка**

85

### **Достоинства**

Оптимизация пулов потоков предотвращает сценарий "thread pile-up", когда замедление бэкенда вызывает лавинообразный рост числа потоков Varnish, окончательно исчерпывающий память сервера.35  
Корректная настройка workspace параметров обеспечивает стабильную работу сложных VCL-логик и VMOD, предотвращая трудноуловимые ошибки обработки запросов.35  
Снижение накладных расходов на управление потоками освобождает процессорное время для полезной работы, повышая общую пропускную способность системы.39  
Предсказуемое потребление памяти служебными структурами позволяет точнее планировать размер основного кэша.40

### **Недостатки**

Слишком агрессивное ограничение thread_pool_max может привести к тому, что Varnish начнет сбрасывать входящие соединения (drop connections) во время легитимных пиков трафика, вызывая отказ в обслуживании.35  
Поиск оптимальных значений для workspace параметров требует итеративного подхода и анализа логов ошибок, так как универсальных значений не существует.35  
Неправильная настройка thread_pools может привести к неравномерному распределению нагрузки между ядрами процессора.39

## **Рекомендация 6: Внедрение Memory Governor (Varnish Enterprise Feature)**

### **Суть**

Данная рекомендация рассматривает возможность миграции на коммерческую версию Varnish Enterprise для использования функции Memory Governor, которая автоматизирует управление памятью.38  
В Open Source версии администратор вынужден вручную рассчитывать распределение памяти между хранилищем объектов (malloc) и накладными расходами, оставляя значительный "запас" (headroom) на случай непредвиденных всплесков, что неэффективно.38  
Технология Massive Storage Engine (MSE) в версии Enterprise включает компонент Memory Governor, который позволяет задать единый лимит памяти для всего процесса (например, memory_target=90%), динамически регулируя размер кэша в зависимости от текущих накладных расходов.38  
Это позволяет безопасно использовать практически всю доступную оперативную память сервера, не опасаясь OOM-сбоев, так как система сама агрессивно уменьшит кэш при росте потребления памяти потоками или transient-объектами.38  
Для бизнеса масштаба RunRepeat.com стоимость лицензии может быть оправдана снижением операционных рисков и доступом к премиальной поддержке.43

### **Оценка**

80

### **Достоинства**

Полная автоматизация управления памятью устраняет человеческий фактор и необходимость сложного ручного тюнинга параметров, обеспечивая высокую стабильность работы.42  
Более эффективная утилизация аппаратных ресурсов позволяет хранить больше объектов в кэше на том же оборудовании, повышая Hit Rate.38  
Доступ к профессиональной поддержке вендора и расширенным функциям безопасности (WAF, SSL/TLS).43

### **Недостатки**

Внедрение требует финансовых затрат на лицензирование, что может быть не предусмотрено бюджетом проекта.22  
Использование проприетарных технологий (MSE) создает зависимость от вендора (vendor lock-in) и усложняет возможный возврат к Open Source решениям.44  
Данное решение является скорее "страховкой", чем исправлением корневых проблем архитектуры (таких как дублирование URL), которые все равно требуют устранения.38

## **Вердикт**

Анализ инфраструктуры RunRepeat.com показывает, что проблемы с памятью вызваны сочетанием архитектурных особенностей (Graviton CPU, высокая кардинальность URL) и дефолтных настроек Varnish.

1. **Рекомендация 3 (Нормализация Query String)** является критической и обязательной к исполнению, так как устраняет первопричину раздувания кэша.  
2. **Рекомендация 4 (Контроль Transient Storage)** и **Рекомендация 2 (Jemalloc)** обеспечат техническую стабильность и защиту от утечек памяти.  
3. **Рекомендация 1 (64k Pages)** даст системный прирост производительности на платформе ARM64.  
4. **Рекомендация 5** и **Рекомендация 6** служат дополнительными мерами тонкой настройки и стратегического развития.

#### **Works cited**

1. Improve Performance with 64K Memory Pages on AWS Graviton Processors, accessed December 11, 2025, [https://dev.to/aws-builders/improve-performance-with-64k-memory-pages-on-aws-graviton-processors-ifa](https://dev.to/aws-builders/improve-performance-with-64k-memory-pages-on-aws-graviton-processors-ifa)  
2. (aarch64) 64k Base Page Size on Arm - Oracle Help Center, accessed December 11, 2025, [https://docs.oracle.com/en/operating-systems/uek/8/relnotes8.0/uek8.0-DefaultPageSizeonArmPlatform.html](https://docs.oracle.com/en/operating-systems/uek/8/relnotes8.0/uek8.0-DefaultPageSizeonArmPlatform.html)  
3. Graviton arm64 / aarch64 EC2 instance types with 64k pagesize? - AWS re:Post, accessed December 11, 2025, [https://repost.aws/questions/QUlK_MQuthTKWWlviBv2xv8g/graviton-arm64-aarch64-ec2-instance-types-with-64k-pagesize](https://repost.aws/questions/QUlK_MQuthTKWWlviBv2xv8g/graviton-arm64-aarch64-ec2-instance-types-with-64k-pagesize)  
4. Understanding Memory Page Sizes on Arm64 - Ampere Computing, accessed December 11, 2025, [https://amperecomputing.com/tuning-guides/understanding-memory-page-sizes-on-arm64](https://amperecomputing.com/tuning-guides/understanding-memory-page-sizes-on-arm64)  
5. Efficient Use of the Page Cache with 64 KB Pages - The Linux Kernel Archives, accessed December 11, 2025, [https://www.kernel.org/doc/ols/2006/ols2006v2-pages-73-78.pdf](https://www.kernel.org/doc/ols/2006/ols2006v2-pages-73-78.pdf)  
6. Operating System Settings — NVIDIA Grace Performance Tuning Guide, accessed December 11, 2025, [https://docs.nvidia.com/grace-perf-tuning-guide/os-settings.html](https://docs.nvidia.com/grace-perf-tuning-guide/os-settings.html)  
7. 64K Kernel Page Size Performance Benefits For HPC Shown With NVIDIA's GH200 Grace CPU - Phoronix, accessed December 11, 2025, [https://www.phoronix.com/review/aarch64-64k-kernel-perf](https://www.phoronix.com/review/aarch64-64k-kernel-perf)  
8. Install 64k page kernel on ARM64 instances - Ubuntu on AWS documentation, accessed December 11, 2025, [https://documentation.ubuntu.com/aws/aws-how-to/instances/install-64k-kernel/](https://documentation.ubuntu.com/aws/aws-how-to/instances/install-64k-kernel/)  
9. Updating the Linux kernel on AL2023 - AWS Documentation, accessed December 11, 2025, [https://docs.aws.amazon.com/linux/al2023/ug/kernel-update.html](https://docs.aws.amazon.com/linux/al2023/ug/kernel-update.html)  
10. AWS Graviton: Best Price Performance, accessed December 11, 2025, [https://aws.amazon.com/awstv/watch/acde308f81f/](https://aws.amazon.com/awstv/watch/acde308f81f/)  
11. CPU and memory usage of jemalloc as compared to glibc malloc - Stack Overflow, accessed December 11, 2025, [https://stackoverflow.com/questions/13027475/cpu-and-memory-usage-of-jemalloc-as-compared-to-glibc-malloc](https://stackoverflow.com/questions/13027475/cpu-and-memory-usage-of-jemalloc-as-compared-to-glibc-malloc)  
12. Java in K8s: how we've reduced memory usage without changing any code | by Mickael Jeanroy | malt-engineering, accessed December 11, 2025, [https://blog.malt.engineering/java-in-k8s-how-weve-reduced-memory-usage-without-changing-any-code-cbef5d740ad](https://blog.malt.engineering/java-in-k8s-how-weve-reduced-memory-usage-without-changing-any-code-cbef5d740ad)  
13. Storage backends — Varnish version trunk documentation, accessed December 11, 2025, [https://varnish-cache.org/docs/trunk/users-guide/storage-backends.html](https://varnish-cache.org/docs/trunk/users-guide/storage-backends.html)  
14. Why does the default glibc allocator have relatively poor performance? (What mak... | Hacker News, accessed December 11, 2025, [https://news.ycombinator.com/item?id=8612645](https://news.ycombinator.com/item?id=8612645)  
15. How glibc Memory Handling Affects Java Applications: The Hidden Cost of Fragmentation | by Daniyal Hassan | Medium, accessed December 11, 2025, [https://medium.com/@daniyal.hass/how-glibc-memory-handling-affects-java-applications-the-hidden-cost-of-fragmentation-8e666ee6e000](https://medium.com/@daniyal.hass/how-glibc-memory-handling-affects-java-applications-the-hidden-cost-of-fragmentation-8e666ee6e000)  
16. Why isn't varnish taking into account the malloc limit? - Stack Overflow, accessed December 11, 2025, [https://stackoverflow.com/questions/16693677/why-isnt-varnish-taking-into-account-the-malloc-limit](https://stackoverflow.com/questions/16693677/why-isnt-varnish-taking-into-account-the-malloc-limit)  
17. Understanding Varnish Cache Memory Usage - Resources, accessed December 11, 2025, [https://info.varnish-software.com/blog/understanding-varnish-cache-memory-usage](https://info.varnish-software.com/blog/understanding-varnish-cache-memory-usage)  
18. jemalloc/INSTALL.md at dev - GitHub, accessed December 11, 2025, [https://github.com/jemalloc/jemalloc/blob/dev/INSTALL.md](https://github.com/jemalloc/jemalloc/blob/dev/INSTALL.md)  
19. Extra Packages for Enterprise Linux (EPEL) - Amazon Linux 2023 - AWS Documentation, accessed December 11, 2025, [https://docs.aws.amazon.com/linux/al2023/ug/epel.html](https://docs.aws.amazon.com/linux/al2023/ug/epel.html)  
20. How to install jemalloc on AWS Elastic Beanstalk - Matthew Lein, accessed December 11, 2025, [https://matthewlein.com/articles/install-jemalloc-elastic-beanstalk](https://matthewlein.com/articles/install-jemalloc-elastic-beanstalk)  
21. Configuring Varnish systemd services - Varnish Developer Portal, accessed December 11, 2025, [https://www.varnish-software.com/developers/tutorials/configuring-varnish-systemd-services/](https://www.varnish-software.com/developers/tutorials/configuring-varnish-systemd-services/)  
22. How to install varnish cache in Amazon Linux 2023? - Server Fault, accessed December 11, 2025, [https://serverfault.com/questions/1137676/how-to-install-varnish-cache-in-amazon-linux-2023](https://serverfault.com/questions/1137676/how-to-install-varnish-cache-in-amazon-linux-2023)  
23. Achieving a high cache hit rate with Varnish - Resources, accessed December 11, 2025, [https://info.varnish-software.com/blog/high-hit-rate-with-varnish](https://info.varnish-software.com/blog/high-hit-rate-with-varnish)  
24. Achieving a high hitrate — Varnish version 7.4.3 documentation, accessed December 11, 2025, [https://varnish-cache.org/docs/7.4/users-guide/increasing-your-hitrate.html](https://varnish-cache.org/docs/7.4/users-guide/increasing-your-hitrate.html)  
25. Varnish: Normalizing / Normalising the url - Richy's Random Ramblings, accessed December 11, 2025, [https://blog.rac.me.uk/2010/03/03/normalizing_the_url_in_varnish/](https://blog.rac.me.uk/2010/03/03/normalizing_the_url_in_varnish/)  
26. The essential vmods all Varnish users should know about - Resources, accessed December 11, 2025, [https://info.varnish-software.com/blog/essential-vmods-all-varnish-users-should-know-about](https://info.varnish-software.com/blog/essential-vmods-all-varnish-users-should-know-about)  
27. Stripping out select querystring attribute/value pairs so varnish will not vary cache by them, accessed December 11, 2025, [https://stackoverflow.com/questions/13144172/stripping-out-select-querystring-attribute-value-pairs-so-varnish-will-not-vary](https://stackoverflow.com/questions/13144172/stripping-out-select-querystring-attribute-value-pairs-so-varnish-will-not-vary)  
28. Strip query parameters with Varnish | by Danila Vershinin - Medium, accessed December 11, 2025, [https://medium.com/@getpagespeed/strip-query-parameters-with-varnish-bf3cb2877530](https://medium.com/@getpagespeed/strip-query-parameters-with-varnish-bf3cb2877530)  
29. vmod_querystring: Varnish Query-String Module | Man Page | Library Functions | vmod-querystring | ManKier, accessed December 11, 2025, [https://www.mankier.com/3/vmod_querystring](https://www.mankier.com/3/vmod_querystring)  
30. How to Speed Up Varnish Cache and Prevent Hangs : r/programming - Reddit, accessed December 11, 2025, [https://www.reddit.com/r/programming/comments/1k0az4g/how_to_speed_up_varnish_cache_and_prevent_hangs/](https://www.reddit.com/r/programming/comments/1k0az4g/how_to_speed_up_varnish_cache_and_prevent_hangs/)  
31. 10 Varnish Cache mistakes and how to avoid them, accessed December 11, 2025, [https://varnish-software.medium.com/10-varnish-cache-mistakes-and-how-to-avoid-them-d240f452ab35](https://varnish-software.medium.com/10-varnish-cache-mistakes-and-how-to-avoid-them-d240f452ab35)  
32. How to Enable 'Ignore Query String' for Varnish Cache | Cloudways Help Center, accessed December 11, 2025, [https://support.cloudways.com/en/articles/8437462-how-to-enable-ignore-query-string-for-varnish-cache](https://support.cloudways.com/en/articles/8437462-how-to-enable-ignore-query-string-for-varnish-cache)  
33. Stripping query strings in Varnish | Acquia Product Documentation, accessed December 11, 2025, [https://docs.acquia.com/acquia-cloud-platform/stripping-query-strings-varnish](https://docs.acquia.com/acquia-cloud-platform/stripping-query-strings-varnish)  
34. Overuse of Transient storage with hit-for-miss objects · Issue #2654 · varnishcache/varnish-cache - GitHub, accessed December 11, 2025, [https://github.com/varnishcache/varnish-cache/issues/2654](https://github.com/varnishcache/varnish-cache/issues/2654)  
35. Varnish memory usage keeps increasing - Stack Overflow, accessed December 11, 2025, [https://stackoverflow.com/questions/76209998/varnish-memory-usage-keeps-increasing](https://stackoverflow.com/questions/76209998/varnish-memory-usage-keeps-increasing)  
36. careful selection of hitpass vs hitmiss · Issue #2865 · varnishcache/varnish-cache - GitHub, accessed December 11, 2025, [https://github.com/varnishcache/varnish-cache/issues/2865](https://github.com/varnishcache/varnish-cache/issues/2865)  
37. Hit-for-Miss AND why a NULL TTL is bad for you - Resources - Varnish Software, accessed December 11, 2025, [https://info.varnish-software.com/blog/hit-for-miss-and-why-a-null-ttl-is-bad-for-you](https://info.varnish-software.com/blog/hit-for-miss-and-why-a-null-ttl-is-bad-for-you)  
38. Two-Minute Tech Tuesdays - Memory Governor - Resources - Varnish Software, accessed December 11, 2025, [https://info.varnish-software.com/blog/two-minute-tech-tuesdays-memory-governor](https://info.varnish-software.com/blog/two-minute-tech-tuesdays-memory-governor)  
39. Understanding how Varnish works (Part 1) - Nick Tailor's Technical Blog, accessed December 11, 2025, [https://www.nicktailor.com/varnish-and-how-it-works/](https://www.nicktailor.com/varnish-and-how-it-works/)  
40. Varnish Using Significantly More Memory than Cache? - Stack Overflow, accessed December 11, 2025, [https://stackoverflow.com/questions/78379910/varnish-using-significantly-more-memory-than-cache](https://stackoverflow.com/questions/78379910/varnish-using-significantly-more-memory-than-cache)  
41. VMOD std - Varnish Standard Module, accessed December 11, 2025, [https://varnish-cache.org/docs/trunk/reference/vmod_std.html](https://varnish-cache.org/docs/trunk/reference/vmod_std.html)  
42. Auto-scaling memory usage to increase cache size in Varnish - Resources, accessed December 11, 2025, [https://info.varnish-software.com/blog/auto-scaling-memory-usage-to-increase-cache-size-in-varnish](https://info.varnish-software.com/blog/auto-scaling-memory-usage-to-increase-cache-size-in-varnish)  
43. AWS Marketplace: Varnish Enterprise 6 (Red Hat) - Amazon.com, accessed December 11, 2025, [https://aws.amazon.com/marketplace/pp/prodview-nqecedatdopwg](https://aws.amazon.com/marketplace/pp/prodview-nqecedatdopwg)  
44. Varnish Enterprise 6 (Ubuntu) - AWS Marketplace, accessed December 11, 2025, [https://aws.amazon.com/marketplace/pp/prodview-atq2qasjkejio](https://aws.amazon.com/marketplace/pp/prodview-atq2qasjkejio)