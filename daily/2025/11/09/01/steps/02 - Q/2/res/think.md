Ваши опасения относительно способности приложения обрабатывать concurrent requests полностью обоснованы.
В текущей конфигурации на Replit Autoscale ваше приложение не сможет надежно справиться с внезапным всплеском одновременных запросов.
Проблема заключается не в Python Flask, который является production-ready framework.
При использовании production WSGI server, такого как Gunicorn, Flask способен эффективно обрабатывать параллельные запросы, запуская несколько worker processes.
Ключевая проблема заключается в используемой вами платформе Replit и её модели scale-to-zero.
Scale-to-zero означает, что при отсутствии активности ваше приложение останавливается.
Первый запрос к остановленному приложению инициирует cold start, который может занимать значительное время, пока загружается новый instance.
В течение этого времени входящие запросы к API будут сталкиваться с высокой latency или завершатся ошибкой time-out.
Replit оптимизирован для прототипирования и не подходит для хостинга production SaaS-приложений с высокими требованиями к доступности и производительности.
Для обеспечения надежной масштабируемости я предлагаю разработать план миграции приложения на профессиональную Platform as a Service (PaaS), такую как DigitalOcean App Platform или Railway.
Миграция на профессиональную PaaS устранит проблему cold start.
Дополнительно, для защиты API от перегрузки и чрезмерного потребления ресурсов (риск OWASP API4:2023 Unrestricted Resource Consumption) я внедрю Rate Limiting.
Я реализую это с помощью библиотеки Flask-Limiter, установив ограничения на количество запросов, которое один пользователь может отправить за определенный период времени.