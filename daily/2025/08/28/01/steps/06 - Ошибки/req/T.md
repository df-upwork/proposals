# 1.
## 1.1.
`Aᨀ` ≔ (мой ответ `ꆜ`)

## 1.2.
Содержание `Aᨀ`:
~~~markdown
1) Стратегическая задача, которую вам поручил работодатель — диагностика проблем прошлых запусков ваших pipelines.
Ваше первое возможное заблуждение: попытка провести эту диагностику новым запуском pipeline.
На самом же деле, новый запуск не является первоочередным способом понять, почему конвейеры не работали в прошлом.
Вместо этого в первую очередь следует изучить журналы выполнения прошлых запусков:
1.1) Перейти в Azure Data Factory Studio.
1.2) Открыть вкладку «Monitor» на левой боковой панели.
1.3) В разделе «Pipeline runs» изучить список предыдущих выполнений целевого конвейера. 
Использовать фильтры по имени конвейера (Pipeline name) и статусу (Status, например, «Failed»), чтобы найти интересующие запуски. 
Убедиться, что анализируются запуски типа «Triggered» (производственные запуски), а не «Debug».
1.4) Проанализировать детали сбойного запуска.
1.4.1) Кликнуть на имя конвейера в списке, чтобы перейти к списку «Activity runs» (выполнения действий).
1.4.2) Идентифицировать действие (activity), которое завершилось сбоем.
1.4.3) Изучить детальное сообщение об ошибке. 
Для этого кликнуть на иконку в колонке «Error» для этого activity.
1.4.4) Изучить входные параметры, которые были использованы при этом запуске.
Для этого найти колонку «Parameters» (на уровне Pipeline run или в верхней части экрана Activity runs) и посмотреть значения, которые были фактически переданы в конвейер.
2) Ваше второе возможное заблуждение: вы ищете причину сбоя работы pipeline только внутри него.
На самом же деле, значительная часть сбоев pipeline связана с внешниими причинами: инфраструктурой и безопасностью, особенно в унаследованных средах.
В частности:
- Аутентификация и Авторизация: истекшие учетные данные или ключи в Linked Services, некорректная настройка Managed Identity, отсутствие доступа к Azure Key Vault или целевым хранилищам.
- Сетевые проблемы: конфигурация брандмауэров (Azure Storage, SQL DB), VNet, Private Endpoints, блокирующие доступ.
- Integration Runtime (IR): проблемы с доступностью, конфигурацией или производительностью Self-Hosted IR.

Игнорирование внешних факторов является критической ошибкой при диагностике сбоев в ADF.
Поэтому нужно провести диагностику этих внешних факторов:
2.1) Перейти на вкладку «Manage» на левой боковой панели.
2.2) Проверить Linked Services:
2.2.1) Перейти в раздел «Linked services».
2.2.2) Идентифицировать все Linked Services, используемые в целевом конвейере (их можно найти в настройках Datasets или Activities).
2.2.3) Для каждого Linked Service открыть его конфигурацию и использовать функцию «Test connection». Это позволит проверить базовую доступность ресурса и корректность конфигурации подключения.
Важное примечание: 
Успешный «Test connection» не гарантирует работоспособность при запуске по триггеру (Triggered run). 
Тест часто выполняется в контексте вашей учетной записи пользователя, в то время как производственный запуск выполняется в контексте безопасности самой службы ADF (обычно Managed Identity). 
У этих субъектов могут быть разные права доступа и сетевые разрешения.
2.2.4) Определить метод аутентификации (Authentication method), используемый в Linked Service (например, System-Assigned Managed Identity, Service Principal, Account Key, SQL Authentication).
2.2.5) Верифицировать права доступа субъекта безопасности ADF. 
Если используется Managed Identity или Service Principal, необходимо убедиться, что этому субъекту назначены необходимые роли Azure RBAC или разрешения на целевом ресурсе (например, «Storage Blob Data Contributor» для хранилища или соответствующие разрешения в базе данных SQL). 
Эта проверка выполняется вне ADF Studio, в настройках «Access Control (IAM)» целевого ресурса на портале Azure.
2.3) Проверить Integration Runtimes:
2.3.1) Перейти в раздел «Integration runtimes».
2.3.2) Проверить статус Integration Runtimes, используемых в Linked Services. 
Убедиться, что они находятся в состоянии «Running», особенно если используются Self-Hosted Integration Runtimes.
2.4) Синтез результатов диагностики и определение причин исторических сбоев.
Цель: Выполнить вашу стратегическую задачу — определить, почему конвейеры не работали в прошлом, на основе собранных данных.
2.4.1) Сопоставить детальные сообщения об ошибках (п. 1.4.3) с результатами проверки среды (п. 2.2 и 2.3). Если ошибка указывает на проблемы с подключением (например, «Authentication failed», «Connection timed out»), и «Test connection» (п. 2.2.3) также завершается неудачей или IR недоступен (п. 2.3.2), причина сбоя, вероятно, внешняя (инфраструктура, безопасность).
2.4.2) Проанализировать входные параметры, использованные при сбойных запусках (п. 1.4.4). Определить, могли ли сбои быть вызваны некорректными или неожиданными данными, переданными в конвейер (например, неверный формат даты, несуществующий путь).
2.4.3) Идентифицировать паттерны сбоев. 
Являются ли сбои постоянными (часто указывает на проблему конфигурации или доступа) или периодическими/случайными (часто указывает на проблемы производительности, блокировки ресурсов или зависимость от специфических данных).
2.4.4) Сформулировать выводы о корневой причине (Root Cause) исторических сбоев и классифицировать её (например: аутентификация, сеть, логика конвейера, качество данных).
3) После завершения диагностики исторических сбоев (п. 1-2), для понимания логики работы конвейера и его запуска необходимо идентифицировать и проанализировать Pipeline Parameters.
3.1) Перейти на вкладку «Author» на левой боковой панели.
3.2) Найти и открыть целевой конвейер.
3.3) Кликнуть на пустую область холста (canvas) конвейера, чтобы отобразить его общие настройки.
3.4) Перейти на вкладку «Parameters». 
Составить список всех параметров, зафиксировав их «Name», «Type» (например, `String`, `Int`, `Array`, `Object`, `SecureString`) и «Default value» (значение по умолчанию), если оно указано.
Знание типа данных критично, особенно для сложных типов (`Array`, `Object`).
Источник: Microsoft Learn: Parameters and variables in Azure Data Factory.
3.5) Изучить, как параметры используются внутри конвейера.
3.5.1) Выбрать каждое activity на холсте (например, Copy activity, Lookup, Data Flow).
3.5.2) Проверить вкладки настроек (например, «Settings», «Source», «Sink») на предмет использования динамического содержимого (dynamic content).
3.5.3) Идентифицировать выражения (expressions), которые ссылаются на параметры конвейера, используя синтаксис `@pipeline().parameters.<parameterName>`.

4) Затем нужно определить Parameter Sources
Цель: Определить, как конвейер получает параметры в производственной среде (часто автоматически через триггеры), чтобы эмулировать эти значения при ручном тестировании.
4.1) Проанализировать связанные триггеры (Triggers).
4.1.1) Находясь в редакторе конвейера (вкладка «Author»), нажать кнопку «Trigger» на верхней панели и выбрать «New/Edit».
4.1.2) В открывшейся панели изучить конфигурацию существующих триггеров, связанных с этим конвейером.
4.2) Изучить параметры, передаваемые триггером.
4.2.1) Продвигаясь по конфигурации триггера, обратить внимание на шаг, где заполняются параметры конвейера.
4.2.2) Идентифицировать использование системных переменных (System Variables). 
Это выражения, начинающиеся с `@trigger()` или `@triggerBody()`. 
Примеры:
- `@trigger().outputs.windowStartTime` (для Tumbling Window Trigger).
- `@triggerBody().fileName` (для Storage Event Trigger).

Производственные конвейеры часто получают метаданные (например, временные метки или имена файлов) автоматически от триггеров через System Variables. 
При ручном тестировании (Debug) пользователь должен эмулировать эти значения самостоятельно. 
Незнание этой зависимости является частой причиной проблем с ручным запуском.
4.3) Определить значения для тестирования. 
Использовать комбинацию значений из исторических запусков (пункт 1.4.4 выше), значений по умолчанию (пункт 3.4) и эмулированных значений триггеров (пункт 4.2.2) для формирования набора тестовых входных данных.
5) Обеспечение безопасности тестового запуска (Safety Check)
Цель: Предотвратить случайное повреждение, модификацию, удаление или дублирование производственных данных при запуске унаследованного конвейера.
Обоснование: 
Запуск конвейера без полного понимания его логики и конфигурации приемников данных (Sinks) несет критические риски для целостности данных.

5.1) Идентифицировать операции модификации данных и приемники (Sinks).
Проанализировать все действия (Activities) в конвейере, которые потенциально могут изменять данные во внешних системах:
5.1.1) `Copy activity` (изучить вкладку «Sink»).
5.1.2) `Data Flow` (изучить все Sinks внутри потока данных).
5.1.3) `Stored Procedure activity` и `Script activity` (могут выполнять DML/DDL операции: INSERT, UPDATE, DELETE, TRUNCATE).
5.1.4) `Delete activity`.
5.1.5) `Web`, `Webhook`, `Custom activities` (если они вызывают API для модификации данных).

5.2) Проанализировать целевые системы.
Для каждого действия из п. 5.1 определить, куда именно будут записываться или где будут удаляться данные.
 Изучить конфигурацию целевых Datasets и Linked Services. 
Определить, указывают ли они на производственные (Production) системы.

5.3) Применить стратегию безопасного запуска.
Если конвейер может повлиять на производственные данные, необходимо применить одну или несколько мер безопасности. 
Методы приведены в порядке предпочтения.

5.3.1) Стратегия 1: Перенаправление записи в безопасное место (Наиболее надежный метод).
5.3.1.1) Через параметры: Если конфигурация приемника (путь, имя таблицы, строка подключения) параметризована (см. п. 3.5), убедиться, что при запуске (п. 6.2) будут использованы значения, указывающие на тестовую среду (например, папка "test", схема "dev").
5.3.1.2) Через временное изменение конфигурации: Если параметры не используются, временно изменить настройки Datasets или Linked Services, чтобы они указывали на тестовую среду. 
Важно: Не сохранять и не публиковать (Publish) эти изменения.

5.3.2) Стратегия 2: Использование механизмов изоляции и контроля.
5.3.2.1) Для Data Flows: Временно заменить целевой Sink на «Cache Sink». 
Это позволит просмотреть результаты (Data Preview) без физической записи в хранилище. (Требует активной сессии Data Flow Debug).
5.3.2.2) Для Activities на холсте: Использовать точки останова (Breakpoints). 
Установить точку останова (кликнуть на красный кружок в правом верхнем углу activity) на действии, выполняющем запись. 
При запуске в режиме «Debug» конвейер приостановится перед его выполнением, позволяя проверить входные данные (Input) и принять решение о продолжении.
5.3.2.3) Деактивация действий: Если анализ записи данных не является целью теста, временно деактивировать (кнопка «Deactivate» на верхней панели) действия, выполняющие модификацию.

5.3.3) Стратегия 3: Минимизация воздействия (Использовать с осторожностью).
5.3.3.1) Ограничение объема данных: Открыть «Debug Settings» и установить «Row limit» на малое значение (например, 10-100).
Предупреждение: 
Row limit ограничивает чтение из источника, но не обеспечивает полной безопасности, если конвейер выполняет операции, не зависящие от объема данных (например, TRUNCATE TABLE или удаление файлов).

5.4) Условие отмены запуска (Go/No-Go Decision).
Если ни один из методов п. 5.3 не может гарантировать безопасность производственных данных, не выполнять запуск (раздел 6). 
В этом случае требуется клонирование (Clone) и модификация конвейера для тестирования в изолированной среде.

6) Выполнить тестовый запуск (Test Run)
Цель: Запустить конвейер с корректными параметрами в контролируемом режиме и проверить его работоспособность.
6.1) Находясь на вкладке «Author» в редакторе целевого конвейера, начать выполнение в режиме отладки, нажав кнопку «Debug» на верхней панели инструментов.
Обоснование: 
Режим «Debug» используется для тестирования текущей версии конвейера на холсте (включая неопубликованные изменения) и позволяет наблюдать за выполнением в реальном времени без необходимости публикации (Publish). 
Он предпочтителен для итеративной разработки и тестирования.
6.2) В открывшейся панели (обычно называется «Pipeline Debug» или «Pipeline run parameters») ввести значения для параметров, определённые на пункте 4.3 выше.
6.3) Соблюдать корректный формат ввода данных:
6.3.1) При эмуляции временных меток триггера использовать формат ISO 8601 (например, `2025-08-27T10:00:00Z`).
6.3.2) Для параметров типа `Array` ввести значение в формате JSON массива. 
Например: `["item1", "item2"]`.
6.3.3. Для параметров типа Object ввести значение в формате JSON объекта. 
Например: `{"key1": "value1", "key2": "value2"}`.
Обоснование: Корректный ввод параметров, особенно сложных типов (`Array`, `Object`), необходим для успешного запуска. 
Неправильный формат JSON приведет к ошибкам валидации еще до начала выполнения.
6.4) Нажать «OK», чтобы начать выполнение.
6.5) Наблюдать за ходом выполнения на вкладке «Output» под холстом конвейера. 
Проверить входные (Input) и выходные (Output) данные для каждого Activity после его завершения, чтобы убедиться, что параметры были интерпретированы корректно.
~~~

# 2. `᛭T`
Проанализируй `Aᨀ`:
1) Есть ли там логические ошибки?
2) Есть ли там фактические ошибки?
3) Упущено ли в `Aᨀ` нечто важное?

# 3. Требования к твоему ответу
## 3.1.
Отвечай на русском языке.
## 3.2.
Мой вопрос не пересказывай.
## 3.3.
Уже сформулированную мной информацию не пересказывай.
## 3.4.
Писать свою версию `Aᨀ` не нужно: просто укажи свои замечания по пунктам.
## 3.5.
До и после списка замечаний ничего не пиши.
## 3.6.
Нумерация замечаний должна быть сквозной.