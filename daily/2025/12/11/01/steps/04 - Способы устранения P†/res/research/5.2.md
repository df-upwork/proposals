https://gemini.google.com/share/7a5ce182ad61


## **Введение**

В современной экосистеме облачных вычислений эффективность доставки контента определяется не только скоростью сети, но и глубокой интеграцией программного обеспечения с аппаратной архитектурой. Данный отчет представляет собой исчерпывающий анализ стратегий оптимизации Varnish Cache в среде Amazon Web Services (AWS), с особым акцентом на использование процессоров AWS Graviton (архитектура ARM64) и операционной системы Amazon Linux 2023 (AL2023). Исследование направлено на решение проблемы (P†), заключающейся в нестабильности потребления ресурсов, непредсказуемой латентности и риске исчерпания памяти (OOM) в высоконагруженных системах.

Мы проанализируем пять ключевых методов устранения этих проблем (Mᚖ⠿), оценив их эффективность, архитектурные последствия и сложность внедрения. Анализ базируется на эмпирических данных, технической документации и лучших практиках индустрии, с целью формирования эталонной архитектуры для систем с экстремальными требованиями к производительности.

## **Раздел 1. Аппаратная парадигма: Переход на AWS Graviton и ARM64**

### **1.1. Эволюция архитектуры процессоров в облаке**

Переход от архитектуры x86_64 к ARM64 в серверном сегменте, возглавляемый процессорами AWS Graviton, знаменует собой фундаментальный сдвиг в подходе к вычислениям, ориентированным на обработку данных. Процессоры Graviton, основанные на ядрах ARM Neoverse, предлагают уникальный баланс между производительностью и энергоэффективностью, что критически важно для приложений типа "in-memory cache", таких как Varnish.1 В отличие от традиционных архитектур, ориентированных на сложные инструкции (CISC), RISC-архитектура ARM позволяет оптимизировать конвейер исполнения команд, что в сочетании с высокоскоростной памятью DDR5 обеспечивает существенный прирост пропускной способности.3

### **1.2. Проблема трансляции адресов в кэширующих системах**

Varnish Cache функционирует как высокоскоростной интерфейс между оперативной памятью и сетевым вводом-выводом, оперируя миллионами объектов. Ключевым узким местом в таких системах становится блок управления памятью (MMU) и буфер ассоциативной трансляции (TLB). При использовании стандартного размера страницы памяти в 4 КБ (4096 байт) для адресации 100 ГБ кэша требуется создание более 26 миллионов записей в таблице страниц. Это создает колоссальное давление на TLB (TLB pressure), так как кэш TLB имеет ограниченный размер и не может вместить все трансляции.4 Частые промахи TLB (TLB misses) вынуждают процессор выполнять дорогостоящие операции обхода таблиц страниц (page walk) в основной памяти, что приводит к задержкам (stalls) в конвейере процессора и снижению количества инструкций, выполняемых за такт (IPC).5

## **Раздел 2. Анализ метода Mᚖ₁: Переход на страницы памяти 64 КБ**

### **2.1. Механизм действия и теоретическое обоснование**

Метод Mᚖ₁ предполагает переключение ядра операционной системы Amazon Linux 2023 на использование страниц памяти размером 64 КБ вместо стандартных 4 КБ. Архитектура ARMv8.2+, используемая в процессорах Graviton2 и новее, аппаратно поддерживает гранулярность страниц 4 КБ, 16 КБ и 64 КБ.5 Увеличение размера страницы в 16 раз (с 4096 до 65536 байт) пропорционально сокращает количество записей в таблице страниц, необходимых для адресации того же объема памяти. Это значительно повышает вероятность попадания в TLB (TLB hit rate), так как одна запись TLB теперь покрывает гораздо больший диапазон виртуальных адресов.5

### **2.2. Реализация в Amazon Linux 2023**

В дистрибутиве Amazon Linux 2023 (AL2023) поддержка страниц 64 КБ реализована на уровне специализированного ядра. В отличие от некоторых других дистрибутивов, где требуется сложная перекомпиляция, AL2023 предоставляет готовый пакет kernel-64k в своих репозиториях.8 Процесс внедрения сводится к установке пакета и обновлению конфигурации загрузчика grubby.

После установки пакета командой dnf install kernel-64k администратор должен явно указать системе использовать это ядро при следующей загрузке. Проверка текущего режима работы осуществляется командой getconf PAGESIZE, которая должна вернуть значение 65536.8 Важно отметить, что поддержка 64 КБ страниц является особенностью именно ARM-архитектуры в контексте AL2023; для архитектуры x86_64 такая опция в стандартных репозиториях обычно отсутствует или требует специфической конфигурации.11

### **2.3. Оценка метода Mᚖ₁**

| Критерий | Характеристика |
| :---- | :---- |
| **Достоинства** | **Снижение Latency:** Радикальное уменьшение "хвоста" латентности (p99) за счет минимизации промахов TLB.5 **Производительность:** Увеличение пропускной способности памяти и снижение накладных расходов CPU на управление памятью без изменения кода приложения.5 **Простота:** Внедрение через стандартный менеджер пакетов dnf в AL2023.9 |
| **Недостатки** | **Внутренняя фрагментация:** Для очень маленьких файлов (менее 64 КБ) использование полной страницы может привести к потере полезного объема памяти (internal fragmentation).4 **Совместимость:** Некоторые проприетарные драйверы или старые приложения могут жестко зависеть от 4 КБ страниц (хотя для Varnish это неактуально). |
| **Оценка (0-100)** | **95** |

**Вердикт по Mᚖ₁:** Это фундаментальная оптимизация для высоконагруженных инстансов Varnish на Graviton. Выигрыш в производительности подсистемы памяти перевешивает незначительные риски внутренней фрагментации, особенно при работе с большими объемами кэша.

## **Раздел 3. Анализ метода Mᚖ₂: Замена аллокатора памяти на Jemalloc**

### **3.1. Проблематика стандартного аллокатора glibc**

По умолчанию Varnish использует системный аллокатор памяти, предоставляемый библиотекой glibc (malloc). glibc является универсальным аллокатором, оптимизированным для широкого спектра задач, но не для специфических паттернов нагрузки высоконагруженного кэша. В условиях интенсивного создания и удаления объектов разного размера (что типично для HTTP-трафика) glibc склонен к внешней фрагментации памяти.12 Это приводит к явлению, известному как "memory bloat", когда процесс потребляет у операционной системы значительно больше физической памяти (RSS), чем фактически необходимо для хранения данных. В долгосрочной перспективе это может вызвать срабатывание механизма OOM Killer и падение сервиса.14

### **3.2. Преимущества Jemalloc**

jemalloc (Jason Evans' malloc) — это специализированный аллокатор, разработанный с упором на предотвращение фрагментации и масштабируемость в многопоточных средах. Он использует концепцию "арен" (arenas), позволяющую распределять память независимо для разных потоков процессора, что снижает конкуренцию за блокировки (lock contention).12 В контексте Varnish и архитектуры Graviton с большим количеством ядер (например, 64 vCPU на c7g.16xlarge), способность jemalloc эффективно масштабироваться по потокам становится критическим преимуществом. Эмпирические тесты показывают, что при длительной работе под нагрузкой инстансы с jemalloc демонстрируют стабильное потребление памяти, в то время как инстансы с glibc показывают неуклонный рост RSS.13

### **3.3. Интеграция в Amazon Linux 2023**

В AL2023 пакет jemalloc доступен для установки через dnf install jemalloc.16 Однако Varnish не переключается на него автоматически. Для активации необходимо использовать механизм предварительной загрузки библиотек (LD_PRELOAD) или перекомпилировать Varnish (что не рекомендуется при использовании пакетной версии). Наиболее надежный метод — модификация юнита systemd для сервиса Varnish:

Ini, TOML

Environment="LD_PRELOAD=/usr/lib64/libjemalloc.so.2"

Это гарантирует, что символы malloc, free и realloc будут перехвачены библиотекой jemalloc при запуске процесса.16

### **3.4. Оценка метода Mᚖ₂**

| Критерий | Характеристика |
| :---- | :---- |
| **Достоинства** | **Стабильность памяти:** Предотвращение фрагментации и утечек памяти при длительной работе (uptime > месяцев).12 **Интроспекция:** Богатые возможности профилирования памяти для отладки.19 **Масштабируемость:** Лучшая работа на многоядерных процессорах Graviton. |
| **Недостатки** | **Сложность настройки:** Требует явного вмешательства в конфигурацию systemd и понимания путей к библиотекам. **Накладные расходы:** В редких сценариях однопоточной нагрузки может незначительно уступать glibc, но для Varnish это неактуально. |
| **Оценка (0-100)** | **90** |

**Вердикт по Mᚖ₂:** Использование jemalloc является обязательным стандартом ("must-have") для производственных инсталляций Varnish, планируемых к длительной эксплуатации без перезагрузок. Это ключевой фактор стабильности.

## **Раздел 4. Анализ метода Mᚖ₃: Управление транзитным хранилищем (Transient Storage)**

### **4.1. Архитектурная уязвимость Transient Storage**

Varnish разделяет хранилище объектов на основное (обычно задается параметром -s malloc,SIZE) и транзитное (Transient). Транзитное хранилище используется для короткоживущих объектов (время жизни меньше параметра shortlived, по умолчанию 10с) и, что более критично, для объектов, которые по каким-то причинам не могут быть закэшированы, но требуют буферизации для передачи клиенту (например, при стриминге или ожидании тела ответа).20

По умолчанию Varnish использует для транзитного хранилища **неограниченный** аллокатор malloc. Это создает критическую уязвимость: если бэкенд начинает отдавать большие объемы некэшируемых данных, или если из-за ошибки в VCL множество запросов попадают в категорию hit-for-miss (когда решение "не кэшировать" само кэшируется), транзитное хранилище начинает бесконтрольно потреблять оперативную память.22 В условиях ограниченных ресурсов это неизбежно приводит к исчерпанию памяти и аварийному завершению процесса.14

### **4.2. Стратегия ограничения и защиты**

Решение заключается в явном определении и ограничении размера транзитного хранилища при запуске демона varnishd. Использование аргумента -s Transient=malloc,2G устанавливает жесткий лимит (например, 2 ГБ). Если потребность в транзитной памяти превышает этот лимит, Varnish активирует механизм вытеснения (nuke), удаляя старые транзитные объекты, или, в крайнем случае, разрывает соединение, но сохраняет работоспособность самого сервиса.15

Дополнительно, необходимо тщательно настраивать параметры shortlived и логику hit-for-miss в VCL, чтобы минимизировать попадание объектов в транзитную зону. Рекомендуется выделять под основное хранилище около 75-80% доступной RAM, оставляя резерв под транзитное хранилище и нужды ядра ОС.19

### **4.3. Оценка метода Mᚖ₃**

| Критерий | Характеристика |
| :---- | :---- |
| **Достоинства** | **Отказоустойчивость:** Гарантированная защита от OOM (Out of Memory) при всплесках некэшируемого трафика.24 **Предсказуемость:** Четкое разделение ресурсов между долговременным кэшем и временными буферами. |
| **Недостатки** | **Риск сброса соединений:** При слишком жестком лимите возможны ошибки 503 или обрывы соединений для легитимных тяжелых запросов. **Сложность планирования:** Требует точного расчета доступной памяти с учетом накладных расходов на структуры данных (overhead).20 |
| **Оценка (0-100)** | **92** |

**Вердикт по Mᚖ₃:** Явное ограничение Transient хранилища является критически важной мерой безопасности. Отсутствие этого ограничения в продакшене — это "бомба замедленного действия".

## **Раздел 5. Анализ метода Mᚖ₄: Нормализация строк запроса (Query String)**

### **5.1. Проблема загрязнения кэша параметрами**

Эффективность кэширования (Cache Hit Ratio) напрямую зависит от уникальности ключа кэширования. URL с различными параметрами запроса (Query String) воспринимаются Varnish как разные объекты. Маркетинговые метки (utm_source, gclid, fbclid), добавляемые к URL, уникальны для каждого пользователя или перехода, но часто не влияют на генерируемый бэкендом контент. Без нормализации кэш заполняется тысячами дубликатов одной и той же страницы, вытесняя полезные данные и увеличивая нагрузку на бэкенд.25

### **5.2. Сравнительный анализ методов нормализации**

Существует три основных подхода к решению этой проблемы:

1. **VCL Regex (regsuball):** Использование встроенных функций регулярных выражений для удаления параметров.  
   * *Код:* set req.url = regsuball(req.url, "(utm_[a-z]+|gclid)=...", "");  
   * *Анализ:* Гибко, но крайне ресурсоемко. Функция regsuball пересобирает строку при каждом совпадении, что создает высокую нагрузку на CPU при длинных URL и сложных регулярных выражениях.27  
2. **Сортировка (std.querysort):** Встроенная функция модуля std, которая сортирует параметры по алфавиту.  
   * *Код:* set req.url = std.querysort(req.url);  
   * *Анализ:* Решает проблему перестановки параметров (?a=1&b=2 vs ?b=2&a=1), но не удаляет мусорные параметры. Полезна как дополнение, но не как самостоятельное решение.29  
3. **Модуль vmod_querystring:** Специализированный VMOD, написанный на C, для парсинга и фильтрации параметров.  
   * *Анализ:* Обеспечивает наивысшую производительность. Позволяет использовать стратегии "keep-list" (оставить только известные параметры) или "drop-list" (удалить известные мусорные). Работает значительно быстрее регулярных выражений, так как не требует компиляции и исполнения regex-машины для каждого запроса.28

### **5.3. Оценка метода Mᚖ₄ (на примере vmod_querystring)**

| Критерий | Характеристика |
| :---- | :---- |
| **Достоинства** | **Максимальный Hit Ratio:** Устраняет дублирование кэша, существенно разгружая бэкенд. **Производительность CPU:** vmod_querystring минимизирует накладные расходы на процессор по сравнению с regsuball.28 **Безопасность:** Стратегия "белого списка" (whitelist) защищает от атак cache poisoning через неизвестные параметры. |
| **Недостатки** | **Зависимость:** Требует компиляции и установки дополнительного модуля, что усложняет поддержку и обновления Varnish.30 |
| **Оценка (0-100)** | **88** |

**Вердикт по Mᚖ₄:** Для высоконагруженных проектов использование vmod_querystring с белым списком параметров является предпочтительным. Если установка модулей невозможна, следует использовать оптимизированные regex (удаляющие параметры группами), но быть готовым к росту CPU Usage.

## **Раздел 6. Анализ метода Mᚖ₅: Управление заголовками Vary и User-Agent**

### **6.1. Фрагментация по User-Agent**

Заголовок Vary: User-Agent, отправляемый бэкендом, инструктирует Varnish хранить отдельную копию страницы для каждого уникального заголовка User-Agent. Учитывая, что современные браузеры и устройства генерируют тысячи вариаций этой строки (разные версии OS, билды браузера), это приводит к катастрофической фрагментации кэша. Фактически, кэширование становится бесполезным, так как вероятность совпадения User-Agent стремится к нулю.31

### **6.2. Стратегия нормализации (Binning)**

Решение заключается в "нормализации" заголовка User-Agent на уровне vcl_recv перед вычислением хэша запроса. Вместо сохранения полной строки, Varnish анализирует её и заменяет на упрощенный маркер: mobile, tablet или desktop.

Code snippet

if (req.http.User-Agent ~ "Mobile|Android") {  
    set req.http.User-Agent = "mobile";  
} else {  
    set req.http.User-Agent = "desktop";  
}

Более радикальный и эффективный подход для адаптивных сайтов (Responsive Design) — полное удаление заголовка User-Agent из ключа кэширования и удаление Vary: User-Agent из ответа бэкенда.33 Это позволяет отдавать один и тот же кэшированный объект всем пользователям, полагаясь на CSS и JS для адаптации отображения на клиенте.

### **6.3. Оценка метода Mᚖ₅**

| Критерий | Характеристика |
| :---- | :---- |
| **Достоинства** | **Критическое влияние на Hit Ratio:** Без этой меры кэширование динамического контента для мобильных устройств практически не работает. **Экономия памяти:** Хранение одной копии вместо тысяч вариаций. **Простота:** Реализуется стандартными средствами VCL без внешних зависимостей.35 |
| **Недостатки** | **Риск ошибок отображения:** Некорректная нормализация может привести к выдаче десктопной версии сайта на мобильном устройстве, если бэкенд реально зависит от UA (серверный рендеринг).36 |
| **Оценка (0-100)** | **98** |

**Вердикт по Mᚖ₅:** Нормализация User-Agent или полное игнорирование этого заголовка (при адаптивной верстке) является обязательным требованием. Отсутствие этой настройки — одна из самых частых причин низкой эффективности кэша.

## **Раздел 7. Итоговый вердикт и эталонная архитектура**

### **7.1. Сводная оценка методов**

На основании проведенного анализа, методы оптимизации ранжируются следующим образом по степени критичности и влиянию на устранение проблем производительности (P†):

1. **Mᚖ₅ (Header Normalization) — Оценка 98/100.** Без этого кэш просто не работает эффективно. Это логическая основа кэширования.  
2. **Mᚖ₁ (64k Pages on Graviton) — Оценка 95/100.** Фундаментальная аппаратная оптимизация, дающая "бесплатный" прирост производительности и стабильности латентности. Уникальное преимущество платформы AL2023/ARM64.  
3. **Mᚖ₃ (Transient Limits) — Оценка 92/100.** Критически важная страховка от аварий (OOM). Обязательна для стабильности (Availability).  
4. **Mᚖ₂ (Jemalloc) — Оценка 90/100.** Ключ к долговременной стабильности памяти. Обязательна для систем с высоким uptime.  
5. **Mᚖ₄ (Query String Optimization) — Оценка 88/100.** Важна для разгрузки бэкенда, но зависит от специфики трафика.

### **7.2. Эталонная конфигурация (Reference Architecture)**

Для построения высоконагруженной системы Varnish на AWS рекомендуется следующая конфигурация, интегрирующая все проанализированные методы:

* **Инстанс:** Семейство AWS Graviton (например, r7g.xlarge или c7g.2xlarge) для доступа к архитектуре ARMv8.2+.  
* **ОС:** Amazon Linux 2023 с установленным ядром kernel-64k.  
* **Системное окружение:** Активация jemalloc через systemd override (LD_PRELOAD).  
* **Параметры запуска (varnishd):**  
  * Основное хранилище: -s main=malloc,80%_RAM.  
  * Транзитное хранилище: -s Transient=malloc,2G (или 5-10% от RAM, но строго лимитировано).  
* **VCL Логика:**  
  * Использование vmod_querystring для белого списка параметров.  
  * Агрессивная нормализация User-Agent (сведение к 2-3 группам) и удаление Vary: User-Agent из ответов бэкенда.

### **Заключение**

Комплексное применение описанных методов (Mᚖ⠿) позволяет трансформировать Varnish из простого кэширующего прокси в надежную, предсказуемую и экстремально быструю платформу доставки контента. Синергия аппаратных возможностей Graviton (64k pages) и программных оптимизаций (jemalloc, VCL normalization) устраняет узкие места (P†) на всех уровнях: от процессорного конвейера до прикладной логики обработки HTTP-запросов. Игнорирование любого из этих уровней приведет к субоптимальной производительности, тогда как их интеграция гарантирует максимальную отдачу от инвестиций в облачную инфраструктуру.

#### **Works cited**

1. AWS Graviton Processor - Amazon EC2, accessed December 11, 2025, [https://aws.amazon.com/ec2/graviton/](https://aws.amazon.com/ec2/graviton/)  
2. AWS Graviton4-based Amazon EC2 R8g instances: best price performance in Amazon EC2, accessed December 11, 2025, [https://aws.amazon.com/blogs/aws/aws-graviton4-based-amazon-ec2-r8g-instances-best-price-performance-in-amazon-ec2/](https://aws.amazon.com/blogs/aws/aws-graviton4-based-amazon-ec2-r8g-instances-best-price-performance-in-amazon-ec2/)  
3. AWS Graviton4 demonstrates leading performance for HPC - Arm Developer, accessed December 11, 2025, [https://developer.arm.com/community/arm-community-blogs/b/servers-and-cloud-computing-blog/posts/leading-hpc-performance-with-graviton4](https://developer.arm.com/community/arm-community-blogs/b/servers-and-cloud-computing-blog/posts/leading-hpc-performance-with-graviton4)  
4. Overview | Arm Learning Paths, accessed December 11, 2025, [https://learn.arm.com/learning-paths/servers-and-cloud-computing/arm_linux_page_size/overview/](https://learn.arm.com/learning-paths/servers-and-cloud-computing/arm_linux_page_size/overview/)  
5. Improve Performance with 64K Memory Pages on AWS Graviton Processors, accessed December 11, 2025, [https://dev.to/aws-builders/improve-performance-with-64k-memory-pages-on-aws-graviton-processors-ifa](https://dev.to/aws-builders/improve-performance-with-64k-memory-pages-on-aws-graviton-processors-ifa)  
6. AL2023 system requirements - Amazon Linux 2023, accessed December 11, 2025, [https://docs.aws.amazon.com/linux/al2023/ug/system-requirements.html](https://docs.aws.amazon.com/linux/al2023/ug/system-requirements.html)  
7. aws-graviton-getting-started/perfrunbook/optimization_recommendation.md at main - GitHub, accessed December 11, 2025, [https://github.com/aws/aws-graviton-getting-started/blob/main/perfrunbook/optimization_recommendation.md](https://github.com/aws/aws-graviton-getting-started/blob/main/perfrunbook/optimization_recommendation.md)  
8. Install 64k page kernel on ARM64 instances - Ubuntu on AWS documentation, accessed December 11, 2025, [https://documentation.ubuntu.com/aws/aws-how-to/instances/install-64k-kernel/](https://documentation.ubuntu.com/aws/aws-how-to/instances/install-64k-kernel/)  
9. Updating the Linux kernel on AL2023 - AWS Documentation, accessed December 11, 2025, [https://docs.aws.amazon.com/linux/al2023/ug/kernel-update.html](https://docs.aws.amazon.com/linux/al2023/ug/kernel-update.html)  
10. How to get page size programmatically within Linux kernel module code - Stack Overflow, accessed December 11, 2025, [https://stackoverflow.com/questions/4888067/how-to-get-page-size-programmatically-within-linux-kernel-module-code](https://stackoverflow.com/questions/4888067/how-to-get-page-size-programmatically-within-linux-kernel-module-code)  
11. AL2023 kernel changes from AL2 - Amazon Linux 2023 - AWS Documentation, accessed December 11, 2025, [https://docs.aws.amazon.com/linux/al2023/ug/compare-with-al2-kernel.html](https://docs.aws.amazon.com/linux/al2023/ug/compare-with-al2-kernel.html)  
12. jemalloc vs glibc malloc: Memory Allocation Performance Comparison | by Binita Bharati, accessed December 11, 2025, [https://medium.com/@binitabharati/jemalloc-vs-glibc-malloc-memory-allocation-performance-comparison-fbaeda1740de](https://medium.com/@binitabharati/jemalloc-vs-glibc-malloc-memory-allocation-performance-comparison-fbaeda1740de)  
13. CPU and memory usage of jemalloc as compared to glibc malloc - Stack Overflow, accessed December 11, 2025, [https://stackoverflow.com/questions/13027475/cpu-and-memory-usage-of-jemalloc-as-compared-to-glibc-malloc](https://stackoverflow.com/questions/13027475/cpu-and-memory-usage-of-jemalloc-as-compared-to-glibc-malloc)  
14. limit readahead for private objects · Issue #2964 · varnishcache/varnish-cache - GitHub, accessed December 11, 2025, [https://github.com/varnishcache/varnish-cache/issues/2964](https://github.com/varnishcache/varnish-cache/issues/2964)  
15. Varnish Using Significantly More Memory than Cache? - Stack Overflow, accessed December 11, 2025, [https://stackoverflow.com/questions/78379910/varnish-using-significantly-more-memory-than-cache](https://stackoverflow.com/questions/78379910/varnish-using-significantly-more-memory-than-cache)  
16. MariaDB & Amazon Linux 2: ERROR: ld.so: object '/usr/lib64/libjemalloc.so.1' from LD_PRELOAD cannot be preloaded, accessed December 11, 2025, [https://unix.stackexchange.com/questions/677387/mariadb-amazon-linux-2-error-ld-so-object-usr-lib64-libjemalloc-so-1-fro](https://unix.stackexchange.com/questions/677387/mariadb-amazon-linux-2-error-ld-so-object-usr-lib64-libjemalloc-so-1-fro)  
17. Extra Packages for Enterprise Linux (EPEL) - Amazon Linux 2023 - AWS Documentation, accessed December 11, 2025, [https://docs.aws.amazon.com/linux/al2023/ug/epel.html](https://docs.aws.amazon.com/linux/al2023/ug/epel.html)  
18. Limiting process resource usage in AL2023 using systemd - Amazon Linux 2023, accessed December 11, 2025, [https://docs.aws.amazon.com/linux/al2023/ug/resource-limiting-systemd.html](https://docs.aws.amazon.com/linux/al2023/ug/resource-limiting-systemd.html)  
19. Understanding Varnish Cache Memory Usage - Resources, accessed December 11, 2025, [https://info.varnish-software.com/blog/understanding-varnish-cache-memory-usage](https://info.varnish-software.com/blog/understanding-varnish-cache-memory-usage)  
20. Storage backends — Varnish version trunk documentation, accessed December 11, 2025, [https://varnish-cache.org/docs/trunk/users-guide/storage-backends.html](https://varnish-cache.org/docs/trunk/users-guide/storage-backends.html)  
21. Storage backends - malloc - Varnish Cache, accessed December 11, 2025, [https://varnish-cache.org/docs/4.1/users-guide/storage-backends.html](https://varnish-cache.org/docs/4.1/users-guide/storage-backends.html)  
22. Troubleshooting Varnish - Varnish Developer Portal, accessed December 11, 2025, [https://www.varnish-software.com/developers/tutorials/troubleshooting-varnish/](https://www.varnish-software.com/developers/tutorials/troubleshooting-varnish/)  
23. Overuse of Transient storage with hit-for-miss objects · Issue #2654 · varnishcache/varnish-cache - GitHub, accessed December 11, 2025, [https://github.com/varnishcache/varnish-cache/issues/2654](https://github.com/varnishcache/varnish-cache/issues/2654)  
24. Configuring Varnish, accessed December 11, 2025, [https://docs.varnish-software.com/book/operations/configuring-varnish/](https://docs.varnish-software.com/book/operations/configuring-varnish/)  
25. Configuring Varnish for WordPress - Varnish Developer Portal, accessed December 11, 2025, [https://www.varnish-software.com/developers/tutorials/configuring-varnish-wordpress/](https://www.varnish-software.com/developers/tutorials/configuring-varnish-wordpress/)  
26. Example VCL template - Varnish Developer Portal, accessed December 11, 2025, [https://www.varnish-software.com/developers/tutorials/example-vcl-template/](https://www.varnish-software.com/developers/tutorials/example-vcl-template/)  
27. Varnish: what does regsuball do? - Stack Overflow, accessed December 11, 2025, [https://stackoverflow.com/questions/69343718/varnish-what-does-regsuball-do](https://stackoverflow.com/questions/69343718/varnish-what-does-regsuball-do)  
28. Strip query parameters with Varnish | by Danila Vershinin - Medium, accessed December 11, 2025, [https://medium.com/@getpagespeed/strip-query-parameters-with-varnish-bf3cb2877530](https://medium.com/@getpagespeed/strip-query-parameters-with-varnish-bf3cb2877530)  
29. VMOD std - Varnish Standard Module, accessed December 11, 2025, [https://varnish-cache.org/docs/trunk/reference/vmod_std.html](https://varnish-cache.org/docs/trunk/reference/vmod_std.html)  
30. The essential vmods all Varnish users should know about - Resources, accessed December 11, 2025, [https://info.varnish-software.com/blog/essential-vmods-all-varnish-users-should-know-about](https://info.varnish-software.com/blog/essential-vmods-all-varnish-users-should-know-about)  
31. 5 Don'ts When Caching with Varnish - Resources, accessed December 11, 2025, [https://info.varnish-software.com/blog/5-varnish-donts](https://info.varnish-software.com/blog/5-varnish-donts)  
32. Vary — Varnish version 3.0.7 documentation, accessed December 11, 2025, [https://varnish-cache.org/docs/3.0/tutorial/vary.html](https://varnish-cache.org/docs/3.0/tutorial/vary.html)  
33. Best practices for using the Vary header - Fastly, accessed December 11, 2025, [https://www.fastly.com/blog/best-practices-using-vary-header](https://www.fastly.com/blog/best-practices-using-vary-header)  
34. Varnish custom html based on User Agent - Stack Overflow, accessed December 11, 2025, [https://stackoverflow.com/questions/52184292/varnish-custom-html-based-on-user-agent](https://stackoverflow.com/questions/52184292/varnish-custom-html-based-on-user-agent)  
35. Device detection — Varnish version 3.0.7 documentation, accessed December 11, 2025, [https://varnish-cache.org/docs/3.0/tutorial/devicedetection.html](https://varnish-cache.org/docs/3.0/tutorial/devicedetection.html)  
36. A Complete Guide to the Vary HTTP Header - BrowserStack, accessed December 11, 2025, [https://www.browserstack.com/guide/what-is-vary-header](https://www.browserstack.com/guide/what-is-vary-header)