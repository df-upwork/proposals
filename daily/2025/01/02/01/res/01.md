Ниже приведён пошаговый разбор основных причин, почему скрипт обрабатывает данные только для первой («Organization») доменной подсказки, а для остальных подсказок либо ничего не извлекает, либо прерывается с ошибками. После каждой причины даны рекомендации, как это поправить. Этот подход позволит скрипту **доработать** каждую из подсказок (Organization Units, Stakeholders, Strategy и т.д.), корректно **собрать несколько инстансов** для каждой доменной области и избежать проблем с парсингом JSON, лимитами и пр.

---

## 1. JSON‑парсинг ломается из‑за «Extra data» или слишком большого количества данных

### Симптом
В логе `analysis_debug.log` появляется ошибка вида:
```
JSON parsing error: Extra data: line 41 column 1 (char 1712)
Problematic response text: {
  ...
}
```
Это значит, что при парсинге ответа от API модель возвращает либо **дополнительные фрагменты**, либо **несколько JSON‑объектов подряд** (или неаккуратное форматирование), и стандартная функция `json.loads(...)` выбрасывает ошибку «Extra data».

### Решения

1. **Упростить или ужесточить формат вывода от Claude/Anthropic**  
   - В блоке, где формируется `system_prompt` и подсказка «Return a JSON...», пропишите чёткие инструкции, например:  
     ```
     1. Выводи строго один JSON (список объектов / один объект). 
     2. Не добавляй текстовых комментариев и пояснений. 
     3. Не добавляй конструкций ```json ... ``` – выводи голый JSON.
     ```
   - То есть нужно избавиться от любых маркировок кода, от пояснительных предложений.  

2. **Наблюдать за ответом и при необходимости «чистить»**  
   Если модель иногда возвращает «Here is the JSON: …» или «```json { ... } ```», в функции `_process_response` можно аккуратно:
   ```python
   # Удалять ````json ...``` и любые 'Here is a JSON:' до парсинга
   if "```json" in response_text:
       # вырезать всё между ```json и следующими ```
   ```
   Либо проверять регуляркой, если есть несколько JSON-структур.

3. **Мягко обрабатывать множественные объекты**  
   - Если у вас бывают ответы, где по требованию приходит _список JSON_, но модель почему-то даёт несколько блоков подряд, — нужно либо парсить каждый блок (split), либо жёстко останавливать на первой валидной конструкции.  
   - Если предполагается именно список (multi-instance), иногда удобно проверять, нет ли во второй части ответа ещё одного «[ { … } , { … } ]» — и если есть, склеивать/объединять.

4. **Закрывать Prompt токенами**  
   Если часть проблемы — это «слишком длинный ответ» или «лимит», можно уменьшить `max_tokens=4096` до чего-нибудь поменьше (напр. 2048 или 3072), либо уменьшить `temperature`, чтобы минимизировать «болтливость» модели.

---

## 2. «Rate limit error» от Anthropic при обработке следующих подсказок

### Симптом
В логе после первой доменной области (Organization) иногда вылетает ошибка:
```
429 - rate_limit_error
... You may also contact sales at ...
```
Это значит, что объём текста (prompt + response) превышает текущие лимиты тарифа Anthropic, либо было слишком много запросов за минуту.

### Решения

1. **Уменьшить chunk_size**  
   - Сейчас в `_chunk_document` стоит `max_chunk_size=12000`. Если в документе много страниц (например, годовой отчёт на сотни КБ текста), то каждый чанк может быть огромным, особенно если складывать туда ещё и сам prompt.  
   - Снизьте `max_chunk_size` (например, до 5000–8000), чтобы итоговый prompt для каждого запроса был короче, и модель не «съедала» лимит.

2. **Добавить паузы и/или более гибкий backoff**  
   - Обратите внимание: в коде есть `max_retries=3`, и при `anthropic.RateLimitError` включён `time.sleep(delay)`. Но если всё равно слишком много chunk’ов и/или больших запросов, вы можете адаптировать логику retrай:
     ```python
     if attempt < max_retries - 1:
         delay = base_delay * (2 ** attempt)
         time.sleep(delay)
     else:
         raise
     ```
   - При большом документе нужно либо больше «окно» (увеличивать `max_retries`), либо больше `base_delay`, либо договориться о повышении лимита у Anthropic.

3. **Сделать сохранение/логирование промежуточных результатов**  
   - Если «rate limit» случается на середине, скрипт может упасть и ничего не сохранить для оставшихся доменов. Полезно сохранять результаты после каждого обрабатываемого домена (впрочем, у вас уже есть `_save_metamodel` после каждого domain). При перезапуске можно продолжить.  

---

## 3. Скрипт обрабатывает **только** первый domain («Organization»), а остальные игнорируются

### Причины
1. **JSON ошибка** при первом же переходе к «Organization Units» из‑за «Extra data», и скрипт переходит в `except` и не добавляет ничего.  
2. **«Rate limit error»** на третьем domain («Stakeholders»), и далее скрипт не доходит до остальных.  
3. **Неверные настройки `is_multi_instance`**. Если, например, в `All_domain_prompts_short.json` у «Organization Units» есть `extractionAndOutput.instructions` со словом `instance…`, надо убедиться, что условие `if "instance" in prompt['extractionAndOutput']['instructions'].lower():` корректно отрабатывает. Иначе он может работать как single_instance и записывать пустой `{}`.

### Решение
- Исправить JSON парсинг и «rate limit» (см. пункты выше).  
- Убедиться, что во всех подсказках в `All_domain_prompts_short.json` поле `extractionAndOutput.instructions` содержит слово `instance`, если нужна мультивыборка. Тогда код `_merge_instances` сделает несколько объектов, а не один.  
- Проверить, не вылетает ли какая-то скрытая ошибка, которую мы не логируем (посмотрите, нет ли `logger.error` с другим сообщением).  

---

## 4. Множественные инстансы (extract multiple instances) для каждого domain

### Как сделать, чтобы каждый domain мог находить более одного объекта?

1. **В prompts.json**  
   Убедитесь, что там, где нужно несколько инстансов, добавлено упоминание «instances» или слово `instance` в `extractionAndOutput.instructions`. Тогда скрипт установит `is_multi_instance = True`, а в `_process_chunk_with_instances` будет выводиться «Return a LIST of JSON objects…»  
2. **Собирайте `domain_results`** как список  
   - Код внутри `if is_multi_instance: domain_results = [] else: domain_results = {...}`. Проверьте, что у нужных подсказок действительно активируется режим списка.  
3. **Для single-instance** доменов тоже проверяйте, что поле `domain_results` не затирается (у вас есть `_merge_single_instance`).  

---

## 5. Проверить, что результаты **добавляются** в `victoria_police_metamodel.json`

### Совет
- В конце каждой доменной обработки в `analyze_domain` вызывается `_save_metamodel({prompt['type']: domain_results})`. Убедитесь, что:
  1. В `prompt["type"]` у вас уникальные названия — `"Organization"`, `"Organization Units"`, …  
  2. Действительно они пишутся в **общую** `self.metamodel_data`, а затем сериализуются в JSON.  
- Если после всего цикла в метамодели только «Organization», значит остальные домены упали с ошибками (см. пункты выше).

---

## Кратко: что именно предпринять

1. **Уменьшить размер chunk** (параметр `max_chunk_size` ~ от 12000 до 5000–8000).  
2. **Заставить Claude/Anthropic отвечать одним JSON** — корректируйте подсказки (`system_prompt`), вырезайте разметку ```json, убирайте Extra data.  
3. **Добавить логику распознавания, если модель вернула несколько JSON**: разбивать либо брать первый валидный.  
4. **При «Rate limit error»** увеличить задержки (больше `time.sleep`) либо уменьшить загрузку (меньше chunk’ов или покупать лимиты).  
5. **Проверить** правильность `is_multi_instance`, чтобы действительно формировать список объектов для нужных доменов.  
6. **Вести промежуточные логи** и проверять, не прерывается ли код на втором домене (Organization Units) из-за JSONDecodeError. Если да, обрабатывать это аккуратнее (напр., `return []` или всё-таки retry).  

Выполнив эти доработки, вы сможете:
- Устранить проблему «Extra data» в парсинге.
- Не вылетать на лимитах Anthropic, обрабатывая документ и все домены целиком.
- Собирать корректно несколько объектов (instances) по всем подсказкам и сохранять их в `victoria_police_metamodel.json`.