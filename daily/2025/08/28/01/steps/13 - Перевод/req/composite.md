# 1. `B.md`
~~~~~~markdown
# 1. `᛭MDi`
## 1.1.
Каждый отдельный (произвольный, неопределённый) документ в формате Markdown, прикреплённый мной к этому запросу, буду обозначать `᛭Di`.
## 1.2.
Имя файла `᛭Di` всегда имеет расширение `.md`.
## 1.3.
Множество всех `᛭Di` буду обозначать `᛭Ds`.

# 2. `L.md`
### 2.1.
`L.md` ∈ `᛭Ds`.
## 2.2.
`L.md` описывает полуформальный язык: `᛭L`.
## 2.3.
Большинство `᛭Di` написаны на `᛭L`.
## 2.4.
Множество всех `᛭Di`, написанных на `᛭L`, буду обозначать `᛭DLs`.
Таким образом, `᛭DLs` ⊆ `᛭Ds`. 

# 3. `O.md`
## 3.1.
`O.md` ∈ `᛭DLs`
## 3.2.
`O.md` описывает некую **онтологию** (`᛭O`)  — модель предметной области, в которой тебе предстоит решать задачу.
«An **ontology** encompasses a representation, formal naming, and definitions of the categories, properties, and relations between the concepts, data, or entities»: https://en.wikipedia.org/wiki/Ontology_(information_science)

# 4. `T.md`
## 4.1.
`T.md` ∈ `᛭DLs`
## 4.2.
`T.md` описывает задачу (`᛭T`), которую ты должен решить.

# 5. Порядок твоих действий
Действуй пошагово:
## 5.1.
Сначала внимательно и полностью прочитай `L.md`.
В точности запомни его содержание.

## 5.2.
Затем внимательно и полностью прочитай `O.md`. 
В точности запомни его содержание.

## 5.3.
Затем внимательно и полностью прочитай `T.md`. 
Выполни `᛭T`.

~~~~~~

# 2. `L.md`
~~~~~~markdown
# 1. `≔`
## 1.1.
- `≔` — это бинарный оператор.
## 1.2.
`A ≔ B` means that `A` **denotes** `B`.
## 1.3.
Я использую `≔` для сокращения записи.
В выражении `A ≔ B` `B` обычно — это длинный текст, а `A` — это более короткое обозначение.  
## 1.4.
~~~code
A ≔
```
B
```
~~~
равнозначно `A ≔ B` и используется, когда `B` — многострочный текст.

# 2. `→`
~~~code
A → B
~~~
denotes a material conditional (https://en.wikipedia.org/wiki/Material_conditional)

# 3. `⊢`
~~~code
A ⊢ B
~~~
denotes a logical consequence (https://en.wikipedia.org/wiki/Logical_consequence)

# 4. `⊤`
## 4.1.
~~~code
⊤ B
~~~
means that `B` is true (is a fact).

## 4.2.
~~~code
⊤⟦Rs⟧ B
~~~
means:
```
(⊤ `B`) AND (`Rs` are the reasons why `B` is true)
```

## 4.3.
~~~code
A ≔⊤
```
B
```
~~~
means:
```code
(`A` ≔ `B`) AND (⊤ `B`).
```

## 4.4.
~~~code
A ≔⊤⟦Rs⟧
```
B
```
~~~
means:
```code
(`A` ≔ `B`) AND (⊤⟦Rs⟧ B).
```

# 5. `≔!`
## 5.1.
~~~code
A ≔! B
~~~
means:
```code
(`A` ≔⊤ `B`) AND (`B` is surprising).
```

## 5.2.
~~~code
A ≔!⟦Rs⟧ B
~~~
means:
```code
(`A` ≔⊤⟦Rs⟧ `B`) AND (`B` is surprising).
```

# 6. `?`
## 6.1.
~~~code
? B
~~~
means that `B` is a hypothesis.

## 6.2.
~~~code
?⟦Rs⟧ B
~~~
means:
```code
(? `B`) AND (`Rs` are the reasons for the hypothesis)
```

## 6.3.
~~~code
A ≔? B
~~~
means:
```code
(? `B`) AND (`A` ≔ `B`)
```

## 6.4.
~~~code
A ≔?⟦Rs⟧ B
~~~
means:
```code
(?⟦Rs⟧ `B`) AND (`A` ≔ `B`)
```

# 7.
## 7.1.
~~~code
A : S ≔ B
~~~
means:
```code
(`A` ≔ `B`) AND (`A` ∈ `S`).
```

## 7.2.
~~~code
A : S
~~~
means:
```code
`A` : `S` ≔ (an arbitrary element of `S`)
```

# 8. `⠿{…}`
## 8.1. `⠿{I₁, I₂, …, Iₙ}`
`⠿{I₁, I₂, …, Iₙ}` обозначает множество, заданное точным перечислением всех его элементов: {`I₁`, `I₂`, …, `Iₙ`}.

## 8.2. `⠿{I₁-Iₙ}` 
`⠿{I₁-Iₙ}` обозначает множество, заданное интервалом (диапазоном) его значений.
Это множество, в числе прочего, включает границы указанного интервала: `I₁` и `Iₙ`.

# 9. `⠿~`
## 9.1. `⠿~ (D)`
`⠿~ (D)` обозначает множество, заданное неформальным (словесным) описанием его элементов (`D`).

## 9.2.
~~~code
⠿~
```
D
```	
~~~
равнозначно `⠿~ (D)` и используется, когда `D` — многострочный текст.

## 9.3.
~~~code
S ≔ ⠿~ (D)
```yaml
- I₁
- I₂
- …
- Iₙ
```	
~~~
означает: (`S ≔ ⠿~ (D)`) AND (⠿{`I₁`, `I₂`, …, `Iₙ`} ⊆ `S`) .

# 10.
## 10.1.
`᛭DLi` : `᛭DLs`
## 10.2.
### 10.2.1.
`᛭Dc` — это обозначение `᛭DLi` самого себя.
Другими словами, если текст `᛭DLi` содержит упоминание `᛭Dс` — это значит, что `᛭Di` упоминает сам себя. 
### 10.2.2.
Например: если имя файла `᛭Di` — `sample.md`, и текст `sample.md` использует обозначение `᛭Dc`, это значит, что `᛭Dc` в данном случае обозначает документ `sample.md`.  

# 11. `§`
## 11.1.
~~~code
§P
~~~
означает ссылку на пункт `P` `᛭Dc`.
Например, §8.2.2 означает ссылку на пункт 8.2.2 `᛭Dc`.
## 11.2.
~~~code
`᛭DLi`::§P
~~~
означает ссылку на пункт `P` `᛭DLi`.
  
# 12. Local Definitions
## 12.1.
~~~code
A[§P] ≔ B
~~~
Означает:
- Для понятия `B` я **временно**, **только в рамках** §`P`, использую обозначение `A`.
- Вне §`P` это правило не применяется: в частности, если до §`P` обозначение `A` имело другой смысл, то после §`P` обозначение `A` снова будет иметь этот смысл.
- По сути, `A[§P] ≔ B` объявляет **локальную переменную** `A` с **областью действия** §`P`.
- В отличие от `A[§P] ≔ B`, `A ≔ B` объявляет **глобальную переменную** `A`.

## 12.2.
~~~code
A[§P₁, §P₂, …, §Pₙ] ≔ B
~~~
Означает, что обозначение `A` имеет значение `B` в контексте ⠿{§`P₁`, §`P₂`, …, §`Pₙ`}.
По сути, это правило аналогично §12.1, но область действия локальной переменной `A` ограничивается не одним пунктом, а множеством пунктов.

## 12.3.
~~~code
A[§P₁-§Pₙ] ≔ B
~~~
Означает, что обозначение `A` имеет значение `B` в контексте ⠿{§P₁-§Pₙ}.
По сути, это правило аналогично §12.1 и §12.2.

# 13. `≔†`
~~~code
A ≔† B
~~~
means:
```code
(`A` ≔ `B`) AND (`B` is a **problem** to me).
```

# 14. `▶`
```
▶ A
```
означает, что в описываемой мной ситуации я использую `A`.



~~~~~~

# 3. `O.md`
~~~~~~markdown
# 1.
## 1.1.
`UW` ≔ (Upwork: https://en.wikipedia.org/wiki/Upwork)

## 1.2.
`ꆜ` ≔ (Некий конкретный потенциальный клиент на `UW`)

## 1.3.
`P⁎` ≔ (Некий конкретный потенциальный проект, опубликованный `ꆜ` на `UW`)

# 2. Информация о `P⁎`
## 2.1. URL
https://www.upwork.com/jobs/~021960782395149854631

## 2.2. Title
Azure Data Factory pipelines

## 2.3. Description
`PD` ≔ 
```text
I joined a new company last month in the UK. 
I have been tasked to understand why some Azure Data Factory pipelines have not been working. 
Now why am i here? 
I cannot even test the pipeline. 
I wanted to run the pipeline but because it is a parameterised pipeline, i just don't know how to go about it. 
I want someone to look at the pipeline, tell me what it is doing and then show me how to run it or test it. 
Then your job is done. 
Is that something you are happy or can help with?
Thank you
Charles
```

## 2.4. Tags
STUB

# 3. Информация о `ꆜ`
## 3.1. Местоположение
nited Kingdom

## 3.2. Характеристики компании
### 3.2.1. Сектор экономики
неизвестно

### 3.2.2. Количество сотрудников
неизвестно

## 3.3. Характеристики учётной записи на `UW`
### 3.3.1. Member since
STUB
### 3.3.2. Hire rate (%)
 Aug 27, 2025
### 3.3.3. Количество опубликованных проектов (jobs posted)
1
### 3.3.4. Total spent (USD)
0
### 3.3.5. Количество оплаченных часов в почасовых проектах
0

# 4. Другие проекты `ꆜ` на `UW`
отсутствуют

# 5.
`P†` ≔†
```
Проблема, о которой `ꆜ` пишет в `PD`:
~~~
I wanted to run the pipeline but because it is a parameterised pipeline, i just don't know how to go about it
~~~
```

# 6.
## 6.1.
`Ⰰ⠿` ≔? ⠿~ (Возможные причины `P†`)
 
## 6.2.
`Ⰰᵢ` : `Ⰰ⠿`

# 7.
## 7.1. 
`Ⰰ1` : `Ⰰ⠿` ≔ 
```
# Отсутствие контекста и документации по значениям параметров

## Оценка правдоподобности: 95/100

## Доводы за 
Это критическая проблема при работе с унаследованными системами. 
Даже если клиент знает, *как* технически ввести параметр , он не знает, *какое* значение корректно (например, путь к хранилищу, строка подключения, диапазон дат). 
Его запрос — "tell me what it is doing and then show me how to run it" — прямо указывает на отсутствие понимания логики работы конвейера и, следовательно, его входных требований. 
Кроме того, новый сотрудник может опасаться запускать конвейер с неверными данными, чтобы не повредить производственную среду.

## Доводы против 
Если бы для параметров были установлены значения по умолчанию, он мог бы попытаться запустить конвейер с ними. Его заявление подразумевает отсутствие таких значений или недоверие к ним
``` 

## 7.2. 
`Ⰰ2` : `Ⰰ⠿` ≔ 
```
#  Недостаток фундаментальных знаний и опыта работы с ADF

## Оценка правдоподобности: 80/100

## Доводы за 
Клиент прямо заявляет: "i just don't know how to go about it". 
Будучи новым сотрудником (1 месяц в компании), он может быть не знаком с ADF. 
Он может не понимать разницу между режимами запуска ("Debug" и "Trigger Now"), как параметры используются в выражениях (expressions) или как взаимодействовать с панелью ввода параметров.

## Доводы против
Клиент смог найти конвейеры и корректно идентифицировал их как "parameterised pipeline", что предполагает базовое взаимодействие с интерфейсом ADF Studio и понимание того, что именно параметры являются блокером.
``` 

## 7.3. 
`Ⰰ3` : `Ⰰ⠿` ≔ 
```
#  Сложность эмуляции параметров, автоматически предоставляемых триггерами

## Оценка правдоподобности: 75/100

## Доводы за
Производственные конвейеры часто получают параметры автоматически от триггеров (например, Tumbling Window или Storage Event) через системные переменные (например, `@trigger().outputs.windowStartTime` или `@triggerBody().fileName`). 
При ручном тестировании (Debug) пользователь должен эмулировать эти значения самостоятельно. 
Если клиент не знает об этой зависимости и о том, какие данные обычно предоставляет триггер, он не сможет корректно запустить конвейер вручную.

## Доводы против
Не все параметризованные конвейеры зависят от метаданных триггера; они могут использовать только простые конфигурационные параметры (покрывается `Ⰰ1`).
``` 

## 7.4. 
`Ⰰ4` : `Ⰰ⠿`  ≔ 
```
# Сложность типов входных данных (Object/Array)

## Оценка правдоподобности: 60/100

## Доводы за
Если конвейер ожидает параметры типа `Object` или `Array` (часто используется в сложных, управляемых метаданными конвейерах), пользователь должен ввести синтаксически корректный JSON. 
Ошибки в форматировании сложных структур данных в UI являются рас пространенной проблемой для новичков и могут приводить к ошибкам валидации еще до запуска.

## Доводы против
Мы не знаем типы параметров; они могут быть простыми (String, Int). 
Эта проблема часто является частным случаем `Ⰰ1` (незнание формата и значения).
``` 

# 8.
## 8.1.
`ᛝ⠿` ≔? ⠿~ (Возможные заблуждения `ꆜ` относительно `P†`)
 
## 8.2.
`ᛝᵢ` : `ᛝ⠿`

# 9.
## 9.1. 
`ᛝ1` : `ᛝ⠿` ≔ 
```
# Чтобы диагностировать прошлые сбои, необходимо запустить конвейер сейчас.

##
Фокус на немедленном запуске для диагностики исторических проблем игнорирует основной инструмент анализа сбоев в ADF (Monitor) и различия в режимах выполнения.

##
###
Задача клиента — диагностировать *исторические* сбои. 
Стандартным и наиболее эффективным первым шагом в ADF является просмотр журналов выполнения на вкладке «Monitor» (Источник: Microsoft Learn, *Monitor and manage pipelines*). 
Там хранятся точные сообщения об ошибках, входные параметры и статус каждого действия для прошлых запусков.
###
Повторный запуск может не воспроизвести ошибку, если она была вызвана временными условиями (таймауты сети, блокировки БД) или специфическими данными того времени.
###
Существуют критические различия между режимом отладки (Debug) и запуском по триггеру (Triggered run). Они могут использовать разные версии кода (текущая на холсте против опубликованной) и разные контексты безопасности (учетные данные пользователя против Managed Identity ADF). Диагностика производственных сбоев (Triggered runs) путем запуска в Debug может ввести в заблуждение.

##
###
*Воспроизведение сбоя путем запуска конвейера — распространенная техника отладки для проверки исправлений и наблюдения за поведением системы в реальном времени.
###
Некоторые ошибки (например, проблемы производительности или сложные логические ошибки в потоках данных) лучше диагностировать в режиме отладки (Debug).
```  
 
## 9.2. 
`ᛝ2` : `ᛝ⠿` ≔ 
```
# Проблема внутренняя (логика/параметры), а не внешняя (среда))

##
Игнорирование внешних факторов является критической ошибкой при диагностике сбоев в ADF.

##
###
Конвейеры ADF сильно зависят от внешних систем. 
Значительная часть сбоев связана с инфраструктурой и безопасностью, особенно в унаследованных средах (Источник: Microsoft Learn, *Troubleshoot pipeline orchestration and execution*):

1.  **Аутентификация и Авторизация:** Истекшие учетные данные или ключи в Linked Services, некорректная настройка Managed Identity, отсутствие доступа к Azure Key Vault или целевым хранилищам.
2.  **Сетевые проблемы:** Конфигурация брандмауэров (Azure Storage, SQL DB), VNet, Private Endpoints, блокирующие доступ.
3.  **Integration Runtime (IR):** Проблемы с доступностью, конфигурацией или производительностью Self-Hosted IR.

###
Поскольку клиент является новым сотрудником, вероятность проблем, связанных с конфигурацией среды и доступом, значительно возрастает.

##
Некоторые сбои действительно вызваны ошибками в логике конвейера (например, некорректные выражения или маппинги) или неправильной обработкой параметров.
```   

~~~~~~

# 4. `T.md`
~~~~~~markdown
# 1.
## 1.1. 
`L_SOURCE` ≔ (Русский язык)

## 1.2. 
`L_TARGET` ≔ (English)

# 2.
## 2.1.
`D` ≔ (мой ответ `ꆜ`)

## 2.2.
Содержание `D`:
~~~markdown
1) Для диагностики прошлых сбоев Azure Data Factory предоставляет функциональность повторного запуска («Rerun») на вкладке «Monitor».
Эта функциональность позволяет перезапустить pipeline с использованием точных исторических параметров и конфигурации (Snapshot), которые использовались во время сбойного запуска.
Это часто является самым приоритетным способом проверки временных проблем (e.g., таймауты сети) или воспроизведения сбоя.
Этот этап, наряду с анализом журналов, я описываю в разделе 4 ниже.
Если же требуется запустить pipeline с новыми параметрами (e.g., для тестирования исправлений или обработки новых данных), то необходимо понимать логику его работы и требования к входным данным.
Это я описываю в разделах 7-10 ниже.
2) Вашим вероятным упущением является сужение области поиска источника сбоя до проблемного pipeline.
На самом же деле, значительная часть сбоев pipeline связана с внешними причинами: инфраструктурой и безопасностью, особенно в унаследованных средах.
В частности:
- Аутентификация и Авторизация: истекшие учетные данные или ключи в Linked Services, некорректная настройка Managed Identity, отсутствие доступа к Azure Key Vault или целевым хранилищам.
- Сетевые проблемы: конфигурация брандмауэров (Azure Storage, SQL DB), VNet, Private Endpoints, блокирующие доступ.
- Integration Runtime (IR): проблемы с доступностью, конфигурацией или производительностью Self-Hosted IR.

Игнорирование внешних факторов является критической ошибкой при диагностике сбоев в Azure Data Factory.
Анализ внешних факторов — следующий по приоритетности этап диагностики сбоев после анализа журналов.
Я описываю его в разделе 5 ниже.

3) Самое же главное, с чего вообще надо начать подобную диагностику — определенить конфигурацию Source Control и режима работы Azure Data Factory.
Проще говоря, надо понять, как управляются версии кода (versioning) и как соотносятся версия на холсте («Author» canvas) и опубликованная (Published) версия, которая используется в производственных запусках.
Это критически важно для корректной диагностики исторических сбоев (Раздел 3) и анализа текущей логики (Раздел 5).
Для этого надо проверить конфигурацию Git:
3.1) Перейти на вкладку «Manage» на левой боковой панели.
3.2) Перейти в раздел «Source control» → «Git configuration» или проверить наличие элементов управления Git (e.g., селектор веток) на верхней панели ADF Studio.
3.3) Определить режим работы ADF.
3.3.1) `Live Mode` (Authoring directly against the data factory service): Если интеграция с Git не настроена.
В этом режиме изменения на холсте («Author» canvas) можно сохранить с помощью кнопок «Save» или «Save all».
Эти сохраненные изменения доступны для запусков в режиме отладки («Debug» runs).
Однако эти изменения не активируются для запусков по триггеру («Triggered» runs) до момента их публикации непосредственно в службу Data Factory с помощью кнопки «Publish all».
Только опубликованная версия является версией, используемой в «Triggered» runs.
3.3.2) `Git Mode` (e.g., Azure DevOps Git или GitHub): Если конфигурация указывает на репозиторий.
В этом режиме изменения на холсте («Author» canvas) сохраняются в выбранной ветке Git (e.g., feature branch) с помощью «Save» или «Save all».
Эти изменения не применяются к производственной службе (и не используются в «Triggered» runs) до момента публикации («Publish») из Collaboration branch.

4) Анализ журналов
4.1) Перейти в Azure Data Factory Studio.
4.2) Открыть вкладку «Monitor» на левой боковой панели.
4.3) В разделе «Pipeline runs» изучить список предыдущих выполнений целевого конвейера.
Использовать фильтры по имени конвейера («Pipeline name») и статусу (Status, например, «Failed»), чтобы найти интересующие запуски.
Убедиться, что анализируются запуски типа «Triggered».
Запуски типа «Triggered» являются производственными запусками и всегда используют ту версию конвейера, которая была опубликована (Published) в службе Azure Data Factory на момент запуска.
Это соответствует опубликованной версии в `Live Mode` (пункт 3.3.1 выше) или версии, опубликованной из Collaboration branch в `Git Mode` (пункт 3.3.2).
Запуски типа «Debug» используют текущую версию конвейера на холсте разработки («Author» canvas).
В `Git Mode` это версия из текущей выбранной ветки.
В `Live Mode` это текущая версия на холсте, которая может содержать неопубликованные изменения.
4.4) Проанализировать детали сбойного запуска.
4.4.1) Кликнуть на имя конвейера в списке, чтобы перейти к списку «Activity runs» (выполнения действий).
4.4.2) Идентифицировать действие (activity), которое завершилось сбоем.
4.4.3) Изучить детальное сообщение об ошибке. 
Для этого кликнуть на иконку в колонке «Error» для этого activity.
4.4.4) Изучить входные параметры, которые были использованы при этом запуске.
Для этого найти колонку «Parameters» (на уровне Pipeline run или в верхней части экрана Activity runs) и посмотреть значения, которые были фактически переданы в конвейер.
4.5) Выполнить повторный запуск («Rerun») сбойного выполнения.
Цель: Проверить, была ли причина сбоя временной (e.g., таймаут сети, недоступность ресурса) или она является постоянной (e.g., ошибка конфигурации, логики или данных).
Функциональность «Rerun» использует те же самые входные параметры (п. 4.4.4) и ту же самую конфигурацию pipeline (Snapshot, см. п. 4.6), которые использовались в оригинальном запуске.
4.5.1) Повторный запуск с начала pipeline.
Находясь в списке «Pipeline runs» (п. 4.3), навести курсор на сбойный запуск и нажать кнопку «Rerun».
4.5.2) Повторный запуск с неудавшегося действия («Rerun from failed activity»).
Это предпочтительный вариант для многошаговых конвейеров, позволяющий пропустить успешно завершенные шаги и начать выполнение непосредственно с действия, которое завершилось сбоем.
Находясь в представлении «Activity runs» (п. 4.4.1), использовать опцию «Rerun from failed activity» (на верхней панели) или «Rerun from activity» (для конкретного действия).
4.5.3) Проанализировать результат повторного запуска.
Если повторный запуск успешен, вероятно, причина оригинального сбоя была временной.
Если повторный запуск также завершается сбоем с той же ошибкой, это указывает на постоянную проблему, требующую дальнейшего анализа (начиная с п. 4.6).
4.6) Проанализировать снимок (Snapshot) конфигурации конвейера, использованный во время сбойного запуска.
Цель: Увидеть точную конфигурацию и код, которые привели к сбою, так как текущая версия конвейера может отличаться.
4.6.1) Находясь в представлении «Activity runs» (пункт 4.4.1), найти возможность просмотра кода конвейера.
Обычно это иконка с всплывающей подсказкой «Code» (в виде фигурных скобок), расположенная на верхней панели рядом с названием конвейера.
4.6.2) Изучить JSON-определение (JSON definition) конвейера и связанных ресурсов (e.g., Datasets) в том виде, в котором они существовали на момент этого конкретного запуска.

5) Анализ внешних факторов
5.1) Перейти на вкладку «Manage» на левой боковой панели.
5.2) Проверить Linked Services:
5.2.1) Перейти в раздел «Linked services».
5.2.2) Идентифицировать все Linked Services, используемые в целевом конвейере (их можно найти в настройках Datasets или Activities).
5.2.3) Для каждого Linked Service открыть его конфигурацию и использовать функцию «Test connection».
Это позволит проверить базовую возможность подключения к ресурсу из соответствующего Integration Runtime.
Важное примечание:
Функция «Test connection» выполняется не в контексте вашей учетной записи пользователя.
Она выполняется на инфраструктуре Integration Runtime (Azure IR или Self-Hosted IR), указанного в Linked Service.
Она использует учетные данные, определенные в конфигурации Linked Service (e.g., Managed Identity, Service Principal, Account Key).
Успешный «Test connection» не гарантирует работоспособность во время выполнения pipeline (Pipeline run) по следующим причинам:
5.2.3.1) Сетевые различия.
Могут существовать различия в сетевой конфигурации между интерактивным тестированием и автоматическим выполнением.
Это особенно актуально при использовании Self-Hosted IR, Virtual Networks (VNet) или Private Endpoints.
Правила брандмауэров (Firewall rules), Network Security Groups (NSG) или маршрутизация могут отличаться, блокируя доступ во время выполнения.
5.2.3.2) Недостаточные разрешения.
Успешный тест проверяет только возможность аутентификации и сетевого подключения.
Он не гарантирует наличие разрешений для выполнения конкретных операций с данными (e.g., чтение таблицы, выполнение Stored Procedure), требуемых в Pipeline (см. пункт 5.2.5).
5.2.4) Определить метод аутентификации (Authentication method), используемый в Linked Service (например, System-Assigned Managed Identity, Service Principal, Account Key, SQL Authentication).
5.2.5) Верифицировать права доступа субъекта безопасности ADF.
Необходимо проверить разрешения на двух различных уровнях, так как успешная аутентификация не означает наличие необходимой авторизации для доступа к данным.
5.2.5.1) Уровень Azure RBAC (Role-Based Access Control).
Если используется Managed Identity или Service Principal, необходимо убедиться, что этому субъекту назначены необходимые роли Azure RBAC для доступа к данным (Data Plane) на целевом ресурсе.
E.g., роль «Storage Blob Data Contributor» для Azure Storage.
Эта проверка выполняется вне ADF Studio, в настройках «Access Control (IAM)» целевого ресурса на портале Azure.
5.2.5.2) Уровень внутренних разрешений целевой системы (Data Store Permissions).
Для систем, таких как Azure SQL Database и SQL Pools в Azure Synapse Analytics, стандартный Azure RBAC (упомянутый в п. 5.2.5.1) не управляет детальным доступом к объектам внутри базы данных (Data Plane).
Даже если аутентификация происходит через Microsoft Entra ID (Azure AD), авторизация управляется через разрешения T-SQL.
Необходимо убедиться, что субъект безопасности имеет необходимые разрешения внутри целевой системы.
Субъект безопасности (e.g., Managed Identity) должен быть добавлен как пользователь базы данных (database user), например, с использованием `CREATE USER […] FROM EXTERNAL PROVIDER`.
Этому пользователю должны быть назначены соответствующие роли базы данных (e.g., `db_datareader`, `db_datawriter`) или предоставлены прямые разрешения (GRANT).
Если pipeline выполняет Stored Procedures, пользователю также требуется разрешение `EXECUTE`.
Эта проверка выполняется путем подключения к базе данных с использованием инструментов управления (e.g., SQL Server Management Studio (SSMS) или Azure Data Studio).
5.3) Проверить Integration Runtimes:
5.3.1) Перейти в раздел «Integration runtimes».
5.3.2) Проверить статус Integration Runtimes, используемых в Linked Services. 
Убедиться, что они находятся в состоянии «Running», особенно если используются Self-Hosted Integration Runtimes.

6) Синтез результатов диагностики и определение причин исторических сбоев
Цель: Выполнить вашу стратегическую задачу — определить, почему конвейеры не работали в прошлом, на основе собранных данных.
6.1) Сопоставить детальные сообщения об ошибках (раздел 4) с результатами проверки среды (раздел 5).
Детальные сообщения об ошибках из исторических запусков  являются первичным источником для диагностики прошлых сбоев.
Необходимо учитывать временной контекст при интерпретации результатов текущей проверки среды.
Результаты «Test connection» или статуса IR отражают текущее состояние системы.
Это состояние могло измениться с момента исторического сбоя (e.g., обновление истекших учетных данных, изменение сетевых правил).
Нельзя полагаться исключительно на текущее состояние для диагностики прошлых проблем.
6.1.1) Если историческая ошибка указывает на проблемы с подключением (e.g., «Authentication failed», «Connection timed out»), и текущий «Test connection» также завершается неудачей, вероятно, существует постоянная проблема конфигурации инфраструктуры или безопасности.
6.1.2) Если историческая ошибка указывает на проблемы с подключением, но текущий «Test connection» (п. 2.2.3) успешен, это может указывать на то, что проблема была временной (e.g., таймаут сети, недоступность ресурса) или что конфигурация среды была исправлена с момента сбоя.
6.2) Проанализировать входные параметры, использованные при сбойных запусках. 
Определить, могли ли сбои быть вызваны некорректными или неожиданными данными, переданными в конвейер (например, неверный формат даты, несуществующий путь).
6.3) Идентифицировать паттерны сбоев. 
Являются ли сбои постоянными (часто указывает на проблему конфигурации или доступа) или периодическими/случайными (часто указывает на проблемы производительности, блокировки ресурсов или зависимость от специфических данных).
6.4) Сформулировать выводы о корневой причине (Root Cause) исторических сбоев и классифицировать её (например: аутентификация, сеть, логика конвейера, качество данных).

7) Идентификация и анализ pipeline parameters
7.1) Перейти на вкладку «Author» на левой боковой панели для анализа текущей разрабатываемой версии конвейера.
7.1.1) Если фабрика работает в `Git Mode`, убедиться, что в селекторе веток выбрана корректная ветка для анализа (обычно Collaboration branch или актуальная feature branch).
7.1.2) Если фабрика работает в `Live Mode`, проверить наличие индикатора неопубликованных изменений (e.g., активность кнопки «Publish All»).
7.2) Найти и открыть целевой конвейер.
Важное примечание: Необходимо учитывать, что эта версия на холсте может отличаться от опубликованной версии, которая анализировалась в разделе 4.
7.3) Кликнуть на пустую область холста (canvas) конвейера, чтобы отобразить его общие настройки.
7.4) Перейти на вкладку «Parameters». 
Составить список всех параметров, зафиксировав их «Name», «Type» (например, `String`, `Int`, `Array`, `Object`, `SecureString`) и «Default value» (значение по умолчанию), если оно указано.
Знание типа данных критично, особенно для сложных типов (`Array`, `Object`).
7.5) Изучить, как параметры используются внутри конвейера (Parameter Usage Analysis).
Цель: Проследить поток данных от параметров конвейера до конечных ресурсов (Linked Services, Datasets, Activities) для понимания динамической конфигурации.
7.5.1) Анализ использования в Activities.
7.5.1.1) Выбрать каждое activity на холсте (например, Copy activity, Lookup, Data Flow).
7.5.1.2) Проверить вкладки настроек (например, «Settings», «Source», «Sink») на предмет использования динамического содержимого (dynamic content).
7.5.1.3) Идентифицировать выражения (expressions), которые ссылаются на параметры конвейера напрямую, используя синтаксис `@pipeline().parameters.<parameterName>`.
7.5.2) Анализ использования в Datasets.
Многие Activities (e.g., Copy, Lookup, Data Flow) используют Datasets для определения источника (Source) и приемника (Sink).
Конвейер может передавать свои параметры в параметры Dataset.
7.5.2.1) Для каждого activity, использующего Dataset (см. п. 7.5.1), проверить конфигурацию Source или Sink.
7.5.2.2) Идентифицировать значения, передаваемые в «Dataset properties» (или «Parameters» в зависимости от типа Activity).
Определить, являются ли эти значения статическими или динамическими выражениями, ссылающимися на параметры конвейера.
7.5.2.3) Открыть конфигурацию соответствующего Dataset (кнопка «Open»).
7.5.2.4) В Dataset перейти на вкладку «Parameters», чтобы увидеть список параметров, которые он ожидает.
7.5.2.5) В Dataset перейти на вкладку «Connection».
Изучить, как параметры Dataset используются для динамической конфигурации свойств (e.g., `File path`, `Table name`), используя синтаксис `@dataset().<datasetParameterName>`.
7.5.3) Анализ использования в Linked Services.
Datasets используют Linked Services для подключения к хранилищам данных.
Dataset может передавать свои параметры в параметры Linked Service.
7.5.3.1) В конфигурации Dataset (вкладка «Connection», п. 7.5.2.5), изучить раздел «Linked service properties».
Идентифицировать значения, передаваемые в параметры Linked Service.
Определить, ссылаются ли они на параметры Dataset.
7.5.3.2) Открыть конфигурацию соответствующего Linked Service (перейти в «Manage» → «Linked services» или использовать редактирование из Dataset).
7.5.3.3) В Linked Service изучить раздел «Parameters».
7.5.3.4) Изучить, как параметры Linked Service используются в строке подключения (`Connection string`), URL или других свойствах подключения (e.g., `Database name`, `Secret name` для Azure Key Vault), используя синтаксис `@linkedService().<linkedServiceParameterName>`.
7.6) Сравнить текущую версию конвейера со снимком исторического запуска.
Цель: Идентифицировать расхождения между кодом, который вызвал сбой, и кодом, доступным для анализа и тестирования.
7.6.1) Получить JSON-представление текущей версии конвейера.
Для этого использовать кнопку «Code» (в виде фигурных скобок) на верхней панели вкладки «Author».
7.6.2) Сопоставить это JSON-представление с JSON-конфигурацией из снимка исторического запуска (п. 4.5.2).
7.6.3) Идентифицировать любые различия в логике, структуре, expressions или конфигурации activities и parameters.
7.6.4) Если различия существуют, дальнейший анализ логики (п. 7.5) и тестовый запуск (раздел 10 ниже) должны учитывать эти различия.

8) Идентификация parameter sources
Цель: Определить, как конвейер получает параметры в производственной среде (через Triggers или от родительского конвейера через `Execute Pipeline` activity), чтобы эмулировать эти значения при ручном тестировании.
8.1.1) Находясь в редакторе конвейера (вкладка «Author»), нажать кнопку «Trigger» на верхней панели и выбрать «New/Edit».
8.1.2) В открывшейся панели изучить конфигурацию существующих триггеров, связанных с этим конвейером.
8.2) Изучить параметры, передаваемые триггером.
8.2.1) Продвигаясь по конфигурации триггера, обратить внимание на шаг, где заполняются параметры конвейера.
8.2.2) Идентифицировать использование системных переменных (System Variables). 
Это выражения, начинающиеся с `@trigger()` или `@triggerBody()`. 
Примеры:
- `@trigger().outputs.windowStartTime` (для Tumbling Window Trigger).
- `@triggerBody().fileName` (для Storage Event Trigger).

Производственные конвейеры часто получают метаданные (например, временные метки или имена файлов) автоматически от триггеров через System Variables. 
При ручном тестировании (Debug) пользователь должен эмулировать эти значения самостоятельно. 
Незнание этой зависимости является частой причиной проблем с ручным запуском.
8.3) Проанализировать родительские конвейеры (Parent Pipelines) и `Execute Pipeline` activity.
Цель: Определить, вызывается ли целевой конвейер другим конвейером и какие параметры при этом передаются.
8.3.1) Идентифицировать Parent Pipelines.
8.3.1.1) Находясь в редакторе целевого конвейера (вкладка «Author»), открыть панель свойств конвейера (иконка «Properties»).
8.3.1.2) Перейти на вкладку «Related».
8.3.1.3) В разделе «Pipelines» изучить список конвейеров, которые ссылаются на текущий (используют `Execute Pipeline` activity для его вызова).
8.3.1.4) В качестве альтернативы или для перепроверки использовать глобальный поиск (Global Search) в Azure Data Factory Studio по имени целевого конвейера.
8.3.2) Изучить конфигурацию `Execute Pipeline` activity в Parent Pipeline.
Для каждого Parent Pipeline, идентифицированного в п. 8.3.1:
8.3.2.1) Открыть Parent Pipeline на вкладке «Author».
8.3.2.2) Найти `Execute Pipeline` activity, которое вызывает целевой конвейер.
8.3.2.3) Выбрать это activity и перейти на вкладку «Settings».
8.3.2.4) В разделе «Parameters» изучить, какие значения или выражения (dynamic content) передаются в параметры целевого конвейера.
8.3.3) Определить источники значений в Parent Pipeline.
Значения могут быть статическими, производными от параметров Parent Pipeline (e.g., `@pipeline().parameters.<ParentParameterName>`), переменных (variables) или выходов (Outputs) предыдущих activities (e.g., `@activity('<ActivityName>').output.<PropertyName>`).
8.4) Определить значения для тестирования.
Использовать комбинацию значений из исторических запусков (раздел 4), значений по умолчанию (пункт 7.4), эмулированных значений триггеров (пункт 8.2.2) и значений, передаваемых из Parent Pipelines (пункт 8.3.3) для формирования набора тестовых входных данных.

9) Обеспечение безопасности тестового запуска (Safety Check)
Цель: Предотвратить случайное повреждение, модификацию, удаление или дублирование производственных данных при запуске унаследованного конвейера.
Обоснование: 
Запуск конвейера без полного понимания его логики и конфигурации приемников данных (Sinks) несет критические риски для целостности данных.
9.1) Активировать сессию «Data Flow Debug» (если применимо).
Цель: Обеспечить среду выполнения Spark для `Data Flow` activities во время отладки и интерактивного анализа.
9.1.1) Определить, содержит ли конвейер действия типа `Data Flow activity`.
9.1.2) Если `Data Flow activity` присутствуют, для их выполнения в режиме «Debug» (раздел 10) или использования «Data Preview» (п. 9.4.2.1) требуется активная сессия отладки.
9.1.3) На верхней панели инструментов (toolbar) ADF Studio активировать переключатель «Data Flow Debug».
9.1.4) Выбрать конфигурацию `Integration Runtime` и установить `Time to live` (TTL).
9.1.5) Дождаться готовности кластера (индикатор статуса станет зеленым).
Запуск кластера (cold boot) может занять несколько минут.
9.2) Идентифицировать операции модификации данных и приемники (Sinks).
Проанализировать все действия (Activities) в конвейере, которые потенциально могут изменять данные во внешних системах:
9.2.1) `Copy activity` (изучить вкладку «Sink»).
9.2.2) `Data Flow` (изучить все Sinks внутри потока данных).
9.2.3) `Stored Procedure activity` и `Script activity` (могут выполнять DML/DDL операции: INSERT, UPDATE, DELETE, TRUNCATE).
9.2.4) `Delete activity`.
9.2.5) `Web`, `Webhook`, `Custom activities` (если они вызывают API для модификации данных).

9.3) Проанализировать целевые системы.
Для каждого действия из пунктов раздела 9.2 определить, куда именно будут записываться или где будут удаляться данные.
Изучить конфигурацию целевых Datasets и Linked Services. 
Определить, указывают ли они на производственные (Production) системы.

9.4) Применить стратегию безопасного запуска.
Если конвейер может повлиять на производственные данные, необходимо применить одну или несколько мер безопасности. 
Методы приведены в порядке предпочтения.

9.4.1) Стратегия 1: Перенаправление записи в безопасное место (Наиболее надежный метод).
9.4.1.1) Через параметры: Если конфигурация приемника (путь, имя таблицы, строка подключения) параметризована (см. раздел 3), убедиться, что при запуске (раздел 10) будут использованы значения, указывающие на тестовую среду (например, папка `test`, схема `dev`).
9.4.1.2) Через временное изменение конфигурации: Если параметры не используются, временно изменить настройки Datasets или Linked Services, чтобы они указывали на тестовую среду. 
Важно: Не сохранять и не публиковать (Publish) эти изменения.

9.4.2) Стратегия 2: Использование механизмов изоляции и контроля.
9.4.2.1) Для `Data Flow` activities: Использовать «Data Preview» для инспекции данных.
Это требует активной сессии «Data Flow Debug» (пункт 9.1).
В редакторе `Data Flow` выбрать transformation, непосредственно предшествующую `Sink`.
Перейти на вкладку «Data Preview» и нажать «Refresh», чтобы получить интерактивный снимок (interactive snapshot) данных.
Это позволяет проверить логику трансформаций без записи данных в целевую систему.
Критическое примечание о Pipeline Debug Run:
Существует фундаментальное различие между интерактивной отладкой («Data Preview») и запуском конвейера в режиме «Debug» (раздел 10).
Утверждение о том, что данные не записываются в `Sink`, справедливо только для «Data Preview» внутри редактора `Data Flow`.
При запуске всего конвейера в режиме «Debug», `Data Flow activity` будет выполнять запись в `Sink` transformations.
Поэтому для предотвращения записи при запуске конвейера необходимо использовать другие стратегии (например, п. 9.4.1 или 9.4.2.2).
9.4.2.2) Для Activities на холсте: Использовать точки останова (Breakpoints) для итеративной отладки (Iterative Debugging).
Установить точку останова на действии (activity), перед выполнением которого необходимо приостановить конвейер.
Для этого кликнуть на пустой красный кружок в правом верхнем углу activity (опция «Debug Until»).
Кружок изменится на заполненный красный кружок (filled red circle).
При запуске в режиме «Debug» конвейер выполнится только до activity с точкой останова.
Само activity с точкой останова (breakpoint activity) не включается в тестовый запуск.
Это позволяет проверить промежуточные результаты и входные данные (Input) предшествующих действий перед выполнением потенциально опасных операций.
9.4.2.3) Деактивация действий: Если анализ записи данных не является целью теста, временно деактивировать (кнопка «Deactivate» на верхней панели) действия, выполняющие модификацию.

9.4.3) Стратегия 3: Минимизация воздействия (Использовать с осторожностью).
9.4.3.1) Ограничение объема данных.
Применить методы ограничения количества обрабатываемых строк, специфичные для типа действия.
9.4.3.1.1) Для `Data Flow` activities: Открыть «Debug Settings» на панели инструментов холста `Data Flow`.
Установить «Row limit» на малое значение (e.g., 100-1000).
Эта настройка ограничивает количество строк, считываемых из источников (`Sources`) только для текущей debug session.
Это требует активной сессии «Data Flow Debug» (пункт. 9.1).
9.4.3.1.2) Для `Copy activity` и `Lookup activity`: Настройка «Row limit» из п. 9.4.3.1.1 не применяется.
Необходимо временно модифицировать конфигурацию источника (Source).
E.g., если источником является база данных SQL, модифицировать запрос (Query), добавив `TOP N` или `LIMIT` (e.g., `SELECT TOP 100 * FROM schema.table`).
Предупреждение:
Ограничение объема данных ограничивает чтение из источника, но не обеспечивает полной безопасности, если конвейер выполняет операции, не зависящие от объема данных (e.g., `TRUNCATE TABLE` через «Pre-copy script» или удаление файлов через `Delete activity`).

9.5) Условие отмены запуска (Go/No-Go Decision).
Если ни один из методов п. 9.4 не может гарантировать безопасность производственных данных, не выполнять запуск (раздел 10). 
В этом случае требуется клонирование (Clone) и модификация конвейера для тестирования в изолированной среде.

10) Test Run
Цель: Запустить конвейер с корректными параметрами в контролируемом режиме и проверить его работоспособность.
10.1) Находясь на вкладке «Author» в редакторе целевого конвейера, выбрать стратегию запуска и начать выполнение в режиме отладки («Debug»).
Обоснование:
Режим «Debug» используется для тестирования текущей версии конвейера на холсте (включая неопубликованные изменения) и позволяет наблюдать за выполнением в реальном времени без необходимости публикации (Publish).
10.1.1) Выбор стратегии: Итеративная отладка (Iterative Debugging) или Полный запуск.
Для сложных или унаследованных конвейеров рекомендуется использовать итеративную отладку для пошагового и более безопасного анализа.
10.1.2) Для итеративной отладки («Debug Until»): Убедиться, что установлены точки останова (Breakpoints) (раздел 9).
Нажать кнопку «Debug».
Конвейер выполнится только до первого activity с точкой останова.
10.1.3) Для полного запуска: Убедиться, что точки останова не установлены (или будут проигнорированы, если требуется выполнить конвейер целиком несмотря на них).
Нажать кнопку «Debug».
10.2) В открывшейся панели (обычно называется «Pipeline Debug» или «Pipeline run parameters») ввести значения для параметров, определённые в разделе 8.
10.3) Соблюдать корректный формат ввода данных:
10.3.1) При эмуляции временных меток триггера использовать формат ISO 8601 (например, `2025-08-27T10:00:00Z`).
10.3.2) Для параметров типа `Array` ввести значение в формате JSON массива. 
Например: `["item1", "item2"]`.
10.3.3) Для параметров типа Object ввести значение в формате JSON объекта. 
Например: `{"key1": "value1", "key2": "value2"}`.
Обоснование: Корректный ввод параметров, особенно сложных типов (`Array`, `Object`), необходим для успешного запуска. 
Неправильный формат JSON приведет к ошибкам валидации еще до начала выполнения.
10.4) Нажать «OK», чтобы начать выполнение.
10.5) Наблюдать за ходом выполнения на вкладке «Output» под холстом конвейера. 
Проверить входные (Input) и выходные (Output) данные для каждого Activity после его завершения, чтобы убедиться, что параметры были интерпретированы корректно.
~~~

# 3.
## 3.1.
`D2` ≔ (начальная часть `D`, переведённая с `L_SOURCE` на `L_TARGET`)

## 3.2.
Содержание `D2`:
~~~markdown
1) To diagnose past failures, Azure Data Factory provides the «Rerun» functionality on the «Monitor» tab.
This functionality allows to rerun the pipeline using the exact historical parameters and configuration (Snapshot) that were used during the failed run.
This is often the highest-priority method for verifying transient issues (e.g., network timeouts) or reproducing the failure.
I describe this step, along with log analysis, in section 4 below.
However, if it is necessary to run the pipeline with new parameters (e.g., for testing fixes or processing new data), then it is necessary to understand its logic and input data requirements.
I describe this in sections 7-10 below.
2) Your likely oversight is narrowing the scope of the failure investigation to the problematic pipeline.
In fact, a significant portion of pipeline failures is caused by external factors: infrastructure and security, especially in legacy environments.
In particular:
- Authentication and Authorization: expired credentials or keys in Linked Services, incorrect configuration of Managed Identity, lack of access to Azure Key Vault or target data stores.
- Network issues: configuration of firewalls (Azure Storage, SQL DB), VNet, Private Endpoints, blocking access.
- Integration Runtime (IR): issues with availability, configuration, or performance of Self-Hosted IR.

Ignoring external factors is a critical mistake when diagnosing failures in Azure Data Factory.
Analysis of external factors is the next highest-priority diagnostic step after log analysis.
I describe it in section 5 below.

3) First and foremost, any such diagnosis must begin by determining the Source Control configuration and operational mode of Azure Data Factory.
Simply put, it is necessary to understand how code versions (versioning) are managed and how the version on the «Author» canvas relates to the published (Published) version, which is used in production runs.
This is critically important for the correct diagnosis of historical failures (Section 3) and the analysis of the current logic (Section 5).
For this, it is necessary to check the Git configuration:
3.1) Navigate to the «Manage» tab on the left side panel.
3.2) Go to «Source control» → «Git configuration» or check for Git controls (e.g., the branch selector) on the top bar of ADF Studio.
3.3) Determine the ADF operating mode.
3.3.1) `Live Mode` (Authoring directly against the data factory service): If Git integration is not configured.
In this mode, changes on the «Author» canvas can be saved using the Save or Save all buttons.
These saved changes are available for «Debug» runs.
However, these changes are not activated for «Triggered» runs until they are published directly to the Data Factory service using the «Publish all» button.
Only the published version is the version used in «Triggered» runs.
3.3.2) `Git Mode` (e.g., Azure DevOps Git or GitHub): If the configuration points to a repository.
In this mode, changes on the «Author» canvas are saved to the selected Git branch (e.g., feature branch) using «Save» or «Save all».
These changes are not applied to the production service (and are not used in «Triggered» runs) until they are published («Publish») from the Collaboration branch.
4) Analysis of logs
4.1) Navigate to Azure Data Factory Studio.
4.2) Open the «Monitor» tab on the left side panel.
4.3) In the «Pipeline runs» section, review the list of previous runs of the target pipeline.
Use the filters by pipeline name («Pipeline name») and status (Status, e.g., «Failed») to find the runs of interest.
Ensure that «Triggered» runs are analyzed.
«Triggered» runs are production runs and always use the version of the pipeline that was published (Published) in the Azure Data Factory service at the time of the run.
This corresponds to the published version in `Live Mode` (point 3.3.1 above) or the version published from the Collaboration branch in `Git Mode` (point 3.3.2).
«Debug» runs use the current version of the pipeline on the «Author» canvas.
In `Git Mode` this is the version from the currently selected branch.
In `Live Mode` this is the current version on the canvas, which may contain unpublished changes.
4.4) Analyze the details of the failed run.
4.4.1) Click on the pipeline name in the list to navigate to the «Activity runs» list.
4.4.2) Identify the activity that failed.
4.4.3) Examine the detailed error message.
To do this, click on the icon in the «Error» column for this activity.
4.4.4) Examine the input parameters that were used for this run.
To do this, find the «Parameters» column (at the Pipeline run level or at the top of the Activity runs screen) and review the values that were actually passed to the pipeline.
4.5) Execute a rerun («Rerun») of the failed execution.
Objective: To verify whether the cause of the failure was transient (e.g., network timeout, resource unavailability) or it is persistent (e.g., a configuration, logic, or data error).
The «Rerun» functionality uses the same input parameters (point 4.4.4) and the same pipeline configuration (Snapshot, see point 4.6) that were used in the original run.
4.5.1) Rerun from the start of the pipeline.
In the «Pipeline runs» list (point 4.3), hover the cursor over the failed run and click the «Rerun» button.
4.5.2) Rerunning from the failed activity («Rerun from failed activity»).
This is the preferred option for multi-step pipelines, allowing to skip successfully completed steps and start execution directly from the activity that failed.
In the «Activity runs» view (point 4.4.1), use the «Rerun from failed activity» option (on the top panel) or «Rerun from activity» (for a specific activity).
4.5.3) Analyze the result of the rerun.
If the rerun is successful, it is likely that the cause of the original failure was transient.
If the rerun also fails with the same error, this indicates a persistent problem that requires further analysis (starting from point 4.6).
4.6) Analyze the Snapshot of the pipeline configuration that was used during the failed run.
Objective: To see the exact configuration and code that led to the failure, as the current version of the pipeline may differ.
4.6) Analyze the snapshot (Snapshot) of the pipeline configuration used during the failed run.
Objective: To see the exact configuration and code that led to the failure, as the current version of the pipeline may differ.
4.6.1) In the «Activity runs» view (point 4.4.1), find the option to view the pipeline code.
This is typically an icon with the «Code» tooltip (in the form of curly braces), located on the top bar next to the pipeline name.
4.6.2) Examine the JSON definition of the pipeline and related resources (e.g., Datasets) as they existed at the time of that specific run.
5) Analysis of external factors
5.1) Navigate to the «Manage» tab on the left side panel.
5.2) Check Linked Services:
5.2.1) Go to the «Linked services» section.
5.2.2) Identify all Linked Services used in the target pipeline (they can be found in the settings of Datasets or Activities).
5.2.3) For each Linked Service, open its configuration and use the «Test connection» function.
This will make it possible to verify the basic connectivity to the resource from the corresponding Integration Runtime.
Important note:
The «Test connection» functionality is not executed in the context of the user account.
It is executed on the Integration Runtime (Azure IR or Self-Hosted IR) specified in the Linked Service.
It uses the credentials defined in the Linked Service configuration (e.g., Managed Identity, Service Principal, Account Key).
A successful «Test connection» does not guarantee a successful pipeline execution (Pipeline run) for the following reasons:
5.2.3.1) Network differences.
There may be differences in the network configuration between interactive testing and automated execution.
This is especially relevant when using Self-Hosted IR, Virtual Networks (VNet) or Private Endpoints.
Firewall rules, Network Security Groups (NSG) or routing may differ, blocking access during execution.
5.2.3.2) Insufficient permissions.
A successful test verifies only authentication and network connectivity.
It does not guarantee the permissions required to perform specific data operations (e.g., reading a table, executing a Stored Procedure) in the Pipeline (see point 5.2.5).
5.2.4) Identify the authentication method (Authentication method) used in the Linked Service (e.g., System-Assigned Managed Identity, Service Principal, Account Key, SQL Authentication).
5.2.5) Verify the permissions of the ADF security principal.
It is necessary to check permissions at two different levels, as successful authentication does not mean the presence of the necessary authorization for data access.
5.2.5.1) Azure RBAC (Role-Based Access Control) level.
If Managed Identity or Service Principal is used, it is necessary to verify that this security principal is assigned the necessary Azure RBAC roles for data access (Data Plane) on the target resource.
E.g., the «Storage Blob Data Contributor» role for Azure Storage.
This verification is performed outside of ADF Studio, in the «Access Control (IAM)» settings of the target resource on the Azure portal.
5.2.5.2) Level of internal permissions of the target system (Data Store Permissions).
For systems such as Azure SQL Database and SQL Pools in Azure Synapse Analytics, standard Azure RBAC (mentioned in point 5.2.5.1) does not manage granular access to objects within the database (Data Plane).
Even if authentication is handled by Microsoft Entra ID (Azure AD), authorization is controlled by T-SQL permissions.
It is necessary to ensure that the security principal has the necessary permissions within the target system.
The security principal (e.g., Managed Identity) must be added as a database user, e.g., using `CREATE USER […] FROM EXTERNAL PROVIDER`.
This user must be assigned the appropriate database roles (e.g., `db_datareader`, `db_datawriter`) or granted direct permissions (GRANT).
If the pipeline executes Stored Procedures, the user also requires the `EXECUTE` permission.
This check is performed by connecting to the database using management tools (e.g., SQL Server Management Studio (SSMS) or Azure Data Studio).
5.3) Check Integration Runtimes:
5.3.1) Navigate to the «Integration runtimes» section.
5.3.2) Check the status of the Integration Runtimes used in Linked Services.
Ensure that they are in the «Running» state, especially if Self-Hosted Integration Runtimes are used.
6) Synthesis of diagnostic results and identification of the causes of historical failures
Objective: To accomplish your strategic task — to determine why the pipelines did not work in the past, based on the collected data.
6.1) Correlate the detailed error messages (section 4) with the results of the environment check (section 5).
Detailed error messages from historical runs are the primary source for diagnosing past failures.
It is necessary to consider the temporal context when interpreting the results of the current environment check.
The results of the «Test connection» or the IR status reflect the current state of the system.
This state could have changed since the historical failure (e.g., updating expired credentials, changing network rules).
It is not possible to rely solely on the current state to diagnose past problems.
6.1.1) If the historical error indicates connection problems (e.g., «Authentication failed», «Connection timed out»), and the current «Test connection» also fails, it is likely that a persistent infrastructure or security configuration problem exists.
6.1.2) If the historical error indicates connection problems, but the current «Test connection» (point 2.2.3) is successful, this may indicate that the problem was transient (e.g., network timeout, resource unavailability) or that the environment configuration has been corrected since the failure.
6.2) Analyze the input parameters used in the failed runs.
Determine if the failures could have been caused by incorrect or unexpected data passed to the pipeline (e.g., an incorrect date format, a non-existent path).
6.3) Identify failure patterns.
Determine whether the failures are persistent (often indicating a configuration or access issue) or intermittent/random (often indicating performance issues, resource locking, or a dependency on specific data).
6.4) Formulate conclusions about the root cause (Root Cause) of historical failures and classify it (e.g., authentication, network, pipeline logic, data quality).
7) Identification and analysis of pipeline parameters
7.1) Navigate to the «Author» tab on the left side panel to analyze the current development version of the pipeline.
7.1.1) If the factory is operating in `Git Mode`, ensure that the correct branch is selected for analysis in the branch selector (usually the Collaboration branch or the relevant feature branch).
7.1.2) If the factory is operating in `Live Mode`, check for an indicator of unpublished changes (e.g., the activity of the «Publish All» button).
7.2) Find and open the target pipeline.
Important note: It is necessary to consider that this version on the canvas may differ from the published version which was analyzed in section 4.
7.3) Click on the empty area of the pipeline canvas to display its general settings.
7.4) Navigate to the «Parameters» tab.
Compile a list of all parameters, recording their «Name», «Type» (e.g., `String`, `Int`, `Array`, `Object`, `SecureString`), and «Default value», if specified.
Knowing the data type is critical, especially for complex types (`Array`, `Object`).
7.5) Examine how parameters are used inside the pipeline (Parameter Usage Analysis).
Objective: To trace the data flow from pipeline parameters to the end resources (Linked Services, Datasets, Activities) to understand the dynamic configuration.
7.5.1) Analysis of usage in Activities.
7.5.1.1) Select each activity on the canvas (e.g., Copy activity, Lookup, Data Flow).
7.5.1.2) Check the settings tabs (e.g., «Settings», «Source», «Sink») for the use of dynamic content.
7.5.1.3) Identify the expressions that directly reference pipeline parameters, using the syntax `@pipeline().parameters.<parameterName>`.
7.5.2) Analysis of usage in Datasets.
Many Activities (e.g., Copy, Lookup, Data Flow) use Datasets to define the source (Source) and the sink (Sink).
The pipeline can pass its parameters to Dataset parameters.
7.5.2.1) For each activity that uses a Dataset (see point 7.5.1), check the Source or Sink configuration.
7.5.2.2) Identify the values passed to «Dataset properties» (or «Parameters» depending on the Activity type).
Determine whether these values are static or dynamic expressions referencing the pipeline parameters.
7.5.2.3) Open the configuration of the corresponding Dataset (the «Open» button).
7.5.2.4) In the Dataset, navigate to the «Parameters» tab to see the list of parameters that it expects.
7.5.2.5) In the Dataset, navigate to the «Connection» tab.
Examine how the Dataset parameters are used for the dynamic configuration of properties (e.g., `File path`, `Table name`), using the syntax `@dataset().<datasetParameterName>`.
7.5.3) Analysis of usage in Linked Services.
Datasets use Linked Services to connect to data stores.
A Dataset can pass its parameters to the parameters of a Linked Service.
7.5.3.1) In the Dataset configuration (the «Connection» tab, point 7.5.2.5), examine the «Linked service properties» section.
Identify the values passed to the Linked Service parameters.
Determine if they reference the Dataset parameters.
7.5.3.2) Open the configuration of the corresponding Linked Service (go to «Manage» → «Linked services» or use the edit option from the Dataset).
7.5.3.3) In the Linked Service, examine the «Parameters» section.
Examine how the Linked Service parameters are used in the connection string (`Connection string`), URL or other connection properties (e.g., `Database name`, `Secret name` for Azure Key Vault), using the syntax `@linkedService().<linkedServiceParameterName>`.
7.6) Compare the current pipeline version with the snapshot of the historical run.
Objective: To identify discrepancies between the code that caused the failure and the code available for analysis and testing.
7.6.1) Obtain the JSON representation of the current pipeline version.
To do this, use the «Code» button (in the form of curly braces) on the top bar of the «Author» tab..
7.6.2) Compare this JSON representation with the JSON configuration from the snapshot of the historical run (point 4.5.2).
7.6.3) Identify any differences in the logic, structure, expressions, or configuration of activities and parameters.
7.6.4) If differences exist, the further analysis of the logic (point 7.5) and the test run (section 10 below) must account for these differences.
8) Identification of parameter sources
Objective: To determine how the pipeline receives parameters in the production environment (via Triggers or from a parent pipeline through the `Execute Pipeline` activity) in order to emulate these values during manual testing.
8.1.1) In the pipeline editor (the «Author» tab), click the «Trigger» button on the top bar and select «New/Edit».
8.1.2) In the opened panel, examine the configuration of existing triggers associated with this pipeline.
8.2) Examine the parameters passed by the trigger.
8.2.1) While proceeding through the trigger configuration, pay attention to the step where the pipeline parameters are filled in.
8.2.2) Identify the use of system variables (System Variables).
These are expressions that start with `@trigger()` or `@triggerBody()`.
E.g.:
- `@trigger().outputs.windowStartTime` (for Tumbling Window Trigger).
- `@triggerBody().fileName` (for Storage Event Trigger).

Production pipelines often receive metadata (e.g., timestamps or file names) automatically from triggers via System Variables.
During manual testing (Debug), it is necessary to emulate these values manually.
Unawareness of this dependency is a common cause of issues with manual runs.
8.3) Analyze Parent Pipelines and the `Execute Pipeline` activity.
Objective: To determine whether the target pipeline is called by another pipeline and what parameters are passed.
8.3.1) Identify Parent Pipelines.
8.3.1.1) While in the target pipeline editor (the «Author» tab), open the pipeline properties pane (the «Properties» icon).
8.3.1.2) Navigate to the «Related» tab.
8.3.1.3) In the «Pipelines» section, examine the list of pipelines that reference the current one (they use the `Execute Pipeline` activity to call it).
8.3.1.4) As an alternative or for re-verification, use the Global Search in Azure Data Factory Studio by the name of the target pipeline.
8.3.2) Examine the configuration of the `Execute Pipeline` activity in the Parent Pipeline.
For each Parent Pipeline identified in point 8.3.1:
8.3.2.1) Open the Parent Pipeline on the «Author» tab.
8.3.2.2) Find the `Execute Pipeline` activity that calls the target pipeline.
8.3.2.3) Select this activity and navigate to the «Settings» tab.
8.3.2.4) In the «Parameters» section, examine what values or expressions (dynamic content) are passed to the parameters of the target pipeline.
8.3.3) Determine the sources of the values in the Parent Pipeline.
Values can be static, derived from Parent Pipeline parameters (e.g., `@pipeline().parameters.<ParentParameterName>`), variables, or the Outputs of preceding activities (e.g., `@activity('<ActivityName>').output.<PropertyName>`).
8.4) Determine the values for testing.
Use a combination of values from historical runs (section 4), default values (point 7.4), emulated trigger values (point 8.2.2), and values passed from Parent Pipelines (point 8.3.3) to form a set of test input data.
9) Ensuring a Safe Test Run (Safety Check)
Objective: To prevent accidental damage, modification, deletion, or duplication of production data when running the legacy pipeline.
Rationale: Running the pipeline without a full understanding of its logic and the configuration of its data Sinks poses critical risks to data integrity.
9.1) Activate the «Data Flow Debug» session (if applicable).
Objective: To ensure a Spark execution environment for `Data Flow` activities during debugging and interactive analysis.
9.1.1) Determine if the pipeline contains `Data Flow` activities.
9.1.2) If `Data Flow activity` are present, an active debug session is required for their execution in «Debug» mode (section 10) or for using «Data Preview» (point 9.4.2.1).
9.1.3) On the top toolbar of ADF Studio, activate the «Data Flow Debug» switch.
9.1.4) Select the `Integration Runtime` configuration and set the `Time to live` (TTL).
9.1.5) Wait for the cluster to be ready (the status indicator will turn green).
The cluster startup (cold boot) may take several minutes.
9.2) To identify data modification operations and Sinks.
To analyze all Activities in the pipeline that can potentially modify data in external systems:
9.2.1) `Copy activity` (to examine the «Sink» tab).
9.2.2) `Data Flow` (to examine all Sinks inside the data flow).
9.2.3) Stored Procedure activity and Script activity (can perform DML/DDL operations: `INSERT`, `UPDATE`, `DELETE`, `TRUNCATE`).
9.2.4) Delete activity.
9.2.5) Web, Webhook, Custom activities (if they call an API to modify data).
9.3) To analyze target systems.
To determine for each activity from the points of section 9.2 where exactly data will be written or deleted.
To examine the configuration of the target Datasets and Linked Services. 
To determine whether they point to production (Production) systems.
9.4) Apply a safe run strategy.
If the pipeline can affect production data, it is necessary to apply one or more safety measures.
The methods are listed in order of preference.
9.4.1) Strategy 1: Redirecting writes to a safe location (The most reliable method).
9.4.1.1) Via parameters: If the Sink configuration (path, table name, connection string) is parameterized (see section 3), ensure that during the run (section 10) values pointing to a test environment (e.g., a `test` folder, a `dev` schema) are used.
9.4.1.2) Through temporary configuration change: If parameters are not used, temporarily change the settings of Datasets or Linked Services to point to a test environment.
Important: Do not save and do not publish (Publish) these changes.
9.4.2) Strategy 2: Use of isolation and control mechanisms.
9.4.2.1) For `Data Flow` activities: Use «Data Preview» for data inspection.
This requires an active «Data Flow Debug» session (point 9.1).
In the Data Flow editor, select the transformation immediately preceding the Sink.
Navigate to the «Data Preview» tab and click «Refresh» to obtain an interactive snapshot of the data.
This makes it possible to verify the transformation logic without writing data to the target system.
Critical note about Pipeline Debug Run:
There is a fundamental difference between interactive debugging («Data Preview») and running the pipeline in «Debug» mode (section 10).
The statement that data are not written to the Sink is true only for «Data Preview» inside the Data Flow editor.
When running the entire pipeline in «Debug» mode, the Data Flow activity will perform writes to Sink transformations.
Therefore, to prevent writes when running the pipeline, it is necessary to use other strategies (e.g., points 9.4.1 or 9.4.2.2).
9.4.2.2) For Activities on the canvas: Use Breakpoints for Iterative Debugging.
Set a breakpoint on an activity to pause the pipeline before its execution.
To do this, click on the empty red circle in the upper-right corner of the activity (the «Debug Until» option).
The circle will change to a filled red circle.
When running in «Debug» mode, the pipeline will execute only up to the activity with the breakpoint.
The breakpoint activity itself is not included in the test run.
This makes it possible to check the intermediate results and input data (Input) of the preceding activities before executing potentially dangerous operations.
9.4.2.3) Deactivating activities: If the analysis of data writes is not the objective of the test, temporarily deactivate (the «Deactivate» button on the top bar) the activities that perform modifications.
9.4.3) Strategy 3: Minimization of impact (Use with caution).
9.4.3.1) Limitation of data volume.
To apply methods for limiting the number of processed rows, specific to the activity type.
9.4.3.1.1) For `Data Flow` activities: To open «Debug Settings» on the `Data Flow` canvas toolbar.
Set the «Row limit» to a small value (e.g., 100-1000).
This setting limits the number of rows read from the sources (`Sources`) only for the current debug session.
This requires an active «Data Flow Debug» session (point 9.1).
9.4.3.1.2) For `Copy activity` and `Lookup activity`: The «Row limit» setting from point 9.4.3.1.1 does not apply.
It is necessary to temporarily modify the source (Source) configuration.
E.g., if the source is an SQL database, modify the query (Query) by adding `TOP N` or `LIMIT` (e.g., `SELECT TOP 100 * FROM schema.table`).
Warning:
Limiting the data volume limits reading from the source, but does not ensure complete safety if the pipeline performs operations that do not depend on the data volume (e.g., `TRUNCATE TABLE` via the «Pre-copy script» or deleting files via the `Delete activity`).
9.5) Run Cancellation Condition (Go/No-Go Decision).
If none of the methods in point 9.4 can guarantee the safety of production data, do not execute the run (section 10).
In this case, it is necessary to clone (Clone) and modify the pipeline for testing in an isolated environment.
~~~

# 4.
## 4.1.
`F` ≔ (фрагмент `D`)

## 4.2.
Содержание `F`:
~~~markdown
10.5) Наблюдать за ходом выполнения на вкладке «Output» под холстом конвейера. 
Проверить входные (Input) и выходные (Output) данные для каждого Activity после его завершения, чтобы убедиться, что параметры были интерпретированы корректно.
~~~

# 5. `᛭T`
Переведи `F` на `L_TARGET`, с учётом:
- контекста `D`
- `D2`: уже переведённой части `D`
- `᛭O`

# 6. Правила перевода
## 6.1.
Переводи именно в той стилистике, как написано на `L_SOURCE`.
Не делай перевод более вежливым, чем оригинал.

## 6.2.
Те предложения, которые сейчас полностью на `L_TARGET` — оставь без изменения.

## 6.3.
### 6.3.1.
Не используй Markdown: только plain text.
### 6.3.2.
При этом можно и нужно использовать то форматирование, которое уже есть в оригинале: его не убирай.
### 6.3.3.
Не форматируй веб-ссылки посредством Markdown, если они не отформатированы так в оригинале. 
Например, не пиши так:
```
[https://www.eca.web.tr/eca-nita-esnek-uclu-eviye-bataryasi-beyaz-102118110-308](https://www.eca.web.tr/eca-nita-esnek-uclu-eviye-bataryasi-beyaz-102118110-308)
```
если в оригинале скобок `[]()` нет.

## 6.4.
Форматируй перевод в точности как оригинал. 
В частности:
*) каждый абзац должен содержать ровно одно предложение
*) между абзацами не должно оставаться пустых строк.
*) кавычки используй те же, что и в оригинале: «» и ``.

## 6.5.
Не используй сокращения типа «don't». Все подобные фразы пиши полностью: «do not».

## 6.6.
Не используй жаргон.
Вместо этого используй официальные термины.
### 6.6.1.
В частности, фразы в кавычках используй только в том случае, когда они являются точными цитатами.
Не используй фразы в кавычках для применения жаргонных фраз.
Например, следующий фрагмент текста недопустим, потому что там используется жаргонная фраза «пролетел»: 
```
Например, код, который пушит данные о покупке, подключён асинхронно и загружается с небольшой задержкой, а триггер уже «пролетел».
```

## 6.7.
При обсуждении программного обеспечения используй точные официальные термины на английском языке: именно в том виде, как они указаны в официальной англоязычной документации к этому программному обеспечению.

## 6.8.
Не используй «you need» и другие подобные обращённые к клиенту фразы, перекладывающие действия на него.
Помни: я пишу клиенту или потенциальному клиенту.
Делать в любом случае буду я, а не клиент.
Вместо «you need» используй 2 альтернативы:
### 6.8.1.
Нейтральные фразы типа «it is necessary».
### 6.8.2.
Глаголы в неопределённой форме.
Например, во фрагменте ниже использованы подобные глаголы «set up», «create»:
```
1.2) Set up the transfer of login events from WordPress to Power BI using Fabric / OneLake.
1.2.1) Set up a «Data Pipeline» from the WordPress database table that stores login events (see point 1.1) to Fabric / OneLake.
1.2.2) Set up a connection from Power BI to Fabric / OneLake to pass login events.
1.3) Create the data model in Power BI.
```
Обрати внимание, в этом фрагменте не говорится, кто именно будет выполнять описанные действия: ответственность не перекладывается на клиента, в отличие от «you need».

## 6.9.
Никогда не переводи понятие «сайт» / «веб-сайт» как «site». 
Вместо этого используй форму «website»: это является более профессиональным.

## 6.10.
Никогда не переводи понятие «пункт нумерованного списка» как «item».
Всегда переводи это как «point».

## 6.11.
Вместо «for example» используй «e.g.».
При этом не забывай, что в начале предложения эта фраза должна начинатся с заглавной буквы: «E.g.»
~~~~~~