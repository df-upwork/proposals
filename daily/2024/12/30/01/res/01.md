**Короткий ответ**  
Да, в первом пункте **нет противоречий** с точки зрения того, как обычно решают задачу комбинирования возможностей универсальной модели и узкоспециализированной экспертизы.  

**Подробный ответ**  
1. **Задача сочетания общей (универсальной) и узкой (доменной) экспертизы**.  
   - Современные LLM (ChatGPT, Claude, PaLM и т.д.) действительно обучены на больших корпусах текстов, но их знание специфических, узких доменов (например, юридической базы конкретной страны или какой-то отрасли) может быть неполным или устаревшим.  
   - Поэтому, если требуется точность на уровне конкретных документов, законов, регламентов и т.д., то одной «чистой» LLM часто недостаточно.  

2. **Подход «одна сторона – универсальная модель, другая – точные знания»**.  
   - Описанная в пункте 1 идея о том, что модель должна сочетать «общие знания» и «узкие знания», лежит в основе многих современных архитектур чатботов, включая RAG (Retrieval Augmented Generation), о котором идёт речь далее в пункте 2.  
   - В случае с юридической системой (как вы упомянули), особенно важно, чтобы у бота был доступ к актуальным базам правовых норм и конкретным кейсам, которых «голая» LLM может попросту не знать.  

3. **Практика разработки**.  
   - В реальных проектах по созданию чатботов с юридической специализацией (или любым другим узким доменом) часто именно так и делают:  
     1) Используют «большую» LLM (например, GPT-4) как движок понимания языка и генерации текста.  
     2) Снабжают её актуальной и узкоспециализированной информацией через механизмы RAG или иные схемы «донаучивания» (fine-tuning, few-shot prompting, retrieval из векторной БД и т.д.).  

Таким образом, **пункт 1** отражает реальную логику построения подобных систем: вы берёте стандартную LLM и дополняете её внешними знаниями, чтобы преодолеть ограниченность модели в специфической области. С технической точки зрения это корректное описание проблемы и её базового подхода к решению.