Альтернативы действительно существуют — как для задачи клиента (интеграция чатбота в Magento), так и для юридической системы. Упомянутая в пункте 2 Retrieval Augmented Generation (RAG) — наиболее «прицельно» решает задачу дополнения LLM узкоспециализированным или свежим контентом, **но** это не единственный возможный вариант. Ниже перечислены основные альтернативы:

---

## 1. Fine-tuning (дообучение) существующих LLM
- **Суть**: Взять уже обученную большую модель (например, GPT-3.5, GPT-4 или Claude) и дообучить её (fine-tune) на ваших собственных данных.  
- **Плюсы**:  
  - Позволяет «вшить» доменные знания в саму модель.  
  - Запросы не требуют сложного retrieval-процесса.  
  - При правильном объёме данных качество может быть очень высоким.  
- **Минусы**:  
  - Стоимость и технические требования могут быть высокими (особенно для крупных LLM).  
  - «Вшитые» данные могут устаревать, и придётся периодически дообучать.  
  - Имеются определённые ограничения (например, у OpenAI для GPT-3.5/GPT-4 есть процесс модерации для fine-tuning, да и не все модели допускают гибкое дообучение).  

**Применимость для клиента (чатбот для B2B в Magento)**  
- Fine-tuning уместен, если объём специфического материала (FAQ, документация, базы знаний) достаточно большой и относительно стабильный.  
- Если информация быстро меняется (например, новые товары, акции), придётся обновлять модель.

**Применимость для юридической системы (пункт 1)**  
- Можно «зашить» законодательные акты, комментарии экспертов, судебную практику и т.д.  
- Но при изменениях в законодательстве потребуется обновление модели — это может быть дорого и сложно.  

---

## 2. Knowledge Graph + LLM
- **Суть**: Строится семантическая сеть (знаний), где факты (узлы) и связи (рёбра) описывают бизнес-процессы, законы и т.д. LLM обращается к этой сети через вопросы (SPARQL или иной query language), получает «короткие» точные ответы и затем формирует развернутый текст.  
- **Плюсы**:  
  - Возможность хранить жёстко структурированные факты.  
  - Удобно для сложных предметных областей, например, с иерархическими определениями, правовым анализом и т.п.  
- **Минусы**:  
  - Построение и поддержка графа могут оказаться нетривиальными (требуется чёткая онтология).  
  - Сложность реализации: нужен отдельный слой (обычно сервер, хранящий KG) и «прокладка» для LLM.  

**Применимость для клиента**  
- Если требуется очень формализованное хранение бизнес-логики (например, каталог товаров с большим количеством параметров), Knowledge Graph может помочь. Но обычно для e-commerce всё же проще (и дешевле) RAG или fine-tuning.  

**Применимость для юридической системы**  
- Идеально подходит, если нужно моделировать сложные правовые связи.  
- Но создание графа потребует больших трудозатрат для классификации и формализации законов.

---

## 3. Символьные (rule-based) эксперты + LLM
- **Суть**: Классические «экспертные системы», в которых правила (if-then) и логика определены вручную. LLM занимается «человеко-понятной» выдачей, а движок правил проверяет соответствие строгим критериям.  
- **Плюсы**:  
  - Высочайший уровень точности для алгоритмических/юридических сценариев, где нарушать правила нельзя.  
  - Легко объяснять решения: «сработало правило X».  
- **Минусы**:  
  - Сложно писать правила на все возможные кейсы, особенно если тематика обширная.  
  - При изменениях в законодательстве/бизнес-процессах нужно постоянно обновлять систему правил.

**Применимость для клиента**  
- Для типовых кейсов (например, жёстких правил возврата товара, гарантий, прайсингов) может быть удобно. Но обычно хотят более гибкую систему.  

**Применимость для юридической системы**  
- Часто применяется в юриспруденции для формализации норм («от 0 до 100 МРОТ — штраф», «если истёк срок исковой давности — отклонить»).  
- Но не все правовые ситуации можно выразить правилами.  

---

## 4. Использовать LLM с длинным контекстом (Long context)  
- **Суть**: Некоторые модели (например, Claude 2, GPT-4 32k) поддерживают расширенный контекст (десятки тысяч токенов), куда можно «прямо» загрузить большие фрагменты документации без отдельной Retrieval-логики.  
- **Плюсы**:  
  - Проще в реализации: не нужно создавать векторную БД, retriever, pipeline.  
  - Быстрое прототипирование.  
- **Минусы**:  
  - При очень большом количестве информации (выше 50–100 страниц текста) контекст может «лопнуть».  
  - Дороже в плане токенов и может быть не столь эффективно, как RAG.  

**Применимость для клиента**  
- Если объём данных невелик или их можно порционно подгружать.  
- Но для B2B e-commerce обычно нужны много данных: каталоги, различные условия, история заказов, — поэтому такой подход быстро вырастет в цене.

**Применимость для юридической системы**  
- Если объём нормативных актов невелик или анализируется отдельный участок права.  
- Может выручить как быстрое решение, но для крупной системы, где тысячи страниц законов, всё же придётся «дробить» и использовать retrieval.

---

## 5. Гибридные подходы
На практике часто комбинируют:
- Fine-tuning + RAG (модель дообучена на «скелете» знаний, а редкие и свежие данные подгружаются через retrieval).  
- Knowledge Graph + RAG + LLM (когда часть данных более формализована, а часть — в виде текстов).  

---

### Итог
- **RAG** остаётся одним из (но далеко не единственным) способов эффективно «подмешивать» специфические знания к LLM без жёсткого дообучения.  
- **Fine-tuning** (или «Instruct Fine-tuning») часто хорош, когда есть стабильная база данных, которую не нужно часто обновлять.  
- **Knowledge Graph** полезен в сильно формализованных предметных областях (например, юридическая логика, сложные B2B‑процессы).  
- **Символьные системы** незаменимы там, где нужна 100% прозрачность принятия решений и лаконичные бизнес-/юридические правила.  
- **Длинный контекст** подойдёт для небольших сборников материалов, когда хочется «всё загрузить напрямую».

**Для клиента** (чатбот на Magento) чаще всего выбирают RAG или fine-tuning (либо их гибрид).  
**Для юридической системы** (п. 1) помимо RAG могут оказаться полезны экспертные правила (rule-based) или Knowledge Graph — всё зависит от того, насколько формализована правовая база и требуется ли объясняемость решений.