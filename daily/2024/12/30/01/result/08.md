1)  I am currently developing a similar chatbot (but for lawyers). 
The best solution for such a chatbot in the fall of 2024 is to bridge a general-purpose LLM (a Large Language Model; the best ones currently are from OpenAI and Antropic) with domain-specific knowledge.
In your case (B2B customer support) I would achieve this with a combination of 2 technologies:
2.1) RAG (Retrieval Augmented Generation):
- https://en.wikipedia.org/wiki/Retrieval-augmented-generation
- https://help.openai.com/en/articles/8868588
2.2) «Function calling» (OpenAI's term) / «Tools» (Anthropic's term):
- https://platform.openai.com/docs/guides/function-calling
- https://docs.anthropic.com/en/docs/build-with-claude/tool-use
3) RAG would be like a mini personal Google for your business, but it will serve the chatbot instead of humans, and it will have access to some of your company's data to serve the chatbot.
Like Google, RAG indexes data in advance.
RAG is good for its versatility: it can index everything uniformly (like Google) and does not require programming to understand a specific document.  
RAG is most effective for data that remains stable between scheduled indexing cycles (e.g. a business day):  
*) Specifications of your products  
*) Legal documents: your contracts with business partners
*) A knowledge base of answers to typical user questions (FAQ)  
4) The «Function calling» / «Tools» technology will perform 2 essential tasks:  
4.1) Like RAG, it will provide the chatbot with data, but in a different way and at a different stage:  
4.1.1)  «Function calling» / «Tools» is able to retrieve data in more complex ways than RAG, and from more complicated sources, because each retrieval scenario is individually programmed by a developer (me).   
In your case, I would program the «Function calling» / «Tools» technology to provide the chatbot with data:  
*) from the database of your online store (Magento)  
*) from other IT systems used by your company  
*) from the IT systems of your partners (if they provide a suitable interface for integration)  
4.1.2) Unlike RAG, «Function calling» / «Tools» retrieves data in real-time (when responding to a specific user request).
So this technology is essential for data that would change rapidly:   
*) Status of an order 
*) Stock level of a product  
*) Price of a product in a specific context (this is especially important in B2B)  
4.2) «Function calling» / «Tools» can also perform predefined actions when users request them through the chatbot.  
In your case, I would use this technology to handle all the actions that your customers currently perform through the Magento storefront or their accounts in Magento:  
*) Accept a new order from a customer and register it in Magento  
*) Register a new shipping address, edit an existing one
*) Edit an order 
*) Repeat an order  
*) Accept a review of a product or a service
5) How would I implement RAG in your case?
5.1) I would document your business knowledge in the formats commonly used for LLMs today: Markdown and XML (and possibly enrich them with PDFs and images).
5.2) Then, I would convert the data from the previous step into embeddings:
- https://en.wikipedia.org/wiki/Word_embedding
- https://platform.openai.com/docs/guides/embeddings
5.3) Then, I would store the embeddings in a vector database: https://en.wikipedia.org/wiki/Vector_database
5.4) When a customer asks your chatbot something, the chatbot will retrieve the most relevant documents from the vector database to augment the customer's query.
5.5) Then, the chatbot will feed the retrieved data into the underlying LLM.
5.6) Finally, the underlying LLM will generate output based on both the customer's query and the retrieved documents from the vector database.
6) How would I implement «Function calling» / «Tools» in your case?
6.1) I would identify the functions (API methods) that the chatbot would call within your Magento environment.
6.2) Then, I will instruct the chatbot when to call each function.
For example: «If the user wants to place an order, call the `placeOrder` function with these parameters. Do not generate a customer-facing response at this step—just generate the JSON function call».
6.3) The chatbot will then pass the request to the underlying LLM.
6.4) When the LLM returns the JSON, the chatbot will pass the JSON to my Magento module (installed in your store).
6.5) My Magento module will trigger the appropriate Magento functionality and then send the response from Magento back to the chatbot.
6.4) Finally, the chatbot will incorporate  the response from my Magento module into a customer-friendly response (e.g., «Your order `ORD-1234` has been placed»).
---
I have done 532 Magento projects here on Upwork.
My GitHub profiles: https://github.com/dmitrii-fediuk and https://github.com/mage2pro
My websites: https://mage2.pro?order=views and https://df.tips?order=views